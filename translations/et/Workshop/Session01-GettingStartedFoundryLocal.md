<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "8c30436578b1bd604c48233ecdd39701",
  "translation_date": "2025-11-12T01:02:26+00:00",
  "source_file": "Workshop/Session01-GettingStartedFoundryLocal.md",
  "language_code": "et"
}
-->
# Sessioon 1: Alustamine Foundry Localiga

## Kokkuv√µte

√ïpi paigaldama, seadistama ja k√§ivitama oma esimesi AI-mudeleid, kasutades Microsoft Foundry Locali. See praktiline sessioon pakub samm-sammulist juhendit lokaalse inferentsi kohta, alates paigaldamisest kuni esimese vestlusrakenduse loomiseni, kasutades mudeleid nagu Phi-4, Qwen ja DeepSeek.

## √ïpieesm√§rgid

Sessiooni l√µpuks oskad:

- **Paigaldada ja seadistada**: Seadista Foundry Local ja kontrolli paigaldamise √µigsust
- **Valdada CLI operatsioone**: Kasuta Foundry Local CLI-d mudelite haldamiseks ja juurutamiseks
- **K√§ivitada oma esimese mudeli**: Juuruta ja suhtle lokaalse AI-mudeliga
- **Luua vestlusrakenduse**: Koosta lihtne vestlusrakendus, kasutades Foundry Local Python SDK-d
- **M√µista lokaalse AI olemust**: Saada √ºlevaade lokaalsest inferentsist ja mudelite haldamisest

## Eeltingimused

### S√ºsteemin√µuded

- **Windows**: Windows 11 (22H2 v√µi uuem) V√ïI **macOS**: macOS 11+ (piiratud tugi)
- **RAM**: Minimaalselt 8GB, soovitatavalt 16GB+
- **Salvestusruum**: V√§hemalt 10GB vaba ruumi mudelite jaoks
- **Python**: Paigaldatud versioon 3.10 v√µi uuem
- **Administraatori√µigused**: Vajalikud paigaldamiseks

### Arenduskeskkond

- Visual Studio Code koos Python laiendusega (soovitatav)
- Juurdep√§√§s k√§sureale (PowerShell Windowsis, Terminal macOS-is)
- Git repositooriumide kloonimiseks (valikuline)

## T√∂√∂tuba (30 minutit)

### Samm 1: Foundry Locali paigaldamine (5 minutit)

#### Paigaldamine Windowsis

Paigalda Foundry Local, kasutades Windowsi pakihaldurit:

```powershell
# Install via winget (recommended)
winget install Microsoft.FoundryLocal
```

Alternatiiv: Laadi otse alla [Microsoft Learnist](https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/install)

#### Paigaldamine macOS-is (piiratud tugi)

> [!NOTE] 
> macOS-i tugi on hetkel eelvaates. Kontrolli ametlikku dokumentatsiooni, et saada v√§rskeimat infot.

Kui saadaval, paigalda Homebrew abil:

```bash
# If Homebrew formula is available
brew update
brew install foundry-local

# Or manual download (check official docs for latest)
curl -L -o foundry-local.tar.gz "https://download.microsoft.com/foundry-local/latest/macos/foundry-local.tar.gz"
tar -xzf foundry-local.tar.gz
sudo ./install.sh
```

**Alternatiiv macOS-i kasutajatele:**
- Kasuta Windows 11 virtuaalmasinat (Parallels/UTM) ja j√§rgi Windowsi juhiseid
- K√§ivita konteineris, kui saadaval, ja konfigureeri `FOUNDRY_LOCAL_ENDPOINT`

### Samm 2: Paigaldamise kontrollimine (3 minutit)

P√§rast paigaldamist taask√§ivita terminal ja kontrolli, kas Foundry Local t√∂√∂tab:

```powershell
# Check if Foundry Local is installed correctly
foundry --version

# View available commands
foundry --help
```

Oodatav v√§ljund peaks n√§itama versiooni infot ja saadaval olevaid k√§ske.

### Samm 3: Python keskkonna seadistamine (5 minutit)

Loo selle t√∂√∂toa jaoks eraldi Python keskkond:

**Windows:**
```powershell
# Create virtual environment
py -m venv .venv

# Activate environment
.\.venv\Scripts\Activate.ps1

# Upgrade pip and install dependencies
python -m pip install --upgrade pip
pip install foundry-local-sdk openai
```

**macOS/Linux:**
```bash
# Create virtual environment
python3 -m venv .venv

# Activate environment
source .venv/bin/activate

# Upgrade pip and install dependencies
python -m pip install --upgrade pip
pip install foundry-local-sdk openai
```

### Samm 4: K√§ivita oma esimene mudel (7 minutit)

N√º√ºd k√§ivitame oma esimese AI-mudeli lokaalselt!

#### Alusta Phi-4 Mini mudeliga (soovitatav esimene mudel)

```powershell
# Download and start phi-4-mini (lightweight, fast)
foundry model run phi-4-mini

# Test the model with a simple prompt
foundry model run phi-4-mini --prompt "Hello, introduce yourself in one sentence"
```

> [!TIP]
> See k√§sk laadib mudeli alla (esmakordsel kasutamisel) ja k√§ivitab Foundry Local teenuse automaatselt.

#### Kontrolli, mis t√∂√∂tab

```powershell
# List available models (shows downloaded models)
foundry model list

# Check service status
foundry service status

# See what models are cached locally
foundry cache list
```

#### Proovi erinevaid mudeleid

Kui phi-4-mini t√∂√∂tab, katseta teisi mudeleid:

```powershell
# Larger model with better capabilities
foundry model run gpt-oss-20b --prompt "Explain edge AI in simple terms"

# Fast, efficient model
foundry model run qwen2.5-0.5b --prompt "What are the benefits of local AI inference?"
```

### Samm 5: Loo oma esimene vestlusrakendus (10 minutit)

N√º√ºd loome Python rakenduse, mis kasutab just k√§ivitatud mudeleid.

#### Loo vestluse skript

Loo uus fail nimega `my_first_chat.py` (v√µi kasuta etteantud n√§idist):

```python
#!/usr/bin/env python3
"""
My First Foundry Local Chat Application
Using FoundryLocalManager for automatic service management
"""

import os
from foundry_local import FoundryLocalManager
from openai import OpenAI

def main():
    # Get model alias from environment or use default
    alias = os.getenv("FOUNDRY_LOCAL_ALIAS", "phi-4-mini")
    
    try:
        # Initialize Foundry Local Manager (auto-starts service, downloads model)
        manager = FoundryLocalManager(alias)
        
        # Create OpenAI client pointing to local endpoint
        client = OpenAI(
            base_url=manager.endpoint,
            api_key=manager.api_key or "not-needed"
        )
        
        # Get the actual model ID for this alias
        model_id = manager.get_model_info(alias).id
        
        print("ü§ñ Welcome to your first local AI chat!")
        print(f"ÔøΩ Using model: {alias} -> {model_id}")
        print(f"üåê Endpoint: {manager.endpoint}")
        print("ÔøΩüí° Type 'quit' to exit\n")
        
    except Exception as e:
        print(f"‚ùå Failed to initialize Foundry Local: {e}")
        print("üí° Make sure Foundry Local is installed: foundry --version")
        return
    
    while True:
        # Get user input
        user_message = input("You: ").strip()
        
        if user_message.lower() in ['quit', 'exit', 'bye']:
            print("üëã Goodbye!")
            break
            
        if not user_message:
            continue
            
        try:
            # Send message to local AI model
            response = client.chat.completions.create(
                model=model_id,
                messages=[
                    {"role": "system", "content": "You are a helpful AI assistant running locally."},
                    {"role": "user", "content": user_message}
                ],
                max_tokens=200,
                temperature=0.7
            )
            
            # Display the response
            ai_response = response.choices[0].message.content
            print(f"ü§ñ AI: {ai_response}\n")
            
        except Exception as e:
            print(f"‚ùå Error: {e}")
            print("üí° Check service status: foundry service status\n")

if __name__ == "__main__":
    main()
```

> [!TIP]
> **Seotud n√§ited**: T√§psemaks kasutamiseks vaata:
>
> - **Python n√§idis**: `Workshop/samples/session01/chat_bootstrap.py` - Sisaldab voogesituse vastuseid ja veak√§sitlust
> - **Jupyter Notebook**: `Workshop/notebooks/session01_chat_bootstrap.ipynb` - Interaktiivne versioon koos detailsete selgitustega

#### Testi oma vestlusrakendust

```powershell
# No need to manually start models - FoundryLocalManager handles this!
# Just run your chat application
python my_first_chat.py
```

Alternatiiv: Kasuta otse etteantud n√§idiseid

```powershell
# Try the complete sample with streaming support
cd Workshop/samples
python -m session01.chat_bootstrap "Your question here"
```

V√µi avasta interaktiivset m√§rkmikku
Ava Workshop/notebooks/session01_chat_bootstrap.ipynb VS Code'is

Proovi neid n√§itevestlusi:

- "Mis on Microsoft Foundry Local?"
- "Loetle 3 eelist AI-mudelite lokaalsel k√§itamisel"
- "Aita mul m√µista edge AI-d"

## Mida oled saavutanud

Palju √µnne! Oled edukalt:

1. ‚úÖ **Paigaldanud Foundry Locali** ja kontrollinud selle toimimist
2. ‚úÖ **K√§ivitanud oma esimese AI-mudeli** (phi-4-mini) lokaalselt
3. ‚úÖ **Testinud erinevaid mudeleid** k√§sureal
4. ‚úÖ **Loonud vestlusrakenduse**, mis √ºhendub sinu lokaalse AI-ga
5. ‚úÖ **Kogenud lokaalse AI inferentsi**, ilma pilveteenusteta

## Mis toimus

### Lokaalne AI inferents

- Sinu AI-mudelid t√∂√∂tavad t√§ielikult sinu arvutis
- Andmeid ei saadeta pilve
- Vastused genereeritakse lokaalselt, kasutades sinu CPU/GPU-d
- Privaatsus ja turvalisus on tagatud

### Mudelite haldamine

- `foundry model run` laadib ja k√§ivitab mudeleid
- **FoundryLocalManager SDK** haldab automaatselt teenuse k√§ivitamist ja mudelite laadimist
- Mudelid salvestatakse lokaalselt tulevaseks kasutamiseks
- Mitmeid mudeleid saab alla laadida, kuid tavaliselt t√∂√∂tab korraga √ºks
- Teenus haldab automaatselt mudelite eluts√ºklit

### SDK vs CLI l√§henemised

- **CLI l√§henemine**: Mudelite k√§sitsi haldamine `foundry model run <model>` abil
- **SDK l√§henemine**: Automaatne teenuse ja mudelite haldamine `FoundryLocalManager(alias)` abil
- **Soovitus**: Kasuta SDK-d rakenduste jaoks, CLI-d testimiseks ja uurimiseks

## Oluliste k√§skude viide

### P√µhilised CLI k√§sud

```powershell
# Installation & Setup
foundry --version              # Check installation
foundry --help                 # View all commands

# Model Management
foundry model list             # List available models
foundry model run <model>      # Download and start a model
foundry model run <model> --prompt "text"  # One-shot prompt
foundry cache list             # Show downloaded models

# Service Management
foundry service status         # Check if service is running
foundry service start          # Start the service manually
foundry service stop           # Stop the service
```

### Mudelisoovitused

- **phi-4-mini**: Parim algusmudel - kiire, kerge, hea kvaliteet
- **qwen2.5-0.5b**: Kiireim inferents, minimaalne m√§lukasutus
- **gpt-oss-20b**: K√µrgema kvaliteediga vastused, vajab rohkem ressursse
- **deepseek-coder-1.3b**: Optimeeritud programmeerimise ja koodiga seotud √ºlesannete jaoks

## T√µrkeotsing

### "Foundry k√§sku ei leitud"

**Lahendus:**

```powershell
# Restart your terminal after installation
# Or manually add to PATH (Windows)
$env:PATH += ";C:\Program Files\Microsoft\FoundryLocal"
```

### "Mudel ei laaditud"

**Lahendus:**

```powershell
# Check available system memory
foundry service status

# Try a smaller model first
foundry model run phi-4-mini

# Check disk space for model downloads
# Models are stored in: %USERPROFILE%\.foundry\models (Windows)
```

### "√úhendus localhostiga keelatud"

**Lahendus:**

```powershell
# Check if service is running
foundry service status

# Start service if needed
foundry service start

# Verify the port (default is 5273)
# Check for port conflicts with: netstat -an | findstr 5273
```

## J√§rgmised sammud

### Kohesed tegevused

1. **Katseta** erinevaid mudeleid ja k√ºsimusi
2. **Muuda** oma vestlusrakendust, et proovida erinevaid mudeleid
3. **Loo** oma k√ºsimused ja testi vastuseid
4. **Uuri** Sessiooni 2: RAG rakenduste loomine

### T√§iustatud √µppeprogramm

1. **Sessioon 2**: AI lahenduste loomine RAG-ga (Retrieval-Augmented Generation)
2. **Sessioon 3**: Erinevate avatud l√§htekoodiga mudelite v√µrdlemine
3. **Sessioon 4**: T√∂√∂tamine tipptasemel mudelitega
4. **Sessioon 5**: Multi-agent AI s√ºsteemide loomine

## Keskkonnamuutujad (valikuline)

T√§psemaks kasutamiseks saad m√§√§rata j√§rgmised keskkonnamuutujad:

| Muutuja | Eesm√§rk | N√§ide |
|---------|---------|-------|
| `FOUNDRY_LOCAL_ALIAS` | Vaikimisi kasutatav mudel | `phi-4-mini` |
| `FOUNDRY_LOCAL_ENDPOINT` | √úlekirjutatud endpoint URL | `http://localhost:5273/v1` |

Loo `.env` fail oma projekti kausta:
```
FOUNDRY_LOCAL_ALIAS=phi-4-mini
FOUNDRY_LOCAL_ENDPOINT=auto
```

## Lisamaterjalid

### Dokumentatsioon

- [Foundry Local Python SDK viide](https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/reference/reference-sdk?pivots=programming-language-python)
- [Foundry Local paigaldusjuhend](https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/install)
- [Mudelikataloog](https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/models)

### N√§idiskood

- **Sessioon01 Python n√§idis**: `Workshop/samples/session01/chat_bootstrap.py` - T√§ielik vestlusrakendus voogesitusega
- **Sessioon01 m√§rkmik**: `Workshop/notebooks/session01_chat_bootstrap.ipynb` - Interaktiivne √µpetus  
- [Moodul08 N√§idis 01](../Module08/samples/01/README.md) - REST vestluse kiirjuhend
- [Moodul08 N√§idis 02](../Module08/samples/02/README.md) - OpenAI SDK integratsioon
- [Moodul08 N√§idis 03](../Module08/samples/03/README.md) - Mudelite avastamine ja v√µrdlemine

### Kogukond

- [Foundry Local GitHub arutelud](https://github.com/microsoft/Foundry-Local/discussions)
- [Azure AI kogukond](https://techcommunity.microsoft.com/category/artificialintelligence)

---

**Sessiooni kestus**: 30 minutit praktilist t√∂√∂d + 15 minutit k√ºsimusi ja vastuseid  
**Raskusaste**: Algaja  
**Eeltingimused**: Windows 11/macOS 11+, Python 3.10+, Administraatori√µigused

## T√∂√∂tuba: N√§idissituatsioon

### Reaalne kontekst

**Situatsioon**: Ettev√µtte IT-tiim peab hindama seadmesisese AI-inferentsi kasutamist tundliku t√∂√∂tajate tagasiside t√∂√∂tlemiseks, ilma andmeid v√§listeenustesse saatmata.

**Sinu eesm√§rk**: N√§idata, et lokaalsed AI-mudelid suudavad pakkuda kvaliteetseid vastuseid alla sekundi pikkuse viivitusega, s√§ilitades samal ajal t√§ieliku andmete privaatsuse.

### Testk√ºsimused

Kasuta neid k√ºsimusi, et oma seadistust kontrollida:

```json
[
    "List two benefits of local inference.",
    "Summarize why keeping data on device improves privacy.",
    "Give one trade-off when choosing a small model over a large model."
]
```

### Edukuse kriteeriumid

- ‚úÖ K√µigile k√ºsimustele saadakse vastused alla 2 sekundi
- ‚úÖ √úhtegi andmeid ei saadeta sinu arvutist v√§lja
- ‚úÖ Vastused on asjakohased ja kasulikud
- ‚úÖ Sinu vestlusrakendus t√∂√∂tab sujuvalt

See valideerimine kinnitab, et sinu Foundry Local seadistus on valmis edasisteks t√∂√∂tubadeks Sessioonides 2-6.

---

<!-- CO-OP TRANSLATOR DISCLAIMER START -->
**Lahti√ºtlus**:  
See dokument on t√µlgitud AI t√µlketeenuse [Co-op Translator](https://github.com/Azure/co-op-translator) abil. Kuigi p√º√ºame tagada t√§psust, palume arvestada, et automaatsed t√µlked v√µivad sisaldada vigu v√µi ebat√§psusi. Algne dokument selle algses keeles tuleks pidada autoriteetseks allikaks. Olulise teabe puhul soovitame kasutada professionaalset inimt√µlget. Me ei vastuta arusaamatuste v√µi valesti t√µlgenduste eest, mis v√µivad tekkida selle t√µlke kasutamise t√µttu.
<!-- CO-OP TRANSLATOR DISCLAIMER END -->