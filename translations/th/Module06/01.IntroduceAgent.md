<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "44bc28c27b993c5fb988791b7a115705",
  "translation_date": "2025-10-30T12:55:29+00:00",
  "source_file": "Module06/01.IntroduceAgent.md",
  "language_code": "th"
}
-->
# à¸•à¸±à¸§à¹à¸—à¸™ AI à¹à¸¥à¸°à¹‚à¸¡à¹€à¸”à¸¥à¸ à¸²à¸©à¸²à¸‚à¸™à¸²à¸”à¹€à¸¥à¹‡à¸: à¸„à¸¹à¹ˆà¸¡à¸·à¸­à¸‰à¸šà¸±à¸šà¸ªà¸¡à¸šà¸¹à¸£à¸“à¹Œ

## à¸šà¸—à¸™à¸³

à¹ƒà¸™à¸šà¸—à¹€à¸£à¸µà¸¢à¸™à¸™à¸µà¹‰ à¹€à¸£à¸²à¸ˆà¸°à¸ªà¸³à¸£à¸§à¸ˆà¸•à¸±à¸§à¹à¸—à¸™ AI à¹à¸¥à¸°à¹‚à¸¡à¹€à¸”à¸¥à¸ à¸²à¸©à¸²à¸‚à¸™à¸²à¸”à¹€à¸¥à¹‡à¸ (SLMs) à¸£à¸§à¸¡à¸–à¸¶à¸‡à¸à¸¥à¸¢à¸¸à¸—à¸˜à¹Œà¸à¸²à¸£à¹ƒà¸Šà¹‰à¸‡à¸²à¸™à¸‚à¸±à¹‰à¸™à¸ªà¸¹à¸‡à¸ªà¸³à¸«à¸£à¸±à¸šà¸ªà¸ à¸²à¸žà¹à¸§à¸”à¸¥à¹‰à¸­à¸¡à¸à¸²à¸£à¸›à¸£à¸°à¸¡à¸§à¸¥à¸œà¸¥à¸—à¸µà¹ˆà¸‚à¸­à¸š à¹€à¸£à¸²à¸ˆà¸°à¸„à¸£à¸­à¸šà¸„à¸¥à¸¸à¸¡à¹à¸™à¸§à¸„à¸´à¸”à¸žà¸·à¹‰à¸™à¸à¸²à¸™à¸‚à¸­à¸‡ AI à¹à¸šà¸šà¸•à¸±à¸§à¹à¸—à¸™ à¹€à¸—à¸„à¸™à¸´à¸„à¸à¸²à¸£à¸›à¸£à¸±à¸šà¹à¸•à¹ˆà¸‡ SLM à¸à¸¥à¸¢à¸¸à¸—à¸˜à¹Œà¸à¸²à¸£à¹ƒà¸Šà¹‰à¸‡à¸²à¸™à¸ˆà¸£à¸´à¸‡à¸ªà¸³à¸«à¸£à¸±à¸šà¸­à¸¸à¸›à¸à¸£à¸“à¹Œà¸—à¸µà¹ˆà¸¡à¸µà¸—à¸£à¸±à¸žà¸¢à¸²à¸à¸£à¸ˆà¸³à¸à¸±à¸” à¹à¸¥à¸° Microsoft Agent Framework à¸ªà¸³à¸«à¸£à¸±à¸šà¸à¸²à¸£à¸ªà¸£à¹‰à¸²à¸‡à¸£à¸°à¸šà¸šà¸•à¸±à¸§à¹à¸—à¸™à¸—à¸µà¹ˆà¸žà¸£à¹‰à¸­à¸¡à¹ƒà¸Šà¹‰à¸‡à¸²à¸™à¹ƒà¸™à¸£à¸°à¸”à¸±à¸šà¸à¸²à¸£à¸œà¸¥à¸´à¸•

à¸ à¸¹à¸¡à¸´à¸—à¸±à¸¨à¸™à¹Œà¸‚à¸­à¸‡à¸›à¸±à¸à¸à¸²à¸›à¸£à¸°à¸”à¸´à¸©à¸à¹Œà¸à¸³à¸¥à¸±à¸‡à¹€à¸›à¸¥à¸µà¹ˆà¸¢à¸™à¹à¸›à¸¥à¸‡à¸­à¸¢à¹ˆà¸²à¸‡à¸¡à¸µà¸™à¸±à¸¢à¸ªà¸³à¸„à¸±à¸à¹ƒà¸™à¸›à¸µ 2025 à¹ƒà¸™à¸‚à¸“à¸°à¸—à¸µà¹ˆà¸›à¸µ 2023 à¹€à¸›à¹‡à¸™à¸›à¸µà¸‚à¸­à¸‡à¹à¸Šà¸—à¸šà¸­à¸— à¹à¸¥à¸°à¸›à¸µ 2024 à¸¡à¸µà¸à¸²à¸£à¹€à¸•à¸´à¸šà¹‚à¸•à¸‚à¸­à¸‡à¹‚à¸„à¹„à¸žà¸¥à¸­à¸• à¸›à¸µ 2025 à¹€à¸›à¹‡à¸™à¸›à¸µà¸‚à¸­à¸‡à¸•à¸±à¸§à¹à¸—à¸™ AI â€” à¸£à¸°à¸šà¸šà¸­à¸±à¸ˆà¸‰à¸£à¸´à¸¢à¸°à¸—à¸µà¹ˆà¸„à¸´à¸” à¸§à¸²à¸‡à¹à¸œà¸™ à¹ƒà¸Šà¹‰à¹€à¸„à¸£à¸·à¹ˆà¸­à¸‡à¸¡à¸·à¸­ à¹à¸¥à¸°à¸”à¸³à¹€à¸™à¸´à¸™à¸à¸²à¸£à¸‡à¸²à¸™à¸”à¹‰à¸§à¸¢à¸à¸²à¸£à¸›à¹‰à¸­à¸™à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸ˆà¸²à¸à¸¡à¸™à¸¸à¸©à¸¢à¹Œà¸™à¹‰à¸­à¸¢à¸—à¸µà¹ˆà¸ªà¸¸à¸” à¹‚à¸”à¸¢à¹„à¸”à¹‰à¸£à¸±à¸šà¸žà¸¥à¸±à¸‡à¸ˆà¸²à¸à¹‚à¸¡à¹€à¸”à¸¥à¸ à¸²à¸©à¸²à¸‚à¸™à¸²à¸”à¹€à¸¥à¹‡à¸à¸—à¸µà¹ˆà¸¡à¸µà¸›à¸£à¸°à¸ªà¸´à¸—à¸˜à¸´à¸ à¸²à¸žà¸¡à¸²à¸à¸‚à¸¶à¹‰à¸™ Microsoft Agent Framework à¸à¸¥à¸²à¸¢à¹€à¸›à¹‡à¸™à¹‚à¸‹à¸¥à¸¹à¸Šà¸±à¸™à¸Šà¸±à¹‰à¸™à¸™à¸³à¸ªà¸³à¸«à¸£à¸±à¸šà¸à¸²à¸£à¸ªà¸£à¹‰à¸²à¸‡à¸£à¸°à¸šà¸šà¸­à¸±à¸ˆà¸‰à¸£à¸´à¸¢à¸°à¹€à¸«à¸¥à¹ˆà¸²à¸™à¸µà¹‰à¸”à¹‰à¸§à¸¢à¸„à¸§à¸²à¸¡à¸ªà¸²à¸¡à¸²à¸£à¸–à¹à¸šà¸šà¸­à¸­à¸Ÿà¹„à¸¥à¸™à¹Œà¸—à¸µà¹ˆà¸‚à¸­à¸š

## à¸§à¸±à¸•à¸–à¸¸à¸›à¸£à¸°à¸ªà¸‡à¸„à¹Œà¸à¸²à¸£à¹€à¸£à¸µà¸¢à¸™à¸£à¸¹à¹‰

à¹€à¸¡à¸·à¹ˆà¸­à¸ˆà¸šà¸šà¸—à¹€à¸£à¸µà¸¢à¸™à¸™à¸µà¹‰ à¸„à¸¸à¸“à¸ˆà¸°à¸ªà¸²à¸¡à¸²à¸£à¸–:

- ðŸ¤– à¹€à¸‚à¹‰à¸²à¹ƒà¸ˆà¹à¸™à¸§à¸„à¸´à¸”à¸žà¸·à¹‰à¸™à¸à¸²à¸™à¸‚à¸­à¸‡à¸•à¸±à¸§à¹à¸—à¸™ AI à¹à¸¥à¸°à¸£à¸°à¸šà¸šà¸•à¸±à¸§à¹à¸—à¸™
- ðŸ”¬ à¸£à¸°à¸šà¸¸à¸‚à¹‰à¸­à¸”à¸µà¸‚à¸­à¸‡à¹‚à¸¡à¹€à¸”à¸¥à¸ à¸²à¸©à¸²à¸‚à¸™à¸²à¸”à¹€à¸¥à¹‡à¸à¹€à¸¡à¸·à¹ˆà¸­à¹€à¸—à¸µà¸¢à¸šà¸à¸±à¸šà¹‚à¸¡à¹€à¸”à¸¥à¸ à¸²à¸©à¸²à¸‚à¸™à¸²à¸”à¹ƒà¸«à¸à¹ˆà¹ƒà¸™à¹à¸­à¸›à¸žà¸¥à¸´à¹€à¸„à¸Šà¸±à¸™à¸•à¸±à¸§à¹à¸—à¸™
- ðŸš€ à¹€à¸£à¸µà¸¢à¸™à¸£à¸¹à¹‰à¸à¸¥à¸¢à¸¸à¸—à¸˜à¹Œà¸à¸²à¸£à¹ƒà¸Šà¹‰à¸‡à¸²à¸™ SLM à¸‚à¸±à¹‰à¸™à¸ªà¸¹à¸‡à¸ªà¸³à¸«à¸£à¸±à¸šà¸ªà¸ à¸²à¸žà¹à¸§à¸”à¸¥à¹‰à¸­à¸¡à¸à¸²à¸£à¸›à¸£à¸°à¸¡à¸§à¸¥à¸œà¸¥à¸—à¸µà¹ˆà¸‚à¸­à¸š
- ðŸ“± à¹ƒà¸Šà¹‰à¸‡à¸²à¸™à¸•à¸±à¸§à¹à¸—à¸™à¸—à¸µà¹ˆà¸‚à¸±à¸šà¹€à¸„à¸¥à¸·à¹ˆà¸­à¸™à¸”à¹‰à¸§à¸¢ SLM à¸ªà¸³à¸«à¸£à¸±à¸šà¹à¸­à¸›à¸žà¸¥à¸´à¹€à¸„à¸Šà¸±à¸™à¹ƒà¸™à¹‚à¸¥à¸à¸ˆà¸£à¸´à¸‡
- ðŸ—ï¸ à¸ªà¸£à¹‰à¸²à¸‡à¸•à¸±à¸§à¹à¸—à¸™à¸—à¸µà¹ˆà¸žà¸£à¹‰à¸­à¸¡à¹ƒà¸Šà¹‰à¸‡à¸²à¸™à¹ƒà¸™à¸£à¸°à¸”à¸±à¸šà¸à¸²à¸£à¸œà¸¥à¸´à¸•à¹‚à¸”à¸¢à¹ƒà¸Šà¹‰ Microsoft Agent Framework
- ðŸŒ à¹ƒà¸Šà¹‰à¸‡à¸²à¸™à¸•à¸±à¸§à¹à¸—à¸™à¹à¸šà¸šà¸­à¸­à¸Ÿà¹„à¸¥à¸™à¹Œà¸—à¸µà¹ˆà¸‚à¸­à¸šà¸”à¹‰à¸§à¸¢à¸à¸²à¸£à¸œà¸ªà¸²à¸™à¸£à¸§à¸¡ LLM à¹à¸¥à¸° SLM à¹ƒà¸™à¸žà¸·à¹‰à¸™à¸—à¸µà¹ˆ
- ðŸ”§ à¸œà¸ªà¸²à¸™à¸£à¸§à¸¡ Microsoft Agent Framework à¸à¸±à¸š Foundry Local à¸ªà¸³à¸«à¸£à¸±à¸šà¸à¸²à¸£à¹ƒà¸Šà¹‰à¸‡à¸²à¸™à¸—à¸µà¹ˆà¸‚à¸­à¸š

## à¸à¸²à¸£à¸—à¸³à¸„à¸§à¸²à¸¡à¹€à¸‚à¹‰à¸²à¹ƒà¸ˆà¸•à¸±à¸§à¹à¸—à¸™ AI: à¸žà¸·à¹‰à¸™à¸à¸²à¸™à¹à¸¥à¸°à¸à¸²à¸£à¸ˆà¸³à¹à¸™à¸à¸›à¸£à¸°à¹€à¸ à¸—

### à¸„à¸³à¸ˆà¸³à¸à¸±à¸”à¸„à¸§à¸²à¸¡à¹à¸¥à¸°à¹à¸™à¸§à¸„à¸´à¸”à¸«à¸¥à¸±à¸

à¸•à¸±à¸§à¹à¸—à¸™à¸›à¸±à¸à¸à¸²à¸›à¸£à¸°à¸”à¸´à¸©à¸à¹Œ (AI) à¸«à¸¡à¸²à¸¢à¸–à¸¶à¸‡à¸£à¸°à¸šà¸šà¸«à¸£à¸·à¸­à¹‚à¸›à¸£à¹à¸à¸£à¸¡à¸—à¸µà¹ˆà¸ªà¸²à¸¡à¸²à¸£à¸–à¸”à¸³à¹€à¸™à¸´à¸™à¸à¸²à¸£à¸‡à¸²à¸™à¹„à¸”à¹‰à¹‚à¸”à¸¢à¸­à¸±à¸•à¹‚à¸™à¸¡à¸±à¸•à¸´à¹ƒà¸™à¸™à¸²à¸¡à¸‚à¸­à¸‡à¸œà¸¹à¹‰à¹ƒà¸Šà¹‰à¸«à¸£à¸·à¸­à¸£à¸°à¸šà¸šà¸­à¸·à¹ˆà¸™ à¹‚à¸”à¸¢à¸à¸²à¸£à¸­à¸­à¸à¹à¸šà¸šà¸à¸£à¸°à¸šà¸§à¸™à¸à¸²à¸£à¸—à¸³à¸‡à¸²à¸™à¹à¸¥à¸°à¹ƒà¸Šà¹‰à¹€à¸„à¸£à¸·à¹ˆà¸­à¸‡à¸¡à¸·à¸­à¸—à¸µà¹ˆà¸¡à¸µà¸­à¸¢à¸¹à¹ˆ à¹à¸•à¸à¸•à¹ˆà¸²à¸‡à¸ˆà¸²à¸ AI à¹à¸šà¸šà¸”à¸±à¹‰à¸‡à¹€à¸”à¸´à¸¡à¸—à¸µà¹ˆà¹€à¸žà¸µà¸¢à¸‡à¸•à¸­à¸šà¸„à¸³à¸–à¸²à¸¡ à¸•à¸±à¸§à¹à¸—à¸™à¸ªà¸²à¸¡à¸²à¸£à¸–à¸”à¸³à¹€à¸™à¸´à¸™à¸à¸²à¸£à¹„à¸”à¹‰à¸­à¸¢à¹ˆà¸²à¸‡à¸­à¸´à¸ªà¸£à¸°à¹€à¸žà¸·à¹ˆà¸­à¸šà¸£à¸£à¸¥à¸¸à¹€à¸›à¹‰à¸²à¸«à¸¡à¸²à¸¢

### à¸à¸£à¸­à¸šà¸à¸²à¸£à¸ˆà¸³à¹à¸™à¸à¸›à¸£à¸°à¹€à¸ à¸—à¸•à¸±à¸§à¹à¸—à¸™

à¸à¸²à¸£à¸—à¸³à¸„à¸§à¸²à¸¡à¹€à¸‚à¹‰à¸²à¹ƒà¸ˆà¸‚à¸­à¸šà¹€à¸‚à¸•à¸‚à¸­à¸‡à¸•à¸±à¸§à¹à¸—à¸™à¸Šà¹ˆà¸§à¸¢à¹ƒà¸™à¸à¸²à¸£à¹€à¸¥à¸·à¸­à¸à¸›à¸£à¸°à¹€à¸ à¸—à¸•à¸±à¸§à¹à¸—à¸™à¸—à¸µà¹ˆà¹€à¸«à¸¡à¸²à¸°à¸ªà¸¡à¸ªà¸³à¸«à¸£à¸±à¸šà¸ªà¸–à¸²à¸™à¸à¸²à¸£à¸“à¹Œà¸à¸²à¸£à¸›à¸£à¸°à¸¡à¸§à¸¥à¸œà¸¥à¸•à¹ˆà¸²à¸‡à¹†:

- **ðŸ”¬ à¸•à¸±à¸§à¹à¸—à¸™à¹à¸šà¸šà¸ªà¸°à¸—à¹‰à¸­à¸™à¸‡à¹ˆà¸²à¸¢**: à¸£à¸°à¸šà¸šà¸—à¸µà¹ˆà¹ƒà¸Šà¹‰à¸à¸Žà¸—à¸µà¹ˆà¸•à¸­à¸šà¸ªà¸™à¸­à¸‡à¸•à¹ˆà¸­à¸à¸²à¸£à¸£à¸±à¸šà¸£à¸¹à¹‰à¸—à¸±à¸™à¸—à¸µ (à¹€à¸„à¸£à¸·à¹ˆà¸­à¸‡à¸„à¸§à¸šà¸„à¸¸à¸¡à¸­à¸¸à¸“à¸«à¸ à¸¹à¸¡à¸´, à¸£à¸°à¸šà¸šà¸­à¸±à¸•à¹‚à¸™à¸¡à¸±à¸•à¸´à¸žà¸·à¹‰à¸™à¸à¸²à¸™)
- **ðŸ“± à¸•à¸±à¸§à¹à¸—à¸™à¹à¸šà¸šà¹ƒà¸Šà¹‰à¹‚à¸¡à¹€à¸”à¸¥**: à¸£à¸°à¸šà¸šà¸—à¸µà¹ˆà¸£à¸±à¸à¸©à¸²à¸ªà¸–à¸²à¸™à¸°à¸ à¸²à¸¢à¹ƒà¸™à¹à¸¥à¸°à¸„à¸§à¸²à¸¡à¸ˆà¸³ (à¸«à¸¸à¹ˆà¸™à¸¢à¸™à¸•à¹Œà¸”à¸¹à¸”à¸à¸¸à¹ˆà¸™, à¸£à¸°à¸šà¸šà¸™à¸³à¸—à¸²à¸‡)
- **âš–ï¸ à¸•à¸±à¸§à¹à¸—à¸™à¸—à¸µà¹ˆà¸¡à¸¸à¹ˆà¸‡à¹€à¸›à¹‰à¸²à¸«à¸¡à¸²à¸¢**: à¸£à¸°à¸šà¸šà¸—à¸µà¹ˆà¸§à¸²à¸‡à¹à¸œà¸™à¹à¸¥à¸°à¸”à¸³à¹€à¸™à¸´à¸™à¸à¸²à¸£à¸¥à¸³à¸”à¸±à¸šà¹€à¸žà¸·à¹ˆà¸­à¸šà¸£à¸£à¸¥à¸¸à¸§à¸±à¸•à¸–à¸¸à¸›à¸£à¸°à¸ªà¸‡à¸„à¹Œ (à¸•à¸±à¸§à¸§à¸²à¸‡à¹à¸œà¸™à¹€à¸ªà¹‰à¸™à¸—à¸²à¸‡, à¸•à¸±à¸§à¸ˆà¸±à¸”à¸•à¸²à¸£à¸²à¸‡à¸‡à¸²à¸™)
- **ðŸ§  à¸•à¸±à¸§à¹à¸—à¸™à¸—à¸µà¹ˆà¹€à¸£à¸µà¸¢à¸™à¸£à¸¹à¹‰à¹„à¸”à¹‰**: à¸£à¸°à¸šà¸šà¸—à¸µà¹ˆà¸›à¸£à¸±à¸šà¸›à¸£à¸¸à¸‡à¸›à¸£à¸°à¸ªà¸´à¸—à¸˜à¸´à¸ à¸²à¸žà¹€à¸¡à¸·à¹ˆà¸­à¹€à¸§à¸¥à¸²à¸œà¹ˆà¸²à¸™à¹„à¸› (à¸£à¸°à¸šà¸šà¹à¸™à¸°à¸™à¸³, à¸œà¸¹à¹‰à¸Šà¹ˆà¸§à¸¢à¸ªà¹ˆà¸§à¸™à¸•à¸±à¸§)

### à¸‚à¹‰à¸­à¸”à¸µà¸ªà¸³à¸„à¸±à¸à¸‚à¸­à¸‡à¸•à¸±à¸§à¹à¸—à¸™ AI

à¸•à¸±à¸§à¹à¸—à¸™ AI à¸¡à¸µà¸‚à¹‰à¸­à¸”à¸µà¸«à¸¥à¸²à¸¢à¸›à¸£à¸°à¸à¸²à¸£à¸—à¸µà¹ˆà¸—à¸³à¹ƒà¸«à¹‰à¹€à¸«à¸¡à¸²à¸°à¸ªà¸³à¸«à¸£à¸±à¸šà¹à¸­à¸›à¸žà¸¥à¸´à¹€à¸„à¸Šà¸±à¸™à¸à¸²à¸£à¸›à¸£à¸°à¸¡à¸§à¸¥à¸œà¸¥à¸—à¸µà¹ˆà¸‚à¸­à¸š:

**à¸„à¸§à¸²à¸¡à¹€à¸›à¹‡à¸™à¸­à¸´à¸ªà¸£à¸°à¹ƒà¸™à¸à¸²à¸£à¸”à¸³à¹€à¸™à¸´à¸™à¸‡à¸²à¸™**: à¸•à¸±à¸§à¹à¸—à¸™à¸ªà¸²à¸¡à¸²à¸£à¸–à¸”à¸³à¹€à¸™à¸´à¸™à¸à¸²à¸£à¸‡à¸²à¸™à¹„à¸”à¹‰à¹‚à¸”à¸¢à¸­à¸´à¸ªà¸£à¸°à¹‚à¸”à¸¢à¹„à¸¡à¹ˆà¸•à¹‰à¸­à¸‡à¸¡à¸µà¸à¸²à¸£à¸”à¸¹à¹à¸¥à¸ˆà¸²à¸à¸¡à¸™à¸¸à¸©à¸¢à¹Œà¸­à¸¢à¹ˆà¸²à¸‡à¸•à¹ˆà¸­à¹€à¸™à¸·à¹ˆà¸­à¸‡ à¸—à¸³à¹ƒà¸«à¹‰à¹€à¸«à¸¡à¸²à¸°à¸ªà¸³à¸«à¸£à¸±à¸šà¹à¸­à¸›à¸žà¸¥à¸´à¹€à¸„à¸Šà¸±à¸™à¹à¸šà¸šà¹€à¸£à¸µà¸¢à¸¥à¹„à¸—à¸¡à¹Œ à¸žà¸§à¸à¹€à¸‚à¸²à¸•à¹‰à¸­à¸‡à¸à¸²à¸£à¸à¸²à¸£à¸”à¸¹à¹à¸¥à¸™à¹‰à¸­à¸¢à¸—à¸µà¹ˆà¸ªà¸¸à¸”à¹ƒà¸™à¸‚à¸“à¸°à¸—à¸µà¹ˆà¸£à¸±à¸à¸©à¸²à¸žà¸¤à¸•à¸´à¸à¸£à¸£à¸¡à¸—à¸µà¹ˆà¸›à¸£à¸±à¸šà¸•à¸±à¸§à¹„à¸”à¹‰ à¸—à¸³à¹ƒà¸«à¹‰à¸ªà¸²à¸¡à¸²à¸£à¸–à¹ƒà¸Šà¹‰à¸‡à¸²à¸™à¸šà¸™à¸­à¸¸à¸›à¸à¸£à¸“à¹Œà¸—à¸µà¹ˆà¸¡à¸µà¸—à¸£à¸±à¸žà¸¢à¸²à¸à¸£à¸ˆà¸³à¸à¸±à¸”à¹„à¸”à¹‰à¹‚à¸”à¸¢à¸¡à¸µà¸„à¹ˆà¸²à¹ƒà¸Šà¹‰à¸ˆà¹ˆà¸²à¸¢à¹ƒà¸™à¸à¸²à¸£à¸”à¸³à¹€à¸™à¸´à¸™à¸‡à¸²à¸™à¸¥à¸”à¸¥à¸‡

**à¸„à¸§à¸²à¸¡à¸¢à¸·à¸”à¸«à¸¢à¸¸à¹ˆà¸™à¹ƒà¸™à¸à¸²à¸£à¹ƒà¸Šà¹‰à¸‡à¸²à¸™**: à¸£à¸°à¸šà¸šà¹€à¸«à¸¥à¹ˆà¸²à¸™à¸µà¹‰à¸Šà¹ˆà¸§à¸¢à¹ƒà¸«à¹‰à¸ªà¸²à¸¡à¸²à¸£à¸–à¹ƒà¸Šà¹‰à¸‡à¸²à¸™ AI à¸šà¸™à¸­à¸¸à¸›à¸à¸£à¸“à¹Œà¹„à¸”à¹‰à¹‚à¸”à¸¢à¹„à¸¡à¹ˆà¸•à¹‰à¸­à¸‡à¹€à¸Šà¸·à¹ˆà¸­à¸¡à¸•à¹ˆà¸­à¸­à¸´à¸™à¹€à¸—à¸­à¸£à¹Œà¹€à¸™à¹‡à¸• à¹€à¸žà¸´à¹ˆà¸¡à¸„à¸§à¸²à¸¡à¹€à¸›à¹‡à¸™à¸ªà¹ˆà¸§à¸™à¸•à¸±à¸§à¹à¸¥à¸°à¸„à¸§à¸²à¸¡à¸›à¸¥à¸­à¸”à¸ à¸±à¸¢à¸œà¹ˆà¸²à¸™à¸à¸²à¸£à¸›à¸£à¸°à¸¡à¸§à¸¥à¸œà¸¥à¹ƒà¸™à¸žà¸·à¹‰à¸™à¸—à¸µà¹ˆ à¸ªà¸²à¸¡à¸²à¸£à¸–à¸›à¸£à¸±à¸šà¹à¸•à¹ˆà¸‡à¸ªà¸³à¸«à¸£à¸±à¸šà¹à¸­à¸›à¸žà¸¥à¸´à¹€à¸„à¸Šà¸±à¸™à¹€à¸‰à¸žà¸²à¸°à¸”à¹‰à¸²à¸™ à¹à¸¥à¸°à¹€à¸«à¸¡à¸²à¸°à¸ªà¸³à¸«à¸£à¸±à¸šà¸ªà¸ à¸²à¸žà¹à¸§à¸”à¸¥à¹‰à¸­à¸¡à¸à¸²à¸£à¸›à¸£à¸°à¸¡à¸§à¸¥à¸œà¸¥à¸—à¸µà¹ˆà¸‚à¸­à¸šà¸•à¹ˆà¸²à¸‡à¹†

**à¸„à¸§à¸²à¸¡à¸„à¸¸à¹‰à¸¡à¸„à¹ˆà¸²**: à¸£à¸°à¸šà¸šà¸•à¸±à¸§à¹à¸—à¸™à¸¡à¸µà¸„à¹ˆà¸²à¹ƒà¸Šà¹‰à¸ˆà¹ˆà¸²à¸¢à¹ƒà¸™à¸à¸²à¸£à¹ƒà¸Šà¹‰à¸‡à¸²à¸™à¸—à¸µà¹ˆà¸„à¸¸à¹‰à¸¡à¸„à¹ˆà¸²à¸à¸§à¹ˆà¸²à¹‚à¸‹à¸¥à¸¹à¸Šà¸±à¸™à¸šà¸™à¸„à¸¥à¸²à¸§à¸”à¹Œ à¹‚à¸”à¸¢à¸¡à¸µà¸„à¹ˆà¸²à¹ƒà¸Šà¹‰à¸ˆà¹ˆà¸²à¸¢à¹ƒà¸™à¸à¸²à¸£à¸”à¸³à¹€à¸™à¸´à¸™à¸‡à¸²à¸™à¸¥à¸”à¸¥à¸‡à¹à¸¥à¸°à¸„à¸§à¸²à¸¡à¸•à¹‰à¸­à¸‡à¸à¸²à¸£à¹à¸šà¸™à¸”à¹Œà¸§à¸´à¸”à¸—à¹Œà¸•à¹ˆà¸³à¸ªà¸³à¸«à¸£à¸±à¸šà¹à¸­à¸›à¸žà¸¥à¸´à¹€à¸„à¸Šà¸±à¸™à¸—à¸µà¹ˆà¸‚à¸­à¸š

## à¸à¸¥à¸¢à¸¸à¸—à¸˜à¹Œà¹‚à¸¡à¹€à¸”à¸¥à¸ à¸²à¸©à¸²à¸‚à¸™à¸²à¸”à¹€à¸¥à¹‡à¸à¸‚à¸±à¹‰à¸™à¸ªà¸¹à¸‡

### à¸žà¸·à¹‰à¸™à¸à¸²à¸™à¸‚à¸­à¸‡ SLM (Small Language Model)

à¹‚à¸¡à¹€à¸”à¸¥à¸ à¸²à¸©à¸²à¸‚à¸™à¸²à¸”à¹€à¸¥à¹‡à¸ (SLM) à¸„à¸·à¸­à¹‚à¸¡à¹€à¸”à¸¥à¸ à¸²à¸©à¸²à¸—à¸µà¹ˆà¸ªà¸²à¸¡à¸²à¸£à¸–à¹ƒà¸Šà¹‰à¸‡à¸²à¸™à¸šà¸™à¸­à¸¸à¸›à¸à¸£à¸“à¹Œà¸­à¸´à¹€à¸¥à¹‡à¸à¸—à¸£à¸­à¸™à¸´à¸à¸ªà¹Œà¸—à¸±à¹ˆà¸§à¹„à¸›à¹à¸¥à¸°à¸”à¸³à¹€à¸™à¸´à¸™à¸à¸²à¸£à¸­à¸™à¸¸à¸¡à¸²à¸™à¸”à¹‰à¸§à¸¢à¸„à¸§à¸²à¸¡à¸«à¸™à¹ˆà¸§à¸‡à¸•à¹ˆà¸³à¸žà¸­à¸—à¸µà¹ˆà¸ˆà¸°à¹ƒà¸Šà¹‰à¸‡à¸²à¸™à¹„à¸”à¹‰à¸ˆà¸£à¸´à¸‡à¹€à¸¡à¸·à¹ˆà¸­à¹ƒà¸«à¹‰à¸šà¸£à¸´à¸à¸²à¸£à¸„à¸³à¸‚à¸­à¸‚à¸­à¸‡à¸•à¸±à¸§à¹à¸—à¸™à¸ªà¸³à¸«à¸£à¸±à¸šà¸œà¸¹à¹‰à¹ƒà¸Šà¹‰à¸«à¸™à¸¶à¹ˆà¸‡à¸„à¸™ à¹ƒà¸™à¸—à¸²à¸‡à¸›à¸à¸´à¸šà¸±à¸•à¸´ SLM à¸¡à¸±à¸à¹€à¸›à¹‡à¸™à¹‚à¸¡à¹€à¸”à¸¥à¸—à¸µà¹ˆà¸¡à¸µà¸žà¸²à¸£à¸²à¸¡à¸´à¹€à¸•à¸­à¸£à¹Œà¸™à¹‰à¸­à¸¢à¸à¸§à¹ˆà¸² 10 à¸žà¸±à¸™à¸¥à¹‰à¸²à¸™à¸•à¸±à¸§

**à¸„à¸¸à¸“à¸ªà¸¡à¸šà¸±à¸•à¸´à¸à¸²à¸£à¸„à¹‰à¸™à¸žà¸šà¸£à¸¹à¸›à¹à¸šà¸š**: SLM à¸¡à¸µà¸à¸²à¸£à¸ªà¸™à¸±à¸šà¸ªà¸™à¸¸à¸™à¸‚à¸±à¹‰à¸™à¸ªà¸¹à¸‡à¸ªà¸³à¸«à¸£à¸±à¸šà¸£à¸°à¸”à¸±à¸šà¸à¸²à¸£à¸šà¸µà¸šà¸­à¸±à¸”à¸•à¹ˆà¸²à¸‡à¹† à¸„à¸§à¸²à¸¡à¹€à¸‚à¹‰à¸²à¸à¸±à¸™à¹„à¸”à¹‰à¸‚à¹‰à¸²à¸¡à¹à¸žà¸¥à¸•à¸Ÿà¸­à¸£à¹Œà¸¡ à¸à¸²à¸£à¸›à¸£à¸±à¸šà¹à¸•à¹ˆà¸‡à¸›à¸£à¸°à¸ªà¸´à¸—à¸˜à¸´à¸ à¸²à¸žà¹à¸šà¸šà¹€à¸£à¸µà¸¢à¸¥à¹„à¸—à¸¡à¹Œ à¹à¸¥à¸°à¸„à¸§à¸²à¸¡à¸ªà¸²à¸¡à¸²à¸£à¸–à¹ƒà¸™à¸à¸²à¸£à¹ƒà¸Šà¹‰à¸‡à¸²à¸™à¸—à¸µà¹ˆà¸‚à¸­à¸š à¸œà¸¹à¹‰à¹ƒà¸Šà¹‰à¸ªà¸²à¸¡à¸²à¸£à¸–à¹€à¸‚à¹‰à¸²à¸–à¸¶à¸‡à¸„à¸§à¸²à¸¡à¹€à¸›à¹‡à¸™à¸ªà¹ˆà¸§à¸™à¸•à¸±à¸§à¸—à¸µà¹ˆà¹€à¸žà¸´à¹ˆà¸¡à¸‚à¸¶à¹‰à¸™à¸œà¹ˆà¸²à¸™à¸à¸²à¸£à¸›à¸£à¸°à¸¡à¸§à¸¥à¸œà¸¥à¹ƒà¸™à¸žà¸·à¹‰à¸™à¸—à¸µà¹ˆà¹à¸¥à¸°à¸à¸²à¸£à¸ªà¸™à¸±à¸šà¸ªà¸™à¸¸à¸™ WebGPU à¸ªà¸³à¸«à¸£à¸±à¸šà¸à¸²à¸£à¹ƒà¸Šà¹‰à¸‡à¸²à¸™à¹ƒà¸™à¹€à¸šà¸£à¸²à¸§à¹Œà¹€à¸‹à¸­à¸£à¹Œ

**à¸„à¸­à¸¥à¹€à¸¥à¸à¸Šà¸±à¸™à¸£à¸°à¸”à¸±à¸šà¸à¸²à¸£à¸šà¸µà¸šà¸­à¸±à¸”**: à¸£à¸¹à¸›à¹à¸šà¸š SLM à¸—à¸µà¹ˆà¹„à¸”à¹‰à¸£à¸±à¸šà¸„à¸§à¸²à¸¡à¸™à¸´à¸¢à¸¡ à¹„à¸”à¹‰à¹à¸à¹ˆ Q4_K_M à¸ªà¸³à¸«à¸£à¸±à¸šà¸à¸²à¸£à¸šà¸µà¸šà¸­à¸±à¸”à¸—à¸µà¹ˆà¸ªà¸¡à¸”à¸¸à¸¥à¹ƒà¸™à¹à¸­à¸›à¸žà¸¥à¸´à¹€à¸„à¸Šà¸±à¸™à¸¡à¸·à¸­à¸–à¸·à¸­ Q5_K_S series à¸ªà¸³à¸«à¸£à¸±à¸šà¸à¸²à¸£à¹ƒà¸Šà¹‰à¸‡à¸²à¸™à¸—à¸µà¹ˆà¸‚à¸­à¸šà¸—à¸µà¹ˆà¹€à¸™à¹‰à¸™à¸„à¸¸à¸“à¸ à¸²à¸ž Q8_0 à¸ªà¸³à¸«à¸£à¸±à¸šà¸„à¸§à¸²à¸¡à¹à¸¡à¹ˆà¸™à¸¢à¸³à¹ƒà¸à¸¥à¹‰à¹€à¸„à¸µà¸¢à¸‡à¸•à¹‰à¸™à¸‰à¸šà¸±à¸šà¸šà¸™à¸­à¸¸à¸›à¸à¸£à¸“à¹Œà¸—à¸µà¹ˆà¸‚à¸­à¸šà¸—à¸µà¹ˆà¸¡à¸µà¸›à¸£à¸°à¸ªà¸´à¸—à¸˜à¸´à¸ à¸²à¸ž à¹à¸¥à¸°à¸£à¸¹à¸›à¹à¸šà¸šà¸—à¸”à¸¥à¸­à¸‡à¹€à¸Šà¹ˆà¸™ Q2_K à¸ªà¸³à¸«à¸£à¸±à¸šà¸ªà¸–à¸²à¸™à¸à¸²à¸£à¸“à¹Œà¸—à¸µà¹ˆà¸¡à¸µà¸—à¸£à¸±à¸žà¸¢à¸²à¸à¸£à¸•à¹ˆà¸³à¸¡à¸²à¸

### GGUF (General GGML Universal Format) à¸ªà¸³à¸«à¸£à¸±à¸šà¸à¸²à¸£à¹ƒà¸Šà¹‰à¸‡à¸²à¸™ SLM

GGUF à¹€à¸›à¹‡à¸™à¸£à¸¹à¸›à¹à¸šà¸šà¸«à¸¥à¸±à¸à¸ªà¸³à¸«à¸£à¸±à¸šà¸à¸²à¸£à¹ƒà¸Šà¹‰à¸‡à¸²à¸™ SLM à¸—à¸µà¹ˆà¸šà¸µà¸šà¸­à¸±à¸”à¸šà¸™ CPU à¹à¸¥à¸°à¸­à¸¸à¸›à¸à¸£à¸“à¹Œà¸—à¸µà¹ˆà¸‚à¸­à¸š à¹‚à¸”à¸¢à¹€à¸‰à¸žà¸²à¸°à¸­à¸¢à¹ˆà¸²à¸‡à¸¢à¸´à¹ˆà¸‡à¸ªà¸³à¸«à¸£à¸±à¸šà¹à¸­à¸›à¸žà¸¥à¸´à¹€à¸„à¸Šà¸±à¸™à¸•à¸±à¸§à¹à¸—à¸™:

**à¸„à¸¸à¸“à¸ªà¸¡à¸šà¸±à¸•à¸´à¸—à¸µà¹ˆà¸›à¸£à¸±à¸šà¹à¸•à¹ˆà¸‡à¸ªà¸³à¸«à¸£à¸±à¸šà¸•à¸±à¸§à¹à¸—à¸™**: à¸£à¸¹à¸›à¹à¸šà¸šà¸™à¸µà¹‰à¹ƒà¸«à¹‰à¸—à¸£à¸±à¸žà¸¢à¸²à¸à¸£à¸—à¸µà¹ˆà¸„à¸£à¸­à¸šà¸„à¸¥à¸¸à¸¡à¸ªà¸³à¸«à¸£à¸±à¸šà¸à¸²à¸£à¹à¸›à¸¥à¸‡à¹à¸¥à¸°à¸à¸²à¸£à¹ƒà¸Šà¹‰à¸‡à¸²à¸™ SLM à¸žà¸£à¹‰à¸­à¸¡à¸à¸²à¸£à¸ªà¸™à¸±à¸šà¸ªà¸™à¸¸à¸™à¸‚à¸±à¹‰à¸™à¸ªà¸¹à¸‡à¸ªà¸³à¸«à¸£à¸±à¸šà¸à¸²à¸£à¹€à¸£à¸µà¸¢à¸à¹€à¸„à¸£à¸·à¹ˆà¸­à¸‡à¸¡à¸·à¸­ à¸à¸²à¸£à¸ªà¸£à¹‰à¸²à¸‡à¸œà¸¥à¸¥à¸±à¸žà¸˜à¹Œà¸—à¸µà¹ˆà¸¡à¸µà¹‚à¸„à¸£à¸‡à¸ªà¸£à¹‰à¸²à¸‡ à¹à¸¥à¸°à¸à¸²à¸£à¸ªà¸™à¸—à¸™à¸²à¹à¸šà¸šà¸«à¸¥à¸²à¸¢à¸£à¸­à¸š à¸„à¸§à¸²à¸¡à¹€à¸‚à¹‰à¸²à¸à¸±à¸™à¹„à¸”à¹‰à¸‚à¹‰à¸²à¸¡à¹à¸žà¸¥à¸•à¸Ÿà¸­à¸£à¹Œà¸¡à¸Šà¹ˆà¸§à¸¢à¹ƒà¸«à¹‰à¸žà¸¤à¸•à¸´à¸à¸£à¸£à¸¡à¸‚à¸­à¸‡à¸•à¸±à¸§à¹à¸—à¸™à¸ªà¸­à¸”à¸„à¸¥à¹‰à¸­à¸‡à¸à¸±à¸™à¹ƒà¸™à¸­à¸¸à¸›à¸à¸£à¸“à¹Œà¸—à¸µà¹ˆà¸‚à¸­à¸šà¸•à¹ˆà¸²à¸‡à¹†

**à¸à¸²à¸£à¸›à¸£à¸±à¸šà¹à¸•à¹ˆà¸‡à¸›à¸£à¸°à¸ªà¸´à¸—à¸˜à¸´à¸ à¸²à¸ž**: GGUF à¸Šà¹ˆà¸§à¸¢à¹ƒà¸«à¹‰à¸à¸²à¸£à¹ƒà¸Šà¹‰à¸‡à¸²à¸™à¸«à¸™à¹ˆà¸§à¸¢à¸„à¸§à¸²à¸¡à¸ˆà¸³à¸¡à¸µà¸›à¸£à¸°à¸ªà¸´à¸—à¸˜à¸´à¸ à¸²à¸žà¸ªà¸³à¸«à¸£à¸±à¸šà¸à¸£à¸°à¸šà¸§à¸™à¸à¸²à¸£à¸—à¸³à¸‡à¸²à¸™à¸‚à¸­à¸‡à¸•à¸±à¸§à¹à¸—à¸™ à¸ªà¸™à¸±à¸šà¸ªà¸™à¸¸à¸™à¸à¸²à¸£à¹‚à¸«à¸¥à¸”à¹‚à¸¡à¹€à¸”à¸¥à¹à¸šà¸šà¹„à¸”à¸™à¸²à¸¡à¸´à¸à¸ªà¸³à¸«à¸£à¸±à¸šà¸£à¸°à¸šà¸šà¸•à¸±à¸§à¹à¸—à¸™à¸«à¸¥à¸²à¸¢à¸•à¸±à¸§ à¹à¸¥à¸°à¹ƒà¸«à¹‰à¸à¸²à¸£à¸­à¸™à¸¸à¸¡à¸²à¸™à¸—à¸µà¹ˆà¸›à¸£à¸±à¸šà¹à¸•à¹ˆà¸‡à¸ªà¸³à¸«à¸£à¸±à¸šà¸à¸²à¸£à¹‚à¸•à¹‰à¸•à¸­à¸šà¸‚à¸­à¸‡à¸•à¸±à¸§à¹à¸—à¸™à¹à¸šà¸šà¹€à¸£à¸µà¸¢à¸¥à¹„à¸—à¸¡à¹Œ

### à¹€à¸Ÿà¸£à¸¡à¹€à¸§à¸´à¸£à¹Œà¸ SLM à¸—à¸µà¹ˆà¸›à¸£à¸±à¸šà¹à¸•à¹ˆà¸‡à¸ªà¸³à¸«à¸£à¸±à¸šà¸à¸²à¸£à¹ƒà¸Šà¹‰à¸‡à¸²à¸™à¸—à¸µà¹ˆà¸‚à¸­à¸š

#### à¸à¸²à¸£à¸›à¸£à¸±à¸šà¹à¸•à¹ˆà¸‡ Llama.cpp à¸ªà¸³à¸«à¸£à¸±à¸šà¸•à¸±à¸§à¹à¸—à¸™

Llama.cpp à¸¡à¸µà¹€à¸—à¸„à¸™à¸´à¸„à¸à¸²à¸£à¸šà¸µà¸šà¸­à¸±à¸”à¸—à¸µà¹ˆà¸¥à¹‰à¸³à¸ªà¸¡à¸±à¸¢à¸‹à¸¶à¹ˆà¸‡à¸›à¸£à¸±à¸šà¹à¸•à¹ˆà¸‡à¹‚à¸”à¸¢à¹€à¸‰à¸žà¸²à¸°à¸ªà¸³à¸«à¸£à¸±à¸šà¸à¸²à¸£à¹ƒà¸Šà¹‰à¸‡à¸²à¸™ SLM à¹à¸šà¸šà¸•à¸±à¸§à¹à¸—à¸™:

**à¸à¸²à¸£à¸šà¸µà¸šà¸­à¸±à¸”à¹€à¸‰à¸žà¸²à¸°à¸•à¸±à¸§à¹à¸—à¸™**: à¹€à¸Ÿà¸£à¸¡à¹€à¸§à¸´à¸£à¹Œà¸à¸ªà¸™à¸±à¸šà¸ªà¸™à¸¸à¸™ Q4_0 (à¹€à¸«à¸¡à¸²à¸°à¸ªà¸³à¸«à¸£à¸±à¸šà¸à¸²à¸£à¹ƒà¸Šà¹‰à¸‡à¸²à¸™à¸•à¸±à¸§à¹à¸—à¸™à¸šà¸™à¸¡à¸·à¸­à¸–à¸·à¸­à¸”à¹‰à¸§à¸¢à¸à¸²à¸£à¸¥à¸”à¸‚à¸™à¸²à¸” 75%) Q5_1 (à¸„à¸¸à¸“à¸ à¸²à¸ž-à¸à¸²à¸£à¸šà¸µà¸šà¸­à¸±à¸”à¸—à¸µà¹ˆà¸ªà¸¡à¸”à¸¸à¸¥à¸ªà¸³à¸«à¸£à¸±à¸šà¸•à¸±à¸§à¹à¸—à¸™à¸­à¸™à¸¸à¸¡à¸²à¸™à¸—à¸µà¹ˆà¸‚à¸­à¸š) à¹à¸¥à¸° Q8_0 (à¸„à¸¸à¸“à¸ à¸²à¸žà¹ƒà¸à¸¥à¹‰à¹€à¸„à¸µà¸¢à¸‡à¸•à¹‰à¸™à¸‰à¸šà¸±à¸šà¸ªà¸³à¸«à¸£à¸±à¸šà¸£à¸°à¸šà¸šà¸•à¸±à¸§à¹à¸—à¸™à¹ƒà¸™à¸£à¸°à¸”à¸±à¸šà¸à¸²à¸£à¸œà¸¥à¸´à¸•) à¸£à¸¹à¸›à¹à¸šà¸šà¸‚à¸±à¹‰à¸™à¸ªà¸¹à¸‡à¸Šà¹ˆà¸§à¸¢à¹ƒà¸«à¹‰à¸•à¸±à¸§à¹à¸—à¸™à¸—à¸µà¹ˆà¸šà¸µà¸šà¸­à¸±à¸”à¸¡à¸²à¸à¸ªà¸³à¸«à¸£à¸±à¸šà¸ªà¸–à¸²à¸™à¸à¸²à¸£à¸“à¹Œà¸—à¸µà¹ˆà¸‚à¸­à¸šà¸ªà¸¸à¸”à¸‚à¸µà¸”

**à¸›à¸£à¸°à¹‚à¸¢à¸Šà¸™à¹Œà¹ƒà¸™à¸à¸²à¸£à¹ƒà¸Šà¹‰à¸‡à¸²à¸™**: à¸à¸²à¸£à¸­à¸™à¸¸à¸¡à¸²à¸™à¸—à¸µà¹ˆà¸›à¸£à¸±à¸šà¹à¸•à¹ˆà¸‡à¸ªà¸³à¸«à¸£à¸±à¸š CPU à¸žà¸£à¹‰à¸­à¸¡à¸à¸²à¸£à¹€à¸£à¹ˆà¸‡à¸„à¸§à¸²à¸¡à¹€à¸£à¹‡à¸§ SIMD à¹ƒà¸«à¹‰à¸à¸²à¸£à¸”à¸³à¹€à¸™à¸´à¸™à¸à¸²à¸£à¸•à¸±à¸§à¹à¸—à¸™à¸—à¸µà¹ˆà¸¡à¸µà¸›à¸£à¸°à¸ªà¸´à¸—à¸˜à¸´à¸ à¸²à¸žà¸”à¹‰à¸²à¸™à¸«à¸™à¹ˆà¸§à¸¢à¸„à¸§à¸²à¸¡à¸ˆà¸³ à¸„à¸§à¸²à¸¡à¹€à¸‚à¹‰à¸²à¸à¸±à¸™à¹„à¸”à¹‰à¸‚à¹‰à¸²à¸¡à¹à¸žà¸¥à¸•à¸Ÿà¸­à¸£à¹Œà¸¡à¹ƒà¸™à¸ªà¸–à¸²à¸›à¸±à¸•à¸¢à¸à¸£à¸£à¸¡ x86, ARM à¹à¸¥à¸° Apple Silicon à¸Šà¹ˆà¸§à¸¢à¹ƒà¸«à¹‰à¸ªà¸²à¸¡à¸²à¸£à¸–à¹ƒà¸Šà¹‰à¸‡à¸²à¸™à¸•à¸±à¸§à¹à¸—à¸™à¹„à¸”à¹‰à¸­à¸¢à¹ˆà¸²à¸‡à¸ªà¸²à¸à¸¥

#### à¹€à¸Ÿà¸£à¸¡à¹€à¸§à¸´à¸£à¹Œà¸ Apple MLX à¸ªà¸³à¸«à¸£à¸±à¸šà¸•à¸±à¸§à¹à¸—à¸™ SLM

Apple MLX à¸¡à¸µà¸à¸²à¸£à¸›à¸£à¸±à¸šà¹à¸•à¹ˆà¸‡à¹à¸šà¸šà¹€à¸™à¸—à¸µà¸Ÿà¸—à¸µà¹ˆà¸­à¸­à¸à¹à¸šà¸šà¸¡à¸²à¹‚à¸”à¸¢à¹€à¸‰à¸žà¸²à¸°à¸ªà¸³à¸«à¸£à¸±à¸šà¸•à¸±à¸§à¹à¸—à¸™à¸—à¸µà¹ˆà¸‚à¸±à¸šà¹€à¸„à¸¥à¸·à¹ˆà¸­à¸™à¸”à¹‰à¸§à¸¢ SLM à¸šà¸™à¸­à¸¸à¸›à¸à¸£à¸“à¹Œ Apple Silicon:

**à¸à¸²à¸£à¸›à¸£à¸±à¸šà¹à¸•à¹ˆà¸‡à¸•à¸±à¸§à¹à¸—à¸™à¸ªà¸³à¸«à¸£à¸±à¸š Apple Silicon**: à¹€à¸Ÿà¸£à¸¡à¹€à¸§à¸´à¸£à¹Œà¸à¹ƒà¸Šà¹‰à¸ªà¸–à¸²à¸›à¸±à¸•à¸¢à¸à¸£à¸£à¸¡à¸«à¸™à¹ˆà¸§à¸¢à¸„à¸§à¸²à¸¡à¸ˆà¸³à¹à¸šà¸šà¸£à¸§à¸¡à¸à¸±à¸šà¸à¸²à¸£à¸œà¸ªà¸²à¸™ Metal Performance Shaders à¸à¸²à¸£à¸­à¸™à¸¸à¸¡à¸²à¸™à¹à¸šà¸šà¸œà¸ªà¸¡à¸­à¸±à¸•à¹‚à¸™à¸¡à¸±à¸•à¸´à¸ªà¸³à¸«à¸£à¸±à¸šà¸•à¸±à¸§à¹à¸—à¸™ à¹à¸¥à¸°à¹à¸šà¸™à¸”à¹Œà¸§à¸´à¸”à¸—à¹Œà¸«à¸™à¹ˆà¸§à¸¢à¸„à¸§à¸²à¸¡à¸ˆà¸³à¸—à¸µà¹ˆà¸›à¸£à¸±à¸šà¹à¸•à¹ˆà¸‡à¸ªà¸³à¸«à¸£à¸±à¸šà¸£à¸°à¸šà¸šà¸•à¸±à¸§à¹à¸—à¸™à¸«à¸¥à¸²à¸¢à¸•à¸±à¸§ à¸•à¸±à¸§à¹à¸—à¸™ SLM à¹à¸ªà¸”à¸‡à¸›à¸£à¸°à¸ªà¸´à¸—à¸˜à¸´à¸ à¸²à¸žà¸—à¸µà¹ˆà¸¢à¸­à¸”à¹€à¸¢à¸µà¹ˆà¸¢à¸¡à¸šà¸™à¸Šà¸´à¸› M-series

**à¸„à¸¸à¸“à¸ªà¸¡à¸šà¸±à¸•à¸´à¸à¸²à¸£à¸žà¸±à¸’à¸™à¸²**: à¸à¸²à¸£à¸ªà¸™à¸±à¸šà¸ªà¸™à¸¸à¸™ API Python à¹à¸¥à¸° Swift à¸žà¸£à¹‰à¸­à¸¡à¸à¸²à¸£à¸›à¸£à¸±à¸šà¹à¸•à¹ˆà¸‡à¹€à¸‰à¸žà¸²à¸°à¸•à¸±à¸§à¹à¸—à¸™ à¸à¸²à¸£à¹à¸¢à¸à¸„à¸§à¸²à¸¡à¹à¸•à¸à¸•à¹ˆà¸²à¸‡à¸­à¸±à¸•à¹‚à¸™à¸¡à¸±à¸•à¸´à¸ªà¸³à¸«à¸£à¸±à¸šà¸à¸²à¸£à¹€à¸£à¸µà¸¢à¸™à¸£à¸¹à¹‰à¸‚à¸­à¸‡à¸•à¸±à¸§à¹à¸—à¸™ à¹à¸¥à¸°à¸à¸²à¸£à¸œà¸ªà¸²à¸™à¸£à¸§à¸¡à¸—à¸µà¹ˆà¸£à¸²à¸šà¸£à¸·à¹ˆà¸™à¸à¸±à¸šà¹€à¸„à¸£à¸·à¹ˆà¸­à¸‡à¸¡à¸·à¸­à¸žà¸±à¸’à¸™à¸²à¸‚à¸­à¸‡ Apple à¹ƒà¸«à¹‰à¸ªà¸ à¸²à¸žà¹à¸§à¸”à¸¥à¹‰à¸­à¸¡à¸à¸²à¸£à¸žà¸±à¸’à¸™à¸²à¸•à¸±à¸§à¹à¸—à¸™à¸—à¸µà¹ˆà¸„à¸£à¸­à¸šà¸„à¸¥à¸¸à¸¡

#### ONNX Runtime à¸ªà¸³à¸«à¸£à¸±à¸šà¸•à¸±à¸§à¹à¸—à¸™ SLM à¸‚à¹‰à¸²à¸¡à¹à¸žà¸¥à¸•à¸Ÿà¸­à¸£à¹Œà¸¡

ONNX Runtime à¹ƒà¸«à¹‰à¹€à¸„à¸£à¸·à¹ˆà¸­à¸‡à¸¡à¸·à¸­à¸­à¸™à¸¸à¸¡à¸²à¸™à¸ªà¸²à¸à¸¥à¸—à¸µà¹ˆà¸Šà¹ˆà¸§à¸¢à¹ƒà¸«à¹‰à¸•à¸±à¸§à¹à¸—à¸™ SLM à¸—à¸³à¸‡à¸²à¸™à¹„à¸”à¹‰à¸­à¸¢à¹ˆà¸²à¸‡à¸ªà¸¡à¹ˆà¸³à¹€à¸ªà¸¡à¸­à¹ƒà¸™à¹à¸žà¸¥à¸•à¸Ÿà¸­à¸£à¹Œà¸¡à¸®à¸²à¸£à¹Œà¸”à¹à¸§à¸£à¹Œà¹à¸¥à¸°à¸£à¸°à¸šà¸šà¸›à¸à¸´à¸šà¸±à¸•à¸´à¸à¸²à¸£à¸—à¸µà¹ˆà¸«à¸¥à¸²à¸à¸«à¸¥à¸²à¸¢:

**à¸à¸²à¸£à¹ƒà¸Šà¹‰à¸‡à¸²à¸™à¸ªà¸²à¸à¸¥**: ONNX Runtime à¸Šà¹ˆà¸§à¸¢à¹ƒà¸«à¹‰à¸žà¸¤à¸•à¸´à¸à¸£à¸£à¸¡à¸‚à¸­à¸‡à¸•à¸±à¸§à¹à¸—à¸™ SLM à¸ªà¸­à¸”à¸„à¸¥à¹‰à¸­à¸‡à¸à¸±à¸™à¹ƒà¸™à¹à¸žà¸¥à¸•à¸Ÿà¸­à¸£à¹Œà¸¡ Windows, Linux, macOS, iOS à¹à¸¥à¸° Android à¸„à¸§à¸²à¸¡à¹€à¸‚à¹‰à¸²à¸à¸±à¸™à¹„à¸”à¹‰à¸‚à¹‰à¸²à¸¡à¹à¸žà¸¥à¸•à¸Ÿà¸­à¸£à¹Œà¸¡à¸™à¸µà¹‰à¸Šà¹ˆà¸§à¸¢à¹ƒà¸«à¹‰à¸™à¸±à¸à¸žà¸±à¸’à¸™à¸²à¸ªà¸²à¸¡à¸²à¸£à¸–à¹€à¸‚à¸µà¸¢à¸™à¹‚à¸„à¹‰à¸”à¸„à¸£à¸±à¹‰à¸‡à¹€à¸”à¸µà¸¢à¸§à¹à¸¥à¸°à¹ƒà¸Šà¹‰à¸‡à¸²à¸™à¹„à¸”à¹‰à¸—à¸¸à¸à¸—à¸µà¹ˆ à¸¥à¸”à¸„à¹ˆà¸²à¹ƒà¸Šà¹‰à¸ˆà¹ˆà¸²à¸¢à¹ƒà¸™à¸à¸²à¸£à¸žà¸±à¸’à¸™à¸²à¹à¸¥à¸°à¸à¸²à¸£à¸šà¸³à¸£à¸¸à¸‡à¸£à¸±à¸à¸©à¸²à¸ªà¸³à¸«à¸£à¸±à¸šà¹à¸­à¸›à¸žà¸¥à¸´à¹€à¸„à¸Šà¸±à¸™à¸«à¸¥à¸²à¸¢à¹à¸žà¸¥à¸•à¸Ÿà¸­à¸£à¹Œà¸¡à¸­à¸¢à¹ˆà¸²à¸‡à¸¡à¸²à¸

**à¸•à¸±à¸§à¹€à¸¥à¸·à¸­à¸à¸à¸²à¸£à¹€à¸£à¹ˆà¸‡à¸®à¸²à¸£à¹Œà¸”à¹à¸§à¸£à¹Œ**: à¹€à¸Ÿà¸£à¸¡à¹€à¸§à¸´à¸£à¹Œà¸à¹ƒà¸«à¹‰à¸•à¸±à¸§à¹€à¸¥à¸·à¸­à¸à¸à¸²à¸£à¸”à¸³à¹€à¸™à¸´à¸™à¸à¸²à¸£à¸—à¸µà¹ˆà¸›à¸£à¸±à¸šà¹à¸•à¹ˆà¸‡à¸ªà¸³à¸«à¸£à¸±à¸šà¸à¸²à¸£à¸à¸³à¸«à¸™à¸”à¸„à¹ˆà¸²à¸®à¸²à¸£à¹Œà¸”à¹à¸§à¸£à¹Œà¸•à¹ˆà¸²à¸‡à¹† à¸£à¸§à¸¡à¸–à¸¶à¸‡ CPU (Intel, AMD, ARM), GPU (NVIDIA CUDA, AMD ROCm) à¹à¸¥à¸°à¸•à¸±à¸§à¹€à¸£à¹ˆà¸‡à¸žà¸´à¹€à¸¨à¸© (Intel VPU, Qualcomm NPU) à¸•à¸±à¸§à¹à¸—à¸™ SLM à¸ªà¸²à¸¡à¸²à¸£à¸–à¹ƒà¸Šà¹‰à¸®à¸²à¸£à¹Œà¸”à¹à¸§à¸£à¹Œà¸—à¸µà¹ˆà¸”à¸µà¸—à¸µà¹ˆà¸ªà¸¸à¸”à¸—à¸µà¹ˆà¸¡à¸µà¸­à¸¢à¸¹à¹ˆà¹‚à¸”à¸¢à¸­à¸±à¸•à¹‚à¸™à¸¡à¸±à¸•à¸´à¹‚à¸”à¸¢à¹„à¸¡à¹ˆà¸•à¹‰à¸­à¸‡à¹€à¸›à¸¥à¸µà¹ˆà¸¢à¸™à¹‚à¸„à¹‰à¸”

**à¸„à¸¸à¸“à¸ªà¸¡à¸šà¸±à¸•à¸´à¸žà¸£à¹‰à¸­à¸¡à¹ƒà¸Šà¹‰à¸‡à¸²à¸™à¹ƒà¸™à¸£à¸°à¸”à¸±à¸šà¸à¸²à¸£à¸œà¸¥à¸´à¸•**: ONNX Runtime à¸¡à¸µà¸„à¸¸à¸“à¸ªà¸¡à¸šà¸±à¸•à¸´à¸£à¸°à¸”à¸±à¸šà¸­à¸‡à¸„à¹Œà¸à¸£à¸—à¸µà¹ˆà¸ˆà¸³à¹€à¸›à¹‡à¸™à¸ªà¸³à¸«à¸£à¸±à¸šà¸à¸²à¸£à¹ƒà¸Šà¹‰à¸‡à¸²à¸™à¸•à¸±à¸§à¹à¸—à¸™à¹ƒà¸™à¸£à¸°à¸”à¸±à¸šà¸à¸²à¸£à¸œà¸¥à¸´à¸• à¸£à¸§à¸¡à¸–à¸¶à¸‡à¸à¸²à¸£à¸›à¸£à¸±à¸šà¹à¸•à¹ˆà¸‡à¸à¸£à¸²à¸Ÿà¸ªà¸³à¸«à¸£à¸±à¸šà¸à¸²à¸£à¸­à¸™à¸¸à¸¡à¸²à¸™à¸—à¸µà¹ˆà¹€à¸£à¹‡à¸§à¸‚à¸¶à¹‰à¸™ à¸à¸²à¸£à¸ˆà¸±à¸”à¸à¸²à¸£à¸«à¸™à¹ˆà¸§à¸¢à¸„à¸§à¸²à¸¡à¸ˆà¸³à¸ªà¸³à¸«à¸£à¸±à¸šà¸ªà¸ à¸²à¸žà¹à¸§à¸”à¸¥à¹‰à¸­à¸¡à¸—à¸µà¹ˆà¸¡à¸µà¸—à¸£à¸±à¸žà¸¢à¸²à¸à¸£à¸ˆà¸³à¸à¸±à¸” à¹à¸¥à¸°à¹€à¸„à¸£à¸·à¹ˆà¸­à¸‡à¸¡à¸·à¸­à¸§à¸´à¹€à¸„à¸£à¸²à¸°à¸«à¹Œà¸›à¸£à¸°à¸ªà¸´à¸—à¸˜à¸´à¸ à¸²à¸žà¸—à¸µà¹ˆà¸„à¸£à¸­à¸šà¸„à¸¥à¸¸à¸¡ à¹€à¸Ÿà¸£à¸¡à¹€à¸§à¸´à¸£à¹Œà¸à¸ªà¸™à¸±à¸šà¸ªà¸™à¸¸à¸™à¸—à¸±à¹‰à¸‡ API Python à¹à¸¥à¸° C++ à¸ªà¸³à¸«à¸£à¸±à¸šà¸à¸²à¸£à¸œà¸ªà¸²à¸™à¸£à¸§à¸¡à¸—à¸µà¹ˆà¸¢à¸·à¸”à¸«à¸¢à¸¸à¹ˆà¸™

## SLM vs LLM à¹ƒà¸™à¸£à¸°à¸šà¸šà¸•à¸±à¸§à¹à¸—à¸™: à¸à¸²à¸£à¹€à¸›à¸£à¸µà¸¢à¸šà¹€à¸—à¸µà¸¢à¸šà¸‚à¸±à¹‰à¸™à¸ªà¸¹à¸‡

### à¸‚à¹‰à¸­à¸”à¸µà¸‚à¸­à¸‡ SLM à¹ƒà¸™à¹à¸­à¸›à¸žà¸¥à¸´à¹€à¸„à¸Šà¸±à¸™à¸•à¸±à¸§à¹à¸—à¸™

**à¸›à¸£à¸°à¸ªà¸´à¸—à¸˜à¸´à¸ à¸²à¸žà¸à¸²à¸£à¸”à¸³à¹€à¸™à¸´à¸™à¸‡à¸²à¸™**: SLM à¹ƒà¸«à¹‰à¸à¸²à¸£à¸¥à¸”à¸„à¹ˆà¸²à¹ƒà¸Šà¹‰à¸ˆà¹ˆà¸²à¸¢ 10-30Ã— à¹€à¸¡à¸·à¹ˆà¸­à¹€à¸—à¸µà¸¢à¸šà¸à¸±à¸š LLM à¸ªà¸³à¸«à¸£à¸±à¸šà¸‡à¸²à¸™à¸•à¸±à¸§à¹à¸—à¸™ à¸Šà¹ˆà¸§à¸¢à¹ƒà¸«à¹‰à¸à¸²à¸£à¸•à¸­à¸šà¸ªà¸™à¸­à¸‡à¹à¸šà¸šà¸•à¸±à¸§à¹à¸—à¸™à¹à¸šà¸šà¹€à¸£à¸µà¸¢à¸¥à¹„à¸—à¸¡à¹Œà¹ƒà¸™à¸£à¸°à¸”à¸±à¸šà¹ƒà¸«à¸à¹ˆ à¸žà¸§à¸à¹€à¸‚à¸²à¹ƒà¸«à¹‰à¹€à¸§à¸¥à¸²à¸à¸²à¸£à¸­à¸™à¸¸à¸¡à¸²à¸™à¸—à¸µà¹ˆà¹€à¸£à¹‡à¸§à¸‚à¸¶à¹‰à¸™à¹€à¸™à¸·à¹ˆà¸­à¸‡à¸ˆà¸²à¸à¸„à¸§à¸²à¸¡à¸‹à¸±à¸šà¸‹à¹‰à¸­à¸™à¹ƒà¸™à¸à¸²à¸£à¸„à¸³à¸™à¸§à¸“à¸—à¸µà¹ˆà¸¥à¸”à¸¥à¸‡ à¸—à¸³à¹ƒà¸«à¹‰à¹€à¸«à¸¡à¸²à¸°à¸ªà¸³à¸«à¸£à¸±à¸šà¹à¸­à¸›à¸žà¸¥à¸´à¹€à¸„à¸Šà¸±à¸™à¸•à¸±à¸§à¹à¸—à¸™à¹à¸šà¸šà¹‚à¸•à¹‰à¸•à¸­à¸š

**à¸„à¸§à¸²à¸¡à¸ªà¸²à¸¡à¸²à¸£à¸–à¹ƒà¸™à¸à¸²à¸£à¹ƒà¸Šà¹‰à¸‡à¸²à¸™à¸—à¸µà¹ˆà¸‚à¸­à¸š**: SLM à¸Šà¹ˆà¸§à¸¢à¹ƒà¸«à¹‰à¸à¸²à¸£à¸”à¸³à¹€à¸™à¸´à¸™à¸à¸²à¸£à¸•à¸±à¸§à¹à¸—à¸™à¸šà¸™à¸­à¸¸à¸›à¸à¸£à¸“à¹Œà¹‚à¸”à¸¢à¹„à¸¡à¹ˆà¸•à¹‰à¸­à¸‡à¸žà¸¶à¹ˆà¸‡à¸žà¸²à¸­à¸´à¸™à¹€à¸—à¸­à¸£à¹Œà¹€à¸™à¹‡à¸• à¹€à¸žà¸´à¹ˆà¸¡à¸„à¸§à¸²à¸¡à¹€à¸›à¹‡à¸™à¸ªà¹ˆà¸§à¸™à¸•à¸±à¸§à¸œà¹ˆà¸²à¸™à¸à¸²à¸£à¸›à¸£à¸°à¸¡à¸§à¸¥à¸œà¸¥à¸•à¸±à¸§à¹à¸—à¸™à¹ƒà¸™à¸žà¸·à¹‰à¸™à¸—à¸µà¹ˆ à¹à¸¥à¸°à¸à¸²à¸£à¸›à¸£à¸±à¸šà¹à¸•à¹ˆà¸‡à¸ªà¸³à¸«à¸£à¸±à¸šà¹à¸­à¸›à¸žà¸¥à¸´à¹€à¸„à¸Šà¸±à¸™à¸•à¸±à¸§à¹à¸—à¸™à¹€à¸‰à¸žà¸²à¸°à¸”à¹‰à¸²à¸™à¸—à¸µà¹ˆà¹€à¸«à¸¡à¸²à¸°à¸ªà¸³à¸«à¸£à¸±à¸šà¸ªà¸ à¸²à¸žà¹à¸§à¸”à¸¥à¹‰à¸­à¸¡à¸à¸²à¸£à¸›à¸£à¸°à¸¡à¸§à¸¥à¸œà¸¥à¸—à¸µà¹ˆà¸‚à¸­à¸šà¸•à¹ˆà¸²à¸‡à¹†

**à¸à¸²à¸£à¸›à¸£à¸±à¸šà¹à¸•à¹ˆà¸‡à¹€à¸‰à¸žà¸²à¸°à¸•à¸±à¸§à¹à¸—à¸™**: SLM à¹‚à¸”à¸”à¹€à¸”à¹ˆà¸™à¹ƒà¸™à¸à¸²à¸£à¹€à¸£à¸µà¸¢à¸à¹€à¸„à¸£à¸·à¹ˆà¸­à¸‡à¸¡à¸·à¸­ à¸à¸²à¸£à¸ªà¸£à¹‰à¸²à¸‡à¸œà¸¥à¸¥à¸±à¸žà¸˜à¹Œà¸—à¸µà¹ˆà¸¡à¸µà¹‚à¸„à¸£à¸‡à¸ªà¸£à¹‰à¸²à¸‡ à¹à¸¥à¸°à¸à¸£à¸°à¸šà¸§à¸™à¸à¸²à¸£à¸•à¸±à¸”à¸ªà¸´à¸™à¹ƒà¸ˆà¸•à¸²à¸¡à¸à¸´à¸ˆà¸§à¸±à¸•à¸£à¸—à¸µà¹ˆà¸›à¸£à¸°à¸à¸­à¸šà¸”à¹‰à¸§à¸¢ 70-80% à¸‚à¸­à¸‡à¸‡à¸²à¸™à¸•à¸±à¸§à¹à¸—à¸™à¸—à¸±à¹ˆà¸§à¹„à¸›

### à¹€à¸¡à¸·à¹ˆà¸­à¹ƒà¸”à¸„à¸§à¸£à¹ƒà¸Šà¹‰ SLM à¹€à¸—à¸µà¸¢à¸šà¸à¸±à¸š LLM à¹ƒà¸™à¸£à¸°à¸šà¸šà¸•à¸±à¸§à¹à¸—à¸™

**à¹€à¸«à¸¡à¸²à¸°à¸ªà¸³à¸«à¸£à¸±à¸š SLM**:
- **à¸‡à¸²à¸™à¸•à¸±à¸§à¹à¸—à¸™à¸—à¸µà¹ˆà¸‹à¹‰à¸³à¸‹à¸²à¸**: à¸à¸²à¸£à¸›à¹‰à¸­à¸™à¸‚à¹‰à¸­à¸¡à¸¹à¸¥, à¸à¸²à¸£à¸à¸£à¸­à¸à¹à¸šà¸šà¸Ÿà¸­à¸£à¹Œà¸¡, à¸à¸²à¸£à¹€à¸£à¸µà¸¢à¸ API à¸•à¸²à¸¡à¸à¸´à¸ˆà¸§à¸±à¸•à¸£
- **à¸à¸²à¸£à¸œà¸ªà¸²à¸™à¹€à¸„à¸£à¸·à¹ˆà¸­à¸‡à¸¡à¸·à¸­**: à¸à¸²à¸£à¸„à¹‰à¸™à¸«à¸²à¸à¸²à¸™à¸‚à¹‰à¸­à¸¡à¸¹à¸¥, à¸à¸²à¸£à¸”à¸³à¹€à¸™à¸´à¸™à¸à¸²à¸£à¹„à¸Ÿà¸¥à¹Œ, à¸à¸²à¸£à¹‚à¸•à¹‰à¸•à¸­à¸šà¸à¸±à¸šà¸£à¸°à¸šà¸š
- **à¸à¸£à¸°à¸šà¸§à¸™à¸à¸²à¸£à¸—à¸µà¹ˆà¸¡à¸µà¹‚à¸„à¸£à¸‡à¸ªà¸£à¹‰à¸²à¸‡**: à¸à¸²à¸£à¸›à¸à¸´à¸šà¸±à¸•à¸´à¸•à¸²à¸¡à¸à¸£à¸°à¸šà¸§à¸™à¸à¸²à¸£à¸•à¸±à¸§à¹à¸—à¸™à¸—à¸µà¹ˆà¸à¸³à¸«à¸™à¸”à¹„à¸§à¹‰à¸¥à¹ˆà¸§à¸‡à¸«à¸™à¹‰à¸²
- **à¸•à¸±à¸§à¹à¸—à¸™à¹€à¸‰à¸žà¸²à¸°à¸”à¹‰à¸²à¸™**: à¸à¸²à¸£à¸šà¸£à¸´à¸à¸²à¸£à¸¥à¸¹à¸à¸„à¹‰à¸², à¸à¸²à¸£à¸ˆà¸±à¸”à¸•à¸²à¸£à¸²à¸‡à¹€à¸§à¸¥à¸², à¸à¸²à¸£à¸§à¸´à¹€à¸„à¸£à¸²à¸°à¸«à¹Œà¸žà¸·à¹‰à¸™à¸à¸²à¸™
- **à¸à¸²à¸£à¸›à¸£à¸°à¸¡à¸§à¸¥à¸œà¸¥à¹ƒà¸™à¸žà¸·à¹‰à¸™à¸—à¸µà¹ˆ**: à¸à¸²à¸£à¸”à¸³à¹€à¸™à¸´à¸™à¸à¸²à¸£à¸•à¸±à¸§à¹à¸—à¸™à¸—à¸µà¹ˆà¸•à¹‰à¸­à¸‡à¸à¸²à¸£à¸„à¸§à¸²à¸¡à¹€à¸›à¹‡à¸™à¸ªà¹ˆà¸§à¸™à¸•à¸±à¸§

**à¹€à¸«à¸¡à¸²à¸°à¸ªà¸³à¸«à¸£à¸±à¸š LLM**:
- **à¸à¸²à¸£à¹ƒà¸«à¹‰à¹€à¸«à¸•à¸¸à¸œà¸¥à¸—à¸µà¹ˆà¸‹à¸±à¸šà¸‹à¹‰à¸­à¸™**: à¸à¸²à¸£à¹à¸à¹‰à¸›à¸±à¸à¸«à¸²à¹ƒà¸«à¸¡à¹ˆ, à¸à¸²à¸£à¸§à¸²à¸‡à¹à¸œà¸™à¹€à¸Šà¸´à¸‡à¸à¸¥à¸¢à¸¸à¸—à¸˜à¹Œ
- **à¸à¸²à¸£à¸ªà¸™à¸—à¸™à¸²à¹à¸šà¸šà¹€à¸›à¸´à¸”**: à¸à¸²à¸£à¹à¸Šà¸—à¸—à¸±à¹ˆà¸§à¹„à¸›, à¸à¸²à¸£à¸ªà¸™à¸—à¸™à¸²à¹€à¸Šà¸´à¸‡à¸ªà¸£à¹‰à¸²à¸‡à¸ªà¸£à¸£à¸„à¹Œ
- **à¸‡à¸²à¸™à¸—à¸µà¹ˆà¸•à¹‰à¸­à¸‡à¸à¸²à¸£à¸„à¸§à¸²à¸¡à¸£à¸¹à¹‰à¸à¸§à¹‰à¸²à¸‡à¸‚à¸§à¸²à¸‡**: à¸à¸²à¸£à¸§à¸´à¸ˆà¸±à¸¢à¸—à¸µà¹ˆà¸•à¹‰à¸­à¸‡à¸à¸²à¸£à¸„à¸§à¸²à¸¡à¸£à¸¹à¹‰à¸—à¸±à¹ˆà¸§à¹„à¸›à¹ƒà¸™à¸§à¸‡à¸à¸§à¹‰à¸²à¸‡
- **à¸ªà¸–à¸²à¸™à¸à¸²à¸£à¸“à¹Œà¹ƒà¸«à¸¡à¹ˆ**: à¸à¸²à¸£à¸ˆà¸±à¸”à¸à¸²à¸£à¸ªà¸–à¸²à¸™à¸à¸²à¸£à¸“à¹Œà¸•à¸±à¸§à¹à¸—à¸™à¸—à¸µà¹ˆà¹ƒà¸«à¸¡à¹ˆà¸—à¸±à¹‰à¸‡à¸«à¸¡à¸”

### à¸ªà¸–à¸²à¸›à¸±à¸•à¸¢à¸à¸£à¸£à¸¡à¸•à¸±à¸§à¹à¸—à¸™à¹à¸šà¸šà¹„à¸®à¸šà¸£à¸´à¸”

à¸§à¸´à¸˜à¸µà¸à¸²à¸£à¸—à¸µà¹ˆà¹€à¸«à¸¡à¸²à¸°à¸ªà¸¡à¸—à¸µà¹ˆà¸ªà¸¸à¸”à¸„à¸·à¸­à¸à¸²à¸£à¸œà¸ªà¸²à¸™ SLM à¹à¸¥à¸° LLM à¹ƒà¸™à¸£à¸°à¸šà¸šà¸•à¸±à¸§à¹à¸—à¸™à¹à¸šà¸šà¸œà¸ªà¸¡:

**à¸à¸²à¸£à¸ˆà¸±à¸”à¸à¸²à¸£à¸•à¸±à¸§à¹à¸—à¸™à¸­à¸±à¸ˆà¸‰à¸£à¸´à¸¢à¸°**:
1. **SLM à¹€à¸›à¹‡à¸™à¸«à¸¥à¸±à¸**: à¸ˆà¸±à¸”à¸à¸²à¸£ 70-80% à¸‚à¸­à¸‡à¸‡à¸²à¸™à¸•à¸±à¸§à¹à¸—à¸™à¸•à¸²à¸¡à¸à¸´à¸ˆà¸§à¸±à¸•à¸£à¹ƒà¸™à¸žà¸·à¹‰à¸™à¸—à¸µà¹ˆ
2. **LLM à¹€à¸¡à¸·à¹ˆà¸­à¸ˆà¸³à¹€à¸›à¹‡à¸™**: à¸ªà¹ˆà¸‡à¸„à¸³à¸–à¸²à¸¡à¸—à¸µà¹ˆà¸‹à¸±à¸šà¸‹à¹‰à¸­à¸™à¹„à¸›à¸¢à¸±à¸‡à¹‚à¸¡à¹€à¸”à¸¥à¸‚à¸™à¸²à¸”à¹ƒà¸«à¸à¹ˆà¸šà¸™à¸„à¸¥à¸²à¸§à¸”à¹Œ
3. **SLM à¹€à¸‰à¸žà¸²à¸°à¸”à¹‰à¸²à¸™**: à¹‚à¸¡à¹€à¸”à¸¥à¸‚à¸™à¸²à¸”à¹€à¸¥à¹‡à¸à¸•à¹ˆà¸²à¸‡à¹† à¸ªà¸³à¸«à¸£à¸±à¸šà¹‚à¸”à¹€à¸¡à¸™à¸•à¸±à¸§à¹à¸—à¸™à¸•à¹ˆà¸²à¸‡à¹†
4. **à¸à¸²à¸£à¸›à¸£à¸±à¸šà¹à¸•à¹ˆà¸‡à¸„à¹ˆà¸²à¹ƒà¸Šà¹‰à¸ˆà¹ˆà¸²à¸¢**: à¸¥à¸”à¸à¸²à¸£à¹€à¸£à¸µà¸¢à¸ LLM à¸—à¸µà¹ˆà¸¡à¸µà¸„à¹ˆà¸²à¹ƒà¸Šà¹‰à¸ˆà¹ˆà¸²à¸¢à¸ªà¸¹à¸‡à¸œà¹ˆà¸²à¸™à¸à¸²à¸£à¸ˆà¸±à¸”à¸à¸²à¸£à¸—à¸µà¹ˆà¸Šà¸²à¸à¸‰à¸¥à¸²à¸”

## à¸à¸¥à¸¢à¸¸à¸—à¸˜à¹Œà¸à¸²à¸£à¹ƒà¸Šà¹‰à¸‡à¸²à¸™à¸•à¸±à¸§à¹à¸—à¸™ SLM à¹ƒà¸™à¸£à¸°à¸”à¸±à¸šà¸à¸²à¸£à¸œà¸¥à¸´à¸•

### Foundry Local: Runtime AI à¸—à¸µà¹ˆà¸‚à¸­à¸šà¹ƒà¸™à¸£à¸°à¸”à¸±à¸šà¸­à¸‡à¸„à¹Œà¸à¸£

Foundry Local (https://github.com/microsoft/foundry-local) à¹€à¸›à¹‡à¸™à¹‚à¸‹à¸¥à¸¹à¸Šà¸±à¸™à¹€à¸£à¸·à¸­à¸˜à¸‡à¸‚à¸­à¸‡ Microsoft à¸ªà¸³à¸«à¸£à¸±à¸šà¸à¸²à¸£à¹ƒà¸Šà¹‰à¸‡à¸²à¸™à¹‚à¸¡à¹€à¸”à¸¥à¸ à¸²à¸©à¸²à¸‚à¸™à¸²à¸”à¹€à¸¥à¹‡à¸à¹ƒà¸™à¸ªà¸ à¸²à¸žà¹à¸§à¸”à¸¥à¹‰à¸­à¸¡à¸—à¸µà¹ˆà¸‚à¸­à¸šà¹ƒà¸™à¸£à¸°à¸”à¸±à¸šà¸à¸²à¸£à¸œà¸¥à¸´à¸• à¸¡à¸±à¸™à¹ƒà¸«à¹‰à¸ªà¸ à¸²à¸žà¹à¸§à¸”à¸¥à¹‰à¸­à¸¡ runtime à¸—à¸µà¹ˆà¸ªà¸¡à¸šà¸¹à¸£à¸“à¹Œà¸‹à¸¶à¹ˆà¸‡à¸­à¸­à¸à¹à¸šà¸šà¸¡à¸²à¹‚à¸”à¸¢à¹€à¸‰à¸žà¸²à¸°à¸ªà¸³à¸«à¸£à¸±à¸šà¸•à¸±à¸§à¹à¸—à¸™à¸—à¸µà¹ˆà¸‚à¸±à¸šà¹€à¸„à¸¥à¸·à¹ˆà¸­à¸™à¸”à¹‰à¸§à¸¢ SLM à¸žà¸£à¹‰à¸­à¸¡à¸„à¸¸à¸“à¸ªà¸¡à¸šà¸±à¸•à¸´à¸£à¸°à¸”à¸±à¸šà¸­à¸‡à¸„à¹Œà¸à¸£à¹à¸¥à¸°à¸„à¸§à¸²à¸¡à¸ªà¸²à¸¡à¸²à¸£à¸–à¹ƒà¸™à¸à¸²à¸£à¸œà¸ªà¸²à¸™à¸£à¸§à¸¡à¸—à¸µà¹ˆà¸£à¸²à¸šà¸£à¸·à¹ˆà¸™

**à¸ªà¸–à¸²à¸›à¸±à¸•à¸¢à¸à¸£à¸£à¸¡à¹à¸¥à¸°à¸„à¸¸à¸“à¸ªà¸¡à¸šà¸±à¸•à¸´à¸«à¸¥à¸±à¸**:
- **API à¸—à¸µà¹ˆà¹€à¸‚à¹‰à¸²à¸à¸±à¸™à¹„à¸”à¹‰à¸à¸±à¸š OpenAI**: à¸„à¸§à¸²à¸¡à¹€à¸‚à¹‰à¸²à¸à¸±à¸™à¹„à¸”à¹‰à¹€à¸•à¹‡à¸¡à¸£à¸¹à¸›à¹à¸šà¸šà¸à¸±à¸š SDK OpenAI à¹à¸¥à¸°à¸à¸²à¸£à¸œà¸ªà¸²à¸™à¸£à¸§à¸¡ Agent Framework
- **à¸à¸²à¸£à¸›à¸£à¸±à¸šà¹à¸•à¹ˆà¸‡à¸®à¸²à¸£à¹Œà¸”à¹à¸§à¸£à¹Œà¸­à¸±à¸•à¹‚à¸™à¸¡à¸±à¸•à¸´**: à¸à¸²à¸£à¹€à¸¥à¸·à¸­à¸à¸•à¸±à¸§à¹à¸›à¸£à¹‚à¸¡à¹€à¸”à¸¥à¸­à¸¢à¹ˆà¸²à¸‡à¸Šà¸²à¸à¸‰à¸¥à¸²à¸”à¸•à¸²à¸¡à¸®à¸²à¸£à¹Œà¸”à¹à¸§à¸£à¹Œà¸—à¸µà¹ˆà¸¡à¸µà¸­à¸¢à¸¹à¹ˆ (CUDA GPU, Qualcomm NPU, CPU)
- **à¸à¸²à¸£à¸ˆà¸±à¸”à¸à¸²à¸£à¹‚à¸¡à¹€à¸”à¸¥**: à¸à¸²à¸£à¸”à¸²à¸§à¸™à¹Œà¹‚à¸«à¸¥à¸” à¸à¸²à¸£à¹à¸„à¸Š à¹à¸¥à¸°à¸à¸²à¸£à¸ˆà¸±à¸”à¸à¸²à¸£à¸§à¸‡à¸ˆà¸£à¸Šà¸µà¸§à¸´à¸•à¸‚à¸­à¸‡à¹‚à¸¡à¹€à¸”à¸¥ SLM à¹‚à¸”à¸¢à¸­à¸±à¸•à¹‚à¸™à¸¡à¸±à¸•à¸´
- **à¸à¸²à¸£à¸„à¹‰à¸™à¸žà¸šà¸šà¸£à¸´à¸à¸²à¸£**: à¸à¸²à¸£à¸•à¸£à¸§à¸ˆà¸ˆà¸±à¸šà¸šà¸£à¸´à¸à¸²à¸£à¹à¸šà¸šà¹„à¸¡à¹ˆà¸¡à¸µà¸à¸²à¸£à¸à¸³à¸«à¸™à¸”à¸„à¹ˆà¸²à¸ªà¸³à¸«à¸£à¸±à¸šà¹€à¸Ÿà¸£à¸¡à¹€à¸§à¸´à¸£à¹Œà¸à¸•à¸±à¸§à¹à¸—à¸™
- **à¸à¸²à¸£à¸›à¸£à¸±à¸šà¸—à¸£à¸±à¸žà¸¢à¸²à¸à¸£**: à¸à¸²à¸£à¸ˆà¸±à¸”à¸à¸²à¸£à¸«à¸™à¹ˆà¸§à¸¢à¸„à¸§à¸²à¸¡à¸ˆà¸³à¹à¸¥à¸°à¸›à¸£à¸°à¸ªà¸´à¸—à¸˜à¸´à¸ à¸²à¸žà¸žà¸¥à¸±à¸‡à¸‡à¸²à¸™à¸—à¸µà¹ˆà¸Šà¸²à¸à¸‰à¸¥à¸²à¸”à¸ªà¸³à¸«à¸£à¸±à¸šà¸à¸²à¸£à¹ƒà¸Šà¹‰à¸‡à¸²à¸™à¸—à¸µà¹ˆà¸‚à¸­à¸š

#### à¸à¸²à¸£à¸•à¸´à¸”à¸•à¸±à¹‰à¸‡à¹à¸¥à¸°à¸à¸²à¸£à¸•à¸±à¹‰à¸‡à¸„à¹ˆà¸²

**à¸à¸²à¸£
- à¸—à¸”à¸ªà¸­à¸šà¸à¸²à¸£à¸£à¸§à¸¡ Microsoft Agent Framework
- à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸šà¸„à¸§à¸²à¸¡à¸ªà¸²à¸¡à¸²à¸£à¸–à¹ƒà¸™à¸à¸²à¸£à¸—à¸³à¸‡à¸²à¸™à¹à¸šà¸šà¸­à¸­à¸Ÿà¹„à¸¥à¸™à¹Œ
- à¸—à¸”à¸ªà¸­à¸šà¸ªà¸–à¸²à¸™à¸à¸²à¸£à¸“à¹Œà¸à¸²à¸£à¸ªà¸³à¸£à¸­à¸‡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¹à¸¥à¸°à¸à¸²à¸£à¸ˆà¸±à¸”à¸à¸²à¸£à¸‚à¹‰à¸­à¸œà¸´à¸”à¸žà¸¥à¸²à¸”
- à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸šà¸à¸£à¸°à¸šà¸§à¸™à¸à¸²à¸£à¸—à¸³à¸‡à¸²à¸™à¸‚à¸­à¸‡à¹€à¸­à¹€à¸ˆà¸™à¸•à¹Œà¹à¸šà¸šà¸„à¸£à¸šà¸§à¸‡à¸ˆà¸£

**à¹€à¸›à¸£à¸µà¸¢à¸šà¹€à¸—à¸µà¸¢à¸šà¸à¸±à¸š Foundry Local**:

| à¸„à¸¸à¸“à¸ªà¸¡à¸šà¸±à¸•à¸´ | Foundry Local | Ollama |
|-----------|---------------|--------|
| **à¸à¸£à¸“à¸µà¸à¸²à¸£à¹ƒà¸Šà¹‰à¸‡à¸²à¸™à¹€à¸›à¹‰à¸²à¸«à¸¡à¸²à¸¢** | à¸à¸²à¸£à¸œà¸¥à¸´à¸•à¸£à¸°à¸”à¸±à¸šà¸­à¸‡à¸„à¹Œà¸à¸£ | à¸à¸²à¸£à¸žà¸±à¸’à¸™à¸²à¹à¸¥à¸°à¸Šà¸¸à¸¡à¸Šà¸™ |
| **à¸£à¸°à¸šà¸šà¸™à¸´à¹€à¸§à¸¨à¸‚à¸­à¸‡à¹‚à¸¡à¹€à¸”à¸¥** | à¸„à¸±à¸”à¹€à¸¥à¸·à¸­à¸à¹‚à¸”à¸¢ Microsoft | à¸Šà¸¸à¸¡à¸Šà¸™à¸—à¸µà¹ˆà¸à¸§à¹‰à¸²à¸‡à¸‚à¸§à¸²à¸‡ |
| **à¸à¸²à¸£à¸›à¸£à¸±à¸šà¹à¸•à¹ˆà¸‡à¸®à¸²à¸£à¹Œà¸”à¹à¸§à¸£à¹Œ** | à¸­à¸±à¸•à¹‚à¸™à¸¡à¸±à¸•à¸´ (CUDA/NPU/CPU) | à¸à¸²à¸£à¸•à¸±à¹‰à¸‡à¸„à¹ˆà¸²à¸”à¹‰à¸§à¸¢à¸•à¸™à¹€à¸­à¸‡ |
| **à¸„à¸¸à¸“à¸ªà¸¡à¸šà¸±à¸•à¸´à¸£à¸°à¸”à¸±à¸šà¸­à¸‡à¸„à¹Œà¸à¸£** | à¸à¸²à¸£à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸šà¹à¸¥à¸°à¸„à¸§à¸²à¸¡à¸›à¸¥à¸­à¸”à¸ à¸±à¸¢à¹ƒà¸™à¸•à¸±à¸§ | à¹€à¸„à¸£à¸·à¹ˆà¸­à¸‡à¸¡à¸·à¸­à¸Šà¸¸à¸¡à¸Šà¸™ |
| **à¸„à¸§à¸²à¸¡à¸‹à¸±à¸šà¸‹à¹‰à¸­à¸™à¹ƒà¸™à¸à¸²à¸£à¸›à¸£à¸±à¸šà¹ƒà¸Šà¹‰** | à¸‡à¹ˆà¸²à¸¢ (à¸•à¸´à¸”à¸•à¸±à¹‰à¸‡à¸”à¹‰à¸§à¸¢ winget) | à¸‡à¹ˆà¸²à¸¢ (à¸•à¸´à¸”à¸•à¸±à¹‰à¸‡à¸”à¹‰à¸§à¸¢ curl) |
| **à¸„à¸§à¸²à¸¡à¹€à¸‚à¹‰à¸²à¸à¸±à¸™à¹„à¸”à¹‰à¸‚à¸­à¸‡ API** | OpenAI + à¸ªà¹ˆà¸§à¸™à¸‚à¸¢à¸²à¸¢ | à¸¡à¸²à¸•à¸£à¸à¸²à¸™ OpenAI |
| **à¸à¸²à¸£à¸ªà¸™à¸±à¸šà¸ªà¸™à¸¸à¸™** | Microsoft à¸­à¸¢à¹ˆà¸²à¸‡à¹€à¸›à¹‡à¸™à¸—à¸²à¸‡à¸à¸²à¸£ | à¸‚à¸±à¸šà¹€à¸„à¸¥à¸·à¹ˆà¸­à¸™à¹‚à¸”à¸¢à¸Šà¸¸à¸¡à¸Šà¸™ |
| **à¹€à¸«à¸¡à¸²à¸°à¸ªà¸³à¸«à¸£à¸±à¸š** | à¹€à¸­à¹€à¸ˆà¸™à¸•à¹Œà¸à¸²à¸£à¸œà¸¥à¸´à¸• | à¸à¸²à¸£à¸ªà¸£à¹‰à¸²à¸‡à¸•à¹‰à¸™à¹à¸šà¸šà¹à¸¥à¸°à¸à¸²à¸£à¸§à¸´à¸ˆà¸±à¸¢ |

**à¹€à¸¡à¸·à¹ˆà¸­à¸„à¸§à¸£à¹€à¸¥à¸·à¸­à¸ Ollama**:
- **à¸à¸²à¸£à¸žà¸±à¸’à¸™à¸²à¹à¸¥à¸°à¸à¸²à¸£à¸ªà¸£à¹‰à¸²à¸‡à¸•à¹‰à¸™à¹à¸šà¸š**: à¸—à¸”à¸¥à¸­à¸‡à¸­à¸¢à¹ˆà¸²à¸‡à¸£à¸§à¸”à¹€à¸£à¹‡à¸§à¸à¸±à¸šà¹‚à¸¡à¹€à¸”à¸¥à¸•à¹ˆà¸²à¸‡à¹†
- **à¹‚à¸¡à¹€à¸”à¸¥à¸Šà¸¸à¸¡à¸Šà¸™**: à¹€à¸‚à¹‰à¸²à¸–à¸¶à¸‡à¹‚à¸¡à¹€à¸”à¸¥à¸—à¸µà¹ˆà¸Šà¸¸à¸¡à¸Šà¸™à¸¡à¸µà¸ªà¹ˆà¸§à¸™à¸£à¹ˆà¸§à¸¡à¸¥à¹ˆà¸²à¸ªà¸¸à¸”
- **à¸à¸²à¸£à¹ƒà¸Šà¹‰à¸‡à¸²à¸™à¸”à¹‰à¸²à¸™à¸à¸²à¸£à¸¨à¸¶à¸à¸©à¸²**: à¸à¸²à¸£à¹€à¸£à¸µà¸¢à¸™à¸£à¸¹à¹‰à¹à¸¥à¸°à¸à¸²à¸£à¸ªà¸­à¸™à¸à¸²à¸£à¸žà¸±à¸’à¸™à¸²à¹€à¸­à¹€à¸ˆà¸™à¸•à¹Œ AI
- **à¹‚à¸„à¸£à¸‡à¸à¸²à¸£à¸§à¸´à¸ˆà¸±à¸¢**: à¸à¸²à¸£à¸§à¸´à¸ˆà¸±à¸¢à¸—à¸²à¸‡à¸§à¸´à¸Šà¸²à¸à¸²à¸£à¸—à¸µà¹ˆà¸•à¹‰à¸­à¸‡à¸à¸²à¸£à¸à¸²à¸£à¹€à¸‚à¹‰à¸²à¸–à¸¶à¸‡à¹‚à¸¡à¹€à¸”à¸¥à¸—à¸µà¹ˆà¸«à¸¥à¸²à¸à¸«à¸¥à¸²à¸¢
- **à¹‚à¸¡à¹€à¸”à¸¥à¸—à¸µà¹ˆà¸›à¸£à¸±à¸šà¹à¸•à¹ˆà¸‡à¹€à¸­à¸‡**: à¸à¸²à¸£à¸ªà¸£à¹‰à¸²à¸‡à¹à¸¥à¸°à¸—à¸”à¸ªà¸­à¸šà¹‚à¸¡à¹€à¸”à¸¥à¸—à¸µà¹ˆà¸›à¸£à¸±à¸šà¹à¸•à¹ˆà¸‡à¹€à¸­à¸‡

### VLLM: à¸à¸²à¸£à¸­à¸™à¸¸à¸¡à¸²à¸™ SLM Agent à¸›à¸£à¸°à¸ªà¸´à¸—à¸˜à¸´à¸ à¸²à¸žà¸ªà¸¹à¸‡

VLLM (à¸à¸²à¸£à¸­à¸™à¸¸à¸¡à¸²à¸™à¹‚à¸¡à¹€à¸”à¸¥à¸ à¸²à¸©à¸²à¸‚à¸™à¸²à¸”à¹ƒà¸«à¸à¹ˆà¸¡à¸²à¸) à¹ƒà¸«à¹‰à¹€à¸„à¸£à¸·à¹ˆà¸­à¸‡à¸¡à¸·à¸­à¸­à¸™à¸¸à¸¡à¸²à¸™à¸—à¸µà¹ˆà¸¡à¸µà¸›à¸£à¸°à¸ªà¸´à¸—à¸˜à¸´à¸ à¸²à¸žà¸ªà¸¹à¸‡à¹à¸¥à¸°à¸›à¸£à¸°à¸«à¸¢à¸±à¸”à¸«à¸™à¹ˆà¸§à¸¢à¸„à¸§à¸²à¸¡à¸ˆà¸³ à¸‹à¸¶à¹ˆà¸‡à¹„à¸”à¹‰à¸£à¸±à¸šà¸à¸²à¸£à¸›à¸£à¸±à¸šà¹à¸•à¹ˆà¸‡à¹‚à¸”à¸¢à¹€à¸‰à¸žà¸²à¸°à¸ªà¸³à¸«à¸£à¸±à¸šà¸à¸²à¸£à¸›à¸£à¸±à¸šà¹ƒà¸Šà¹‰ SLM à¹ƒà¸™à¸à¸²à¸£à¸œà¸¥à¸´à¸•à¹ƒà¸™à¸£à¸°à¸”à¸±à¸šà¹ƒà¸«à¸à¹ˆ à¹ƒà¸™à¸‚à¸“à¸°à¸—à¸µà¹ˆ Foundry Local à¹€à¸™à¹‰à¸™à¸„à¸§à¸²à¸¡à¸‡à¹ˆà¸²à¸¢à¹ƒà¸™à¸à¸²à¸£à¹ƒà¸Šà¹‰à¸‡à¸²à¸™à¹à¸¥à¸° Ollama à¹€à¸™à¹‰à¸™à¹‚à¸¡à¹€à¸”à¸¥à¸Šà¸¸à¸¡à¸Šà¸™ VLLM à¹‚à¸”à¸”à¹€à¸”à¹ˆà¸™à¹ƒà¸™à¸ªà¸–à¸²à¸™à¸à¸²à¸£à¸“à¹Œà¸—à¸µà¹ˆà¸•à¹‰à¸­à¸‡à¸à¸²à¸£à¸›à¸£à¸°à¸ªà¸´à¸—à¸˜à¸´à¸ à¸²à¸žà¸ªà¸¹à¸‡à¸ªà¸¸à¸”à¹à¸¥à¸°à¸à¸²à¸£à¹ƒà¸Šà¹‰à¸—à¸£à¸±à¸žà¸¢à¸²à¸à¸£à¸­à¸¢à¹ˆà¸²à¸‡à¸¡à¸µà¸›à¸£à¸°à¸ªà¸´à¸—à¸˜à¸´à¸ à¸²à¸ž

**à¸ªà¸–à¸²à¸›à¸±à¸•à¸¢à¸à¸£à¸£à¸¡à¹à¸¥à¸°à¸„à¸¸à¸“à¸ªà¸¡à¸šà¸±à¸•à¸´à¸«à¸¥à¸±à¸**:
- **PagedAttention**: à¸à¸²à¸£à¸ˆà¸±à¸”à¸à¸²à¸£à¸«à¸™à¹ˆà¸§à¸¢à¸„à¸§à¸²à¸¡à¸ˆà¸³à¸—à¸µà¹ˆà¸›à¸à¸´à¸§à¸±à¸•à¸´à¸§à¸‡à¸à¸²à¸£à¸ªà¸³à¸«à¸£à¸±à¸šà¸à¸²à¸£à¸„à¸³à¸™à¸§à¸“ Attention à¸­à¸¢à¹ˆà¸²à¸‡à¸¡à¸µà¸›à¸£à¸°à¸ªà¸´à¸—à¸˜à¸´à¸ à¸²à¸ž
- **Dynamic Batching**: à¸à¸²à¸£à¸ˆà¸±à¸”à¸à¸¥à¸¸à¹ˆà¸¡à¸„à¸³à¸‚à¸­à¸­à¸¢à¹ˆà¸²à¸‡à¸Šà¸²à¸à¸‰à¸¥à¸²à¸”à¹€à¸žà¸·à¹ˆà¸­à¸›à¸£à¸°à¸ªà¸´à¸—à¸˜à¸´à¸ à¸²à¸žà¸ªà¸¹à¸‡à¸ªà¸¸à¸”
- **à¸à¸²à¸£à¸›à¸£à¸±à¸šà¹à¸•à¹ˆà¸‡ GPU**: à¸à¸²à¸£à¸ªà¸™à¸±à¸šà¸ªà¸™à¸¸à¸™ CUDA kernels à¸‚à¸±à¹‰à¸™à¸ªà¸¹à¸‡à¹à¸¥à¸°à¸à¸²à¸£à¸‚à¸™à¸²à¸™ Tensor
- **à¸„à¸§à¸²à¸¡à¹€à¸‚à¹‰à¸²à¸à¸±à¸™à¹„à¸”à¹‰à¸à¸±à¸š OpenAI**: à¸„à¸§à¸²à¸¡à¹€à¸‚à¹‰à¸²à¸à¸±à¸™à¹„à¸”à¹‰à¸‚à¸­à¸‡ API à¹€à¸•à¹‡à¸¡à¸£à¸¹à¸›à¹à¸šà¸šà¹€à¸žà¸·à¹ˆà¸­à¸à¸²à¸£à¸£à¸§à¸¡à¸—à¸µà¹ˆà¸£à¸²à¸šà¸£à¸·à¹ˆà¸™
- **Speculative Decoding**: à¹€à¸—à¸„à¸™à¸´à¸„à¹€à¸£à¹ˆà¸‡à¸à¸²à¸£à¸­à¸™à¸¸à¸¡à¸²à¸™à¸‚à¸±à¹‰à¸™à¸ªà¸¹à¸‡
- **à¸à¸²à¸£à¸ªà¸™à¸±à¸šà¸ªà¸™à¸¸à¸™ Quantization**: INT4, INT8 à¹à¸¥à¸° FP16 à¸ªà¸³à¸«à¸£à¸±à¸šà¸à¸²à¸£à¸›à¸£à¸°à¸«à¸¢à¸±à¸”à¸«à¸™à¹ˆà¸§à¸¢à¸„à¸§à¸²à¸¡à¸ˆà¸³

#### à¸à¸²à¸£à¸•à¸´à¸”à¸•à¸±à¹‰à¸‡à¹à¸¥à¸°à¸à¸²à¸£à¸•à¸±à¹‰à¸‡à¸„à¹ˆà¸²

**à¸•à¸±à¸§à¹€à¸¥à¸·à¸­à¸à¸à¸²à¸£à¸•à¸´à¸”à¸•à¸±à¹‰à¸‡**:
```bash
# Standard installation
pip install vllm

# With additional dependencies for agent frameworks
pip install vllm[agent] openai

# Docker deployment for production
docker pull vllm/vllm-openai:latest

# From source for latest features
git clone https://github.com/vllm-project/vllm.git
cd vllm
pip install -e .
```

**à¹€à¸£à¸´à¹ˆà¸¡à¸•à¹‰à¸™à¸­à¸¢à¹ˆà¸²à¸‡à¸£à¸§à¸”à¹€à¸£à¹‡à¸§à¸ªà¸³à¸«à¸£à¸±à¸šà¸à¸²à¸£à¸žà¸±à¸’à¸™à¸²à¹€à¸­à¹€à¸ˆà¸™à¸•à¹Œ**:
```bash
# Start VLLM server with SLM model
python -m vllm.entrypoints.openai.api_server \
    --model microsoft/Phi-3.5-mini-instruct \
    --trust-remote-code \
    --max-model-len 4096 \
    --gpu-memory-utilization 0.8

# Alternative: Start with Qwen2.5 for lightweight agents
python -m vllm.entrypoints.openai.api_server \
    --model Qwen/Qwen2.5-0.5B-Instruct \
    --trust-remote-code \
    --max-model-len 2048 \
    --tensor-parallel-size 1

# Test API endpoint
curl http://localhost:8000/v1/models

# Test chat completion
curl http://localhost:8000/v1/chat/completions \
    -H "Content-Type: application/json" \
    -d '{
        "model": "microsoft/Phi-3.5-mini-instruct",
        "messages": [{"role": "user", "content": "Hello!"}]
    }'
```

#### à¸à¸²à¸£à¸£à¸§à¸¡ Agent Framework

**VLLM à¸à¸±à¸š Microsoft Agent Framework**:
```python
from microsoft_agent_framework import Agent, Config
import openai
import subprocess
import time
import requests
from typing import Optional, Dict, Any

class VLLMManager:
    def __init__(self, model_name: str, 
                 host: str = "localhost", 
                 port: int = 8000,
                 gpu_memory_utilization: float = 0.8,
                 max_model_len: int = 4096):
        self.model_name = model_name
        self.host = host
        self.port = port
        self.base_url = f"http://{host}:{port}"
        self.gpu_memory_utilization = gpu_memory_utilization
        self.max_model_len = max_model_len
        self.process = None
        self.client = None
        
    def start_server(self) -> bool:
        """Start VLLM server with optimized settings for agents."""
        try:
            cmd = [
                "python", "-m", "vllm.entrypoints.openai.api_server",
                "--model", self.model_name,
                "--host", self.host,
                "--port", str(self.port),
                "--gpu-memory-utilization", str(self.gpu_memory_utilization),
                "--max-model-len", str(self.max_model_len),
                "--trust-remote-code",
                "--disable-log-requests",  # Reduce logging for agents
                "--served-model-name", self.get_served_model_name()
            ]
            
            self.process = subprocess.Popen(cmd, 
                stdout=subprocess.PIPE, 
                stderr=subprocess.PIPE)
            
            # Wait for server to start
            max_retries = 30
            for _ in range(max_retries):
                if self.health_check():
                    self.client = openai.OpenAI(base_url=f"{self.base_url}/v1")
                    return True
                time.sleep(2)
                
            return False
            
        except Exception as e:
            print(f"Failed to start VLLM server: {e}")
            return False
    
    def get_served_model_name(self) -> str:
        """Get a clean model name for serving."""
        return self.model_name.replace("/", "--")
    
    def health_check(self) -> bool:
        """Check if VLLM server is healthy."""
        try:
            response = requests.get(f"{self.base_url}/health", timeout=5)
            return response.status_code == 200
        except:
            return False
    
    def get_openai_client(self) -> openai.OpenAI:
        """Get OpenAI-compatible client for VLLM."""
        if not self.client:
            self.client = openai.OpenAI(base_url=f"{self.base_url}/v1")
        return self.client
    
    def get_model_info(self) -> Dict[str, Any]:
        """Get model information and statistics."""
        try:
            response = requests.get(f"{self.base_url}/v1/models")
            if response.status_code == 200:
                return response.json()
        except:
            pass
        return {}
    
    def shutdown(self):
        """Shutdown VLLM server."""
        if self.process:
            self.process.terminate()
            self.process.wait()

# Initialize VLLM for high-performance agents
vllm_manager = VLLMManager("microsoft/Phi-3.5-mini-instruct")
if vllm_manager.start_server():
    print("VLLM server started successfully")
    
    # Configure agent with VLLM backend
    agent_config = Config(
        name="vllm-performance-agent",
        model_provider="vllm",
        model_id=vllm_manager.get_served_model_name(),
        endpoint=f"{vllm_manager.base_url}/v1",
        api_key="none"  # VLLM doesn't require API key
    )
    
    agent = Agent(config=agent_config)
else:
    print("Failed to start VLLM server")
```

**à¸à¸²à¸£à¸•à¸±à¹‰à¸‡à¸„à¹ˆà¸²à¸«à¸¥à¸²à¸¢à¹€à¸­à¹€à¸ˆà¸™à¸•à¹Œà¸—à¸µà¹ˆà¸¡à¸µà¸›à¸£à¸°à¸ªà¸´à¸—à¸˜à¸´à¸ à¸²à¸žà¸ªà¸¹à¸‡**:
```python
import asyncio
from concurrent.futures import ThreadPoolExecutor
from microsoft_agent_framework import Agent, Config
import openai

class VLLMHighThroughputManager:
    def __init__(self):
        self.model_configs = {
            "lightweight": {
                "model": "Qwen/Qwen2.5-0.5B-Instruct",
                "port": 8000,
                "max_model_len": 2048,
                "gpu_memory_utilization": 0.3
            },
            "balanced": {
                "model": "microsoft/Phi-3.5-mini-instruct",
                "port": 8001,
                "max_model_len": 4096,
                "gpu_memory_utilization": 0.5
            },
            "capable": {
                "model": "meta-llama/Llama-3.2-3B-Instruct",
                "port": 8002,
                "max_model_len": 8192,
                "gpu_memory_utilization": 0.7
            }
        }
        self.managers = {}
        self.agents = {}
        self.client_pool = {}
        
    async def initialize_all_models(self):
        """Initialize all VLLM models in parallel."""
        initialization_tasks = []
        
        for category, config in self.model_configs.items():
            task = self._initialize_model(category, config)
            initialization_tasks.append(task)
        
        results = await asyncio.gather(*initialization_tasks, return_exceptions=True)
        
        successful_inits = 0
        for i, result in enumerate(results):
            category = list(self.model_configs.keys())[i]
            if isinstance(result, Exception):
                print(f"Failed to initialize {category}: {result}")
            else:
                successful_inits += 1
                print(f"Successfully initialized {category} model")
        
        return successful_inits
    
    async def _initialize_model(self, category: str, config: Dict[str, Any]):
        """Initialize a single VLLM model instance."""
        manager = VLLMManager(
            model_name=config["model"],
            port=config["port"],
            max_model_len=config["max_model_len"],
            gpu_memory_utilization=config["gpu_memory_utilization"]
        )
        
        # Start server in thread to avoid blocking
        loop = asyncio.get_event_loop()
        with ThreadPoolExecutor() as executor:
            success = await loop.run_in_executor(executor, manager.start_server)
        
        if success:
            self.managers[category] = manager
            
            # Create agent
            agent_config = Config(
                name=f"vllm-{category}-agent",
                model_provider="vllm",
                model_id=manager.get_served_model_name(),
                endpoint=f"{manager.base_url}/v1",
                api_key="none"
            )
            
            self.agents[category] = Agent(config=agent_config)
            
            # Create client pool for high throughput
            self.client_pool[category] = [
                openai.OpenAI(base_url=f"{manager.base_url}/v1")
                for _ in range(5)  # 5 clients per model for parallelism
            ]
            
            return True
        else:
            raise Exception(f"Failed to start VLLM server for {category}")
    
    def get_optimal_agent(self, request_complexity: str, current_load: Dict[str, int]) -> str:
        """Select optimal agent based on request complexity and current load."""
        complexity_mapping = {
            "simple": "lightweight",
            "moderate": "balanced", 
            "complex": "capable"
        }
        
        preferred_category = complexity_mapping.get(request_complexity, "balanced")
        
        # Check if preferred agent is available and not overloaded
        if (preferred_category in self.agents and 
            current_load.get(preferred_category, 0) < 10):  # Max 10 concurrent per agent
            return preferred_category
        
        # Fallback to least loaded available agent
        available_agents = [(cat, load) for cat, load in current_load.items() 
                          if cat in self.agents and load < 10]
        
        if available_agents:
            return min(available_agents, key=lambda x: x[1])[0]
        
        return "balanced"  # Default fallback
    
    async def process_batch_requests(self, requests: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """Process multiple requests in parallel for maximum throughput."""
        current_load = {cat: 0 for cat in self.agents.keys()}
        tasks = []
        
        for request in requests:
            # Determine optimal agent
            complexity = request.get("complexity", "moderate")
            agent_category = self.get_optimal_agent(complexity, current_load)
            current_load[agent_category] += 1
            
            # Create processing task
            task = self._process_single_request(request, agent_category)
            tasks.append(task)
        
        # Process all requests in parallel
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # Format results
        formatted_results = []
        for i, result in enumerate(results):
            if isinstance(result, Exception):
                formatted_results.append({
                    "request_id": requests[i].get("id", i),
                    "status": "error",
                    "error": str(result)
                })
            else:
                formatted_results.append(result)
        
        return formatted_results
    
    async def _process_single_request(self, request: Dict[str, Any], agent_category: str) -> Dict[str, Any]:
        """Process a single request with the specified agent."""
        start_time = time.time()
        
        try:
            agent = self.agents[agent_category]
            response = await agent.chat_async(request["message"])
            
            processing_time = time.time() - start_time
            
            return {
                "request_id": request.get("id"),
                "status": "success",
                "response": response,
                "agent_used": agent_category,
                "processing_time": processing_time
            }
            
        except Exception as e:
            return {
                "request_id": request.get("id"),
                "status": "error",
                "error": str(e),
                "agent_used": agent_category,
                "processing_time": time.time() - start_time
            }

# High-throughput usage example
throughput_manager = VLLMHighThroughputManager()

# Initialize all models
initialized_count = await throughput_manager.initialize_all_models()
print(f"Initialized {initialized_count} models")

# Process batch requests
batch_requests = [
    {"id": 1, "message": "Simple question", "complexity": "simple"},
    {"id": 2, "message": "Complex analysis needed", "complexity": "complex"},
    {"id": 3, "message": "Moderate difficulty task", "complexity": "moderate"}
]

results = await throughput_manager.process_batch_requests(batch_requests)
for result in results:
    print(f"Request {result['request_id']}: {result['status']} in {result.get('processing_time', 0):.2f}s")
```

#### à¸£à¸¹à¸›à¹à¸šà¸šà¸à¸²à¸£à¸›à¸£à¸±à¸šà¹ƒà¸Šà¹‰à¹ƒà¸™à¸£à¸°à¸”à¸±à¸šà¸à¸²à¸£à¸œà¸¥à¸´à¸•

**à¸šà¸£à¸´à¸à¸²à¸£à¸à¸²à¸£à¸œà¸¥à¸´à¸• VLLM à¸£à¸°à¸”à¸±à¸šà¸­à¸‡à¸„à¹Œà¸à¸£**:
```python
import asyncio
import logging
import time
from typing import Dict, List, Optional
from dataclasses import dataclass
from microsoft_agent_framework import Agent, Config
import uvicorn
from fastapi import FastAPI, HTTPException, BackgroundTasks
from pydantic import BaseModel

@dataclass
class VLLMServerConfig:
    model_name: str
    port: int
    gpu_memory_utilization: float
    max_model_len: int
    tensor_parallel_size: int = 1
    quantization: Optional[str] = None

class AgentRequest(BaseModel):
    message: str
    agent_type: str = "general"
    priority: str = "normal"
    timeout: int = 30

class VLLMProductionService:
    def __init__(self, server_configs: Dict[str, VLLMServerConfig]):
        self.server_configs = server_configs
        self.managers = {}
        self.agents = {}
        self.metrics = {
            "requests_processed": 0,
            "requests_failed": 0,
            "total_processing_time": 0,
            "agent_usage": {name: 0 for name in server_configs.keys()},
            "throughput_per_minute": 0
        }
        self.request_queue = asyncio.Queue(maxsize=1000)
        self.processing_workers = []
        self.app = FastAPI(title="VLLM Agent Service")
        self._setup_routes()
        
    async def initialize_production_environment(self):
        """Initialize all VLLM servers for production."""
        logging.info("Initializing VLLM production environment...")
        
        initialization_tasks = []
        for name, config in self.server_configs.items():
            task = self._initialize_server(name, config)
            initialization_tasks.append(task)
        
        results = await asyncio.gather(*initialization_tasks, return_exceptions=True)
        
        successful_servers = 0
        for i, result in enumerate(results):
            server_name = list(self.server_configs.keys())[i]
            if isinstance(result, Exception):
                logging.error(f"Failed to initialize {server_name}: {result}")
            else:
                successful_servers += 1
                logging.info(f"Successfully initialized {server_name}")
        
        if successful_servers == 0:
            raise Exception("No VLLM servers could be initialized")
        
        # Start processing workers
        self.processing_workers = [
            asyncio.create_task(self._processing_worker(i))
            for i in range(min(4, successful_servers))  # 4 workers max
        ]
        
        logging.info(f"Production environment ready with {successful_servers} servers")
        return successful_servers
    
    async def _initialize_server(self, name: str, config: VLLMServerConfig):
        """Initialize a single VLLM server."""
        manager = VLLMManager(
            model_name=config.model_name,
            port=config.port,
            gpu_memory_utilization=config.gpu_memory_utilization,
            max_model_len=config.max_model_len
        )
        
        # Add quantization if specified
        if config.quantization:
            # This would be added to the manager's start command
            pass
        
        success = manager.start_server()
        if success:
            self.managers[name] = manager
            
            # Create production agent
            agent_config = Config(
                name=f"vllm-production-{name}",
                model_provider="vllm",
                model_id=manager.get_served_model_name(),
                endpoint=f"{manager.base_url}/v1",
                api_key="none",
                timeout=30.0
            )
            
            agent = Agent(config=agent_config)
            
            # Add production tools
            self._add_production_tools(agent, name)
            
            self.agents[name] = agent
            return True
        else:
            raise Exception(f"Failed to start VLLM server for {name}")
    
    def _add_production_tools(self, agent: Agent, server_type: str):
        """Add production tools based on server type."""
        if server_type == "customer_service":
            @agent.tool
            def escalate_to_human(issue: str, customer_id: str) -> str:
                """Escalate complex issues to human agents."""
                return f"Escalated issue for customer {customer_id}: {issue}"
            
            @agent.tool
            def lookup_order_status(order_id: str) -> dict:
                """Look up order status from production database."""
                # Production database lookup
                return {"order_id": order_id, "status": "shipped", "eta": "2 days"}
        
        elif server_type == "technical_support":
            @agent.tool
            def run_system_diagnostics(system_id: str) -> dict:
                """Run comprehensive system diagnostics."""
                return {"system_id": system_id, "status": "healthy", "issues": []}
            
            @agent.tool
            def create_incident_report(description: str, severity: str) -> str:
                """Create incident report in production system."""
                incident_id = f"INC-{hash(description) % 100000:05d}"
                return f"Created incident {incident_id} with severity {severity}"
    
    def _setup_routes(self):
        """Set up FastAPI routes for production service."""
        @self.app.post("/chat")
        async def chat_endpoint(request: AgentRequest, background_tasks: BackgroundTasks):
            try:
                # Add request to queue
                await self.request_queue.put({
                    "request": request,
                    "timestamp": time.time(),
                    "future": asyncio.Future()
                })
                
                # Wait for processing (with timeout)
                result = await asyncio.wait_for(
                    self._wait_for_result(request),
                    timeout=request.timeout
                )
                
                return result
                
            except asyncio.TimeoutError:
                raise HTTPException(status_code=408, detail="Request timeout")
            except Exception as e:
                raise HTTPException(status_code=500, detail=str(e))
        
        @self.app.get("/health")
        async def health_endpoint():
            return await self.get_health_status()
        
        @self.app.get("/metrics")
        async def metrics_endpoint():
            return self.get_production_metrics()
    
    async def _processing_worker(self, worker_id: int):
        """Background worker for processing agent requests."""
        logging.info(f"Starting processing worker {worker_id}")
        
        while True:
            try:
                # Get request from queue
                queue_item = await self.request_queue.get()
                request_data = queue_item["request"]
                request_future = queue_item["future"]
                
                # Select appropriate agent
                agent_name = self._select_agent(request_data.agent_type)
                
                if agent_name not in self.agents:
                    request_future.set_exception(Exception(f"Agent {agent_name} not available"))
                    continue
                
                # Process request
                start_time = time.time()
                try:
                    agent = self.agents[agent_name]
                    response = await agent.chat_async(request_data.message)
                    
                    processing_time = time.time() - start_time
                    
                    # Update metrics
                    self.metrics["requests_processed"] += 1
                    self.metrics["total_processing_time"] += processing_time
                    self.metrics["agent_usage"][agent_name] += 1
                    
                    result = {
                        "response": response,
                        "agent_used": agent_name,
                        "processing_time": processing_time,
                        "worker_id": worker_id
                    }
                    
                    request_future.set_result(result)
                    
                except Exception as e:
                    self.metrics["requests_failed"] += 1
                    request_future.set_exception(e)
                
                finally:
                    self.request_queue.task_done()
                    
            except Exception as e:
                logging.error(f"Worker {worker_id} error: {e}")
                await asyncio.sleep(1)
    
    def _select_agent(self, agent_type: str) -> str:
        """Select appropriate agent based on request type."""
        agent_mapping = {
            "customer_service": "customer_service",
            "technical": "technical_support",
            "general": "general_purpose"
        }
        
        return agent_mapping.get(agent_type, "general_purpose")
    
    async def _wait_for_result(self, request: AgentRequest):
        """Wait for request processing to complete."""
        # This is simplified - in production you'd track futures properly
        await asyncio.sleep(0.1)  # Placeholder
        return {"response": "Processed", "status": "success"}
    
    async def get_health_status(self) -> dict:
        """Get comprehensive health status of all services."""
        health_status = {
            "overall_status": "healthy",
            "servers": {},
            "queue_size": self.request_queue.qsize(),
            "active_workers": len([w for w in self.processing_workers if not w.done()]),
            "timestamp": time.time()
        }
        
        unhealthy_servers = 0
        for name, manager in self.managers.items():
            try:
                is_healthy = manager.health_check()
                health_status["servers"][name] = {
                    "status": "healthy" if is_healthy else "unhealthy",
                    "endpoint": manager.base_url,
                    "model": manager.model_name
                }
                if not is_healthy:
                    unhealthy_servers += 1
            except Exception as e:
                health_status["servers"][name] = {
                    "status": "error",
                    "error": str(e)
                }
                unhealthy_servers += 1
        
        if unhealthy_servers > 0:
            health_status["overall_status"] = "degraded" if unhealthy_servers < len(self.managers) else "unhealthy"
        
        return health_status
    
    def get_production_metrics(self) -> dict:
        """Get production performance metrics."""
        total_requests = self.metrics["requests_processed"] + self.metrics["requests_failed"]
        avg_processing_time = (
            self.metrics["total_processing_time"] / self.metrics["requests_processed"]
            if self.metrics["requests_processed"] > 0 else 0
        )
        
        success_rate = (
            self.metrics["requests_processed"] / total_requests * 100
            if total_requests > 0 else 0
        )
        
        return {
            "total_requests": total_requests,
            "successful_requests": self.metrics["requests_processed"],
            "failed_requests": self.metrics["requests_failed"],
            "success_rate_percent": success_rate,
            "average_processing_time_seconds": avg_processing_time,
            "agent_usage_distribution": self.metrics["agent_usage"],
            "queue_size": self.request_queue.qsize()
        }
    
    async def start_production_server(self, host: str = "0.0.0.0", port: int = 8080):
        """Start the production FastAPI server."""
        config = uvicorn.Config(
            self.app,
            host=host,
            port=port,
            log_level="info",
            workers=1  # Single worker for simplicity
        )
        server = uvicorn.Server(config)
        await server.serve()

# Production deployment example
production_configs = {
    "customer_service": VLLMServerConfig(
        model_name="microsoft/Phi-3.5-mini-instruct",
        port=8000,
        gpu_memory_utilization=0.4,
        max_model_len=4096
    ),
    "technical_support": VLLMServerConfig(
        model_name="meta-llama/Llama-3.2-3B-Instruct",
        port=8001,
        gpu_memory_utilization=0.6,
        max_model_len=8192
    ),
    "general_purpose": VLLMServerConfig(
        model_name="Qwen/Qwen2.5-1.5B-Instruct",
        port=8002,
        gpu_memory_utilization=0.3,
        max_model_len=2048
    )
}

production_service = VLLMProductionService(production_configs)

# Initialize and start production service
# await production_service.initialize_production_environment()
# await production_service.start_production_server()
```

#### à¸„à¸¸à¸“à¸ªà¸¡à¸šà¸±à¸•à¸´à¸£à¸°à¸”à¸±à¸šà¸­à¸‡à¸„à¹Œà¸à¸£à¹à¸¥à¸°à¸à¸²à¸£à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸š

**à¸à¸²à¸£à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸šà¸›à¸£à¸°à¸ªà¸´à¸—à¸˜à¸´à¸ à¸²à¸ž VLLM à¸‚à¸±à¹‰à¸™à¸ªà¸¹à¸‡**:
```python
import psutil
import nvidia_ml_py3 as nvml
from dataclasses import dataclass
from typing import List, Dict, Optional
import json
import asyncio

@dataclass
class PerformanceMetrics:
    timestamp: float
    requests_per_second: float
    average_latency_ms: float
    gpu_utilization_percent: float
    gpu_memory_used_gb: float
    cpu_utilization_percent: float
    memory_used_gb: float
    queue_length: int
    active_requests: int

class VLLMAdvancedMonitoring:
    def __init__(self, vllm_managers: Dict[str, VLLMManager]):
        self.managers = vllm_managers
        self.metrics_history = []
        self.alert_thresholds = {
            "gpu_utilization_max": 95,
            "gpu_memory_max_gb": 10,
            "latency_max_ms": 3000,
            "queue_length_max": 50,
            "error_rate_max_percent": 10
        }
        
        # Initialize NVIDIA ML for GPU monitoring
        try:
            nvml.nvmlInit()
            self.gpu_monitoring_available = True
            self.gpu_count = nvml.nvmlDeviceGetCount()
        except:
            self.gpu_monitoring_available = False
            self.gpu_count = 0
    
    async def collect_comprehensive_metrics(self) -> Dict[str, PerformanceMetrics]:
        """Collect detailed performance metrics for all VLLM instances."""
        all_metrics = {}
        
        for name, manager in self.managers.items():
            try:
                metrics = await self._collect_single_instance_metrics(name, manager)
                all_metrics[name] = metrics
            except Exception as e:
                logging.error(f"Failed to collect metrics for {name}: {e}")
                # Create error metrics
                all_metrics[name] = PerformanceMetrics(
                    timestamp=time.time(),
                    requests_per_second=0,
                    average_latency_ms=0,
                    gpu_utilization_percent=0,
                    gpu_memory_used_gb=0,
                    cpu_utilization_percent=0,
                    memory_used_gb=0,
                    queue_length=0,
                    active_requests=0
                )
        
        return all_metrics
    
    async def _collect_single_instance_metrics(self, name: str, manager: VLLMManager) -> PerformanceMetrics:
        """Collect metrics for a single VLLM instance."""
        timestamp = time.time()
        
        # Get VLLM-specific metrics via API
        vllm_stats = await self._get_vllm_stats(manager)
        
        # Get system metrics
        cpu_percent = psutil.cpu_percent(interval=0.1)
        memory_info = psutil.virtual_memory()
        memory_used_gb = memory_info.used / (1024**3)
        
        # Get GPU metrics if available
        gpu_utilization = 0
        gpu_memory_used = 0
        
        if self.gpu_monitoring_available and self.gpu_count > 0:
            try:
                # Assuming first GPU for simplicity
                handle = nvml.nvmlDeviceGetHandleByIndex(0)
                gpu_util = nvml.nvmlDeviceGetUtilizationRates(handle)
                gpu_utilization = gpu_util.gpu
                
                gpu_mem = nvml.nvmlDeviceGetMemoryInfo(handle)
                gpu_memory_used = gpu_mem.used / (1024**3)
                
            except Exception as e:
                logging.warning(f"GPU monitoring failed: {e}")
        
        return PerformanceMetrics(
            timestamp=timestamp,
            requests_per_second=vllm_stats.get("requests_per_second", 0),
            average_latency_ms=vllm_stats.get("average_latency_ms", 0),
            gpu_utilization_percent=gpu_utilization,
            gpu_memory_used_gb=gpu_memory_used,
            cpu_utilization_percent=cpu_percent,
            memory_used_gb=memory_used_gb,
            queue_length=vllm_stats.get("queue_length", 0),
            active_requests=vllm_stats.get("active_requests", 0)
        )
    
    async def _get_vllm_stats(self, manager: VLLMManager) -> dict:
        """Get VLLM-specific statistics via API calls."""
        try:
            # Test inference to measure latency
            start_time = time.time()
            client = manager.get_openai_client()
            
            response = await asyncio.wait_for(
                asyncio.to_thread(
                    client.chat.completions.create,
                    model=manager.get_served_model_name(),
                    messages=[{"role": "user", "content": "ping"}],
                    max_tokens=1
                ),
                timeout=5.0
            )
            
            latency_ms = (time.time() - start_time) * 1000
            
            return {
                "average_latency_ms": latency_ms,
                "requests_per_second": 1000 / latency_ms if latency_ms > 0 else 0,
                "queue_length": 0,  # Would need to be exposed by VLLM
                "active_requests": 1  # Approximation
            }
            
        except Exception as e:
            logging.warning(f"Failed to get VLLM stats: {e}")
            return {
                "average_latency_ms": 0,
                "requests_per_second": 0,
                "queue_length": 0,
                "active_requests": 0
            }
    
    def generate_performance_report(self, time_window_minutes: int = 60) -> dict:
        """Generate comprehensive performance report."""
        cutoff_time = time.time() - (time_window_minutes * 60)
        recent_metrics = [
            metrics for metrics in self.metrics_history
            if any(m.timestamp > cutoff_time for m in metrics.values())
        ]
        
        if not recent_metrics:
            return {"error": "No recent metrics available"}
        
        report = {
            "time_window_minutes": time_window_minutes,
            "total_samples": len(recent_metrics),
            "instances": {}
        }
        
        # Analyze each instance
        for instance_name in self.managers.keys():
            instance_metrics = [
                metrics[instance_name] for metrics in recent_metrics
                if instance_name in metrics
            ]
            
            if instance_metrics:
                report["instances"][instance_name] = {
                    "avg_latency_ms": sum(m.average_latency_ms for m in instance_metrics) / len(instance_metrics),
                    "max_latency_ms": max(m.average_latency_ms for m in instance_metrics),
                    "avg_gpu_utilization": sum(m.gpu_utilization_percent for m in instance_metrics) / len(instance_metrics),
                    "avg_requests_per_second": sum(m.requests_per_second for m in instance_metrics) / len(instance_metrics),
                    "max_queue_length": max(m.queue_length for m in instance_metrics),
                    "availability_percent": (len(instance_metrics) / len(recent_metrics)) * 100
                }
        
        return report
    
    async def auto_scaling_recommendations(self) -> List[dict]:
        """Generate auto-scaling recommendations based on performance metrics."""
        recommendations = []
        
        if not self.metrics_history:
            return recommendations
        
        latest_metrics = self.metrics_history[-1]
        
        for instance_name, metrics in latest_metrics.items():
            # High latency recommendation
            if metrics.average_latency_ms > self.alert_thresholds["latency_max_ms"]:
                recommendations.append({
                    "instance": instance_name,
                    "type": "scale_up",
                    "reason": f"High latency: {metrics.average_latency_ms:.0f}ms",
                    "suggestion": "Consider adding tensor parallelism or increasing GPU memory"
                })
            
            # High GPU utilization recommendation
            if metrics.gpu_utilization_percent > self.alert_thresholds["gpu_utilization_max"]:
                recommendations.append({
                    "instance": instance_name,
                    "type": "scale_out",
                    "reason": f"High GPU utilization: {metrics.gpu_utilization_percent:.1f}%",
                    "suggestion": "Consider adding additional GPU instances"
                })
            
            # Low utilization recommendation
            if (metrics.gpu_utilization_percent < 20 and 
                metrics.requests_per_second < 1):
                recommendations.append({
                    "instance": instance_name,
                    "type": "scale_down",
                    "reason": f"Low utilization: {metrics.gpu_utilization_percent:.1f}% GPU, {metrics.requests_per_second:.1f} RPS",
                    "suggestion": "Consider consolidating workloads or reducing resources"
                })
        
        return recommendations

# Advanced monitoring setup
monitoring = VLLMAdvancedMonitoring({
    "customer_service": vllm_manager,
    # Add other managers as needed
})

async def advanced_monitoring_loop():
    """Advanced monitoring with auto-scaling recommendations."""
    while True:
        try:
            # Collect metrics
            metrics = await monitoring.collect_comprehensive_metrics()
            monitoring.metrics_history.append(metrics)
            
            # Keep only last 1000 entries
            if len(monitoring.metrics_history) > 1000:
                monitoring.metrics_history = monitoring.metrics_history[-1000:]
            
            # Generate recommendations every 5 minutes
            if len(monitoring.metrics_history) % 10 == 0:  # Every 10th collection (5 minutes if collecting every 30s)
                recommendations = await monitoring.auto_scaling_recommendations()
                
                if recommendations:
                    logging.info(f"Auto-scaling recommendations: {recommendations}")
            
            # Generate performance report every hour
            if len(monitoring.metrics_history) % 120 == 0:  # Every 120th collection (1 hour)
                report = monitoring.generate_performance_report(60)
                logging.info(f"Performance report: {json.dumps(report, indent=2)}")
            
        except Exception as e:
            logging.error(f"Advanced monitoring error: {e}")
        
        await asyncio.sleep(30)  # Collect metrics every 30 seconds

# Start advanced monitoring
# asyncio.create_task(advanced_monitoring_loop())
```

#### à¸à¸²à¸£à¸•à¸±à¹‰à¸‡à¸„à¹ˆà¸²à¹à¸¥à¸°à¸à¸²à¸£à¸›à¸£à¸±à¸šà¹à¸•à¹ˆà¸‡à¸‚à¸±à¹‰à¸™à¸ªà¸¹à¸‡

**à¹à¸¡à¹ˆà¹à¸šà¸šà¸à¸²à¸£à¸•à¸±à¹‰à¸‡à¸„à¹ˆà¸²à¸à¸²à¸£à¸œà¸¥à¸´à¸• VLLM**:
```python
from enum import Enum
from typing import Dict, Any

class DeploymentScenario(Enum):
    DEVELOPMENT = "development"
    STAGING = "staging"
    PRODUCTION_LOW = "production_low"
    PRODUCTION_HIGH = "production_high"
    ENTERPRISE = "enterprise"

class VLLMConfigTemplates:
    """Production-ready VLLM configuration templates."""
    
    @staticmethod
    def get_config_template(scenario: DeploymentScenario) -> Dict[str, Any]:
        """Get optimized configuration for deployment scenario."""
        
        templates = {
            DeploymentScenario.DEVELOPMENT: {
                "gpu_memory_utilization": 0.6,
                "max_model_len": 2048,
                "tensor_parallel_size": 1,
                "pipeline_parallel_size": 1,
                "quantization": None,
                "enable_prefix_caching": False,
                "max_num_seqs": 32,
                "max_num_batched_tokens": 2048
            },
            
            DeploymentScenario.STAGING: {
                "gpu_memory_utilization": 0.8,
                "max_model_len": 4096,
                "tensor_parallel_size": 1,
                "pipeline_parallel_size": 1,
                "quantization": "awq",
                "enable_prefix_caching": True,
                "max_num_seqs": 64,
                "max_num_batched_tokens": 4096
            },
            
            DeploymentScenario.PRODUCTION_LOW: {
                "gpu_memory_utilization": 0.85,
                "max_model_len": 4096,
                "tensor_parallel_size": 1,
                "pipeline_parallel_size": 1,
                "quantization": "awq",
                "enable_prefix_caching": True,
                "max_num_seqs": 128,
                "max_num_batched_tokens": 8192,
                "enable_chunked_prefill": True
            },
            
            DeploymentScenario.PRODUCTION_HIGH: {
                "gpu_memory_utilization": 0.9,
                "max_model_len": 8192,
                "tensor_parallel_size": 2,
                "pipeline_parallel_size": 1,
                "quantization": "awq",
                "enable_prefix_caching": True,
                "max_num_seqs": 256,
                "max_num_batched_tokens": 16384,
                "enable_chunked_prefill": True,
                "speculative_model": "small_draft_model"
            },
            
            DeploymentScenario.ENTERPRISE: {
                "gpu_memory_utilization": 0.95,
                "max_model_len": 16384,
                "tensor_parallel_size": 4,
                "pipeline_parallel_size": 2,
                "quantization": "awq",
                "enable_prefix_caching": True,
                "max_num_seqs": 512,
                "max_num_batched_tokens": 32768,
                "enable_chunked_prefill": True,
                "speculative_model": "optimized_draft_model",
                "guided_decoding_backend": "outlines"
            }
        }
        
        return templates[scenario]
    
    @staticmethod
    def generate_vllm_command(model_name: str, 
                             scenario: DeploymentScenario,
                             port: int = 8000,
                             host: str = "0.0.0.0") -> List[str]:
        """Generate optimized VLLM command for deployment scenario."""
        
        config = VLLMConfigTemplates.get_config_template(scenario)
        
        cmd = [
            "python", "-m", "vllm.entrypoints.openai.api_server",
            "--model", model_name,
            "--host", host,
            "--port", str(port),
            "--gpu-memory-utilization", str(config["gpu_memory_utilization"]),
            "--max-model-len", str(config["max_model_len"]),
            "--tensor-parallel-size", str(config["tensor_parallel_size"]),
            "--max-num-seqs", str(config["max_num_seqs"]),
            "--max-num-batched-tokens", str(config["max_num_batched_tokens"]),
            "--trust-remote-code",
            "--disable-log-requests"
        ]
        
        # Add optional parameters
        if config.get("quantization"):
            cmd.extend(["--quantization", config["quantization"]])
        
        if config.get("enable_prefix_caching"):
            cmd.append("--enable-prefix-caching")
        
        if config.get("enable_chunked_prefill"):
            cmd.append("--enable-chunked-prefill")
        
        if config.get("pipeline_parallel_size", 1) > 1:
            cmd.extend(["--pipeline-parallel-size", str(config["pipeline_parallel_size"])])
        
        if config.get("speculative_model"):
            cmd.extend(["--speculative-model", config["speculative_model"]])
        
        return cmd

# Usage examples
dev_cmd = VLLMConfigTemplates.generate_vllm_command(
    "microsoft/Phi-3.5-mini-instruct",
    DeploymentScenario.DEVELOPMENT,
    port=8000
)

prod_cmd = VLLMConfigTemplates.generate_vllm_command(
    "microsoft/Phi-3.5-mini-instruct",
    DeploymentScenario.PRODUCTION_HIGH,
    port=8001
)

print(f"Development command: {' '.join(dev_cmd)}")
print(f"Production command: {' '.join(prod_cmd)}")
```

**à¸£à¸²à¸¢à¸à¸²à¸£à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸šà¸à¸²à¸£à¸›à¸£à¸±à¸šà¹ƒà¸Šà¹‰à¸à¸²à¸£à¸œà¸¥à¸´à¸•à¸ªà¸³à¸«à¸£à¸±à¸š VLLM**:

âœ… **à¸à¸²à¸£à¸›à¸£à¸±à¸šà¹à¸•à¹ˆà¸‡à¸®à¸²à¸£à¹Œà¸”à¹à¸§à¸£à¹Œ**:
- à¸•à¸±à¹‰à¸‡à¸„à¹ˆà¸²à¸à¸²à¸£à¸‚à¸™à¸²à¸™ Tensor à¸ªà¸³à¸«à¸£à¸±à¸šà¸à¸²à¸£à¸•à¸±à¹‰à¸‡à¸„à¹ˆà¸²à¸«à¸¥à¸²à¸¢ GPU
- à¹€à¸›à¸´à¸”à¹ƒà¸Šà¹‰à¸‡à¸²à¸™ Quantization (AWQ/GPTQ) à¹€à¸žà¸·à¹ˆà¸­à¸›à¸£à¸°à¸«à¸¢à¸±à¸”à¸«à¸™à¹ˆà¸§à¸¢à¸„à¸§à¸²à¸¡à¸ˆà¸³
- à¸•à¸±à¹‰à¸‡à¸„à¹ˆà¸²à¸à¸²à¸£à¹ƒà¸Šà¹‰à¸«à¸™à¹ˆà¸§à¸¢à¸„à¸§à¸²à¸¡à¸ˆà¸³ GPU à¸—à¸µà¹ˆà¹€à¸«à¸¡à¸²à¸°à¸ªà¸¡ (85-95%)
- à¸à¸³à¸«à¸™à¸”à¸‚à¸™à¸²à¸”à¸à¸¥à¸¸à¹ˆà¸¡à¸—à¸µà¹ˆà¹€à¸«à¸¡à¸²à¸°à¸ªà¸¡à¸ªà¸³à¸«à¸£à¸±à¸šà¸›à¸£à¸°à¸ªà¸´à¸—à¸˜à¸´à¸ à¸²à¸ž

âœ… **à¸à¸²à¸£à¸›à¸£à¸±à¸šà¹à¸•à¹ˆà¸‡à¸›à¸£à¸°à¸ªà¸´à¸—à¸˜à¸´à¸ à¸²à¸ž**:
- à¹€à¸›à¸´à¸”à¹ƒà¸Šà¹‰à¸‡à¸²à¸™à¸à¸²à¸£à¹à¸„à¸Š Prefix à¸ªà¸³à¸«à¸£à¸±à¸šà¸„à¸³à¸–à¸²à¸¡à¸‹à¹‰à¸³
- à¸•à¸±à¹‰à¸‡à¸„à¹ˆà¸²à¸à¸²à¸£à¹€à¸•à¸´à¸¡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¹à¸šà¸š Chunked à¸ªà¸³à¸«à¸£à¸±à¸šà¸¥à¸³à¸”à¸±à¸šà¸¢à¸²à¸§
- à¸•à¸±à¹‰à¸‡à¸„à¹ˆà¸²à¸à¸²à¸£à¸­à¸™à¸¸à¸¡à¸²à¸™ Speculative à¹€à¸žà¸·à¹ˆà¸­à¸à¸²à¸£à¸•à¸­à¸šà¸ªà¸™à¸­à¸‡à¸—à¸µà¹ˆà¹€à¸£à¹‡à¸§à¸‚à¸¶à¹‰à¸™
- à¸›à¸£à¸±à¸šà¹à¸•à¹ˆà¸‡ max_num_seqs à¸•à¸²à¸¡à¸®à¸²à¸£à¹Œà¸”à¹à¸§à¸£à¹Œ

âœ… **à¸„à¸¸à¸“à¸ªà¸¡à¸šà¸±à¸•à¸´à¸à¸²à¸£à¸œà¸¥à¸´à¸•**:
- à¸•à¸±à¹‰à¸‡à¸„à¹ˆà¸²à¸à¸²à¸£à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸šà¸ªà¸¸à¸‚à¸ à¸²à¸žà¹à¸¥à¸°à¸à¸²à¸£à¸£à¸§à¸šà¸£à¸§à¸¡à¹€à¸¡à¸•à¸£à¸´à¸
- à¸à¸³à¸«à¸™à¸”à¸à¸²à¸£à¸£à¸µà¸ªà¸•à¸²à¸£à¹Œà¸—à¹à¸¥à¸°à¸à¸²à¸£à¸ªà¸³à¸£à¸­à¸‡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸­à¸±à¸•à¹‚à¸™à¸¡à¸±à¸•à¸´
- à¹ƒà¸Šà¹‰à¸à¸²à¸£à¸ˆà¸±à¸”à¸„à¸´à¸§à¸„à¸³à¸‚à¸­à¹à¸¥à¸°à¸à¸²à¸£à¸›à¸£à¸±à¸šà¸ªà¸¡à¸”à¸¸à¸¥à¹‚à¸«à¸¥à¸”
- à¸•à¸±à¹‰à¸‡à¸„à¹ˆà¸²à¸à¸²à¸£à¸šà¸±à¸™à¸—à¸¶à¸à¹à¸¥à¸°à¸à¸²à¸£à¹à¸ˆà¹‰à¸‡à¹€à¸•à¸·à¸­à¸™à¸—à¸µà¹ˆà¸„à¸£à¸­à¸šà¸„à¸¥à¸¸à¸¡

âœ… **à¸„à¸§à¸²à¸¡à¸›à¸¥à¸­à¸”à¸ à¸±à¸¢à¹à¸¥à¸°à¸„à¸§à¸²à¸¡à¸™à¹ˆà¸²à¹€à¸Šà¸·à¹ˆà¸­à¸–à¸·à¸­**:
- à¸à¸³à¸«à¸™à¸”à¸à¸Žà¹„à¸Ÿà¸£à¹Œà¸§à¸­à¸¥à¸¥à¹Œà¹à¸¥à¸°à¸à¸²à¸£à¸„à¸§à¸šà¸„à¸¸à¸¡à¸à¸²à¸£à¹€à¸‚à¹‰à¸²à¸–à¸¶à¸‡
- à¸•à¸±à¹‰à¸‡à¸„à¹ˆà¸²à¸à¸²à¸£à¸ˆà¸³à¸à¸±à¸”à¸­à¸±à¸•à¸£à¸² API à¹à¸¥à¸°à¸à¸²à¸£à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸šà¸ªà¸´à¸—à¸˜à¸´à¹Œ
- à¹ƒà¸Šà¹‰à¸à¸²à¸£à¸›à¸´à¸”à¸£à¸°à¸šà¸šà¹à¸¥à¸°à¸à¸²à¸£à¸¥à¹‰à¸²à¸‡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸­à¸¢à¹ˆà¸²à¸‡à¸£à¸²à¸šà¸£à¸·à¹ˆà¸™
- à¸à¸³à¸«à¸™à¸”à¸à¸²à¸£à¸ªà¸³à¸£à¸­à¸‡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¹à¸¥à¸°à¸à¸²à¸£à¸à¸¹à¹‰à¸„à¸·à¸™à¸ˆà¸²à¸à¸ à¸±à¸¢à¸žà¸´à¸šà¸±à¸•à¸´

âœ… **à¸à¸²à¸£à¸—à¸”à¸ªà¸­à¸šà¸à¸²à¸£à¸£à¸§à¸¡**:
- à¸—à¸”à¸ªà¸­à¸šà¸à¸²à¸£à¸£à¸§à¸¡ Microsoft Agent Framework
- à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸šà¸ªà¸–à¸²à¸™à¸à¸²à¸£à¸“à¹Œà¸—à¸µà¹ˆà¸¡à¸µà¸›à¸£à¸°à¸ªà¸´à¸—à¸˜à¸´à¸ à¸²à¸žà¸ªà¸¹à¸‡
- à¸—à¸”à¸ªà¸­à¸šà¸‚à¸±à¹‰à¸™à¸•à¸­à¸™à¸à¸²à¸£à¸ªà¸³à¸£à¸­à¸‡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¹à¸¥à¸°à¸à¸²à¸£à¸à¸¹à¹‰à¸„à¸·à¸™
- à¸§à¸±à¸”à¸›à¸£à¸°à¸ªà¸´à¸—à¸˜à¸´à¸ à¸²à¸žà¸ à¸²à¸¢à¹ƒà¸•à¹‰à¹‚à¸«à¸¥à¸”

**à¹€à¸›à¸£à¸µà¸¢à¸šà¹€à¸—à¸µà¸¢à¸šà¸à¸±à¸šà¹‚à¸‹à¸¥à¸¹à¸Šà¸±à¸™à¸­à¸·à¹ˆà¸™à¹†**:

| à¸„à¸¸à¸“à¸ªà¸¡à¸šà¸±à¸•à¸´ | VLLM | Foundry Local | Ollama |
|-----------|------|---------------|--------|
| **à¸à¸£à¸“à¸µà¸à¸²à¸£à¹ƒà¸Šà¹‰à¸‡à¸²à¸™à¹€à¸›à¹‰à¸²à¸«à¸¡à¸²à¸¢** | à¸à¸²à¸£à¸œà¸¥à¸´à¸•à¸—à¸µà¹ˆà¸¡à¸µà¸›à¸£à¸°à¸ªà¸´à¸—à¸˜à¸´à¸ à¸²à¸žà¸ªà¸¹à¸‡ | à¸„à¸§à¸²à¸¡à¸‡à¹ˆà¸²à¸¢à¹ƒà¸™à¸à¸²à¸£à¹ƒà¸Šà¹‰à¸‡à¸²à¸™à¸£à¸°à¸”à¸±à¸šà¸­à¸‡à¸„à¹Œà¸à¸£ | à¸à¸²à¸£à¸žà¸±à¸’à¸™à¸²à¹à¸¥à¸°à¸Šà¸¸à¸¡à¸Šà¸™ |
| **à¸›à¸£à¸°à¸ªà¸´à¸—à¸˜à¸´à¸ à¸²à¸ž** | à¸›à¸£à¸°à¸ªà¸´à¸—à¸˜à¸´à¸ à¸²à¸žà¸ªà¸¹à¸‡à¸ªà¸¸à¸” | à¸ªà¸¡à¸”à¸¸à¸¥ | à¸”à¸µ |
| **à¸›à¸£à¸°à¸ªà¸´à¸—à¸˜à¸´à¸ à¸²à¸žà¸«à¸™à¹ˆà¸§à¸¢à¸„à¸§à¸²à¸¡à¸ˆà¸³** | à¸à¸²à¸£à¸›à¸£à¸±à¸šà¹à¸•à¹ˆà¸‡ PagedAttention | à¸à¸²à¸£à¸›à¸£à¸±à¸šà¹à¸•à¹ˆà¸‡à¸­à¸±à¸•à¹‚à¸™à¸¡à¸±à¸•à¸´ | à¸¡à¸²à¸•à¸£à¸à¸²à¸™ |
| **à¸„à¸§à¸²à¸¡à¸‹à¸±à¸šà¸‹à¹‰à¸­à¸™à¹ƒà¸™à¸à¸²à¸£à¸•à¸±à¹‰à¸‡à¸„à¹ˆà¸²** | à¸ªà¸¹à¸‡ (à¸žà¸²à¸£à¸²à¸¡à¸´à¹€à¸•à¸­à¸£à¹Œà¸¡à¸²à¸à¸¡à¸²à¸¢) | à¸•à¹ˆà¸³ (à¸­à¸±à¸•à¹‚à¸™à¸¡à¸±à¸•à¸´) | à¸•à¹ˆà¸³ (à¸‡à¹ˆà¸²à¸¢) |
| **à¸„à¸§à¸²à¸¡à¸ªà¸²à¸¡à¸²à¸£à¸–à¹ƒà¸™à¸à¸²à¸£à¸›à¸£à¸±à¸šà¸‚à¸¢à¸²à¸¢** | à¸¢à¸­à¸”à¹€à¸¢à¸µà¹ˆà¸¢à¸¡ (à¸à¸²à¸£à¸‚à¸™à¸²à¸™ Tensor/à¸—à¹ˆà¸­) | à¸”à¸µ | à¸ˆà¸³à¸à¸±à¸” |
| **Quantization** | à¸‚à¸±à¹‰à¸™à¸ªà¸¹à¸‡ (AWQ, GPTQ, FP8) | à¸­à¸±à¸•à¹‚à¸™à¸¡à¸±à¸•à¸´ | à¸¡à¸²à¸•à¸£à¸à¸²à¸™ GGUF |
| **à¸„à¸¸à¸“à¸ªà¸¡à¸šà¸±à¸•à¸´à¸£à¸°à¸”à¸±à¸šà¸­à¸‡à¸„à¹Œà¸à¸£** | à¸•à¹‰à¸­à¸‡à¸à¸²à¸£à¸à¸²à¸£à¸›à¸£à¸±à¸šà¹à¸•à¹ˆà¸‡à¹€à¸­à¸‡ | à¸¡à¸µà¹ƒà¸™à¸•à¸±à¸§ | à¹€à¸„à¸£à¸·à¹ˆà¸­à¸‡à¸¡à¸·à¸­à¸Šà¸¸à¸¡à¸Šà¸™ |
| **à¹€à¸«à¸¡à¸²à¸°à¸ªà¸³à¸«à¸£à¸±à¸š** | à¹€à¸­à¹€à¸ˆà¸™à¸•à¹Œà¸à¸²à¸£à¸œà¸¥à¸´à¸•à¹ƒà¸™à¸£à¸°à¸”à¸±à¸šà¹ƒà¸«à¸à¹ˆ | à¸à¸²à¸£à¸œà¸¥à¸´à¸•à¸£à¸°à¸”à¸±à¸šà¸­à¸‡à¸„à¹Œà¸à¸£ | à¸à¸²à¸£à¸žà¸±à¸’à¸™à¸² |

**à¹€à¸¡à¸·à¹ˆà¸­à¸„à¸§à¸£à¹€à¸¥à¸·à¸­à¸ VLLM**:
- **à¸„à¸§à¸²à¸¡à¸•à¹‰à¸­à¸‡à¸à¸²à¸£à¸›à¸£à¸°à¸ªà¸´à¸—à¸˜à¸´à¸ à¸²à¸žà¸ªà¸¹à¸‡**: à¸à¸²à¸£à¸›à¸£à¸°à¸¡à¸§à¸¥à¸œà¸¥à¸„à¸³à¸‚à¸­à¸«à¸¥à¸²à¸¢à¸£à¹‰à¸­à¸¢à¸„à¸³à¸•à¹ˆà¸­à¸§à¸´à¸™à¸²à¸—à¸µ
- **à¸à¸²à¸£à¸›à¸£à¸±à¸šà¹ƒà¸Šà¹‰à¹ƒà¸™à¸£à¸°à¸”à¸±à¸šà¹ƒà¸«à¸à¹ˆ**: à¸à¸²à¸£à¸›à¸£à¸±à¸šà¹ƒà¸Šà¹‰à¸«à¸¥à¸²à¸¢ GPU à¹à¸¥à¸°à¸«à¸¥à¸²à¸¢à¹‚à¸«à¸™à¸”
- **à¸„à¸§à¸²à¸¡à¸ªà¸³à¸„à¸±à¸à¸”à¹‰à¸²à¸™à¸›à¸£à¸°à¸ªà¸´à¸—à¸˜à¸´à¸ à¸²à¸ž**: à¹€à¸§à¸¥à¸²à¸•à¸­à¸šà¸ªà¸™à¸­à¸‡à¸•à¹ˆà¸³à¸à¸§à¹ˆà¸² 1 à¸§à¸´à¸™à¸²à¸—à¸µà¹ƒà¸™à¸£à¸°à¸”à¸±à¸šà¹ƒà¸«à¸à¹ˆ
- **à¸à¸²à¸£à¸›à¸£à¸±à¸šà¹à¸•à¹ˆà¸‡à¸‚à¸±à¹‰à¸™à¸ªà¸¹à¸‡**: à¸•à¹‰à¸­à¸‡à¸à¸²à¸£ Quantization à¹à¸¥à¸°à¸à¸²à¸£à¸ˆà¸±à¸”à¸à¸¥à¸¸à¹ˆà¸¡à¸—à¸µà¹ˆà¸›à¸£à¸±à¸šà¹à¸•à¹ˆà¸‡à¹€à¸­à¸‡
- **à¸à¸²à¸£à¹ƒà¸Šà¹‰à¸—à¸£à¸±à¸žà¸¢à¸²à¸à¸£à¸­à¸¢à¹ˆà¸²à¸‡à¸¡à¸µà¸›à¸£à¸°à¸ªà¸´à¸—à¸˜à¸´à¸ à¸²à¸ž**: à¸à¸²à¸£à¹ƒà¸Šà¹‰à¸®à¸²à¸£à¹Œà¸”à¹à¸§à¸£à¹Œ GPU à¸—à¸µà¹ˆà¸¡à¸µà¸£à¸²à¸„à¸²à¹à¸žà¸‡à¸­à¸¢à¹ˆà¸²à¸‡à¸ªà¸¹à¸‡à¸ªà¸¸à¸”

## à¸à¸²à¸£à¹ƒà¸Šà¹‰à¸‡à¸²à¸™ SLM Agent à¹ƒà¸™à¹‚à¸¥à¸à¸ˆà¸£à¸´à¸‡

### à¹€à¸­à¹€à¸ˆà¸™à¸•à¹Œà¸šà¸£à¸´à¸à¸²à¸£à¸¥à¸¹à¸à¸„à¹‰à¸² SLM
- **à¸„à¸§à¸²à¸¡à¸ªà¸²à¸¡à¸²à¸£à¸–à¸‚à¸­à¸‡ SLM**: à¸à¸²à¸£à¸„à¹‰à¸™à¸«à¸²à¸šà¸±à¸à¸Šà¸µ, à¸à¸²à¸£à¸£à¸µà¹€à¸‹à¹‡à¸•à¸£à¸«à¸±à¸ªà¸œà¹ˆà¸²à¸™, à¸à¸²à¸£à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸šà¸ªà¸–à¸²à¸™à¸°à¸„à¸³à¸ªà¸±à¹ˆà¸‡à¸‹à¸·à¹‰à¸­
- **à¸›à¸£à¸°à¹‚à¸¢à¸Šà¸™à¹Œà¸”à¹‰à¸²à¸™à¸•à¹‰à¸™à¸—à¸¸à¸™**: à¸¥à¸”à¸•à¹‰à¸™à¸—à¸¸à¸™à¸à¸²à¸£à¸­à¸™à¸¸à¸¡à¸²à¸™à¸¥à¸‡ 10 à¹€à¸—à¹ˆà¸²à¹€à¸¡à¸·à¹ˆà¸­à¹€à¸—à¸µà¸¢à¸šà¸à¸±à¸šà¹€à¸­à¹€à¸ˆà¸™à¸•à¹Œ LLM
- **à¸›à¸£à¸°à¸ªà¸´à¸—à¸˜à¸´à¸ à¸²à¸ž**: à¹€à¸§à¸¥à¸²à¸•à¸­à¸šà¸ªà¸™à¸­à¸‡à¹€à¸£à¹‡à¸§à¸‚à¸¶à¹‰à¸™à¸žà¸£à¹‰à¸­à¸¡à¸„à¸¸à¸“à¸ à¸²à¸žà¸—à¸µà¹ˆà¸ªà¸¡à¹ˆà¸³à¹€à¸ªà¸¡à¸­à¸ªà¸³à¸«à¸£à¸±à¸šà¸„à¸³à¸–à¸²à¸¡à¸—à¸±à¹ˆà¸§à¹„à¸›

### à¹€à¸­à¹€à¸ˆà¸™à¸•à¹Œà¸à¸£à¸°à¸šà¸§à¸™à¸à¸²à¸£à¸˜à¸¸à¸£à¸à¸´à¸ˆ SLM
- **à¹€à¸­à¹€à¸ˆà¸™à¸•à¹Œà¸›à¸£à¸°à¸¡à¸§à¸¥à¸œà¸¥à¹ƒà¸šà¹à¸ˆà¹‰à¸‡à¸«à¸™à¸µà¹‰**: à¸”à¸¶à¸‡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥, à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸šà¸‚à¹‰à¸­à¸¡à¸¹à¸¥, à¸ªà¹ˆà¸‡à¸•à¹ˆà¸­à¹€à¸žà¸·à¹ˆà¸­à¸­à¸™à¸¸à¸¡à¸±à¸•à¸´
- **à¹€à¸­à¹€à¸ˆà¸™à¸•à¹Œà¸ˆà¸±à¸”à¸à¸²à¸£à¸­à¸µà¹€à¸¡à¸¥**: à¸ˆà¸±à¸”à¸«à¸¡à¸§à¸”à¸«à¸¡à¸¹à¹ˆ, à¸ˆà¸±à¸”à¸¥à¸³à¸”à¸±à¸šà¸„à¸§à¸²à¸¡à¸ªà¸³à¸„à¸±à¸, à¸£à¹ˆà¸²à¸‡à¸„à¸³à¸•à¸­à¸šà¸­à¸±à¸•à¹‚à¸™à¸¡à¸±à¸•à¸´
- **à¹€à¸­à¹€à¸ˆà¸™à¸•à¹Œà¸ˆà¸±à¸”à¸•à¸²à¸£à¸²à¸‡à¹€à¸§à¸¥à¸²**: à¸›à¸£à¸°à¸ªà¸²à¸™à¸‡à¸²à¸™à¸à¸²à¸£à¸›à¸£à¸°à¸Šà¸¸à¸¡, à¸ˆà¸±à¸”à¸à¸²à¸£à¸›à¸à¸´à¸—à¸´à¸™, à¸ªà¹ˆà¸‡à¸à¸²à¸£à¹à¸ˆà¹‰à¸‡à¹€à¸•à¸·à¸­à¸™

### à¸œà¸¹à¹‰à¸Šà¹ˆà¸§à¸¢à¸”à¸´à¸ˆà¸´à¸—à¸±à¸¥ SLM à¸ªà¹ˆà¸§à¸™à¸šà¸¸à¸„à¸„à¸¥
- **à¹€à¸­à¹€à¸ˆà¸™à¸•à¹Œà¸ˆà¸±à¸”à¸à¸²à¸£à¸‡à¸²à¸™**: à¸ªà¸£à¹‰à¸²à¸‡, à¸­à¸±à¸›à¹€à¸”à¸•, à¸ˆà¸±à¸”à¸£à¸°à¹€à¸šà¸µà¸¢à¸šà¸£à¸²à¸¢à¸à¸²à¸£à¸ªà¸´à¹ˆà¸‡à¸—à¸µà¹ˆà¸•à¹‰à¸­à¸‡à¸—à¸³à¸­à¸¢à¹ˆà¸²à¸‡à¸¡à¸µà¸›à¸£à¸°à¸ªà¸´à¸—à¸˜à¸´à¸ à¸²à¸ž
- **à¹€à¸­à¹€à¸ˆà¸™à¸•à¹Œà¸£à¸§à¸šà¸£à¸§à¸¡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥**: à¸§à¸´à¸ˆà¸±à¸¢à¸«à¸±à¸§à¸‚à¹‰à¸­, à¸ªà¸£à¸¸à¸›à¸œà¸¥à¸à¸²à¸£à¸„à¹‰à¸™à¸«à¸²à¹ƒà¸™à¸žà¸·à¹‰à¸™à¸—à¸µà¹ˆ
- **à¹€à¸­à¹€à¸ˆà¸™à¸•à¹Œà¸à¸²à¸£à¸ªà¸·à¹ˆà¸­à¸ªà¸²à¸£**: à¸£à¹ˆà¸²à¸‡à¸­à¸µà¹€à¸¡à¸¥, à¸‚à¹‰à¸­à¸„à¸§à¸²à¸¡, à¹‚à¸žà¸ªà¸•à¹Œà¹‚à¸‹à¹€à¸Šà¸µà¸¢à¸¥à¸¡à¸µà¹€à¸”à¸µà¸¢à¸­à¸¢à¹ˆà¸²à¸‡à¹€à¸›à¹‡à¸™à¸ªà¹ˆà¸§à¸™à¸•à¸±à¸§

### à¹€à¸­à¹€à¸ˆà¸™à¸•à¹Œà¸à¸²à¸£à¸‹à¸·à¹‰à¸­à¸‚à¸²à¸¢à¹à¸¥à¸°à¸à¸²à¸£à¹€à¸‡à¸´à¸™ SLM
- **à¹€à¸­à¹€à¸ˆà¸™à¸•à¹Œà¸•à¸´à¸”à¸•à¸²à¸¡à¸•à¸¥à¸²à¸”**: à¸•à¸´à¸”à¸•à¸²à¸¡à¸£à¸²à¸„à¸², à¸£à¸°à¸šà¸¸à¹à¸™à¸§à¹‚à¸™à¹‰à¸¡à¹à¸šà¸šà¹€à¸£à¸µà¸¢à¸¥à¹„à¸—à¸¡à¹Œ
- **à¹€à¸­à¹€à¸ˆà¸™à¸•à¹Œà¸ªà¸£à¹‰à¸²à¸‡à¸£à¸²à¸¢à¸‡à¸²à¸™**: à¸ªà¸£à¹‰à¸²à¸‡à¸ªà¸£à¸¸à¸›à¸£à¸²à¸¢à¸§à¸±à¸™/à¸£à¸²à¸¢à¸ªà¸±à¸›à¸”à¸²à¸«à¹Œà¸­à¸±à¸•à¹‚à¸™à¸¡à¸±à¸•à¸´
- **à¹€à¸­à¹€à¸ˆà¸™à¸•à¹Œà¸›à¸£à¸°à¹€à¸¡à¸´à¸™à¸„à¸§à¸²à¸¡à¹€à¸ªà¸µà¹ˆà¸¢à¸‡**: à¸›à¸£à¸°à¹€à¸¡à¸´à¸™à¸•à¸³à¹à¸«à¸™à¹ˆà¸‡à¸žà¸­à¸£à¹Œà¸•à¹‚à¸Ÿà¸¥à¸´à¹‚à¸­à¹‚à¸”à¸¢à¹ƒà¸Šà¹‰à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¹ƒà¸™à¸žà¸·à¹‰à¸™à¸—à¸µà¹ˆ

### à¹€à¸­à¹€à¸ˆà¸™à¸•à¹Œà¸ªà¸™à¸±à¸šà¸ªà¸™à¸¸à¸™à¸”à¹‰à¸²à¸™à¸ªà¸¸à¸‚à¸ à¸²à¸ž SLM
- **à¹€à¸­à¹€à¸ˆà¸™à¸•à¹Œà¸ˆà¸±à¸”à¸•à¸²à¸£à¸²à¸‡à¹€à¸§à¸¥à¸²à¸œà¸¹à¹‰à¸›à¹ˆà¸§à¸¢**: à¸›à¸£à¸°à¸ªà¸²à¸™à¸‡à¸²à¸™à¸à¸²à¸£à¸™à¸±à¸”à¸«à¸¡à¸²à¸¢, à¸ªà¹ˆà¸‡à¸à¸²à¸£à¹à¸ˆà¹‰à¸‡à¹€à¸•à¸·à¸­à¸™à¸­à¸±à¸•à¹‚à¸™à¸¡à¸±à¸•à¸´
- **à¹€à¸­à¹€à¸ˆà¸™à¸•à¹Œà¹€à¸­à¸à¸ªà¸²à¸£**: à¸ªà¸£à¹‰à¸²à¸‡à¸ªà¸£à¸¸à¸›à¸—à¸²à¸‡à¸à¸²à¸£à¹à¸žà¸—à¸¢à¹Œ, à¸£à¸²à¸¢à¸‡à¸²à¸™à¹ƒà¸™à¸žà¸·à¹‰à¸™à¸—à¸µà¹ˆ
- **à¹€à¸­à¹€à¸ˆà¸™à¸•à¹Œà¸ˆà¸±à¸”à¸à¸²à¸£à¹ƒà¸šà¸ªà¸±à¹ˆà¸‡à¸¢à¸²**: à¸•à¸´à¸”à¸•à¸²à¸¡à¸à¸²à¸£à¹€à¸•à¸´à¸¡à¸¢à¸², à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸šà¸à¸²à¸£à¹‚à¸•à¹‰à¸•à¸­à¸šà¸­à¸¢à¹ˆà¸²à¸‡à¹€à¸›à¹‡à¸™à¸ªà¹ˆà¸§à¸™à¸•à¸±à¸§

## Microsoft Agent Framework: à¸à¸²à¸£à¸žà¸±à¸’à¸™à¸²à¹€à¸­à¹€à¸ˆà¸™à¸•à¹Œà¸—à¸µà¹ˆà¸žà¸£à¹‰à¸­à¸¡à¸ªà¸³à¸«à¸£à¸±à¸šà¸à¸²à¸£à¸œà¸¥à¸´à¸•

### à¸ à¸²à¸žà¸£à¸§à¸¡à¹à¸¥à¸°à¸ªà¸–à¸²à¸›à¸±à¸•à¸¢à¸à¸£à¸£à¸¡

Microsoft Agent Framework à¹ƒà¸«à¹‰à¹à¸žà¸¥à¸•à¸Ÿà¸­à¸£à¹Œà¸¡à¸—à¸µà¹ˆà¸„à¸£à¸­à¸šà¸„à¸¥à¸¸à¸¡à¹à¸¥à¸°à¸£à¸°à¸”à¸±à¸šà¸­à¸‡à¸„à¹Œà¸à¸£à¸ªà¸³à¸«à¸£à¸±à¸šà¸à¸²à¸£à¸ªà¸£à¹‰à¸²à¸‡, à¸à¸²à¸£à¸›à¸£à¸±à¸šà¹ƒà¸Šà¹‰, à¹à¸¥à¸°à¸à¸²à¸£à¸ˆà¸±à¸”à¸à¸²à¸£à¹€à¸­à¹€à¸ˆà¸™à¸•à¹Œ AI à¸—à¸µà¹ˆà¸ªà¸²à¸¡à¸²à¸£à¸–à¸—à¸³à¸‡à¸²à¸™à¹„à¸”à¹‰à¸—à¸±à¹‰à¸‡à¹ƒà¸™à¸£à¸°à¸šà¸šà¸„à¸¥à¸²à¸§à¸”à¹Œà¹à¸¥à¸°à¸ªà¸ à¸²à¸žà¹à¸§à¸”à¸¥à¹‰à¸­à¸¡ Edge à¹à¸šà¸šà¸­à¸­à¸Ÿà¹„à¸¥à¸™à¹Œ Framework à¸™à¸µà¹‰à¹„à¸”à¹‰à¸£à¸±à¸šà¸à¸²à¸£à¸­à¸­à¸à¹à¸šà¸šà¸¡à¸²à¹‚à¸”à¸¢à¹€à¸‰à¸žà¸²à¸°à¹€à¸žà¸·à¹ˆà¸­à¸—à¸³à¸‡à¸²à¸™à¸£à¹ˆà¸§à¸¡à¸à¸±à¸š Small Language Models à¹à¸¥à¸°à¸ªà¸–à¸²à¸™à¸à¸²à¸£à¸“à¹Œà¸à¸²à¸£à¸›à¸£à¸°à¸¡à¸§à¸¥à¸œà¸¥ Edge à¸—à¸³à¹ƒà¸«à¹‰à¹€à¸«à¸¡à¸²à¸°à¸ªà¸³à¸«à¸£à¸±à¸šà¸à¸²à¸£à¸›à¸£à¸±à¸šà¹ƒà¸Šà¹‰à¸—à¸µà¹ˆà¹€à¸™à¹‰à¸™à¸„à¸§à¸²à¸¡à¹€à¸›à¹‡à¸™à¸ªà¹ˆà¸§à¸™à¸•à¸±à¸§à¹à¸¥à¸°à¸—à¸£à¸±à¸žà¸¢à¸²à¸à¸£à¸ˆà¸³à¸à¸±à¸”

**à¸­à¸‡à¸„à¹Œà¸›à¸£à¸°à¸à¸­à¸šà¸«à¸¥à¸±à¸à¸‚à¸­à¸‡ Framework**:
- **Agent Runtime**: à¸ªà¸ à¸²à¸žà¹à¸§à¸”à¸¥à¹‰à¸­à¸¡à¸à¸²à¸£à¸”à¸³à¹€à¸™à¸´à¸™à¸à¸²à¸£à¸—à¸µà¹ˆà¸¡à¸µà¸™à¹‰à¸³à¸«à¸™à¸±à¸à¹€à¸šà¸²à¹à¸¥à¸°à¸›à¸£à¸±à¸šà¹à¸•à¹ˆà¸‡à¸ªà¸³à¸«à¸£à¸±à¸šà¸­à¸¸à¸›à¸à¸£à¸“à¹Œ Edge
- **à¸£à¸°à¸šà¸šà¸à¸²à¸£à¸£à¸§à¸¡à¹€à¸„à¸£à¸·à¹ˆà¸­à¸‡à¸¡à¸·à¸­**: à¸ªà¸–à¸²à¸›à¸±à¸•à¸¢à¸à¸£à¸£à¸¡à¸›à¸¥à¸±à¹Šà¸à¸­à¸´à¸™à¸—à¸µà¹ˆà¸‚à¸¢à¸²à¸¢à¹„à¸”à¹‰à¸ªà¸³à¸«à¸£à¸±à¸šà¸à¸²à¸£à¹€à¸Šà¸·à¹ˆà¸­à¸¡à¸•à¹ˆà¸­à¸šà¸£à¸´à¸à¸²à¸£à¹à¸¥à¸° API à¸ à¸²à¸¢à¸™à¸­à¸
- **à¸à¸²à¸£à¸ˆà¸±à¸”à¸à¸²à¸£à¸ªà¸–à¸²à¸™à¸°**: à¸«à¸™à¹ˆà¸§à¸¢à¸„à¸§à¸²à¸¡à¸ˆà¸³à¹€à¸­à¹€à¸ˆà¸™à¸•à¹Œà¸—à¸µà¹ˆà¸„à¸‡à¸­à¸¢à¸¹à¹ˆà¹à¸¥à¸°à¸à¸²à¸£à¸ˆà¸±à¸”à¸à¸²à¸£à¸šà¸£à¸´à¸šà¸—à¸‚à¹‰à¸²à¸¡à¹€à¸‹à¸ªà¸Šà¸±à¸™
- **à¸Šà¸±à¹‰à¸™à¸„à¸§à¸²à¸¡à¸›à¸¥à¸­à¸”à¸ à¸±à¸¢**: à¸à¸²à¸£à¸„à¸§à¸šà¸„à¸¸à¸¡à¸„à¸§à¸²à¸¡à¸›à¸¥à¸­à¸”à¸ à¸±à¸¢à¹ƒà¸™à¸•à¸±à¸§à¸ªà¸³à¸«à¸£à¸±à¸šà¸à¸²à¸£à¸›à¸£à¸±à¸šà¹ƒà¸Šà¹‰à¸£à¸°à¸”à¸±à¸šà¸­à¸‡à¸„à¹Œà¸à¸£
- **à¹€à¸„à¸£à¸·à¹ˆà¸­à¸‡à¸¡à¸·à¸­à¸ˆà¸±à¸”à¸à¸²à¸£à¸à¸²à¸£à¸›à¸£à¸°à¸ªà¸²à¸™à¸‡à¸²à¸™**: à¸à¸²à¸£à¸›à¸£à¸°à¸ªà¸²à¸™à¸‡à¸²à¸™à¸«à¸¥à¸²à¸¢à¹€à¸­à¹€à¸ˆà¸™à¸•à¹Œà¹à¸¥à¸°à¸à¸²à¸£à¸ˆà¸±à¸”à¸à¸²à¸£à¸à¸£à¸°à¸šà¸§à¸™à¸à¸²à¸£à¸—à¸³à¸‡à¸²à¸™

### à¸„à¸¸à¸“à¸ªà¸¡à¸šà¸±à¸•à¸´à¸ªà¸³à¸„à¸±à¸à¸ªà¸³à¸«à¸£à¸±à¸šà¸à¸²à¸£à¸›à¸£à¸±à¸šà¹ƒà¸Šà¹‰ Edge

**à¸ªà¸–à¸²à¸›à¸±à¸•à¸¢à¸à¸£à¸£à¸¡à¹à¸šà¸šà¸­à¸­à¸Ÿà¹„à¸¥à¸™à¹Œà¹€à¸›à¹‡à¸™à¸«à¸¥à¸±à¸**: Microsoft Agent Framework à¹„à¸”à¹‰à¸£à¸±à¸šà¸à¸²à¸£à¸­à¸­à¸à¹à¸šà¸šà¸”à¹‰à¸§à¸¢à¸«à¸¥à¸±à¸à¸à¸²à¸£à¸­à¸­à¸Ÿà¹„à¸¥à¸™à¹Œà¹€à¸›à¹‡à¸™à¸«à¸¥à¸±à¸ à¸—à¸³à¹ƒà¸«à¹‰à¹€à¸­à¹€à¸ˆà¸™à¸•à¹Œà¸ªà¸²à¸¡à¸²à¸£à¸–à¸—à¸³à¸‡à¸²à¸™à¹„à¸”à¹‰à¸­à¸¢à¹ˆà¸²à¸‡à¸¡à¸µà¸›à¸£à¸°à¸ªà¸´à¸—à¸˜à¸´à¸ à¸²à¸žà¹‚à¸”à¸¢à¹„à¸¡à¹ˆà¸•à¹‰à¸­à¸‡à¹€à¸Šà¸·à¹ˆà¸­à¸¡à¸•à¹ˆà¸­à¸­à¸´à¸™à¹€à¸—à¸­à¸£à¹Œà¹€à¸™à¹‡à¸•à¸­à¸¢à¹ˆà¸²à¸‡à¸•à¹ˆà¸­à¹€à¸™à¸·à¹ˆà¸­à¸‡ à¸‹à¸¶à¹ˆà¸‡à¸£à¸§à¸¡à¸–à¸¶à¸‡à¸à¸²à¸£à¸­à¸™à¸¸à¸¡à¸²à¸™à¹‚à¸¡à¹€à¸”à¸¥à¹ƒà¸™à¸žà¸·à¹‰à¸™à¸—à¸µà¹ˆ, à¸à¸²à¸™à¸„à¸§à¸²à¸¡à¸£à¸¹à¹‰à¸—à¸µà¹ˆà¹à¸„à¸Šà¹„à¸§à¹‰, à¸à¸²à¸£à¸”à¸³à¹€à¸™à¸´à¸™à¸à¸²à¸£à¹€à¸„à¸£à¸·à¹ˆà¸­à¸‡à¸¡à¸·à¸­à¹à¸šà¸šà¸­à¸­à¸Ÿà¹„à¸¥à¸™à¹Œ, à¹à¸¥à¸°à¸à¸²à¸£à¸¥à¸”à¸£à¸°à¸”à¸±à¸šà¸­à¸¢à¹ˆà¸²à¸‡à¸£à¸²à¸šà¸£à¸·à¹ˆà¸™à¹€à¸¡à¸·à¹ˆà¸­à¸šà¸£à¸´à¸à¸²à¸£à¸„à¸¥à¸²à¸§à¸”à¹Œà¹„à¸¡à¹ˆà¸žà¸£à¹‰à¸­à¸¡à¹ƒà¸Šà¹‰à¸‡à¸²à¸™

**à¸à¸²à¸£à¸›à¸£à¸±à¸šà¸—à¸£à¸±à¸žà¸¢à¸²à¸à¸£à¹ƒà¸«à¹‰à¹€à¸«à¸¡à¸²à¸°à¸ªà¸¡**: Framework à¸™à¸µà¹‰à¹ƒà¸«à¹‰à¸à¸²à¸£à¸ˆà¸±à¸”à¸à¸²à¸£à¸—à¸£à¸±à¸žà¸¢à¸²à¸à¸£à¸­à¸¢à¹ˆà¸²à¸‡à¸Šà¸²à¸à¸‰à¸¥à¸²à¸”à¸”à¹‰à¸§à¸¢à¸à¸²à¸£à¸›à¸£à¸±à¸šà¸«à¸™à¹ˆà¸§à¸¢à¸„à¸§à¸²à¸¡à¸ˆà¸³à¸­à¸±à¸•à¹‚à¸™à¸¡à¸±à¸•à¸´à¸ªà¸³à¸«à¸£à¸±à¸š SLMs, à¸à¸²à¸£à¸›à¸£à¸±à¸šà¸ªà¸¡à¸”à¸¸à¸¥à¹‚à¸«à¸¥à¸” CPU/GPU à¸ªà¸³à¸«à¸£à¸±à¸šà¸­à¸¸à¸›à¸à¸£à¸“à¹Œ Edge, à¸à¸²à¸£à¹€à¸¥à¸·à¸­à¸à¹‚à¸¡à¹€à¸”à¸¥à¹à¸šà¸šà¸›à¸£à¸±à¸šà¸•à¸±à¸§à¸•à¸²à¸¡à¸—à¸£à¸±à¸žà¸¢à¸²à¸à¸£à¸—à¸µà¹ˆà¸¡à¸µà¸­à¸¢à¸¹à¹ˆ, à¹à¸¥à¸°à¸£à¸¹à¸›à¹à¸šà¸šà¸à¸²à¸£à¸­à¸™à¸¸à¸¡à¸²à¸™à¸—à¸µà¹ˆà¸›à¸£à¸°à¸«à¸¢à¸±à¸”à¸žà¸¥à¸±à¸‡à¸‡à¸²à¸™à¸ªà¸³à¸«à¸£à¸±à¸šà¸à¸²à¸£à¸›à¸£à¸±à¸šà¹ƒà¸Šà¹‰à¸šà¸™à¸¡à¸·à¸­à¸–à¸·à¸­

**à¸„à¸§à¸²à¸¡à¸›à¸¥à¸­à¸”à¸ à¸±à¸¢à¹à¸¥à¸°à¸„à¸§à¸²à¸¡à¹€à¸›à¹‡à¸™à¸ªà¹ˆà¸§à¸™à¸•à¸±à¸§**: à¸„à¸¸à¸“à¸ªà¸¡à¸šà¸±à¸•à¸´à¸„à¸§à¸²à¸¡à¸›à¸¥à¸­à¸”à¸ à¸±à¸¢à¸£à¸°à¸”à¸±à¸šà¸­à¸‡à¸„à¹Œà¸à¸£à¸£à¸§à¸¡à¸–à¸¶à¸‡à¸à¸²à¸£à¸›à¸£à¸°à¸¡à¸§à¸¥à¸œà¸¥à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¹ƒà¸™à¸žà¸·à¹‰à¸™à¸—à¸µà¹ˆà¹€à¸žà¸·à¹ˆà¸­à¸£à¸±à¸à¸©à¸²à¸„à¸§à¸²à¸¡à¹€à¸›à¹‡à¸™à¸ªà¹ˆà¸§à¸™à¸•à¸±à¸§, à¸Šà¹ˆà¸­à¸‡à¸—à¸²à¸‡à¸à¸²à¸£à¸ªà¸·à¹ˆà¸­à¸ªà¸²à¸£à¹€à¸­à¹€à¸ˆà¸™à¸•à¹Œà¸—à¸µà¹ˆà¹€à¸‚à¹‰à¸²à¸£à¸«à¸±à¸ª, à¸à¸²à¸£à¸„à¸§à¸šà¸„à¸¸à¸¡à¸à¸²à¸£à¹€à¸‚à¹‰à¸²à¸–à¸¶à¸‡à¸•à¸²à¸¡à¸šà¸—à¸šà¸²à¸—à¸ªà¸³à¸«à¸£à¸±à¸šà¸„à¸§à¸²à¸¡à¸ªà¸²à¸¡à¸²à¸£à¸–à¸‚à¸­à¸‡à¹€à¸­à¹€à¸ˆà¸™à¸•à¹Œ, à¹à¸¥à¸°à¸à¸²à¸£à¸šà¸±à¸™à¸—à¸¶à¸à¸à¸²à¸£à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸šà¹€à¸žà¸·à¹ˆà¸­à¸„à¸§à¸²à¸¡à¸•à¹‰à¸­à¸‡à¸à¸²à¸£à¸”à¹‰à¸²à¸™à¸à¸²à¸£à¸›à¸à¸´à¸šà¸±à¸•à¸´à¸•à¸²à¸¡à¸‚à¹‰à¸­à¸à¸³à¸«à¸™à¸”

### à¸à¸²à¸£à¸£à¸§à¸¡à¸à¸±à¸š Foundry Local

Microsoft Agent Framework à¸£à¸§à¸¡à¹€à¸‚à¹‰à¸²à¸à¸±à¸š Foundry Local à¹„à¸”à¹‰à¸­à¸¢à¹ˆà¸²à¸‡à¸£à¸²à¸šà¸£à¸·à¹ˆà¸™à¹€à¸žà¸·à¹ˆà¸­à¹ƒà¸«à¹‰à¹‚à¸‹à¸¥à¸¹à¸Šà¸±à¸™ AI Edge à¸—à¸µà¹ˆà¸ªà¸¡à¸šà¸¹à¸£à¸“à¹Œ:

**à¸à¸²à¸£à¸„à¹‰à¸™à¸«à¸²à¹‚à¸¡à¹€à¸”à¸¥à¸­à¸±à¸•à¹‚à¸™à¸¡à¸±à¸•à¸´**: Framework à¸ˆà¸°à¸•à¸£à¸§à¸ˆà¸ˆà¸±à¸šà¹à¸¥à¸°à¹€à¸Šà¸·à¹ˆà¸­à¸¡à¸•à¹ˆà¸­à¸à¸±à¸š Foundry Local à¹‚à¸”à¸¢à¸­à¸±à¸•à¹‚à¸™à¸¡à¸±à¸•à¸´, à¸„à¹‰à¸™à¸«à¸²à¹‚à¸¡à¹€à¸”à¸¥ SLM à¸—à¸µà¹ˆà¸¡à¸µà¸­à¸¢à¸¹à¹ˆ, à¹à¸¥à¸°à¹€à¸¥à¸·à¸­à¸à¹‚à¸¡à¹€à¸”à¸¥à¸—à¸µà¹ˆà¹€à¸«à¸¡à¸²à¸°à¸ªà¸¡à¸—à¸µà¹ˆà¸ªà¸¸à¸”à¸•à¸²à¸¡à¸„à¸§à¸²à¸¡à¸•à¹‰à¸­à¸‡à¸à¸²à¸£à¸‚à¸­à¸‡à¹€à¸­à¹€à¸ˆà¸™à¸•à¹Œà¹à¸¥à¸°à¸„à¸§à¸²à¸¡à¸ªà¸²à¸¡à¸²à¸£à¸–à¸‚à¸­à¸‡à¸®à¸²à¸£à¹Œà¸”à¹à¸§à¸£à¹Œ

**à¸à¸²à¸£à¹‚à¸«à¸¥à¸”à¹‚à¸¡à¹€à¸”à¸¥à¹à¸šà¸šà¹„à¸”à¸™à¸²à¸¡à¸´à¸**: à¹€à¸­à¹€à¸ˆà¸™à¸•à¹Œà¸ªà¸²à¸¡à¸²à¸£à¸–à¹‚à¸«à¸¥à¸” SLM à¸•à¹ˆà¸²à¸‡à¹† à¹à¸šà¸šà¹„à¸”à¸™à¸²à¸¡à¸´à¸à¸ªà¸³à¸«à¸£à¸±à¸šà¸‡à¸²à¸™à¹€à¸‰à¸žà¸²à¸°, à¸—à¸³à¹ƒà¸«à¹‰à¸£à¸°à¸šà¸šà¹€à¸­à¹€à¸ˆà¸™à¸•à¹Œà¸«à¸¥à¸²à¸¢à¹‚à¸¡à¹€à¸”à¸¥à¸—à¸µà¹ˆà¹‚à¸¡à¹€à¸”à¸¥à¸•à¹ˆà¸²à¸‡à¹† à¸ˆà¸±à¸”à¸à¸²à¸£à¸„à¸³à¸‚à¸­à¸›à¸£à¸°à¹€à¸ à¸—à¸•à¹ˆà¸²à¸‡à¹† à¹à¸¥à¸°à¸à¸²à¸£à¸ªà¸³à¸£à¸­à¸‡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸­à¸±à¸•à¹‚à¸™à¸¡à¸±à¸•à¸´à¸£à¸°à¸«à¸§à¹ˆà¸²à¸‡à¹‚à¸¡à¹€à¸”à¸¥à¸•à¸²à¸¡à¸„à¸§à¸²à¸¡à¸žà¸£à¹‰à¸­à¸¡à¹ƒà¸Šà¹‰à¸‡à¸²à¸™à¹à¸¥à¸°à¸›à¸£à¸°à¸ªà¸´à¸—à¸˜à¸´à¸ à¸²à¸ž

**à¸à¸²à¸£à¸›à¸£à¸±à¸šà¸›à¸£à¸°à¸ªà¸´à¸—à¸˜à¸´à¸ à¸²à¸ž**: à¸à¸¥à¹„à¸à¸à¸²à¸£à¹à¸„à¸Šà¸—à¸µà¹ˆà¸£à¸§à¸¡à¸­à¸¢à¸¹à¹ˆà¸Šà¹ˆà¸§à¸¢à¸¥à¸”à¹€à¸§à¸¥à¸²à¹ƒà¸™à¸à¸²à¸£à¹‚à¸«à¸¥à¸”à¹‚à¸¡à¹€à¸”à¸¥, à¸à¸²à¸£à¸£à¸§à¸¡à¸à¸²à¸£à¹€à¸Šà¸·à¹ˆà¸­à¸¡à¸•à¹ˆà¸­à¸Šà¹ˆà¸§à¸¢à¹€à¸žà¸´à¹ˆà¸¡à¸›à¸£à¸°à¸ªà¸´à¸—à¸˜à¸´à¸ à¸²à¸žà¸à¸²à¸£à¹€à¸£à¸µà¸¢à¸ API à¹„à¸›à¸¢à¸±à¸‡ Foundry Local, à¹à¸¥à¸°à¸à¸²à¸£à¸ˆà¸±à¸”à¸à¸¥à¸¸à¹ˆà¸¡à¸„à¸³à¸‚à¸­à¸­à¸¢à¹ˆà¸²à¸‡à¸Šà¸²à¸à¸‰à¸¥à¸²à¸”à¸Šà¹ˆà¸§à¸¢à¹€à¸žà¸´à¹ˆà¸¡à¸›à¸£à¸°à¸ªà¸´à¸—à¸˜à¸´à¸ à¸²à¸žà¸ªà¸³à¸«à¸£à¸±à¸šà¸„à¸³à¸‚à¸­à¹€à¸­à¹€à¸ˆà¸™à¸•à¹Œà¸«à¸¥à¸²à¸¢à¸£à¸²à¸¢à¸à¸²à¸£

### à¸à¸²à¸£à¸ªà¸£à¹‰à¸²à¸‡à¹€à¸­à¹€à¸ˆà¸™à¸•à¹Œà¸”à¹‰à¸§à¸¢ Microsoft Agent Framework

#### à¸à¸²à¸£à¸à¸³à¸«à¸™à¸”à¹à¸¥à¸°à¸à¸²à¸£à¸•à¸±à¹‰à¸‡à¸„à¹ˆà¸²à¹€à¸­à¹€à¸ˆà¸™à¸•à¹Œ

```python
from microsoft_agent_framework import Agent, Tool, Config
from foundry_local import FoundryLocalManager

# Configure agent with Foundry Local integration
config = Config(
    name="customer-service-agent",
    model_provider="foundry-local",
    model_alias="phi-4-mini",
    max_tokens=512,
    temperature=0.1,
    offline_mode=True
)

# Initialize Foundry Local connection
foundry = FoundryLocalManager("phi-4-mini")

# Create agent instance
agent = Agent(
    config=config,
    model_endpoint=foundry.endpoint,
    api_key=foundry.api_key
)
```

#### à¸à¸²à¸£à¸£à¸§à¸¡à¹€à¸„à¸£à¸·à¹ˆà¸­à¸‡à¸¡à¸·à¸­à¸ªà¸³à¸«à¸£à¸±à¸šà¸ªà¸–à¸²à¸™à¸à¸²à¸£à¸“à¹Œ Edge

```python
# Define tools for offline operation
@agent.tool
def lookup_customer_info(customer_id: str) -> dict:
    """Look up customer information from local database."""
    # Local database query - works offline
    return local_db.get_customer(customer_id)

@agent.tool
def create_support_ticket(issue: str, priority: str) -> str:
    """Create a support ticket in local system."""
    # Local ticket creation with sync when online
    ticket_id = local_system.create_ticket(issue, priority)
    return f"Ticket {ticket_id} created successfully"

@agent.tool
def schedule_callback(customer_id: str, preferred_time: str) -> str:
    """Schedule a callback for the customer."""
    # Local scheduling with calendar integration
    return local_calendar.schedule(customer_id, preferred_time)
```

#### à¸à¸²à¸£à¸›à¸£à¸°à¸ªà¸²à¸™à¸‡à¸²à¸™à¸«à¸¥à¸²à¸¢à¹€à¸­à¹€à¸ˆà¸™à¸•à¹Œ

```python
from microsoft_agent_framework import AgentOrchestrator

# Create specialized agents for different domains
scheduling_agent = Agent(
    config=Config(
        name="scheduling-agent",
        model_alias="qwen2.5-0.5b",  # Lightweight for simple tasks
        specialized_for="scheduling"
    )
)

technical_support_agent = Agent(
    config=Config(
        name="technical-agent",
        model_alias="phi-4-mini",  # More capable for complex issues
        specialized_for="technical_support"
    )
)

# Orchestrate multiple agents
orchestrator = AgentOrchestrator([
    scheduling_agent,
    technical_support_agent
])

# Route requests based on intent
result = orchestrator.process_request(
    "I need to schedule a callback for a technical issue",
    routing_strategy="intent-based"
)
```

### à¸£à¸¹à¸›à¹à¸šà¸šà¸à¸²à¸£à¸›à¸£à¸±à¸šà¹ƒà¸Šà¹‰ Edge à¸‚à¸±à¹‰à¸™à¸ªà¸¹à¸‡

#### à¸ªà¸–à¸²à¸›à¸±à¸•à¸¢à¸à¸£à¸£à¸¡à¹€à¸­à¹€à¸ˆà¸™à¸•à¹Œà¹à¸šà¸šà¸¥à¸³à¸”à¸±à¸šà¸Šà¸±à¹‰à¸™

**à¸à¸¥à¸¸à¹ˆà¸¡à¹€à¸­à¹€à¸ˆà¸™à¸•à¹Œà¹ƒà¸™à¸žà¸·à¹‰à¸™à¸—à¸µà¹ˆ**: à¸›à¸£à¸±à¸šà¹ƒà¸Šà¹‰à¹€à¸­à¹€à¸ˆà¸™à¸•à¹Œ SLM à¹€à¸‰à¸žà¸²à¸°à¸—à¸²à¸‡à¸«à¸¥à¸²à¸¢à¸•à¸±à¸§à¸šà¸™à¸­à¸¸à¸›à¸à¸£à¸“à¹Œ Edge à¹‚à¸”à¸¢à¹à¸•à¹ˆà¸¥à¸°à¸•à¸±à¸§à¹„à¸”à¹‰à¸£à¸±à¸šà¸à¸²à¸£à¸›à¸£à¸±à¸šà¹à¸•à¹ˆà¸‡à¸ªà¸³à¸«à¸£à¸±à¸šà¸‡à¸²à¸™à¹€à¸‰à¸žà¸²à¸° à¹ƒà¸Šà¹‰à¹‚à¸¡à¹€à¸”à¸¥à¸™à¹‰à¸³à¸«à¸™à¸±à¸à¹€à¸šà¸² à¹€à¸Šà¹ˆà¸™ Qwen2.5-0.5B à¸ªà¸³à¸«à¸£à¸±à¸šà¸à¸²à¸£à¸ˆà¸±à¸”à¹€à¸ªà¹‰à¸™à¸—à¸²à¸‡à¹à¸¥à¸°à¸à¸²à¸£à¸ˆà¸±à¸”à¸•à¸²à¸£à¸²à¸‡à¹€à¸§à¸¥à¸², à¹‚à¸¡à¹€à¸”à¸¥à¸‚à¸™à¸²à¸”à¸à¸¥à¸²à¸‡ à¹€à¸Šà¹ˆà¸™ Phi-4-Mini à¸ªà¸³à¸«à¸£à¸±à¸šà¸à¸²à¸£à¸šà¸£à¸´à¸à¸²à¸£à¸¥à¸¹à¸à¸„à¹‰à¸²à¹à¸¥à¸°à¹€à¸­à¸à¸ªà¸²à¸£, à¹à¸¥à¸°à¹‚à¸¡à¹€à¸”à¸¥à¸‚à¸™à¸²à¸”à¹ƒà¸«à¸à¹ˆà¸ªà¸³à¸«à¸£à¸±à¸šà¸à¸²à¸£à¹ƒà¸«à¹‰à¹€à¸«à¸•à¸¸à¸œà¸¥à¸—à¸µà¹ˆà¸‹à¸±à¸šà¸‹à¹‰à¸­à¸™à¹€à¸¡à¸·à¹ˆà¸­à¸—à¸£à¸±à¸žà¸¢à¸²à¸à¸£à¸­à¸™à¸¸à¸à¸²à¸•

**à¸à¸²à¸£à¸›à¸£à¸°à¸ªà¸²à¸™à¸‡à¸²à¸™ Edge-to-Cloud**: à¹ƒà¸Šà¹‰à¸£à¸¹à¸›à¹à¸šà¸šà¸à¸²à¸£à¸¢à¸à¸£à¸°à¸”à¸±à¸šà¸­à¸¢à¹ˆà¸²à¸‡à¸Šà¸²à¸à¸‰à¸¥à¸²à¸”à¸—à¸µà¹ˆà¹€à¸­à¹€à¸ˆà¸™à¸•à¹Œà¹ƒà¸™à¸žà¸·à¹‰à¸™à¸—à¸µà¹ˆà¸ˆà¸±à¸”à¸à¸²à¸£à¸‡à¸²à¸™à¸—à¸±à¹ˆà¸§à¹„à¸›, à¹€à¸­à¹€à¸ˆà¸™à¸•à¹Œà¸„à¸¥à¸²à¸§à¸”à¹Œà¹ƒà¸«à¹‰à¹€à¸«à¸•à¸¸à¸œà¸¥à¸—à¸µà¹ˆà¸‹à¸±à¸šà¸‹à¹‰à¸­à¸™à¹€à¸¡à¸·à¹ˆà¸­à¸à¸²à¸£à¹€à¸Šà¸·à¹ˆà¸­à¸¡à¸•à¹ˆà¸­à¸­à¸™à¸¸à¸à¸²à¸•, à¹à¸¥à¸°à¸à¸²à¸£à¸ªà¹ˆà¸‡à¸•à¹ˆà¸­à¸£à¸°à¸«à¸§à¹ˆà¸²à¸‡à¸à¸²à¸£à¸›à¸£à¸°à¸¡à¸§à¸¥à¸œà¸¥ Edge à¹à¸¥à¸°à¸„à¸¥à¸²à¸§à¸”à¹Œà¸­à¸¢à¹ˆà¸²à¸‡à¸£à¸²à¸šà¸£à¸·à¹ˆà¸™à¹€à¸žà¸·à¹ˆà¸­à¸£à¸±à¸à¸©à¸²à¸„à¸§à¸²à¸¡à¸•à¹ˆà¸­à¹€à¸™à¸·à¹ˆà¸­à¸‡

#### à¸à¸²à¸£à¸•à¸±à¹‰à¸‡à¸„à¹ˆà¸²à¸à¸²à¸£à¸›à¸£à¸±à¸šà¹ƒà¸Šà¹‰

**à¸à¸²à¸£à¸›à¸£à¸±à¸šà¹ƒà¸Šà¹‰à¸šà¸™à¸­à¸¸à¸›à¸à¸£à¸“à¹Œà¹€à¸”à¸µà¸¢à¸§**:
```yaml
deployment:
  type: single-device
  hardware: edge-device
  models:
    - alias: "phi-4-mini"
      primary: true
      tasks: ["conversation", "reasoning"]
    - alias: "qwen2.5-0.5b"
      secondary: true
      tasks: ["routing", "classification"]
  agents:
    - name: "primary-agent"
      model: "phi-4-mini"
      tools: ["database", "calendar", "email"]
```

**à¸à¸²à¸£à¸›à¸£à¸±à¸šà¹ƒà¸Šà¹‰ Edge à¹à¸šà¸šà¸à¸£à¸°à¸ˆà¸²à¸¢**:
```yaml
deployment:
  type: distributed-edge
  nodes:
    - id: "edge-1"
      agents: ["customer-service", "scheduling"]
      models: ["phi-4-mini"]
    - id: "edge-2"
      agents: ["technical-support", "documentation"]
      models: ["qwen2.5-coder-0.5b"]
  coordination:
    load_balancing: true
    failover: automatic
```

### à¸à¸²à¸£à¸›à¸£à¸±à¸šà¸›à¸£à¸°à¸ªà¸´à¸—à¸˜à¸´à¸ à¸²à¸žà¸ªà¸³à¸«à¸£à¸±à¸šà¹€à¸­à¹€à¸ˆà¸™à¸•à¹Œ Edge

#### à¸à¸¥à¸¢à¸¸à¸—à¸˜à¹Œà¸à¸²à¸£à¹€à¸¥à¸·à¸­à¸à¹‚à¸¡à¹€à¸”à¸¥

**à¸à¸²à¸£à¸à¸³à¸«à¸™à¸”à¹‚à¸¡à¹€à¸”à¸¥à¸•à¸²à¸¡à¸‡à¸²à¸™**: Microsoft Agent Framework à¸Šà¹ˆà¸§à¸¢à¹ƒà¸«à¹‰à¸à¸²à¸£à¹€à¸¥à¸·à¸­à¸à¹‚à¸¡à¹€à¸”à¸¥à¸­à¸¢à¹ˆà¸²à¸‡à¸Šà¸²à¸à¸‰à¸¥à¸²à¸”à¸•à¸²à¸¡à¸„à¸§à¸²à¸¡à¸‹à¸±à¸šà¸‹à¹‰à¸­à¸™à¸‚à¸­à¸‡à¸‡à¸²à¸™à¹à¸¥à¸°à¸‚à¹‰à¸­à¸à¸³à¸«à¸™à¸”:

- **à¸‡à¸²à¸™à¸‡à¹ˆà¸²à¸¢** (Q&A, à¸à¸²à¸£à¸ˆà¸±à¸”à¹€à¸ªà¹‰à¸™à¸—à¸²à¸‡): Qwen2.5-0.5B (500MB, à¹€à¸§à¸¥à¸²à¸•à¸­à¸šà¸ªà¸™à¸­à¸‡ <100ms)
- **à¸‡à¸²à¸™à¸›à¸²à¸™à¸à¸¥à¸²à¸‡** (à¸à¸²à¸£à¸šà¸£à¸´à¸à¸²à¸£à¸¥à¸¹à¸à¸„à¹‰à¸², à¸à¸²à¸£à¸ˆà¸±à¸”à¸•à¸²à¸£à¸²à¸‡à¹€à¸§à¸¥à¸²): Phi-4-Mini (2.4GB, à¹€à¸§à¸¥à¸²à¸•à¸­à¸šà¸ªà¸™à¸­à¸‡ 200-500ms)
- **à¸‡à¸²à¸™à¸‹à¸±à¸šà¸‹à¹‰à¸­à¸™** (à¸à¸²à¸£à¸§à¸´à¹€à¸„à¸£à¸²à¸°à¸«à¹Œà¸—à¸²à¸‡à¹€à¸—à¸„à¸™à¸´à¸„, à¸à¸²à¸£à¸§à¸²à¸‡à¹à¸œà¸™): Phi-4 (7GB, à¹€à¸§à¸¥à¸²à¸•à¸­à¸šà¸ªà¸™à¸­à¸‡ 1-3s à¹€à¸¡à¸·à¹ˆà¸­à¸—à¸£à¸±à¸žà¸¢à¸²à¸à¸£à¸­à¸™à¸¸à¸à¸²à¸•)

**à¸à¸²à¸£à¸ªà¸¥à¸±à¸šà¹‚à¸¡à¹€à¸”à¸¥à¹à¸šà¸šà¹„à¸”à¸™à¸²à¸¡à¸´à¸**: à¹€à¸­à¹€à¸ˆà¸™à¸•à¹Œà¸ªà¸²à¸¡à¸²à¸£à¸–à¸ªà¸¥à¸±à¸šà¸£à¸°à¸«à¸§à¹ˆà¸²à¸‡à¹‚à¸¡à¹€à¸”à¸¥à¸•à¸²à¸¡à¹‚à¸«à¸¥à¸”à¸£à¸°à¸šà¸šà¸›à¸±à¸ˆà¸ˆà¸¸à¸šà¸±à¸™, à¸à¸²à¸£à¸›à¸£à¸°à¹€à¸¡à¸´à¸™à¸„à¸§à¸²à¸¡à¸‹à¸±à¸šà¸‹à¹‰à¸­à¸™à¸‚à¸­à¸‡à¸‡à¸²à¸™, à¸£à¸°à¸”à¸±à¸šà¸„à¸§à¸²à¸¡à¸ªà¸³à¸„à¸±à¸à¸‚à¸­à¸‡à¸œà¸¹à¹‰à¹ƒà¸Šà¹‰, à¹à¸¥à¸°à¸—à¸£à¸±à¸žà¸¢à¸²à¸à¸£à¸®à¸²à¸£à¹Œà¸”à¹à¸§à¸£à¹Œà¸—à¸µà¹ˆà¸¡à¸µà¸­à¸¢à¸¹à¹ˆ

#### à¸à¸²à¸£à¸ˆà¸±à¸”à¸à¸²à¸£à¸«à¸™à¹ˆà¸§à¸¢à¸„à¸§à¸²à¸¡à¸ˆà¸³à¹à¸¥à¸°à¸—à¸£à¸±à¸žà¸¢à¸²à¸à¸£

```python
# Configure resource constraints for edge deployment
resource_config = ResourceConfig(
    max_memory_usage="4GB",
    max_concurrent_agents=3,
    model_cache_size="2GB",
    auto_unload_idle_models=True,
    power_management=True
)

agent = Agent(
    config=config,
    resource_limits=resource_config
)
```

### à¸£à¸¹à¸›à¹à¸šà¸šà¸à¸²à¸£à¸£à¸§à¸¡à¸£à¸°à¸”à¸±à¸šà¸­à¸‡à¸„à¹Œà¸à¸£

#### à¸„à¸§à¸²à¸¡
**à¸à¸²à¸£à¹€à¸¥à¸·à¸­à¸ Framework à¸ªà¸³à¸«à¸£à¸±à¸šà¸à¸²à¸£à¹ƒà¸Šà¹‰à¸‡à¸²à¸™ Agent**: à¹€à¸¥à¸·à¸­à¸ framework à¸à¸²à¸£à¸›à¸£à¸±à¸šà¹à¸•à¹ˆà¸‡à¸•à¸²à¸¡à¸®à¸²à¸£à¹Œà¸”à¹à¸§à¸£à¹Œà¹€à¸›à¹‰à¸²à¸«à¸¡à¸²à¸¢à¹à¸¥à¸°à¸„à¸§à¸²à¸¡à¸•à¹‰à¸­à¸‡à¸à¸²à¸£à¸‚à¸­à¸‡ Agent à¹ƒà¸Šà¹‰ Llama.cpp à¸ªà¸³à¸«à¸£à¸±à¸šà¸à¸²à¸£à¹ƒà¸Šà¹‰à¸‡à¸²à¸™ Agent à¸—à¸µà¹ˆà¸›à¸£à¸±à¸šà¹à¸•à¹ˆà¸‡à¸ªà¸³à¸«à¸£à¸±à¸š CPU, Apple MLX à¸ªà¸³à¸«à¸£à¸±à¸šà¸à¸²à¸£à¹ƒà¸Šà¹‰à¸‡à¸²à¸™ Agent à¸šà¸™ Apple Silicon à¹à¸¥à¸° ONNX à¸ªà¸³à¸«à¸£à¸±à¸šà¸„à¸§à¸²à¸¡à¹€à¸‚à¹‰à¸²à¸à¸±à¸™à¹„à¸”à¹‰à¸‚à¸­à¸‡ Agent à¸‚à¹‰à¸²à¸¡à¹à¸žà¸¥à¸•à¸Ÿà¸­à¸£à¹Œà¸¡

## à¸à¸²à¸£à¹à¸›à¸¥à¸‡ SLM Agent à¹à¸¥à¸°à¸à¸£à¸“à¸µà¸à¸²à¸£à¹ƒà¸Šà¹‰à¸‡à¸²à¸™à¹ƒà¸™à¸—à¸²à¸‡à¸›à¸à¸´à¸šà¸±à¸•à¸´

### à¸ªà¸–à¸²à¸™à¸à¸²à¸£à¸“à¹Œà¸à¸²à¸£à¹ƒà¸Šà¹‰à¸‡à¸²à¸™ Agent à¹ƒà¸™à¹‚à¸¥à¸à¸ˆà¸£à¸´à¸‡

**à¸à¸²à¸£à¹ƒà¸Šà¹‰à¸‡à¸²à¸™ Agent à¸šà¸™à¸¡à¸·à¸­à¸–à¸·à¸­**: à¸£à¸¹à¸›à¹à¸šà¸š Q4_K à¹€à¸«à¸¡à¸²à¸°à¸ªà¸³à¸«à¸£à¸±à¸šà¸à¸²à¸£à¹ƒà¸Šà¹‰à¸‡à¸²à¸™ Agent à¸šà¸™à¸ªà¸¡à¸²à¸£à¹Œà¸—à¹‚à¸Ÿà¸™à¸—à¸µà¹ˆà¹ƒà¸Šà¹‰à¸«à¸™à¹ˆà¸§à¸¢à¸„à¸§à¸²à¸¡à¸ˆà¸³à¸™à¹‰à¸­à¸¢à¸—à¸µà¹ˆà¸ªà¸¸à¸” à¹ƒà¸™à¸‚à¸“à¸°à¸—à¸µà¹ˆ Q8_0 à¹ƒà¸«à¹‰à¸›à¸£à¸°à¸ªà¸´à¸—à¸˜à¸´à¸ à¸²à¸žà¸—à¸µà¹ˆà¸ªà¸¡à¸”à¸¸à¸¥à¸ªà¸³à¸«à¸£à¸±à¸šà¸£à¸°à¸šà¸š Agent à¸šà¸™à¹à¸—à¹‡à¸šà¹€à¸¥à¹‡à¸• à¸£à¸¹à¸›à¹à¸šà¸š Q5_K à¹ƒà¸«à¹‰à¸„à¸¸à¸“à¸ à¸²à¸žà¸—à¸µà¹ˆà¹€à¸«à¸™à¸·à¸­à¸à¸§à¹ˆà¸²à¸ªà¸³à¸«à¸£à¸±à¸š Agent à¸—à¸µà¹ˆà¸Šà¹ˆà¸§à¸¢à¹€à¸žà¸´à¹ˆà¸¡à¸›à¸£à¸°à¸ªà¸´à¸—à¸˜à¸´à¸ à¸²à¸žà¸à¸²à¸£à¸—à¸³à¸‡à¸²à¸™à¸šà¸™à¸¡à¸·à¸­à¸–à¸·à¸­

**à¸à¸²à¸£à¸›à¸£à¸°à¸¡à¸§à¸¥à¸œà¸¥ Agent à¸šà¸™à¹€à¸”à¸ªà¸à¹Œà¸—à¹‡à¸­à¸›à¹à¸¥à¸° Edge**: Q5_K à¹ƒà¸«à¹‰à¸›à¸£à¸°à¸ªà¸´à¸—à¸˜à¸´à¸ à¸²à¸žà¸—à¸µà¹ˆà¹€à¸«à¸¡à¸²à¸°à¸ªà¸¡à¸ªà¸³à¸«à¸£à¸±à¸šà¸à¸²à¸£à¹ƒà¸Šà¹‰à¸‡à¸²à¸™ Agent à¸šà¸™à¹€à¸”à¸ªà¸à¹Œà¸—à¹‡à¸­à¸› Q8_0 à¹ƒà¸«à¹‰à¸à¸²à¸£à¸§à¸´à¹€à¸„à¸£à¸²à¸°à¸«à¹Œà¸„à¸¸à¸“à¸ à¸²à¸žà¸ªà¸¹à¸‡à¸ªà¸³à¸«à¸£à¸±à¸šà¸ªà¸ à¸²à¸žà¹à¸§à¸”à¸¥à¹‰à¸­à¸¡ Agent à¸šà¸™à¹€à¸§à¸´à¸£à¹Œà¸à¸ªà¹€à¸•à¸Šà¸±à¸™ à¹à¸¥à¸° Q4_K à¸Šà¹ˆà¸§à¸¢à¹ƒà¸«à¹‰à¸à¸²à¸£à¸›à¸£à¸°à¸¡à¸§à¸¥à¸œà¸¥à¸¡à¸µà¸›à¸£à¸°à¸ªà¸´à¸—à¸˜à¸´à¸ à¸²à¸žà¸šà¸™à¸­à¸¸à¸›à¸à¸£à¸“à¹Œ Edge

**Agent à¸ªà¸³à¸«à¸£à¸±à¸šà¸à¸²à¸£à¸§à¸´à¸ˆà¸±à¸¢à¹à¸¥à¸°à¸—à¸”à¸¥à¸­à¸‡**: à¸£à¸¹à¸›à¹à¸šà¸šà¸à¸²à¸£à¸›à¸£à¸±à¸šà¸¥à¸”à¸‚à¸±à¹‰à¸™à¸ªà¸¹à¸‡à¸Šà¹ˆà¸§à¸¢à¹ƒà¸«à¹‰à¸ªà¸²à¸¡à¸²à¸£à¸–à¸ªà¸³à¸£à¸§à¸ˆà¸à¸²à¸£à¸§à¸´à¹€à¸„à¸£à¸²à¸°à¸«à¹Œ Agent à¸—à¸µà¹ˆà¸¡à¸µà¸„à¸§à¸²à¸¡à¹à¸¡à¹ˆà¸™à¸¢à¸³à¸•à¹ˆà¸³à¸¡à¸²à¸à¸ªà¸³à¸«à¸£à¸±à¸šà¸à¸²à¸£à¸§à¸´à¸ˆà¸±à¸¢à¸—à¸²à¸‡à¸§à¸´à¸Šà¸²à¸à¸²à¸£à¹à¸¥à¸°à¸à¸²à¸£à¹ƒà¸Šà¹‰à¸‡à¸²à¸™ Agent à¹à¸šà¸šà¸•à¹‰à¸™à¹à¸šà¸šà¸—à¸µà¹ˆà¸•à¹‰à¸­à¸‡à¸à¸²à¸£à¸—à¸£à¸±à¸žà¸¢à¸²à¸à¸£à¸­à¸¢à¹ˆà¸²à¸‡à¸¡à¸²à¸

### à¸à¸²à¸£à¸§à¸±à¸”à¸›à¸£à¸°à¸ªà¸´à¸—à¸˜à¸´à¸ à¸²à¸žà¸‚à¸­à¸‡ SLM Agent

**à¸„à¸§à¸²à¸¡à¹€à¸£à¹‡à¸§à¹ƒà¸™à¸à¸²à¸£à¸§à¸´à¹€à¸„à¸£à¸²à¸°à¸«à¹Œà¸‚à¸­à¸‡ Agent**: Q4_K à¹ƒà¸«à¹‰à¹€à¸§à¸¥à¸²à¸•à¸­à¸šà¸ªà¸™à¸­à¸‡à¸‚à¸­à¸‡ Agent à¸—à¸µà¹ˆà¹€à¸£à¹‡à¸§à¸—à¸µà¹ˆà¸ªà¸¸à¸”à¸šà¸™ CPU à¸‚à¸­à¸‡à¸¡à¸·à¸­à¸–à¸·à¸­ Q5_K à¹ƒà¸«à¹‰à¸ªà¸¡à¸”à¸¸à¸¥à¸£à¸°à¸«à¸§à¹ˆà¸²à¸‡à¸„à¸§à¸²à¸¡à¹€à¸£à¹‡à¸§à¹à¸¥à¸°à¸„à¸¸à¸“à¸ à¸²à¸žà¸ªà¸³à¸«à¸£à¸±à¸šà¸à¸²à¸£à¹ƒà¸Šà¹‰à¸‡à¸²à¸™ Agent à¸—à¸±à¹ˆà¸§à¹„à¸› Q8_0 à¹ƒà¸«à¹‰à¸„à¸¸à¸“à¸ à¸²à¸žà¸—à¸µà¹ˆà¹€à¸«à¸™à¸·à¸­à¸à¸§à¹ˆà¸²à¸ªà¸³à¸«à¸£à¸±à¸šà¸‡à¸²à¸™ Agent à¸—à¸µà¹ˆà¸‹à¸±à¸šà¸‹à¹‰à¸­à¸™ à¹à¸¥à¸°à¸£à¸¹à¸›à¹à¸šà¸šà¸—à¸”à¸¥à¸­à¸‡à¹ƒà¸«à¹‰ throughput à¸ªà¸¹à¸‡à¸ªà¸¸à¸”à¸ªà¸³à¸«à¸£à¸±à¸šà¸®à¸²à¸£à¹Œà¸”à¹à¸§à¸£à¹Œ Agent à¹€à¸‰à¸žà¸²à¸°à¸—à¸²à¸‡

**à¸„à¸§à¸²à¸¡à¸•à¹‰à¸­à¸‡à¸à¸²à¸£à¸«à¸™à¹ˆà¸§à¸¢à¸„à¸§à¸²à¸¡à¸ˆà¸³à¸‚à¸­à¸‡ Agent**: à¸£à¸°à¸”à¸±à¸šà¸à¸²à¸£à¸›à¸£à¸±à¸šà¸¥à¸”à¸‚à¸­à¸‡ Agent à¸¡à¸µà¸•à¸±à¹‰à¸‡à¹à¸•à¹ˆ Q2_K (à¸•à¹ˆà¸³à¸à¸§à¹ˆà¸² 500MB à¸ªà¸³à¸«à¸£à¸±à¸šà¹‚à¸¡à¹€à¸”à¸¥ Agent à¸‚à¸™à¸²à¸”à¹€à¸¥à¹‡à¸) à¸–à¸¶à¸‡ Q8_0 (à¸›à¸£à¸°à¸¡à¸²à¸“ 50% à¸‚à¸­à¸‡à¸‚à¸™à¸²à¸”à¹€à¸”à¸´à¸¡) à¹‚à¸”à¸¢à¸à¸²à¸£à¸à¸³à¸«à¸™à¸”à¸„à¹ˆà¸²à¸—à¸”à¸¥à¸­à¸‡à¸ªà¸²à¸¡à¸²à¸£à¸–à¸šà¸µà¸šà¸­à¸±à¸”à¹„à¸”à¹‰à¸ªà¸¹à¸‡à¸ªà¸¸à¸”à¸ªà¸³à¸«à¸£à¸±à¸šà¸ªà¸ à¸²à¸žà¹à¸§à¸”à¸¥à¹‰à¸­à¸¡ Agent à¸—à¸µà¹ˆà¸¡à¸µà¸‚à¹‰à¸­à¸ˆà¸³à¸à¸±à¸”à¸”à¹‰à¸²à¸™à¸—à¸£à¸±à¸žà¸¢à¸²à¸à¸£

## à¸„à¸§à¸²à¸¡à¸—à¹‰à¸²à¸—à¸²à¸¢à¹à¸¥à¸°à¸‚à¹‰à¸­à¸„à¸§à¸£à¸žà¸´à¸ˆà¸²à¸£à¸“à¸²à¸ªà¸³à¸«à¸£à¸±à¸š SLM Agent

### à¸à¸²à¸£à¹à¸¥à¸à¹€à¸›à¸¥à¸µà¹ˆà¸¢à¸™à¸›à¸£à¸°à¸ªà¸´à¸—à¸˜à¸´à¸ à¸²à¸žà¹ƒà¸™à¸£à¸°à¸šà¸š Agent

à¸à¸²à¸£à¹ƒà¸Šà¹‰à¸‡à¸²à¸™ SLM Agent à¸•à¹‰à¸­à¸‡à¸žà¸´à¸ˆà¸²à¸£à¸“à¸²à¸­à¸¢à¹ˆà¸²à¸‡à¸£à¸­à¸šà¸„à¸­à¸šà¹€à¸à¸µà¹ˆà¸¢à¸§à¸à¸±à¸šà¸à¸²à¸£à¹à¸¥à¸à¹€à¸›à¸¥à¸µà¹ˆà¸¢à¸™à¸£à¸°à¸«à¸§à¹ˆà¸²à¸‡à¸‚à¸™à¸²à¸”à¹‚à¸¡à¹€à¸”à¸¥ à¸„à¸§à¸²à¸¡à¹€à¸£à¹‡à¸§à¹ƒà¸™à¸à¸²à¸£à¸•à¸­à¸šà¸ªà¸™à¸­à¸‡à¸‚à¸­à¸‡ Agent à¹à¸¥à¸°à¸„à¸¸à¸“à¸ à¸²à¸žà¸‚à¸­à¸‡à¸œà¸¥à¸¥à¸±à¸žà¸˜à¹Œ à¹ƒà¸™à¸‚à¸“à¸°à¸—à¸µà¹ˆ Q4_K à¹ƒà¸«à¹‰à¸„à¸§à¸²à¸¡à¹€à¸£à¹‡à¸§à¹à¸¥à¸°à¸›à¸£à¸°à¸ªà¸´à¸—à¸˜à¸´à¸ à¸²à¸žà¸—à¸µà¹ˆà¸¢à¸­à¸”à¹€à¸¢à¸µà¹ˆà¸¢à¸¡à¸ªà¸³à¸«à¸£à¸±à¸š Agent à¸šà¸™à¸¡à¸·à¸­à¸–à¸·à¸­ Q8_0 à¹ƒà¸«à¹‰à¸„à¸¸à¸“à¸ à¸²à¸žà¸—à¸µà¹ˆà¹€à¸«à¸™à¸·à¸­à¸à¸§à¹ˆà¸²à¸ªà¸³à¸«à¸£à¸±à¸šà¸‡à¸²à¸™ Agent à¸—à¸µà¹ˆà¸‹à¸±à¸šà¸‹à¹‰à¸­à¸™ Q5_K à¹€à¸›à¹‡à¸™à¸•à¸±à¸§à¹€à¸¥à¸·à¸­à¸à¸—à¸µà¹ˆà¸ªà¸¡à¸”à¸¸à¸¥à¹€à¸«à¸¡à¸²à¸°à¸ªà¸³à¸«à¸£à¸±à¸šà¸à¸²à¸£à¹ƒà¸Šà¹‰à¸‡à¸²à¸™ Agent à¸—à¸±à¹ˆà¸§à¹„à¸›

### à¸„à¸§à¸²à¸¡à¹€à¸‚à¹‰à¸²à¸à¸±à¸™à¹„à¸”à¹‰à¸‚à¸­à¸‡à¸®à¸²à¸£à¹Œà¸”à¹à¸§à¸£à¹Œà¸ªà¸³à¸«à¸£à¸±à¸š SLM Agent

à¸­à¸¸à¸›à¸à¸£à¸“à¹Œ Edge à¸•à¹ˆà¸²à¸‡ à¹† à¸¡à¸µà¸„à¸§à¸²à¸¡à¸ªà¸²à¸¡à¸²à¸£à¸–à¸—à¸µà¹ˆà¹à¸•à¸à¸•à¹ˆà¸²à¸‡à¸à¸±à¸™à¸ªà¸³à¸«à¸£à¸±à¸šà¸à¸²à¸£à¹ƒà¸Šà¹‰à¸‡à¸²à¸™ SLM Agent Q4_K à¸—à¸³à¸‡à¸²à¸™à¹„à¸”à¹‰à¸­à¸¢à¹ˆà¸²à¸‡à¸¡à¸µà¸›à¸£à¸°à¸ªà¸´à¸—à¸˜à¸´à¸ à¸²à¸žà¸šà¸™à¹‚à¸›à¸£à¹€à¸‹à¸ªà¹€à¸‹à¸­à¸£à¹Œà¸žà¸·à¹‰à¸™à¸à¸²à¸™à¸ªà¸³à¸«à¸£à¸±à¸š Agent à¸‡à¹ˆà¸²à¸¢ à¹† Q5_K à¸•à¹‰à¸­à¸‡à¸à¸²à¸£à¸—à¸£à¸±à¸žà¸¢à¸²à¸à¸£à¸à¸²à¸£à¸›à¸£à¸°à¸¡à¸§à¸¥à¸œà¸¥à¸›à¸²à¸™à¸à¸¥à¸²à¸‡à¸ªà¸³à¸«à¸£à¸±à¸šà¸›à¸£à¸°à¸ªà¸´à¸—à¸˜à¸´à¸ à¸²à¸ž Agent à¸—à¸µà¹ˆà¸ªà¸¡à¸”à¸¸à¸¥ à¹à¸¥à¸° Q8_0 à¹„à¸”à¹‰à¸›à¸£à¸°à¹‚à¸¢à¸Šà¸™à¹Œà¸ˆà¸²à¸à¸®à¸²à¸£à¹Œà¸”à¹à¸§à¸£à¹Œà¸£à¸°à¸”à¸±à¸šà¸ªà¸¹à¸‡à¸ªà¸³à¸«à¸£à¸±à¸šà¸„à¸§à¸²à¸¡à¸ªà¸²à¸¡à¸²à¸£à¸–à¸‚à¸­à¸‡ Agent à¸‚à¸±à¹‰à¸™à¸ªà¸¹à¸‡

### à¸„à¸§à¸²à¸¡à¸›à¸¥à¸­à¸”à¸ à¸±à¸¢à¹à¸¥à¸°à¸„à¸§à¸²à¸¡à¹€à¸›à¹‡à¸™à¸ªà¹ˆà¸§à¸™à¸•à¸±à¸§à¹ƒà¸™à¸£à¸°à¸šà¸š SLM Agent

à¹ƒà¸™à¸‚à¸“à¸°à¸—à¸µà¹ˆ SLM Agent à¸Šà¹ˆà¸§à¸¢à¹ƒà¸«à¹‰à¸à¸²à¸£à¸›à¸£à¸°à¸¡à¸§à¸¥à¸œà¸¥à¹ƒà¸™à¹€à¸„à¸£à¸·à¹ˆà¸­à¸‡à¸¡à¸µà¸„à¸§à¸²à¸¡à¹€à¸›à¹‡à¸™à¸ªà¹ˆà¸§à¸™à¸•à¸±à¸§à¸¡à¸²à¸à¸‚à¸¶à¹‰à¸™ à¸•à¹‰à¸­à¸‡à¸¡à¸µà¸à¸²à¸£à¸”à¸³à¹€à¸™à¸´à¸™à¸¡à¸²à¸•à¸£à¸à¸²à¸£à¸£à¸±à¸à¸©à¸²à¸„à¸§à¸²à¸¡à¸›à¸¥à¸­à¸”à¸ à¸±à¸¢à¸—à¸µà¹ˆà¹€à¸«à¸¡à¸²à¸°à¸ªà¸¡à¹€à¸žà¸·à¹ˆà¸­à¸›à¸à¸›à¹‰à¸­à¸‡à¹‚à¸¡à¹€à¸”à¸¥ Agent à¹à¸¥à¸°à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¹ƒà¸™à¸ªà¸ à¸²à¸žà¹à¸§à¸”à¸¥à¹‰à¸­à¸¡ Edge à¸ªà¸´à¹ˆà¸‡à¸™à¸µà¹‰à¸¡à¸µà¸„à¸§à¸²à¸¡à¸ªà¸³à¸„à¸±à¸à¸­à¸¢à¹ˆà¸²à¸‡à¸¢à¸´à¹ˆà¸‡à¹€à¸¡à¸·à¹ˆà¸­à¹ƒà¸Šà¹‰à¸‡à¸²à¸™à¸£à¸¹à¸›à¹à¸šà¸š Agent à¸—à¸µà¹ˆà¸¡à¸µà¸„à¸§à¸²à¸¡à¹à¸¡à¹ˆà¸™à¸¢à¸³à¸ªà¸¹à¸‡à¹ƒà¸™à¸ªà¸ à¸²à¸žà¹à¸§à¸”à¸¥à¹‰à¸­à¸¡à¸­à¸‡à¸„à¹Œà¸à¸£ à¸«à¸£à¸·à¸­à¸£à¸¹à¸›à¹à¸šà¸š Agent à¸—à¸µà¹ˆà¸šà¸µà¸šà¸­à¸±à¸”à¹ƒà¸™à¹à¸­à¸›à¸žà¸¥à¸´à¹€à¸„à¸Šà¸±à¸™à¸—à¸µà¹ˆà¸ˆà¸±à¸”à¸à¸²à¸£à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸—à¸µà¹ˆà¸¥à¸°à¹€à¸­à¸µà¸¢à¸”à¸­à¹ˆà¸­à¸™

## à¹à¸™à¸§à¹‚à¸™à¹‰à¸¡à¹ƒà¸™à¸­à¸™à¸²à¸„à¸•à¸‚à¸­à¸‡à¸à¸²à¸£à¸žà¸±à¸’à¸™à¸² SLM Agent

à¸ à¸¹à¸¡à¸´à¸—à¸±à¸¨à¸™à¹Œà¸‚à¸­à¸‡ SLM Agent à¸¢à¸±à¸‡à¸„à¸‡à¸žà¸±à¸’à¸™à¸²à¹„à¸›à¸žà¸£à¹‰à¸­à¸¡à¸à¸±à¸šà¸„à¸§à¸²à¸¡à¸à¹‰à¸²à¸§à¸«à¸™à¹‰à¸²à¹ƒà¸™à¹€à¸—à¸„à¸™à¸´à¸„à¸à¸²à¸£à¸šà¸µà¸šà¸­à¸±à¸” à¸§à¸´à¸˜à¸µà¸à¸²à¸£à¸›à¸£à¸±à¸šà¹à¸•à¹ˆà¸‡ à¹à¸¥à¸°à¸à¸¥à¸¢à¸¸à¸—à¸˜à¹Œà¸à¸²à¸£à¹ƒà¸Šà¹‰à¸‡à¸²à¸™ Edge à¸à¸²à¸£à¸žà¸±à¸’à¸™à¸²à¹ƒà¸™à¸­à¸™à¸²à¸„à¸•à¸£à¸§à¸¡à¸–à¸¶à¸‡à¸­à¸±à¸¥à¸à¸­à¸£à¸´à¸—à¸¶à¸¡à¸à¸²à¸£à¸›à¸£à¸±à¸šà¸¥à¸”à¸—à¸µà¹ˆà¸¡à¸µà¸›à¸£à¸°à¸ªà¸´à¸—à¸˜à¸´à¸ à¸²à¸žà¸¡à¸²à¸à¸‚à¸¶à¹‰à¸™à¸ªà¸³à¸«à¸£à¸±à¸šà¹‚à¸¡à¹€à¸”à¸¥ Agent à¸§à¸´à¸˜à¸µà¸à¸²à¸£à¸šà¸µà¸šà¸­à¸±à¸”à¸—à¸µà¹ˆà¸”à¸µà¸‚à¸¶à¹‰à¸™à¸ªà¸³à¸«à¸£à¸±à¸šà¸à¸£à¸°à¸šà¸§à¸™à¸à¸²à¸£à¸—à¸³à¸‡à¸²à¸™à¸‚à¸­à¸‡ Agent à¹à¸¥à¸°à¸à¸²à¸£à¸œà¸ªà¸²à¸™à¸£à¸§à¸¡à¸—à¸µà¹ˆà¸”à¸µà¸‚à¸¶à¹‰à¸™à¸à¸±à¸šà¸•à¸±à¸§à¹€à¸£à¹ˆà¸‡à¸®à¸²à¸£à¹Œà¸”à¹à¸§à¸£à¹Œ Edge à¸ªà¸³à¸«à¸£à¸±à¸šà¸à¸²à¸£à¸›à¸£à¸°à¸¡à¸§à¸¥à¸œà¸¥ Agent

**à¸à¸²à¸£à¸„à¸²à¸”à¸à¸²à¸£à¸“à¹Œà¸•à¸¥à¸²à¸”à¸ªà¸³à¸«à¸£à¸±à¸š SLM Agent**: à¸ˆà¸²à¸à¸à¸²à¸£à¸§à¸´à¸ˆà¸±à¸¢à¸¥à¹ˆà¸²à¸ªà¸¸à¸” à¸à¸²à¸£à¸—à¸³à¸‡à¸²à¸™à¸­à¸±à¸•à¹‚à¸™à¸¡à¸±à¸•à¸´à¸—à¸µà¹ˆà¸‚à¸±à¸šà¹€à¸„à¸¥à¸·à¹ˆà¸­à¸™à¸”à¹‰à¸§à¸¢ Agent à¸­à¸²à¸ˆà¸¥à¸”à¸‡à¸²à¸™à¸—à¸µà¹ˆà¸•à¹‰à¸­à¸‡à¹ƒà¸Šà¹‰à¸„à¸§à¸²à¸¡à¸„à¸´à¸”à¸‹à¹‰à¸³ à¹† à¹ƒà¸™à¸à¸£à¸°à¸šà¸§à¸™à¸à¸²à¸£à¸—à¸³à¸‡à¸²à¸™à¸‚à¸­à¸‡à¸­à¸‡à¸„à¹Œà¸à¸£à¹„à¸”à¹‰à¸–à¸¶à¸‡ 40â€“60% à¸ à¸²à¸¢à¹ƒà¸™à¸›à¸µ 2027 à¹‚à¸”à¸¢ SLM à¹€à¸›à¹‡à¸™à¸œà¸¹à¹‰à¸™à¸³à¸à¸²à¸£à¹€à¸›à¸¥à¸µà¹ˆà¸¢à¸™à¹à¸›à¸¥à¸‡à¸™à¸µà¹‰à¹€à¸™à¸·à¹ˆà¸­à¸‡à¸ˆà¸²à¸à¸„à¸§à¸²à¸¡à¸„à¸¸à¹‰à¸¡à¸„à¹ˆà¸²à¹à¸¥à¸°à¸„à¸§à¸²à¸¡à¸¢à¸·à¸”à¸«à¸¢à¸¸à¹ˆà¸™à¹ƒà¸™à¸à¸²à¸£à¹ƒà¸Šà¹‰à¸‡à¸²à¸™

**à¹à¸™à¸§à¹‚à¸™à¹‰à¸¡à¹€à¸—à¸„à¹‚à¸™à¹‚à¸¥à¸¢à¸µà¹ƒà¸™ SLM Agent**:
- **SLM Agent à¹€à¸‰à¸žà¸²à¸°à¸—à¸²à¸‡**: à¹‚à¸¡à¹€à¸”à¸¥à¸—à¸µà¹ˆà¹„à¸”à¹‰à¸£à¸±à¸šà¸à¸²à¸£à¸à¸¶à¸à¸à¸™à¹€à¸‰à¸žà¸²à¸°à¸ªà¸³à¸«à¸£à¸±à¸šà¸‡à¸²à¸™ Agent à¹à¸¥à¸°à¸­à¸¸à¸•à¸ªà¸²à¸«à¸à¸£à¸£à¸¡à¹€à¸‰à¸žà¸²à¸°
- **à¸à¸²à¸£à¸›à¸£à¸°à¸¡à¸§à¸¥à¸œà¸¥ Agent à¸šà¸™ Edge**: à¸„à¸§à¸²à¸¡à¸ªà¸²à¸¡à¸²à¸£à¸–à¸‚à¸­à¸‡ Agent à¸šà¸™à¸­à¸¸à¸›à¸à¸£à¸“à¹Œà¸—à¸µà¹ˆà¸”à¸µà¸‚à¸¶à¹‰à¸™à¸žà¸£à¹‰à¸­à¸¡à¸„à¸§à¸²à¸¡à¹€à¸›à¹‡à¸™à¸ªà¹ˆà¸§à¸™à¸•à¸±à¸§à¸—à¸µà¹ˆà¹€à¸žà¸´à¹ˆà¸¡à¸‚à¸¶à¹‰à¸™à¹à¸¥à¸°à¸„à¸§à¸²à¸¡à¸«à¸™à¹ˆà¸§à¸‡à¸•à¹ˆà¸³
- **à¸à¸²à¸£à¸ˆà¸±à¸”à¸à¸²à¸£ Agent**: à¸à¸²à¸£à¸›à¸£à¸°à¸ªà¸²à¸™à¸‡à¸²à¸™à¸—à¸µà¹ˆà¸”à¸µà¸‚à¸¶à¹‰à¸™à¸£à¸°à¸«à¸§à¹ˆà¸²à¸‡ SLM Agent à¸«à¸¥à¸²à¸¢à¸•à¸±à¸§à¸”à¹‰à¸§à¸¢à¸à¸²à¸£à¸à¸³à¸«à¸™à¸”à¹€à¸ªà¹‰à¸™à¸—à¸²à¸‡à¹à¸¥à¸°à¸à¸²à¸£à¸à¸£à¸°à¸ˆà¸²à¸¢à¹‚à¸«à¸¥à¸”à¹à¸šà¸šà¹„à¸”à¸™à¸²à¸¡à¸´à¸
- **à¸à¸²à¸£à¹€à¸‚à¹‰à¸²à¸–à¸¶à¸‡à¸—à¸µà¹ˆà¸à¸§à¹‰à¸²à¸‡à¸‚à¸¶à¹‰à¸™**: à¸„à¸§à¸²à¸¡à¸¢à¸·à¸”à¸«à¸¢à¸¸à¹ˆà¸™à¸‚à¸­à¸‡ SLM à¸Šà¹ˆà¸§à¸¢à¹ƒà¸«à¹‰à¸¡à¸µà¸à¸²à¸£à¸¡à¸µà¸ªà¹ˆà¸§à¸™à¸£à¹ˆà¸§à¸¡à¹ƒà¸™à¸§à¸‡à¸à¸§à¹‰à¸²à¸‡à¸‚à¸¶à¹‰à¸™à¹ƒà¸™à¸à¸²à¸£à¸žà¸±à¸’à¸™à¸² Agent à¹ƒà¸™à¸­à¸‡à¸„à¹Œà¸à¸£à¸•à¹ˆà¸²à¸‡ à¹†

## à¹€à¸£à¸´à¹ˆà¸¡à¸•à¹‰à¸™à¹ƒà¸Šà¹‰à¸‡à¸²à¸™ SLM Agent

### à¸‚à¸±à¹‰à¸™à¸•à¸­à¸™à¸—à¸µà¹ˆ 1: à¸•à¸±à¹‰à¸‡à¸„à¹ˆà¸²à¸ªà¸ à¸²à¸žà¹à¸§à¸”à¸¥à¹‰à¸­à¸¡ Microsoft Agent Framework

**à¸•à¸´à¸”à¸•à¸±à¹‰à¸‡ Dependencies**:
```bash
# Install Microsoft Agent Framework
pip install microsoft-agent-framework

# Install Foundry Local SDK for edge deployment
pip install foundry-local-sdk

# Install additional dependencies for edge agents
pip install openai asyncio
```

**à¹€à¸£à¸´à¹ˆà¸¡à¸•à¹‰à¸™ Foundry Local**:
```bash
# Start Foundry Local service
foundry service start

# Load default model for agent development
foundry model run phi-4-mini
```

### à¸‚à¸±à¹‰à¸™à¸•à¸­à¸™à¸—à¸µà¹ˆ 2: à¹€à¸¥à¸·à¸­à¸ SLM à¸ªà¸³à¸«à¸£à¸±à¸šà¸à¸²à¸£à¹ƒà¸Šà¹‰à¸‡à¸²à¸™ Agent
à¸•à¸±à¸§à¹€à¸¥à¸·à¸­à¸à¸¢à¸­à¸”à¸™à¸´à¸¢à¸¡à¸ªà¸³à¸«à¸£à¸±à¸š Microsoft Agent Framework:
- **Microsoft Phi-4 Mini (3.8B)**: à¹€à¸«à¸¡à¸²à¸°à¸ªà¸³à¸«à¸£à¸±à¸šà¸‡à¸²à¸™ Agent à¸—à¸±à¹ˆà¸§à¹„à¸›à¸—à¸µà¹ˆà¸¡à¸µà¸›à¸£à¸°à¸ªà¸´à¸—à¸˜à¸´à¸ à¸²à¸žà¸ªà¸¡à¸”à¸¸à¸¥
- **Qwen2.5-0.5B (0.5B)**: à¸¡à¸µà¸›à¸£à¸°à¸ªà¸´à¸—à¸˜à¸´à¸ à¸²à¸žà¸ªà¸¹à¸‡à¸ªà¸³à¸«à¸£à¸±à¸š Agent à¸—à¸µà¹ˆà¸—à¸³à¸‡à¸²à¸™à¸‡à¹ˆà¸²à¸¢ à¹€à¸Šà¹ˆà¸™ à¸à¸²à¸£à¸à¸³à¸«à¸™à¸”à¹€à¸ªà¹‰à¸™à¸—à¸²à¸‡à¹à¸¥à¸°à¸à¸²à¸£à¸ˆà¸±à¸”à¸›à¸£à¸°à¹€à¸ à¸—
- **Qwen2.5-Coder-0.5B (0.5B)**: à¹€à¸‰à¸žà¸²à¸°à¸—à¸²à¸‡à¸ªà¸³à¸«à¸£à¸±à¸šà¸‡à¸²à¸™ Agent à¸—à¸µà¹ˆà¹€à¸à¸µà¹ˆà¸¢à¸§à¸‚à¹‰à¸­à¸‡à¸à¸±à¸šà¹‚à¸„à¹‰à¸”
- **Phi-4 (7B)**: à¸à¸²à¸£à¸§à¸´à¹€à¸„à¸£à¸²à¸°à¸«à¹Œà¸‚à¸±à¹‰à¸™à¸ªà¸¹à¸‡à¸ªà¸³à¸«à¸£à¸±à¸šà¸ªà¸–à¸²à¸™à¸à¸²à¸£à¸“à¹Œ Edge à¸—à¸µà¹ˆà¸‹à¸±à¸šà¸‹à¹‰à¸­à¸™à¹€à¸¡à¸·à¹ˆà¸­à¸¡à¸µà¸—à¸£à¸±à¸žà¸¢à¸²à¸à¸£à¹€à¸žà¸µà¸¢à¸‡à¸žà¸­

### à¸‚à¸±à¹‰à¸™à¸•à¸­à¸™à¸—à¸µà¹ˆ 3: à¸ªà¸£à¹‰à¸²à¸‡ Agent à¸•à¸±à¸§à¹à¸£à¸à¸‚à¸­à¸‡à¸„à¸¸à¸“à¸”à¹‰à¸§à¸¢ Microsoft Agent Framework

**à¸à¸²à¸£à¸•à¸±à¹‰à¸‡à¸„à¹ˆà¸² Agent à¹€à¸šà¸·à¹‰à¸­à¸‡à¸•à¹‰à¸™**:
```python
from microsoft_agent_framework import Agent, Config
from foundry_local import FoundryLocalManager

# Initialize Foundry Local connection
foundry = FoundryLocalManager("phi-4-mini")

# Create agent configuration
config = Config(
    name="my-first-agent",
    model_provider="foundry-local",
    model_alias="phi-4-mini",
    offline_mode=True
)

# Create and configure agent
agent = Agent(
    config=config,
    model_endpoint=foundry.endpoint,
    api_key=foundry.api_key
)

# Define a simple tool
@agent.tool
def get_current_time() -> str:
    """Get the current time."""
    from datetime import datetime
    return datetime.now().strftime("%Y-%m-%d %H:%M:%S")

# Test the agent
response = agent.chat("What time is it?")
print(response)
```

### à¸‚à¸±à¹‰à¸™à¸•à¸­à¸™à¸—à¸µà¹ˆ 4: à¸à¸³à¸«à¸™à¸”à¸‚à¸­à¸šà¹€à¸‚à¸•à¹à¸¥à¸°à¸„à¸§à¸²à¸¡à¸•à¹‰à¸­à¸‡à¸à¸²à¸£à¸‚à¸­à¸‡ Agent
à¹€à¸£à¸´à¹ˆà¸¡à¸•à¹‰à¸™à¸”à¹‰à¸§à¸¢à¸à¸²à¸£à¹ƒà¸Šà¹‰à¸‡à¸²à¸™ Agent à¸—à¸µà¹ˆà¸¡à¸µà¹€à¸›à¹‰à¸²à¸«à¸¡à¸²à¸¢à¸Šà¸±à¸”à¹€à¸ˆà¸™à¹à¸¥à¸°à¸à¸³à¸«à¸™à¸”à¹„à¸§à¹‰à¸­à¸¢à¹ˆà¸²à¸‡à¸”à¸µà¹‚à¸”à¸¢à¹ƒà¸Šà¹‰ Microsoft Agent Framework:
- **Agent à¸ªà¸³à¸«à¸£à¸±à¸šà¹‚à¸”à¹€à¸¡à¸™à¹€à¸”à¸µà¸¢à¸§**: à¸à¸²à¸£à¸šà¸£à¸´à¸à¸²à¸£à¸¥à¸¹à¸à¸„à¹‰à¸² à¸«à¸£à¸·à¸­à¸à¸²à¸£à¸ˆà¸±à¸”à¸•à¸²à¸£à¸²à¸‡à¹€à¸§à¸¥à¸² à¸«à¸£à¸·à¸­à¸à¸²à¸£à¸§à¸´à¸ˆà¸±à¸¢
- **à¸§à¸±à¸•à¸–à¸¸à¸›à¸£à¸°à¸ªà¸‡à¸„à¹Œà¸‚à¸­à¸‡ Agent à¸—à¸µà¹ˆà¸Šà¸±à¸”à¹€à¸ˆà¸™**: à¹€à¸›à¹‰à¸²à¸«à¸¡à¸²à¸¢à¸—à¸µà¹ˆà¹€à¸‰à¸žà¸²à¸°à¹€à¸ˆà¸²à¸°à¸ˆà¸‡à¹à¸¥à¸°à¸§à¸±à¸”à¸œà¸¥à¹„à¸”à¹‰à¸ªà¸³à¸«à¸£à¸±à¸šà¸›à¸£à¸°à¸ªà¸´à¸—à¸˜à¸´à¸ à¸²à¸žà¸‚à¸­à¸‡ Agent
- **à¸à¸²à¸£à¸œà¸ªà¸²à¸™à¸£à¸§à¸¡à¹€à¸„à¸£à¸·à¹ˆà¸­à¸‡à¸¡à¸·à¸­à¸—à¸µà¹ˆà¸ˆà¸³à¸à¸±à¸”**: à¹€à¸„à¸£à¸·à¹ˆà¸­à¸‡à¸¡à¸·à¸­ 3-5 à¸•à¸±à¸§à¸ªà¸³à¸«à¸£à¸±à¸šà¸à¸²à¸£à¹ƒà¸Šà¹‰à¸‡à¸²à¸™ Agent à¸„à¸£à¸±à¹‰à¸‡à¹à¸£à¸
- **à¸‚à¸­à¸šà¹€à¸‚à¸•à¸‚à¸­à¸‡ Agent à¸—à¸µà¹ˆà¸à¸³à¸«à¸™à¸”à¹„à¸§à¹‰**: à¹€à¸ªà¹‰à¸™à¸—à¸²à¸‡à¸à¸²à¸£à¸ªà¹ˆà¸‡à¸•à¹ˆà¸­à¸—à¸µà¹ˆà¸Šà¸±à¸”à¹€à¸ˆà¸™à¸ªà¸³à¸«à¸£à¸±à¸šà¸ªà¸–à¸²à¸™à¸à¸²à¸£à¸“à¹Œà¸—à¸µà¹ˆà¸‹à¸±à¸šà¸‹à¹‰à¸­à¸™
- **à¸à¸²à¸£à¸­à¸­à¸à¹à¸šà¸šà¸—à¸µà¹ˆà¹€à¸™à¹‰à¸™ Edge**: à¹ƒà¸«à¹‰à¸„à¸§à¸²à¸¡à¸ªà¸³à¸„à¸±à¸à¸à¸±à¸šà¸Ÿà¸±à¸‡à¸à¹Œà¸Šà¸±à¸™à¸à¸²à¸£à¸—à¸³à¸‡à¸²à¸™à¹à¸šà¸šà¸­à¸­à¸Ÿà¹„à¸¥à¸™à¹Œà¹à¸¥à¸°à¸à¸²à¸£à¸›à¸£à¸°à¸¡à¸§à¸¥à¸œà¸¥à¹ƒà¸™à¹€à¸„à¸£à¸·à¹ˆà¸­à¸‡

### à¸‚à¸±à¹‰à¸™à¸•à¸­à¸™à¸—à¸µà¹ˆ 5: à¹ƒà¸Šà¹‰à¸‡à¸²à¸™ Edge Deployment à¸”à¹‰à¸§à¸¢ Microsoft Agent Framework

**à¸à¸²à¸£à¸à¸³à¸«à¸™à¸”à¸„à¹ˆà¸²à¸—à¸£à¸±à¸žà¸¢à¸²à¸à¸£**:
```python
from microsoft_agent_framework import ResourceConfig

# Configure for edge deployment
resource_config = ResourceConfig(
    max_memory_usage="2GB",
    max_concurrent_agents=2,
    model_cache_size="1GB",
    auto_unload_idle_models=True,
    power_management=True
)

agent = Agent(
    config=config,
    resource_limits=resource_config
)
```

**à¹ƒà¸Šà¹‰à¸¡à¸²à¸•à¸£à¸à¸²à¸£à¸„à¸§à¸²à¸¡à¸›à¸¥à¸­à¸”à¸ à¸±à¸¢à¸ªà¸³à¸«à¸£à¸±à¸š Agent à¸šà¸™ Edge**:
- **à¸à¸²à¸£à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸šà¸„à¸§à¸²à¸¡à¸–à¸¹à¸à¸•à¹‰à¸­à¸‡à¸‚à¸­à¸‡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¹ƒà¸™à¹€à¸„à¸£à¸·à¹ˆà¸­à¸‡**: à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸šà¸„à¸³à¸‚à¸­à¹‚à¸”à¸¢à¹„à¸¡à¹ˆà¸•à¹‰à¸­à¸‡à¸žà¸¶à¹ˆà¸‡à¸žà¸² Cloud
- **à¸à¸²à¸£à¸à¸£à¸­à¸‡à¸œà¸¥à¸¥à¸±à¸žà¸˜à¹Œà¹à¸šà¸šà¸­à¸­à¸Ÿà¹„à¸¥à¸™à¹Œ**: à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸šà¹ƒà¸«à¹‰à¹à¸™à¹ˆà¹ƒà¸ˆà¸§à¹ˆà¸²à¸à¸²à¸£à¸•à¸­à¸šà¸ªà¸™à¸­à¸‡à¸•à¸£à¸‡à¸•à¸²à¸¡à¸¡à¸²à¸•à¸£à¸à¸²à¸™à¸„à¸¸à¸“à¸ à¸²à¸žà¹ƒà¸™à¹€à¸„à¸£à¸·à¹ˆà¸­à¸‡
- **à¸à¸²à¸£à¸„à¸§à¸šà¸„à¸¸à¸¡à¸„à¸§à¸²à¸¡à¸›à¸¥à¸­à¸”à¸ à¸±à¸¢à¸šà¸™ Edge**: à¹ƒà¸Šà¹‰à¸¡à¸²à¸•à¸£à¸à¸²à¸£à¸£à¸±à¸à¸©à¸²à¸„à¸§à¸²à¸¡à¸›à¸¥à¸­à¸”à¸ à¸±à¸¢à¹‚à¸”à¸¢à¹„à¸¡à¹ˆà¸•à¹‰à¸­à¸‡à¹€à¸Šà¸·à¹ˆà¸­à¸¡à¸•à¹ˆà¸­à¸­à¸´à¸™à¹€à¸—à¸­à¸£à¹Œà¹€à¸™à¹‡à¸•
- **à¸à¸²à¸£à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸šà¹ƒà¸™à¹€à¸„à¸£à¸·à¹ˆà¸­à¸‡**: à¸•à¸´à¸”à¸•à¸²à¸¡à¸›à¸£à¸°à¸ªà¸´à¸—à¸˜à¸´à¸ à¸²à¸žà¹à¸¥à¸°à¹à¸ˆà¹‰à¸‡à¸›à¸±à¸à¸«à¸²à¹‚à¸”à¸¢à¹ƒà¸Šà¹‰à¸‚à¹‰à¸­à¸¡à¸¹à¸¥ Telemetry à¸šà¸™ Edge

### à¸‚à¸±à¹‰à¸™à¸•à¸­à¸™à¸—à¸µà¹ˆ 6: à¸§à¸±à¸”à¹à¸¥à¸°à¸›à¸£à¸±à¸šà¸›à¸£à¸¸à¸‡à¸›à¸£à¸°à¸ªà¸´à¸—à¸˜à¸´à¸ à¸²à¸ž Agent à¸šà¸™ Edge
- **à¸­à¸±à¸•à¸£à¸²à¸à¸²à¸£à¸—à¸³à¸‡à¸²à¸™à¸‚à¸­à¸‡ Agent**: à¸•à¸´à¸”à¸•à¸²à¸¡à¸­à¸±à¸•à¸£à¸²à¸„à¸§à¸²à¸¡à¸ªà¸³à¹€à¸£à¹‡à¸ˆà¹ƒà¸™à¸ªà¸–à¸²à¸™à¸à¸²à¸£à¸“à¹Œà¸­à¸­à¸Ÿà¹„à¸¥à¸™à¹Œ
- **à¹€à¸§à¸¥à¸²à¸•à¸­à¸šà¸ªà¸™à¸­à¸‡à¸‚à¸­à¸‡ Agent**: à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸šà¹ƒà¸«à¹‰à¹à¸™à¹ˆà¹ƒà¸ˆà¸§à¹ˆà¸²à¹€à¸§à¸¥à¸²à¸•à¸­à¸šà¸ªà¸™à¸­à¸‡à¸•à¹ˆà¸³à¸à¸§à¹ˆà¸² 1 à¸§à¸´à¸™à¸²à¸—à¸µà¸ªà¸³à¸«à¸£à¸±à¸šà¸à¸²à¸£à¹ƒà¸Šà¹‰à¸‡à¸²à¸™ Edge
- **à¸à¸²à¸£à¹ƒà¸Šà¹‰à¸—à¸£à¸±à¸žà¸¢à¸²à¸à¸£**: à¸•à¸´à¸”à¸•à¸²à¸¡à¸à¸²à¸£à¹ƒà¸Šà¹‰à¸«à¸™à¹ˆà¸§à¸¢à¸„à¸§à¸²à¸¡à¸ˆà¸³ CPU à¹à¸¥à¸°à¹à¸šà¸•à¹€à¸•à¸­à¸£à¸µà¹ˆà¸šà¸™à¸­à¸¸à¸›à¸à¸£à¸“à¹Œ Edge
- **à¸„à¸§à¸²à¸¡à¸„à¸¸à¹‰à¸¡à¸„à¹ˆà¸²**: à¹€à¸›à¸£à¸µà¸¢à¸šà¹€à¸—à¸µà¸¢à¸šà¸•à¹‰à¸™à¸—à¸¸à¸™à¸à¸²à¸£à¹ƒà¸Šà¹‰à¸‡à¸²à¸™ Edge à¸à¸±à¸šà¸—à¸²à¸‡à¹€à¸¥à¸·à¸­à¸à¸—à¸µà¹ˆà¹ƒà¸Šà¹‰ Cloud
- **à¸„à¸§à¸²à¸¡à¸™à¹ˆà¸²à¹€à¸Šà¸·à¹ˆà¸­à¸–à¸·à¸­à¹à¸šà¸šà¸­à¸­à¸Ÿà¹„à¸¥à¸™à¹Œ**: à¸§à¸±à¸”à¸›à¸£à¸°à¸ªà¸´à¸—à¸˜à¸´à¸ à¸²à¸žà¸‚à¸­à¸‡ Agent à¹ƒà¸™à¸£à¸°à¸«à¸§à¹ˆà¸²à¸‡à¸à¸²à¸£à¸‚à¸±à¸”à¸‚à¹‰à¸­à¸‡à¸‚à¸­à¸‡à¹€à¸„à¸£à¸·à¸­à¸‚à¹ˆà¸²à¸¢

## à¸‚à¹‰à¸­à¸ªà¸£à¸¸à¸›à¸ªà¸³à¸„à¸±à¸à¸ªà¸³à¸«à¸£à¸±à¸šà¸à¸²à¸£à¹ƒà¸Šà¹‰à¸‡à¸²à¸™ SLM Agent

1. **SLM à¹€à¸žà¸µà¸¢à¸‡à¸žà¸­à¸ªà¸³à¸«à¸£à¸±à¸š Agent**: à¸ªà¸³à¸«à¸£à¸±à¸šà¸‡à¸²à¸™ Agent à¸ªà¹ˆà¸§à¸™à¹ƒà¸«à¸à¹ˆ à¹‚à¸¡à¹€à¸”à¸¥à¸‚à¸™à¸²à¸”à¹€à¸¥à¹‡à¸à¸—à¸³à¸‡à¸²à¸™à¹„à¸”à¹‰à¸”à¸µà¹€à¸—à¹ˆà¸²à¸à¸±à¸šà¹‚à¸¡à¹€à¸”à¸¥à¸‚à¸™à¸²à¸”à¹ƒà¸«à¸à¹ˆà¹ƒà¸™à¸‚à¸“à¸°à¸—à¸µà¹ˆà¹ƒà¸«à¹‰à¸‚à¹‰à¸­à¹„à¸”à¹‰à¹€à¸›à¸£à¸µà¸¢à¸šà¸—à¸µà¹ˆà¸ªà¸³à¸„à¸±à¸
2. **à¸„à¸§à¸²à¸¡à¸„à¸¸à¹‰à¸¡à¸„à¹ˆà¸²à¹ƒà¸™ Agent**: à¸à¸²à¸£à¹ƒà¸Šà¹‰à¸‡à¸²à¸™ SLM Agent à¸¡à¸µà¸£à¸²à¸„à¸²à¸–à¸¹à¸à¸à¸§à¹ˆà¸² 10-30 à¹€à¸—à¹ˆà¸² à¸—à¸³à¹ƒà¸«à¹‰à¹€à¸«à¸¡à¸²à¸°à¸ªà¸¡à¸—à¸²à¸‡à¹€à¸¨à¸£à¸©à¸à¸à¸´à¸ˆà¸ªà¸³à¸«à¸£à¸±à¸šà¸à¸²à¸£à¹ƒà¸Šà¹‰à¸‡à¸²à¸™à¸­à¸¢à¹ˆà¸²à¸‡à¹à¸žà¸£à¹ˆà¸«à¸¥à¸²à¸¢
3. **à¸„à¸§à¸²à¸¡à¹€à¸Šà¸µà¹ˆà¸¢à¸§à¸Šà¸²à¸à¹€à¸‰à¸žà¸²à¸°à¸—à¸²à¸‡à¸ªà¸³à¸«à¸£à¸±à¸š Agent**: SLM à¸—à¸µà¹ˆà¸›à¸£à¸±à¸šà¹à¸•à¹ˆà¸‡à¸¡à¸±à¸à¸ˆà¸°à¸¡à¸µà¸›à¸£à¸°à¸ªà¸´à¸—à¸˜à¸´à¸ à¸²à¸žà¸”à¸µà¸à¸§à¹ˆà¸² LLM à¸—à¸±à¹ˆà¸§à¹„à¸›à¹ƒà¸™à¸‡à¸²à¸™ Agent à¹€à¸‰à¸žà¸²à¸°à¸—à¸²à¸‡
4. **à¸ªà¸–à¸²à¸›à¸±à¸•à¸¢à¸à¸£à¸£à¸¡ Agent à¹à¸šà¸šà¹„à¸®à¸šà¸£à¸´à¸”**: à¹ƒà¸Šà¹‰ SLM à¸ªà¸³à¸«à¸£à¸±à¸šà¸‡à¸²à¸™ Agent à¸—à¸±à¹ˆà¸§à¹„à¸› à¹à¸¥à¸° LLM à¸ªà¸³à¸«à¸£à¸±à¸šà¸à¸²à¸£à¸§à¸´à¹€à¸„à¸£à¸²à¸°à¸«à¹Œà¸—à¸µà¹ˆà¸‹à¸±à¸šà¸‹à¹‰à¸­à¸™à¹€à¸¡à¸·à¹ˆà¸­à¸ˆà¸³à¹€à¸›à¹‡à¸™
5. **Microsoft Agent Framework à¸Šà¹ˆà¸§à¸¢à¹ƒà¸«à¹‰à¸à¸²à¸£à¹ƒà¸Šà¹‰à¸‡à¸²à¸™à¹ƒà¸™à¸£à¸°à¸”à¸±à¸šà¸à¸²à¸£à¸œà¸¥à¸´à¸•à¹€à¸›à¹‡à¸™à¹„à¸›à¹„à¸”à¹‰**: à¸¡à¸µà¹€à¸„à¸£à¸·à¹ˆà¸­à¸‡à¸¡à¸·à¸­à¸£à¸°à¸”à¸±à¸šà¸­à¸‡à¸„à¹Œà¸à¸£à¸ªà¸³à¸«à¸£à¸±à¸šà¸à¸²à¸£à¸ªà¸£à¹‰à¸²à¸‡ à¸à¸²à¸£à¹ƒà¸Šà¹‰à¸‡à¸²à¸™ à¹à¸¥à¸°à¸à¸²à¸£à¸ˆà¸±à¸”à¸à¸²à¸£ Agent à¸šà¸™ Edge
6. **à¸«à¸¥à¸±à¸à¸à¸²à¸£à¸­à¸­à¸à¹à¸šà¸šà¸—à¸µà¹ˆà¹€à¸™à¹‰à¸™ Edge**: Agent à¸—à¸µà¹ˆà¸ªà¸²à¸¡à¸²à¸£à¸–à¸—à¸³à¸‡à¸²à¸™à¹à¸šà¸šà¸­à¸­à¸Ÿà¹„à¸¥à¸™à¹Œà¸žà¸£à¹‰à¸­à¸¡à¸à¸²à¸£à¸›à¸£à¸°à¸¡à¸§à¸¥à¸œà¸¥à¹ƒà¸™à¹€à¸„à¸£à¸·à¹ˆà¸­à¸‡à¸Šà¹ˆà¸§à¸¢à¹ƒà¸«à¹‰à¸¡à¸±à¹ˆà¸™à¹ƒà¸ˆà¹ƒà¸™à¸„à¸§à¸²à¸¡à¹€à¸›à¹‡à¸™à¸ªà¹ˆà¸§à¸™à¸•à¸±à¸§à¹à¸¥à¸°à¸„à¸§à¸²à¸¡à¸™à¹ˆà¸²à¹€à¸Šà¸·à¹ˆà¸­à¸–à¸·à¸­
7. **à¸à¸²à¸£à¸œà¸ªà¸²à¸™à¸£à¸§à¸¡ Foundry Local**: à¸à¸²à¸£à¹€à¸Šà¸·à¹ˆà¸­à¸¡à¸•à¹ˆà¸­à¸—à¸µà¹ˆà¹„à¸£à¹‰à¸£à¸­à¸¢à¸•à¹ˆà¸­à¸£à¸°à¸«à¸§à¹ˆà¸²à¸‡ Microsoft Agent Framework à¹à¸¥à¸°à¸à¸²à¸£à¸§à¸´à¹€à¸„à¸£à¸²à¸°à¸«à¹Œà¹‚à¸¡à¹€à¸”à¸¥à¹ƒà¸™à¹€à¸„à¸£à¸·à¹ˆà¸­à¸‡
8. **à¸­à¸™à¸²à¸„à¸•à¸„à¸·à¸­ SLM Agent**: à¹‚à¸¡à¹€à¸”à¸¥à¸ à¸²à¸©à¸²à¸‚à¸™à¸²à¸”à¹€à¸¥à¹‡à¸à¸žà¸£à¹‰à¸­à¸¡ framework à¸à¸²à¸£à¸œà¸¥à¸´à¸•à¸„à¸·à¸­à¸­à¸™à¸²à¸„à¸•à¸‚à¸­à¸‡ AI Agent à¸—à¸µà¹ˆà¸Šà¹ˆà¸§à¸¢à¹ƒà¸«à¹‰à¸à¸²à¸£à¹ƒà¸Šà¹‰à¸‡à¸²à¸™ Agent à¸¡à¸µà¸›à¸£à¸°à¸ªà¸´à¸—à¸˜à¸´à¸ à¸²à¸žà¹à¸¥à¸°à¹€à¸‚à¹‰à¸²à¸–à¸¶à¸‡à¹„à¸”à¹‰à¸‡à¹ˆà¸²à¸¢

## à¸­à¹‰à¸²à¸‡à¸­à¸´à¸‡à¹à¸¥à¸°à¸à¸²à¸£à¸­à¹ˆà¸²à¸™à¹€à¸žà¸´à¹ˆà¸¡à¹€à¸•à¸´à¸¡

### à¸‡à¸²à¸™à¸§à¸´à¸ˆà¸±à¸¢à¹à¸¥à¸°à¸ªà¸´à¹ˆà¸‡à¸žà¸´à¸¡à¸žà¹Œà¸«à¸¥à¸±à¸

#### AI Agent à¹à¸¥à¸°à¸£à¸°à¸šà¸š Agentic
- **"Language Agents as Optimizable Graphs"** (2024) - à¸‡à¸²à¸™à¸§à¸´à¸ˆà¸±à¸¢à¸žà¸·à¹‰à¸™à¸à¸²à¸™à¹€à¸à¸µà¹ˆà¸¢à¸§à¸à¸±à¸šà¸ªà¸–à¸²à¸›à¸±à¸•à¸¢à¸à¸£à¸£à¸¡ Agent à¹à¸¥à¸°à¸à¸¥à¸¢à¸¸à¸—à¸˜à¹Œà¸à¸²à¸£à¸›à¸£à¸±à¸šà¹à¸•à¹ˆà¸‡
  - à¸œà¸¹à¹‰à¹€à¸‚à¸µà¸¢à¸™: Wenyue Hua, Lishan Yang, et al.
  - à¸¥à¸´à¸‡à¸à¹Œ: https://arxiv.org/abs/2402.16823
  - à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸ªà¸³à¸„à¸±à¸: à¸à¸²à¸£à¸­à¸­à¸à¹à¸šà¸š Agent à¹à¸šà¸šà¸à¸£à¸²à¸Ÿà¹à¸¥à¸°à¸à¸¥à¸¢à¸¸à¸—à¸˜à¹Œà¸à¸²à¸£à¸›à¸£à¸±à¸šà¹à¸•à¹ˆà¸‡

- **"The Rise and Potential of Large Language Model Based Agents"** (2023)
  - à¸œà¸¹à¹‰à¹€à¸‚à¸µà¸¢à¸™: Zhiheng Xi, Wenxiang Chen, et al.
  - à¸¥à¸´à¸‡à¸à¹Œ: https://arxiv.org/abs/2309.07864
  - à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸ªà¸³à¸„à¸±à¸: à¸à¸²à¸£à¸ªà¸³à¸£à¸§à¸ˆà¸„à¸§à¸²à¸¡à¸ªà¸²à¸¡à¸²à¸£à¸–à¹à¸¥à¸°à¸à¸²à¸£à¹ƒà¸Šà¹‰à¸‡à¸²à¸™à¸‚à¸­à¸‡ Agent à¸—à¸µà¹ˆà¹ƒà¸Šà¹‰ LLM

- **"Cognitive Architectures for Language Agents"** (2024)
  - à¸œà¸¹à¹‰à¹€à¸‚à¸µà¸¢à¸™: Theodore Sumers, Shunyu Yao, et al.
  - à¸¥à¸´à¸‡à¸à¹Œ: https://arxiv.org/abs/2309.02427
  - à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸ªà¸³à¸„à¸±à¸: à¸à¸£à¸­à¸šà¸à¸²à¸£à¸—à¸³à¸‡à¸²à¸™à¸—à¸²à¸‡à¸›à¸±à¸à¸à¸²à¸ªà¸³à¸«à¸£à¸±à¸šà¸à¸²à¸£à¸­à¸­à¸à¹à¸šà¸š Agent à¸­à¸±à¸ˆà¸‰à¸£à¸´à¸¢à¸°

#### à¹‚à¸¡à¹€à¸”à¸¥à¸ à¸²à¸©à¸²à¸‚à¸™à¸²à¸”à¹€à¸¥à¹‡à¸à¹à¸¥à¸°à¸à¸²à¸£à¸›à¸£à¸±à¸šà¹à¸•à¹ˆà¸‡
- **"Phi-3 Technical Report: A Highly Capable Language Model Locally on Your Phone"** (2024)
  - à¸œà¸¹à¹‰à¹€à¸‚à¸µà¸¢à¸™: Microsoft Research Team
  - à¸¥à¸´à¸‡à¸à¹Œ: https://arxiv.org/abs/2404.14219
  - à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸ªà¸³à¸„à¸±à¸: à¸«à¸¥à¸±à¸à¸à¸²à¸£à¸­à¸­à¸à¹à¸šà¸š SLM à¹à¸¥à¸°à¸à¸¥à¸¢à¸¸à¸—à¸˜à¹Œà¸à¸²à¸£à¹ƒà¸Šà¹‰à¸‡à¸²à¸™à¸šà¸™à¸¡à¸·à¸­à¸–à¸·à¸­

- **"Qwen2.5 Technical Report"** (2024)
  - à¸œà¸¹à¹‰à¹€à¸‚à¸µà¸¢à¸™: Alibaba Cloud Team
  - à¸¥à¸´à¸‡à¸à¹Œ: https://arxiv.org/abs/2407.10671
  - à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸ªà¸³à¸„à¸±à¸: à¹€à¸—à¸„à¸™à¸´à¸„à¸à¸²à¸£à¸à¸¶à¸à¸­à¸šà¸£à¸¡ SLM à¸‚à¸±à¹‰à¸™à¸ªà¸¹à¸‡à¹à¸¥à¸°à¸à¸²à¸£à¸›à¸£à¸±à¸šà¹à¸•à¹ˆà¸‡à¸›à¸£à¸°à¸ªà¸´à¸—à¸˜à¸´à¸ à¸²à¸ž

- **"TinyLlama: An Open-Source Small Language Model"** (2024)
  - à¸œà¸¹à¹‰à¹€à¸‚à¸µà¸¢à¸™: Peiyuan Zhang, Guangtao Zeng, et al.
  - à¸¥à¸´à¸‡à¸à¹Œ: https://arxiv.org/abs/2401.02385
  - à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸ªà¸³à¸„à¸±à¸: à¸à¸²à¸£à¸­à¸­à¸à¹à¸šà¸šà¹‚à¸¡à¹€à¸”à¸¥à¸—à¸µà¹ˆà¸à¸°à¸—à¸±à¸”à¸£à¸±à¸”à¹à¸¥à¸°à¸›à¸£à¸°à¸ªà¸´à¸—à¸˜à¸´à¸ à¸²à¸žà¸à¸²à¸£à¸à¸¶à¸à¸­à¸šà¸£à¸¡

### à¹€à¸­à¸à¸ªà¸²à¸£à¹à¸¥à¸° Framework à¸­à¸¢à¹ˆà¸²à¸‡à¹€à¸›à¹‡à¸™à¸—à¸²à¸‡à¸à¸²à¸£

#### Microsoft Agent Framework
- **à¹€à¸­à¸à¸ªà¸²à¸£à¸­à¸¢à¹ˆà¸²à¸‡à¹€à¸›à¹‡à¸™à¸—à¸²à¸‡à¸à¸²à¸£**: https://docs.microsoft.com/en-us/azure/ai-services/agents/
- **GitHub Repository**: https://github.com/microsoft/agent-framework

#### Foundry Local
- **Repository à¸«à¸¥à¸±à¸**: https://github.com/microsoft/foundry-local
- **à¹€à¸­à¸à¸ªà¸²à¸£**: https://github.com/microsoft/foundry-local/blob/main/docs/README.md


#### VLLM
- **Repository à¸«à¸¥à¸±à¸**: https://github.com/vllm-project/vllm
- **à¹€à¸­à¸à¸ªà¸²à¸£**: https://docs.vllm.ai/


#### Ollama
- **à¹€à¸§à¹‡à¸šà¹„à¸‹à¸•à¹Œà¸­à¸¢à¹ˆà¸²à¸‡à¹€à¸›à¹‡à¸™à¸—à¸²à¸‡à¸à¸²à¸£**: https://ollama.ai/
- **GitHub Repository**: https://github.com/ollama/ollama

### Framework à¸à¸²à¸£à¸›à¸£à¸±à¸šà¹à¸•à¹ˆà¸‡à¹‚à¸¡à¹€à¸”à¸¥

#### Llama.cpp
- **Repository**: https://github.com/ggml-org/llama.cpp


#### Microsoft Olive
- **à¹€à¸­à¸à¸ªà¸²à¸£**: https://microsoft.github.io/Olive/
- **GitHub Repository**: https://github.com/microsoft/Olive

#### OpenVINO
- **à¹€à¸§à¹‡à¸šà¹„à¸‹à¸•à¹Œà¸­à¸¢à¹ˆà¸²à¸‡à¹€à¸›à¹‡à¸™à¸—à¸²à¸‡à¸à¸²à¸£**: https://docs.openvino.ai/

#### Apple MLX
- **Repository**: https://github.com/ml-explore/mlx

### à¸£à¸²à¸¢à¸‡à¸²à¸™à¸­à¸¸à¸•à¸ªà¸²à¸«à¸à¸£à¸£à¸¡à¹à¸¥à¸°à¸à¸²à¸£à¸§à¸´à¹€à¸„à¸£à¸²à¸°à¸«à¹Œà¸•à¸¥à¸²à¸”

#### à¸à¸²à¸£à¸§à¸´à¸ˆà¸±à¸¢à¸•à¸¥à¸²à¸” AI Agent
- **"The State of AI Agents 2025"** - McKinsey Global Institute
  - à¸¥à¸´à¸‡à¸à¹Œ: https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/ai-agents-2025
  - à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸ªà¸³à¸„à¸±à¸: à¹à¸™à¸§à¹‚à¸™à¹‰à¸¡à¸•à¸¥à¸²à¸”à¹à¸¥à¸°à¸£à¸¹à¸›à¹à¸šà¸šà¸à¸²à¸£à¸™à¸³à¹„à¸›à¹ƒà¸Šà¹‰à¹ƒà¸™à¸­à¸‡à¸„à¹Œà¸à¸£

#### à¸à¸²à¸£à¸§à¸±à¸”à¸›à¸£à¸°à¸ªà¸´à¸—à¸˜à¸´à¸ à¸²à¸žà¸—à¸²à¸‡à¹€à¸—à¸„à¸™à¸´à¸„

- **"Edge AI Inference Benchmarks"** - MLPerf
  - à¸¥à¸´à¸‡à¸à¹Œ: https://mlcommons.org/en/inference-edge/
  - à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸ªà¸³à¸„à¸±à¸: à¸•à¸±à¸§à¸Šà¸µà¹‰à¸§à¸±à¸”à¸›à¸£à¸°à¸ªà¸´à¸—à¸˜à¸´à¸ à¸²à¸žà¸¡à¸²à¸•à¸£à¸à¸²à¸™à¸ªà¸³à¸«à¸£à¸±à¸šà¸à¸²à¸£à¹ƒà¸Šà¹‰à¸‡à¸²à¸™ Edge

### à¸¡à¸²à¸•à¸£à¸à¸²à¸™à¹à¸¥à¸°à¸‚à¹‰à¸­à¸à¸³à¸«à¸™à¸”

#### à¸£à¸¹à¸›à¹à¸šà¸šà¹‚à¸¡à¹€à¸”à¸¥à¹à¸¥à¸°à¸¡à¸²à¸•à¸£à¸à¸²à¸™
- **ONNX (Open Neural Network Exchange)**: https://onnx.ai/
  - à¸£à¸¹à¸›à¹à¸šà¸šà¹‚à¸¡à¹€à¸”à¸¥à¸‚à¹‰à¸²à¸¡à¹à¸žà¸¥à¸•à¸Ÿà¸­à¸£à¹Œà¸¡à¹€à¸žà¸·à¹ˆà¸­à¸„à¸§à¸²à¸¡à¹€à¸‚à¹‰à¸²à¸à¸±à¸™à¹„à¸”à¹‰
- **GGUF Specification**: https://github.com/ggerganov/ggml/blob/master/docs/gguf.md
  - à¸£à¸¹à¸›à¹à¸šà¸šà¹‚à¸¡à¹€à¸”à¸¥à¸—à¸µà¹ˆà¸›à¸£à¸±à¸šà¸¥à¸”à¸ªà¸³à¸«à¸£à¸±à¸šà¸à¸²à¸£à¸§à¸´à¹€à¸„à¸£à¸²à¸°à¸«à¹Œà¸šà¸™ CPU
- **OpenAI API Specification**: https://platform.openai.com/docs/api-reference
  - à¸£à¸¹à¸›à¹à¸šà¸š API à¸¡à¸²à¸•à¸£à¸à¸²à¸™à¸ªà¸³à¸«à¸£à¸±à¸šà¸à¸²à¸£à¸œà¸ªà¸²à¸™à¸£à¸§à¸¡à¹‚à¸¡à¹€à¸”à¸¥à¸ à¸²à¸©à¸²

#### à¸„à¸§à¸²à¸¡à¸›à¸¥à¸­à¸”à¸ à¸±à¸¢à¹à¸¥à¸°à¸à¸²à¸£à¸›à¸à¸´à¸šà¸±à¸•à¸´à¸•à¸²à¸¡à¸‚à¹‰à¸­à¸à¸³à¸«à¸™à¸”
- **NIST AI Risk Management Framework**: https://www.nist.gov/itl/ai-risk-management-framework
- **ISO/IEC 23053:2022 - AI Systems**: à¸à¸£à¸­à¸šà¸à¸²à¸£à¸—à¸³à¸‡à¸²à¸™à¸ªà¸³à¸«à¸£à¸±à¸šà¸£à¸°à¸šà¸š AI à¹à¸¥à¸°à¸„à¸§à¸²à¸¡à¸›à¸¥à¸­à¸”à¸ à¸±à¸¢
- **IEEE Standards for AI**: https://standards.ieee.org/industry-connections/ai/

à¸à¸²à¸£à¹€à¸›à¸¥à¸µà¹ˆà¸¢à¸™à¹à¸›à¸¥à¸‡à¹„à¸›à¸ªà¸¹à¹ˆ Agent à¸—à¸µà¹ˆà¸‚à¸±à¸šà¹€à¸„à¸¥à¸·à¹ˆà¸­à¸™à¸”à¹‰à¸§à¸¢ SLM à¹€à¸›à¹‡à¸™à¸à¸²à¸£à¹€à¸›à¸¥à¸µà¹ˆà¸¢à¸™à¹à¸›à¸¥à¸‡à¸žà¸·à¹‰à¸™à¸à¸²à¸™à¹ƒà¸™à¸§à¸´à¸˜à¸µà¸—à¸µà¹ˆà¹€à¸£à¸²à¹€à¸‚à¹‰à¸²à¸–à¸¶à¸‡à¸à¸²à¸£à¹ƒà¸Šà¹‰à¸‡à¸²à¸™ AI Microsoft Agent Framework à¸£à¸§à¸¡à¸à¸±à¸šà¹à¸žà¸¥à¸•à¸Ÿà¸­à¸£à¹Œà¸¡à¹ƒà¸™à¹€à¸„à¸£à¸·à¹ˆà¸­à¸‡à¹à¸¥à¸° Small Language Models à¸—à¸µà¹ˆà¸¡à¸µà¸›à¸£à¸°à¸ªà¸´à¸—à¸˜à¸´à¸ à¸²à¸ž à¹ƒà¸«à¹‰à¹‚à¸‹à¸¥à¸¹à¸Šà¸±à¸™à¸—à¸µà¹ˆà¸ªà¸¡à¸šà¸¹à¸£à¸“à¹Œà¸ªà¸³à¸«à¸£à¸±à¸šà¸à¸²à¸£à¸ªà¸£à¹‰à¸²à¸‡ Agent à¸—à¸µà¹ˆà¸žà¸£à¹‰à¸­à¸¡à¹ƒà¸Šà¹‰à¸‡à¸²à¸™à¹ƒà¸™à¸£à¸°à¸”à¸±à¸š

---

**à¸‚à¹‰à¸­à¸ˆà¸³à¸à¸±à¸”à¸„à¸§à¸²à¸¡à¸£à¸±à¸šà¸œà¸´à¸”à¸Šà¸­à¸š**:  
à¹€à¸­à¸à¸ªà¸²à¸£à¸™à¸µà¹‰à¹„à¸”à¹‰à¸£à¸±à¸šà¸à¸²à¸£à¹à¸›à¸¥à¹‚à¸”à¸¢à¹ƒà¸Šà¹‰à¸šà¸£à¸´à¸à¸²à¸£à¹à¸›à¸¥à¸ à¸²à¸©à¸² AI [Co-op Translator](https://github.com/Azure/co-op-translator) à¹à¸¡à¹‰à¸§à¹ˆà¸²à¹€à¸£à¸²à¸ˆà¸°à¸žà¸¢à¸²à¸¢à¸²à¸¡à¹ƒà¸«à¹‰à¸à¸²à¸£à¹à¸›à¸¥à¸¡à¸µà¸„à¸§à¸²à¸¡à¸–à¸¹à¸à¸•à¹‰à¸­à¸‡ à¹à¸•à¹ˆà¹‚à¸›à¸£à¸”à¸—à¸£à¸²à¸šà¸§à¹ˆà¸²à¸à¸²à¸£à¹à¸›à¸¥à¹‚à¸”à¸¢à¸­à¸±à¸•à¹‚à¸™à¸¡à¸±à¸•à¸´à¸­à¸²à¸ˆà¸¡à¸µà¸‚à¹‰à¸­à¸œà¸´à¸”à¸žà¸¥à¸²à¸”à¸«à¸£à¸·à¸­à¸„à¸§à¸²à¸¡à¹„à¸¡à¹ˆà¸–à¸¹à¸à¸•à¹‰à¸­à¸‡ à¹€à¸­à¸à¸ªà¸²à¸£à¸•à¹‰à¸™à¸‰à¸šà¸±à¸šà¹ƒà¸™à¸ à¸²à¸©à¸²à¸”à¸±à¹‰à¸‡à¹€à¸”à¸´à¸¡à¸„à¸§à¸£à¸–à¸·à¸­à¹€à¸›à¹‡à¸™à¹à¸«à¸¥à¹ˆà¸‡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸—à¸µà¹ˆà¹€à¸Šà¸·à¹ˆà¸­à¸–à¸·à¸­à¹„à¸”à¹‰ à¸ªà¸³à¸«à¸£à¸±à¸šà¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸—à¸µà¹ˆà¸ªà¸³à¸„à¸±à¸ à¸‚à¸­à¹à¸™à¸°à¸™à¸³à¹ƒà¸«à¹‰à¹ƒà¸Šà¹‰à¸šà¸£à¸´à¸à¸²à¸£à¹à¸›à¸¥à¸ à¸²à¸©à¸²à¸¡à¸·à¸­à¸­à¸²à¸Šà¸µà¸ž à¹€à¸£à¸²à¸ˆà¸°à¹„à¸¡à¹ˆà¸£à¸±à¸šà¸œà¸´à¸”à¸Šà¸­à¸šà¸•à¹ˆà¸­à¸„à¸§à¸²à¸¡à¹€à¸‚à¹‰à¸²à¹ƒà¸ˆà¸œà¸´à¸”à¸«à¸£à¸·à¸­à¸à¸²à¸£à¸•à¸µà¸„à¸§à¸²à¸¡à¸œà¸´à¸”à¸—à¸µà¹ˆà¹€à¸à¸´à¸”à¸ˆà¸²à¸à¸à¸²à¸£à¹ƒà¸Šà¹‰à¸à¸²à¸£à¹à¸›à¸¥à¸™à¸µà¹‰