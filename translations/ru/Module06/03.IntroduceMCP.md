# Раздел 03 - Интеграция протокола контекста модели (MCP)

## Введение в MCP (Model Context Protocol)

Протокол контекста модели (MCP) — это стандарт с открытым исходным кодом для подключения приложений ИИ к внешним системам. С помощью MCP приложения ИИ, такие как Claude или ChatGPT, могут подключаться к источникам данных (например, локальным файлам, базам данных), инструментам (например, поисковым системам, калькуляторам) и рабочим процессам (например, специализированным подсказкам), что позволяет им получать важную информацию и выполнять задачи.

Представьте MCP как **порт USB-C для приложений ИИ**. Точно так же, как USB-C предоставляет стандартизированный способ подключения электронных устройств, MCP предоставляет стандартизированный способ подключения приложений ИИ к внешним системам.

### Что позволяет MCP?

MCP открывает мощные возможности для приложений ИИ:

- **Персонализированные AI-ассистенты**: Агенты могут получить доступ к вашему Google Calendar и Notion, становясь более персонализированным AI-ассистентом.
- **Продвинутая генерация кода**: Claude Code может создать целое веб-приложение, используя дизайн из Figma.
- **Интеграция данных для предприятий**: Чат-боты для бизнеса могут подключаться к нескольким базам данных в организации, позволяя пользователям анализировать данные через чат.
- **Творческие рабочие процессы**: Модели ИИ могут создавать 3D-дизайны в Blender и печатать их на 3D-принтере.
- **Доступ к информации в реальном времени**: Подключение к внешним источникам данных для получения актуальной информации.
- **Сложные многоэтапные операции**: Выполнение сложных рабочих процессов, объединяющих несколько инструментов и систем.

### Почему MCP важен?

MCP приносит пользу всей экосистеме:

**Для разработчиков**: MCP сокращает время и сложность разработки при создании или интеграции приложения или агента ИИ.

**Для приложений ИИ**: MCP предоставляет доступ к экосистеме источников данных, инструментов и приложений, что улучшает возможности и повышает качество пользовательского опыта.

**Для конечных пользователей**: MCP делает приложения и агентов ИИ более функциональными, позволяя им получать доступ к вашим данным и выполнять действия от вашего имени, когда это необходимо.

## Малые языковые модели (SLMs) в MCP

Малые языковые модели представляют собой эффективный подход к развертыванию ИИ, предлагая несколько преимуществ:

### Преимущества SLMs
- **Эффективность ресурсов**: Меньшие вычислительные требования.
- **Быстрое время отклика**: Сниженная задержка для приложений в реальном времени.  
- **Экономичность**: Минимальные потребности в инфраструктуре.
- **Конфиденциальность**: Возможность работы локально без передачи данных.
- **Настройка**: Легче адаптировать для конкретных областей.

### Почему SLMs хорошо работают с MCP

SLMs в сочетании с MCP создают мощную комбинацию, где возможности рассуждения модели усиливаются за счет внешних инструментов, компенсируя их меньший объем параметров за счет расширенной функциональности.

## Обзор Python MCP SDK

Python MCP SDK предоставляет основу для создания приложений с поддержкой MCP. SDK включает:

- **Клиентские библиотеки**: Для подключения к серверам MCP.
- **Серверный фреймворк**: Для создания пользовательских серверов MCP.
- **Обработчики протоколов**: Для управления коммуникацией.
- **Интеграция инструментов**: Для выполнения внешних функций.

## Практическая реализация: клиент Phi-4 MCP

Давайте рассмотрим реальную реализацию с использованием мини-модели Phi-4 от Microsoft, интегрированной с возможностями MCP.

### Обзор архитектуры MCP

MCP следует **архитектуре клиент-сервер**, где хост MCP (приложение ИИ, такое как Claude Code или Claude Desktop) устанавливает соединения с одним или несколькими серверами MCP. Хост MCP делает это, создавая одного клиента MCP для каждого сервера MCP.

#### Основные участники

- **Хост MCP**: Приложение ИИ, которое координирует и управляет одним или несколькими клиентами MCP.
- **Клиент MCP**: Компонент, поддерживающий соединение с сервером MCP и получающий контекст от сервера MCP для использования хостом MCP.
- **Сервер MCP**: Программа, предоставляющая контекст клиентам MCP.

#### Двухуровневая архитектура

MCP состоит из двух отдельных уровней:

**Уровень данных**: Определяет протокол на основе JSON-RPC для клиент-серверной коммуникации, включая:
- Управление жизненным циклом (инициализация соединения, согласование возможностей).
- Основные примитивы (инструменты, ресурсы, подсказки).
- Функции клиента (выбор, запросы, ведение журнала).
- Утилитарные функции (уведомления, отслеживание прогресса).

**Транспортный уровень**: Определяет механизмы и каналы связи:
- **STDIO Transport**: Использует стандартные потоки ввода/вывода для локальных процессов (оптимальная производительность, отсутствие сетевых накладных расходов).
- **Streamable HTTP Transport**: Использует HTTP POST с опциональными событиями, отправляемыми сервером, для удаленных серверов (поддерживает стандартную HTTP-аутентификацию).

```
┌─────────────────────────────────────┐
│           MCP Host                  │
│     (AI Application)                │
└─────────────────┬───────────────────┘
                  │
┌─────────────────┴───────────────────┐
│         MCP Client 1                │
│  ┌─────────────────────────────────┐ │
│  │        Data Layer               │ │
│  │  ├── Lifecycle Management       │ │
│  │  ├── Primitives (Tools/Resources)│ │
│  │  └── Notifications              │ │
│  └─────────────────────────────────┘ │
│  ┌─────────────────────────────────┐ │
│  │      Transport Layer           │ │
│  │  ├── STDIO Transport           │ │
│  │  └── HTTP Transport            │ │
│  └─────────────────────────────────┘ │
└─────────────────┬───────────────────┘
                  │
┌─────────────────┴───────────────────┐
│         MCP Server 1                │
│    (Local/Remote Context Provider)  │
└─────────────────────────────────────┘
```

### Основные примитивы MCP

MCP определяет примитивы, которые указывают типы контекстной информации, которую можно передавать приложениям ИИ, и диапазон действий, которые можно выполнять.

#### Примитивы сервера

MCP определяет три основных примитива, которые могут предоставлять серверы:

**Инструменты**: Выполняемые функции, которые приложения ИИ могут вызывать для выполнения действий.
- Примеры: операции с файлами, вызовы API, запросы к базе данных.
- Методы: `tools/list`, `tools/call`.
- Поддержка динамического обнаружения и выполнения.

**Ресурсы**: Источники данных, предоставляющие контекстную информацию приложениям ИИ.
- Примеры: содержимое файлов, записи базы данных, ответы API.
- Методы: `resources/list`, `resources/read`.
- Обеспечивают доступ к структурированным данным.

**Подсказки**: Повторно используемые шаблоны, которые помогают структурировать взаимодействие с языковыми моделями.
- Примеры: системные подсказки, примеры few-shot.
- Методы: `prompts/list`, `prompts/get`.
- Стандартизируют шаблоны взаимодействия с ИИ.

#### Примитивы клиента

MCP также определяет примитивы, которые клиенты могут предоставлять для более богатого взаимодействия:

**Выбор**: Позволяет серверам запрашивать завершения языковой модели от приложения ИИ клиента.
- Метод: `sampling/complete`.
- Обеспечивает независимую от модели разработку серверов.
- Предоставляет доступ к языковой модели хоста.

**Запросы**: Позволяет серверам запрашивать дополнительную информацию у пользователей.
- Метод: `elicitation/request`.
- Обеспечивает взаимодействие с пользователем и подтверждение.
- Поддерживает динамический сбор информации.

**Ведение журнала**: Позволяет серверам отправлять сообщения журнала клиентам.
- Используется для отладки и мониторинга.
- Обеспечивает прозрачность операций сервера.

### Жизненный цикл протокола MCP

#### Инициализация и согласование возможностей

MCP — это протокол с состоянием, который требует управления жизненным циклом. Процесс инициализации выполняет несколько критически важных функций:

1. **Согласование версии протокола**: Гарантирует, что клиент и сервер используют совместимые версии протокола (например, "2025-06-18").
2. **Обнаружение возможностей**: Каждая сторона заявляет о поддерживаемых функциях и примитивах.
3. **Обмен идентификацией**: Предоставляет информацию об идентификации и версии.

```python
# Example initialization request
{
  "jsonrpc": "2.0",
  "id": 1,
  "method": "initialize",
  "params": {
    "protocolVersion": "2025-06-18",
    "capabilities": {
      "elicitation": {},  # Client supports user interaction
      "sampling": {}      # Client can provide LLM completions
    },
    "clientInfo": {
      "name": "edge-ai-client",
      "version": "1.0.0"
    }
  }
}
```

#### Обнаружение и выполнение инструментов

После инициализации клиенты могут обнаруживать и выполнять инструменты:

```python
# Discover available tools
tools_response = await session.list_tools()

# Execute a tool
result = await session.call_tool(
    "weather_current",
    {
        "location": "San Francisco",
        "units": "imperial"
    }
)
```

#### Уведомления в реальном времени

MCP поддерживает уведомления в реальном времени для динамических обновлений:

```python
# Server sends notification when tools change
{
  "jsonrpc": "2.0",
  "method": "notifications/tools/list_changed"
}

# Client responds by refreshing tool list
await session.list_tools()  # Get updated tools
```

## Начало работы: пошаговое руководство

### Шаг 1: Настройка окружения

Установите необходимые зависимости:
```bash
pip install fastmcp mcp-python-client openai requests pyautogui Pillow
```

### Шаг 2: Базовая конфигурация

Настройте переменные окружения:
```python
# System Configuration
SYSTEM_PROMPT = "You are an AI assistant with some tools."

# Ollama Configuration (Local)
OLLAMA_URL = "http://localhost:11434/api/chat"
OLLAMA_MODEL_ID = "phi4-mini:3.8b-fp16"

# vLLM Configuration (Server)
VLLM_URL = "http://localhost:8000/v1"
VLLM_MODEL_ID = "microsoft/Phi-4-mini-instruct"
```

### Шаг 3: Запуск первого клиента MCP

**Базовая настройка Ollama:**
```bash
python ghmodel_mcp_demo.py
```

**Использование vLLM Backend:**
```bash
python ghmodel_mcp_demo.py --env vllm
```

**Подключение через события сервера:**
```bash
python ghmodel_mcp_demo.py --run sse
```

**Пользовательский сервер MCP:**
```bash
python ghmodel_mcp_demo.py --server /path/to/server.py
```

### Шаг 4: Программное использование

```python
import asyncio
from ghmodel_mcp_demo import OllamaClient, Phi4MiniMCPClient

async def automated_interaction():
    # Configure MCP server parameters
    server_params = StdioServerParameters(
        command="npx",
        args=["@playwright/mcp@latest"],
        env=None,
    )
    
    # Create MCP client and process tools
    async with Phi4MiniMCPClient(server_params) as mcp_client:
        tools = await process_mcp_tools(mcp_client)
        llm_client = OllamaClient()
        
        # Generate response with tool capabilities
        response, messages = await llm_client.generate_response(
            "Help me automate a web task",
            tools
        )
        return response

# Execute the automation
result = asyncio.run(automated_interaction())
print(result)
```

## Расширенные функции

### Поддержка нескольких бэкендов

Реализация поддерживает как Ollama, так и vLLM бэкенды, позволяя выбирать в зависимости от ваших требований:

- **Ollama**: Лучше для локальной разработки и тестирования.
- **vLLM**: Оптимизирован для производственных и высоконагруженных сценариев.

### Гибкие протоколы подключения

Поддерживаются два режима подключения:

**Режим STDIO**: Прямое взаимодействие процессов.
- Меньшая задержка.
- Подходит для локальных инструментов.
- Простая настройка.

**Режим SSE**: Потоковая передача через HTTP.
- Поддержка сетевых подключений.
- Лучше для распределенных систем.
- Обновления в реальном времени.

### Возможности интеграции инструментов

Система может интегрироваться с различными инструментами:
- Веб-автоматизация (Playwright).
- Операции с файлами.
- Взаимодействие с API.
- Системные команды.
- Пользовательские функции.

## Обработка ошибок и лучшие практики

### Комплексное управление ошибками

Реализация включает надежную обработку ошибок для:

**Ошибки подключения:**
- Сбои серверов MCP.
- Тайм-ауты сети.
- Проблемы с подключением.

**Ошибки выполнения инструментов:**
- Отсутствие инструментов.
- Проверка параметров.
- Сбои выполнения.

**Ошибки обработки ответов:**
- Проблемы с разбором JSON.
- Несоответствия форматов.
- Аномалии ответов LLM.

### Лучшие практики

1. **Управление ресурсами**: Используйте асинхронные контекстные менеджеры.
2. **Обработка ошибок**: Реализуйте комплексные блоки try-catch.
3. **Ведение журнала**: Включите соответствующие уровни логирования.
4. **Безопасность**: Проверяйте входные данные и очищайте выходные.
5. **Производительность**: Используйте пул соединений и кэширование.

## Применение в реальной жизни

### Веб-автоматизация
```python
# Example: Automated web testing
async def web_automation_example():
    tools = await setup_playwright_tools()
    response = await llm_client.generate_response(
        "Navigate to example.com and take a screenshot",
        tools
    )
```

### Обработка данных
```python
# Example: File analysis
async def data_processing_example():
    tools = await setup_file_tools()
    response = await llm_client.generate_response(
        "Analyze the CSV file and generate a summary report",
        tools
    )
```

### Интеграция API
```python
# Example: API interactions
async def api_integration_example():
    tools = await setup_api_tools()
    response = await llm_client.generate_response(
        "Fetch weather data and create a forecast summary",
        tools
    )
```

## Оптимизация производительности

### Управление памятью
- Эффективная обработка истории сообщений.
- Правильная очистка ресурсов.
- Пул соединений.

### Оптимизация сети
- Асинхронные HTTP-операции.
- Настраиваемые тайм-ауты.
- Плавное восстановление после ошибок.

### Конкурентная обработка
- Неблокирующий ввод/вывод.
- Параллельное выполнение инструментов.
- Эффективные асинхронные шаблоны.

## Вопросы безопасности

### Защита данных
- Безопасное управление ключами API.
- Проверка входных данных.
- Очистка выходных данных.

### Сетевая безопасность
- Поддержка HTTPS.
- Локальные конечные точки по умолчанию.
- Безопасное управление токенами.

### Безопасность выполнения
- Фильтрация инструментов.
- Изолированные среды.
- Ведение журнала аудита.

## Экосистема и разработка MCP

### Объем проекта MCP

Экосистема Model Context Protocol включает несколько ключевых компонентов:

- **[Спецификация MCP](https://modelcontextprotocol.io/specification/latest)**: Официальная спецификация, описывающая требования к реализации клиентов и серверов.
- **[SDK MCP](https://modelcontextprotocol.io/docs/sdk)**: SDK для различных языков программирования, реализующих MCP.
- **Инструменты разработки MCP**: Инструменты для разработки серверов и клиентов MCP, включая [MCP Inspector](https://github.com/modelcontextprotocol/inspector).
- **[Референсные реализации серверов MCP](https://github.com/modelcontextprotocol/servers)**: Референсные реализации серверов MCP.

### Начало разработки с MCP

Чтобы начать разработку с MCP:

**Создание серверов**: [Создавайте серверы MCP](https://modelcontextprotocol.io/docs/develop/build-server), чтобы предоставлять ваши данные и инструменты.

**Создание клиентов**: [Разрабатывайте приложения](https://modelcontextprotocol.io/docs/develop/build-client), которые подключаются к серверам MCP.

**Изучение концепций**: [Понимайте основные концепции](https://modelcontextprotocol.io/docs/learn/architecture) и архитектуру MCP.

## Заключение

SLMs, интегрированные с MCP, представляют собой сдвиг парадигмы в разработке приложений ИИ. Объединяя эффективность малых моделей с мощью внешних инструментов, разработчики могут создавать интеллектуальные системы, которые одновременно экономичны и высокофункциональны.

Протокол контекста модели предоставляет стандартизированный способ подключения приложений ИИ к внешним системам, подобно тому, как USB-C обеспечивает универсальный стандарт подключения для электронных устройств. Эта стандартизация позволяет:

- **Бесшовная интеграция**: Подключение моделей ИИ к разнообразным источникам данных и инструментам.
- **Рост экосистемы**: Разработка одного решения для использования в нескольких приложениях ИИ.
- **Расширенные возможности**: Усиление SLMs за счет внешней функциональности.
- **Обновления в реальном времени**: Поддержка динамичных, отзывчивых приложений ИИ.

Основные выводы:
- MCP — это открытый стандарт, соединяющий приложения ИИ и внешние системы.
- Протокол поддерживает инструменты, ресурсы и подсказки как основные примитивы.
- Уведомления в реальном времени позволяют создавать динамичные, отзывчивые приложения.
- Правильное управление жизненным циклом и обработка ошибок необходимы для использования в производстве.
- Экосистема предоставляет комплексные SDK и инструменты для разработки.

## Ссылки и дополнительная информация

### Официальная документация MCP

- **[Официальный сайт Model Context Protocol](https://modelcontextprotocol.io/)** - Полная документация и спецификации.
- **[Руководство по началу работы с MCP](https://modelcontextprotocol.io/docs/getting-started/intro)** - Введение и основные концепции.
- **[Обзор архитектуры MCP](https://modelcontextprotocol.io/docs/learn/architecture)** - Подробная техническая архитектура.
- **[Спецификация MCP](https://modelcontextprotocol.io/specification/latest)** - Официальная спецификация протокола.
- **[Документация SDK MCP](https://modelcontextprotocol.io/docs/sdk)** - Руководства по SDK для различных языков.

### Ресурсы для разработки

- **[MCP для начинающих](https://aka.ms/mcp-for-beginners)** - Полное руководство для начинающих по Model Context Protocol.
- **[Организация MCP на GitHub](https://github.com/modelcontextprotocol)** - Официальные репозитории и примеры.
- **[Репозиторий серверов MCP](https://github.com/modelcontextprotocol/servers)** - Референсные реализации серверов.
- **[MCP Inspector](https://github.com/modelcontextprotocol/inspector)** - Инструмент для разработки и отладки.
- **[Руководство по созданию серверов MCP](https://modelcontextprotocol.io/docs/develop/build-server)** - Учебник по разработке серверов.
- **[Руководство по созданию клиентов MCP](https://modelcontextprotocol.io/docs/develop/build-client)** - Учебник по разработке клиентов.

### Малые языковые модели и Edge AI

- **[Модели Microsoft Phi](https://aka.ms/phicookbook)** - Семейство моделей Phi.
- **[Локальная документация Foundry](https://github.com/microsoft/Foundry-Local)** - Среда выполнения Edge AI от Microsoft.
- **[Документация Ollama](https://ollama.ai/docs)** - Платформа для локального развертывания LLM
- **[Документация vLLM](https://docs.vllm.ai/)** - Высокопроизводительное обслуживание LLM

### Технические стандарты и протоколы

- **[Спецификация JSON-RPC 2.0](https://www.jsonrpc.org/)** - Основной RPC-протокол, используемый MCP
- **[JSON Schema](https://json-schema.org/)** - Стандарт определения схем для инструментов MCP
- **[Спецификация OpenAPI](https://swagger.io/specification/)** - Стандарт документации API
- **[События, отправляемые сервером (SSE)](https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events)** - Веб-стандарт для обновлений в реальном времени

### Разработка AI-агентов

- **[Microsoft Agent Framework](https://github.com/microsoft/agent-framework)** - Готовая к производству платформа для разработки агентов
- **[Документация LangChain](https://docs.langchain.com/)** - Фреймворк для интеграции агентов и инструментов
- **[Semantic Kernel](https://learn.microsoft.com/en-us/semantic-kernel/)** - SDK для оркестрации AI от Microsoft

### Отчеты и исследования отрасли

- **[Анонс протокола Model Context Protocol от Anthropic](https://www.anthropic.com/news/model-context-protocol)** - Первоначальное представление MCP
- **[Обзор малых языковых моделей](https://arxiv.org/abs/2410.20011)** - Академический обзор исследований SLM
- **[Анализ рынка Edge AI](https://www.marketsandmarkets.com/Market-Reports/edge-ai-software-market-74385617.html)** - Тенденции и прогнозы отрасли
- **[Лучшие практики разработки AI-агентов](https://arxiv.org/abs/2309.02427)** - Исследование архитектур агентов

Этот раздел предоставляет основу для создания собственных приложений MCP на базе SLM, открывая возможности для автоматизации, обработки данных и интеграции интеллектуальных систем.

## ➡️ Что дальше

- [Модуль 7. Примеры Edge AI](../Module07/README.md)

---

**Отказ от ответственности**:  
Этот документ был переведен с использованием сервиса автоматического перевода [Co-op Translator](https://github.com/Azure/co-op-translator). Хотя мы стремимся к точности, пожалуйста, учитывайте, что автоматические переводы могут содержать ошибки или неточности. Оригинальный документ на его родном языке следует считать авторитетным источником. Для получения критически важной информации рекомендуется профессиональный перевод человеком. Мы не несем ответственности за любые недоразумения или неправильные интерпретации, возникающие в результате использования данного перевода.