<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "8c30436578b1bd604c48233ecdd39701",
  "translation_date": "2025-11-11T21:46:02+00:00",
  "source_file": "Workshop/Session01-GettingStartedFoundryLocal.md",
  "language_code": "ur"
}
-->
# ุณุดู 1: ูุงุคูฺุฑ ููฺฉู ฺฉ ุณุงุชฺพ ุดุฑูุนุงุช

## ุฎูุงุต

ูุงุฆฺฉุฑูุณุงููน ูุงุคูฺุฑ ููฺฉู ฺฉ ุฐุฑุน ุงูพู ูพู AI ูุงฺูุฒ ฺฉู ุงูุณูนุงูุ ุชุฑุชุจ ุฏฺบ ุงูุฑ ฺูุงุฆฺบ  ุนูู ุณุดู ููุงู ุงููุฑูุณ ฺฉุง ูุฑุญู ูุงุฑ ุชุนุงุฑู ูุฑุงู ฺฉุฑุชุง ุ ุงูุณูนุงูุดู ุณ ู ฺฉุฑ ูุงฺูุฒ ุฌุณ Phi-4ุ Qwenุ ุงูุฑ DeepSeek ฺฉ ุณุงุชฺพ ุงูพู ูพู ฺูน ุงูพูฺฉุดู ุจูุงู ุชฺฉ

## ุณฺฉฺพู ฺฉ ููุงุตุฏ

ุงุณ ุณุดู ฺฉ ุงุฎุชุชุงู ุชฺฉ ุขูพ:

- **ุงูุณูนุงู ุงูุฑ ุชุฑุชุจ ุฏฺบ**: ูุงุคูฺุฑ ููฺฉู ฺฉู ุตุญุญ ุงูุณูนุงูุดู ฺฉ ุชุตุฏู ฺฉ ุณุงุชฺพ ุณูน ุงูพ ฺฉุฑฺบ ฺฏ
- **CLI ุขูพุฑุดูุฒ ูฺบ ูุงุฑุช ุญุงุตู ฺฉุฑฺบ**: ูุงฺู ููุฌูููน ุงูุฑ ฺูพูุงุฆูููน ฺฉ ู ูุงุคูฺุฑ ููฺฉู CLI ุงุณุชุนูุงู ฺฉุฑฺบ ฺฏ
- **ุงูพูุง ูพูุง ูุงฺู ฺูุงุฆฺบ**: ููุงู AI ูุงฺู ฺฉู ฺฉุงูุงุจ ุณ ฺูพูุงุฆ ุงูุฑ ุงููนุฑฺฉูน ฺฉุฑฺบ ฺฏ
- **ฺูน ุงูพ ุจูุงุฆฺบ**: ูุงุคูฺุฑ ููฺฉู ูพุงุฆุชฺพูู SDK ุงุณุชุนูุงู ฺฉุฑุช ูุฆ ุงฺฉ ุจูุงุฏ ฺูน ุงูพูฺฉุดู ุจูุงุฆฺบ ฺฏ
- **ููุงู AI ฺฉู ุณูุฌฺพฺบ**: ููุงู ุงููุฑูุณ ุงูุฑ ูุงฺู ููุฌูููน ฺฉ ุจูุงุฏ ุจุงุชูฺบ ฺฉู ุณูุฌฺพฺบ ฺฏ

## ุถุฑูุฑุงุช

### ุณุณูนู ฺฉ ุถุฑูุฑุงุช

- **ููฺูุฒ**: ููฺูุฒ 11 (22H2 ุง ุจุนุฏ ฺฉุง) ุง **macOS**: macOS 11+ (ูุญุฏูุฏ ุณูพูุฑูน)
- **RAM**: ฺฉู ุงุฒ ฺฉู 8GBุ 16GB+ ุชุฌูุฒ ฺฉุฑุฏ
- **ุงุณูนูุฑุฌ**: ูุงฺูุฒ ฺฉ ู 10GB+ ุฎุงู ุฌฺฏ
- **ูพุงุฆุชฺพูู**: 3.10 ุง ุจุนุฏ ฺฉุง ุงูุณูนุงู ุดุฏ
- **ุงฺูู ุฑุณุงุฆ**: ุงูุณูนุงูุดู ฺฉ ู ุงฺููุณูนุฑูนุฑ ฺฉ ูุฑุงุนุงุช

### ุชุฑูุงุช ูุงุญูู

- ูพุงุฆุชฺพูู ุงฺฉุณูนูุดู ฺฉ ุณุงุชฺพ ูฺูู ุงุณูนูฺู ฺฉูฺ (ุชุฌูุฒ ฺฉุฑุฏ)
- ฺฉูุงูฺ ูุงุฆู ุฑุณุงุฆ (ููฺูุฒ ูพุฑ ูพุงูุฑ ุดูุ macOS ูพุฑ ูนุฑููู)
- ุฑูพูุฒูนุฑุฒ ฺฉููู ฺฉุฑู ฺฉ ู ฺฏูน (ุงุฎุชุงุฑ)

## ูุฑฺฉุดุงูพ ฺฉุง ุจุงุค (30 ูููน)

### ูุฑุญู 1: ูุงุคูฺุฑ ููฺฉู ุงูุณูนุงู ฺฉุฑฺบ (5 ูููน)

#### ููฺูุฒ ุงูุณูนุงูุดู

ููฺูุฒ ูพฺฉุฌ ููุฌุฑ ุงุณุชุนูุงู ฺฉุฑุช ูุฆ ูุงุคูฺุฑ ููฺฉู ุงูุณูนุงู ฺฉุฑฺบ:

```powershell
# Install via winget (recommended)
winget install Microsoft.FoundryLocal
```

ูุชุจุงุฏู: [ูุงุฆฺฉุฑูุณุงููน ูุฑู](https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/install) ุณ ุจุฑุง ุฑุงุณุช ฺุงุคูููฺ ฺฉุฑฺบ

#### macOS ุงูุณูนุงูุดู (ูุญุฏูุฏ ุณูพูุฑูน)

> [!NOTE]  
> macOS ุณูพูุฑูน ู ุงูุญุงู ูพุฑูู ูฺบ  ุชุงุฒ ุชุฑู ุฏุณุชุงุจ ฺฉ ู ุขูุดู ุฏุณุชุงูุฒุงุช ฺฺฉ ฺฉุฑฺบ

ุงฺฏุฑ ุฏุณุชุงุจ ู ุชูุ ูู ุจุฑู ุงุณุชุนูุงู ฺฉุฑุช ูุฆ ุงูุณูนุงู ฺฉุฑฺบ:

```bash
# If Homebrew formula is available
brew update
brew install foundry-local

# Or manual download (check official docs for latest)
curl -L -o foundry-local.tar.gz "https://download.microsoft.com/foundry-local/latest/macos/foundry-local.tar.gz"
tar -xzf foundry-local.tar.gz
sudo ./install.sh
```

**macOS ุตุงุฑูู ฺฉ ู ูุชุจุงุฏู:**
- ููฺูุฒ 11 VM (Parallels/UTM) ุงุณุชุนูุงู ฺฉุฑฺบ ุงูุฑ ููฺูุฒ ฺฉ ูุฑุงุญู ูพุฑ ุนูู ฺฉุฑฺบ
- ฺฉููนูุฑ ฺฉ ุฐุฑุน ฺูุงุฆฺบ ุงฺฏุฑ ุฏุณุชุงุจ ู ุงูุฑ `FOUNDRY_LOCAL_ENDPOINT` ฺฉู ุชุฑุชุจ ุฏฺบ

### ูุฑุญู 2: ุงูุณูนุงูุดู ฺฉ ุชุตุฏู ฺฉุฑฺบ (3 ูููน)

ุงูุณูนุงูุดู ฺฉ ุจุนุฏุ ุงูพูุง ูนุฑููู ุฏูุจุงุฑ ุดุฑูุน ฺฉุฑฺบ ุงูุฑ ุชุตุฏู ฺฉุฑฺบ ฺฉ ูุงุคูฺุฑ ููฺฉู ฺฉุงู ฺฉุฑ ุฑุง :

```powershell
# Check if Foundry Local is installed correctly
foundry --version

# View available commands
foundry --help
```

ูุชููุน ุขุคูน ูพูน ูุฑฺู ฺฉ ูุนูููุงุช ุงูุฑ ุฏุณุชุงุจ ฺฉูุงูฺุฒ ุฏฺฉฺพุงุฆ ฺฏุง

### ูุฑุญู 3: ูพุงุฆุชฺพูู ูุงุญูู ุชุฑุชุจ ุฏฺบ (5 ูููน)

ุงุณ ูุฑฺฉุดุงูพ ฺฉ ู ุงฺฉ ูุฎุตูุต ูพุงุฆุชฺพูู ูุงุญูู ุจูุงุฆฺบ:

**ููฺูุฒ:**
```powershell
# Create virtual environment
py -m venv .venv

# Activate environment
.\.venv\Scripts\Activate.ps1

# Upgrade pip and install dependencies
python -m pip install --upgrade pip
pip install foundry-local-sdk openai
```

**macOS/Linux:**
```bash
# Create virtual environment
python3 -m venv .venv

# Activate environment
source .venv/bin/activate

# Upgrade pip and install dependencies
python -m pip install --upgrade pip
pip install foundry-local-sdk openai
```


### ูุฑุญู 4: ุงูพูุง ูพูุง ูุงฺู ฺูุงุฆฺบ (7 ูููน)

ุงุจ ู ุงูพูุง ูพูุง AI ูุงฺู ููุงู ุทูุฑ ูพุฑ ฺูุงุฆฺบ ฺฏ!

#### Phi-4 Mini ุณ ุดุฑูุน ฺฉุฑฺบ (ุชุฌูุฒ ฺฉุฑุฏ ูพูุง ูุงฺู)

```powershell
# Download and start phi-4-mini (lightweight, fast)
foundry model run phi-4-mini

# Test the model with a simple prompt
foundry model run phi-4-mini --prompt "Hello, introduce yourself in one sentence"
```

> [!TIP]  
>  ฺฉูุงูฺ ูุงฺู ฺฉู ฺุงุคูููฺ ฺฉุฑุช  (ูพู ุจุงุฑ) ุงูุฑ ูุงุคูฺุฑ ููฺฉู ุณุฑูุณ ฺฉู ุฎูุฏ ุจุฎูุฏ ุดุฑูุน ฺฉุฑุช 

#### ฺฺฉ ฺฉุฑฺบ ฺฉ ฺฉุง ฺู ุฑุง 

```powershell
# List available models (shows downloaded models)
foundry model list

# Check service status
foundry service status

# See what models are cached locally
foundry cache list
```


#### ูุฎุชูู ูุงฺูุฒ ุขุฒูุงุฆฺบ

ุงฺฉ ุจุงุฑ phi-4-mini ฺฉุงู ฺฉุฑ ุฑุง ูุ ุฏูุณุฑ ูุงฺูุฒ ฺฉ ุณุงุชฺพ ุชุฌุฑุจ ฺฉุฑฺบ:

```powershell
# Larger model with better capabilities
foundry model run gpt-oss-20b --prompt "Explain edge AI in simple terms"

# Fast, efficient model
foundry model run qwen2.5-0.5b --prompt "What are the benefits of local AI inference?"
```


### ูุฑุญู 5: ุงูพู ูพู ฺูน ุงูพูฺฉุดู ุจูุงุฆฺบ (10 ูููน)

ุงุจ ู ุงฺฉ ูพุงุฆุชฺพูู ุงูพูฺฉุดู ุจูุงุฆฺบ ฺฏ ุฌู ุงู ูุงฺูุฒ ฺฉู ุงุณุชุนูุงู ฺฉุฑ ฺฏ ุฌู ู ู ุงุจฺพ ุดุฑูุน ฺฉ ฺบ

#### ฺูน ุงุณฺฉุฑูพูน ุจูุงุฆฺบ

`my_first_chat.py` ูุงู ุงฺฉ ูุฆ ูุงุฆู ุจูุงุฆฺบ (ุง ูุฑุงู ฺฉุฑุฏ ูููู ุงุณุชุนูุงู ฺฉุฑฺบ):

```python
#!/usr/bin/env python3
"""
My First Foundry Local Chat Application
Using FoundryLocalManager for automatic service management
"""

import os
from foundry_local import FoundryLocalManager
from openai import OpenAI

def main():
    # Get model alias from environment or use default
    alias = os.getenv("FOUNDRY_LOCAL_ALIAS", "phi-4-mini")
    
    try:
        # Initialize Foundry Local Manager (auto-starts service, downloads model)
        manager = FoundryLocalManager(alias)
        
        # Create OpenAI client pointing to local endpoint
        client = OpenAI(
            base_url=manager.endpoint,
            api_key=manager.api_key or "not-needed"
        )
        
        # Get the actual model ID for this alias
        model_id = manager.get_model_info(alias).id
        
        print("๐ค Welcome to your first local AI chat!")
        print(f"๏ฟฝ Using model: {alias} -> {model_id}")
        print(f"๐ Endpoint: {manager.endpoint}")
        print("๏ฟฝ๐ก Type 'quit' to exit\n")
        
    except Exception as e:
        print(f"โ Failed to initialize Foundry Local: {e}")
        print("๐ก Make sure Foundry Local is installed: foundry --version")
        return
    
    while True:
        # Get user input
        user_message = input("You: ").strip()
        
        if user_message.lower() in ['quit', 'exit', 'bye']:
            print("๐ Goodbye!")
            break
            
        if not user_message:
            continue
            
        try:
            # Send message to local AI model
            response = client.chat.completions.create(
                model=model_id,
                messages=[
                    {"role": "system", "content": "You are a helpful AI assistant running locally."},
                    {"role": "user", "content": user_message}
                ],
                max_tokens=200,
                temperature=0.7
            )
            
            # Display the response
            ai_response = response.choices[0].message.content
            print(f"๐ค AI: {ai_response}\n")
            
        except Exception as e:
            print(f"โ Error: {e}")
            print("๐ก Check service status: foundry service status\n")

if __name__ == "__main__":
    main()
```

> [!TIP]  
> **ูุชุนูู ูุซุงูฺบ**: ูุฒุฏ ุฌุฏุฏ ุงุณุชุนูุงู ฺฉ ู ุฏฺฉฺพฺบ:
>
> - **ูพุงุฆุชฺพูู ูููู**: `Workshop/samples/session01/chat_bootstrap.py` - ุงุณูนุฑููฺฏ ุฌูุงุจุงุช ุงูุฑ ุงุฑุฑ ูฺููฺฏ ุดุงูู ฺบ
> - **ุฌููพูนุฑ ูููน ุจฺฉ**: `Workshop/notebooks/session01_chat_bootstrap.ipynb` - ุชูุตู ูุถุงุญุชูฺบ ฺฉ ุณุงุชฺพ ุงููนุฑุงฺฉูนู ูุฑฺู

#### ุงูพู ฺูน ุงูพูฺฉุดู ฺฉ ุฌุงูฺ ฺฉุฑฺบ

```powershell
# No need to manually start models - FoundryLocalManager handles this!
# Just run your chat application
python my_first_chat.py
```

ูุชุจุงุฏู: ูุฑุงู ฺฉุฑุฏ ูููููฺบ ฺฉู ุจุฑุง ุฑุงุณุช ุงุณุชุนูุงู ฺฉุฑฺบ

```powershell
# Try the complete sample with streaming support
cd Workshop/samples
python -m session01.chat_bootstrap "Your question here"
```

ุง ุงููนุฑุงฺฉูนู ูููน ุจฺฉ ฺฉู ุฏุฑุงูุช ฺฉุฑฺบ  
Workshop/notebooks/session01_chat_bootstrap.ipynb ฺฉู VS ฺฉูฺ ูฺบ ฺฉฺพููฺบ

ุงู ูุซุงู ฺฏูุชฺฏู ฺฉู ุขุฒูุงุฆฺบ:

- "ูุงุฆฺฉุฑูุณุงููน ูุงุคูฺุฑ ููฺฉู ฺฉุง ุ"
- "AI ูุงฺูุฒ ฺฉู ููุงู ุทูุฑ ูพุฑ ฺูุงู ฺฉ 3 ููุงุฆุฏ ุจุชุงุฆฺบ"
- "ูุฌฺพ ุงุฌ AI ฺฉู ุณูุฌฺพู ูฺบ ูุฏุฏ ฺฉุฑฺบ"

## ุขูพ ู ฺฉุง ุญุงุตู ฺฉุง

ูุจุงุฑฺฉ ู! ุขูพ ู ฺฉุงูุงุจ ุณ:

1. โ **ูุงุคูฺุฑ ููฺฉู ุงูุณูนุงู ฺฉุง** ุงูุฑ ุชุตุฏู ฺฉ ฺฉ  ฺฉุงู ฺฉุฑ ุฑุง 
2. โ **ุงูพูุง ูพูุง AI ูุงฺู ุดุฑูุน ฺฉุง** (phi-4-mini) ููุงู ุทูุฑ ูพุฑ
3. โ **ูุฎุชูู ูุงฺูุฒ ฺฉู ฺฉูุงูฺ ูุงุฆู ฺฉ ุฐุฑุน ุขุฒูุงุง**
4. โ **ุงฺฉ ฺูน ุงูพูฺฉุดู ุจูุงุฆ** ุฌู ุขูพ ฺฉ ููุงู AI ุณ ุฌฺุช 
5. โ **ููุงู AI ุงููุฑูุณ ฺฉุง ุชุฌุฑุจ ฺฉุง** ุจุบุฑ ฺฉูุงุคฺ ุงูุญุตุงุฑ ฺฉ

## ุฌู ฺฉฺฺพ ูุง ุงุณ ุณูุฌฺพูุง

### ููุงู AI ุงููุฑูุณ

- ุขูพ ฺฉ AI ูุงฺูุฒ ูฺฉูู ุทูุฑ ูพุฑ ุขูพ ฺฉ ฺฉููพููนุฑ ูพุฑ ฺูุช ฺบ
- ฺฉูุฆ ฺูนุง ฺฉูุงุคฺ ฺฉู ูฺบ ุจฺพุฌุง ุฌุงุชุง
- ุฌูุงุจุงุช ุขูพ ฺฉ CPU/GPU ฺฉุง ุงุณุชุนูุงู ฺฉุฑุช ูุฆ ููุงู ุทูุฑ ูพุฑ ุชุงุฑ ฺฉ ุฌุงุช ฺบ
- ูพุฑุงุฆูุณ ุงูุฑ ุณฺฉูุฑูน ุจุฑูุฑุงุฑ ุฑุช 

### ูุงฺู ููุฌูููน

- `foundry model run` ูุงฺูุฒ ฺฉู ฺุงุคูููฺ ุงูุฑ ุดุฑูุน ฺฉุฑุชุง 
- **FoundryLocalManager SDK** ุณุฑูุณ ุงุณูนุงุฑูน ุงูพ ุงูุฑ ูุงฺู ููฺูฺฏ ฺฉู ุฎูุฏ ุจุฎูุฏ ูฺู ฺฉุฑุชุง 
- ูุงฺูุฒ ูุณุชูุจู ฺฉ ุงุณุชุนูุงู ฺฉ ู ููุงู ุทูุฑ ูพุฑ ฺฉุด ฺฉ ุฌุงุช ฺบ
- ูุชุนุฏุฏ ูุงฺูุฒ ฺุงุคูููฺ ฺฉ ุฌุง ุณฺฉุช ฺบ ูฺฉู ุนุงู ุทูุฑ ูพุฑ ุงฺฉ ููุช ูฺบ ุงฺฉ ฺูุชุง 
- ุณุฑูุณ ุฎูุฏ ุจุฎูุฏ ูุงฺู ูุงุฆู ุณุงุฆฺฉู ฺฉู ููุฌ ฺฉุฑุช 

### SDK ุจููุงุจู CLI ุทุฑู

- **CLI ุทุฑู**: `foundry model run <model>` ฺฉ ุณุงุชฺพ ุฏุณุช ูุงฺู ููุฌูููน
- **SDK ุทุฑู**: `FoundryLocalManager(alias)` ฺฉ ุณุงุชฺพ ุฎูุฏฺฉุงุฑ ุณุฑูุณ + ูุงฺู ููุฌูููน
- **ุชุฌูุฒ**: ุงูพูฺฉุดูุฒ ฺฉ ู SDK ุงุณุชุนูุงู ฺฉุฑฺบุ ูนุณูนูฺฏ ุงูุฑ ุงฺฉุณูพููุฑุดู ฺฉ ู CLI

## ุนุงู ฺฉูุงูฺุฒ ฺฉุง ุญูุงู

### ุถุฑูุฑ CLI ฺฉูุงูฺุฒ

```powershell
# Installation & Setup
foundry --version              # Check installation
foundry --help                 # View all commands

# Model Management
foundry model list             # List available models
foundry model run <model>      # Download and start a model
foundry model run <model> --prompt "text"  # One-shot prompt
foundry cache list             # Show downloaded models

# Service Management
foundry service status         # Check if service is running
foundry service start          # Start the service manually
foundry service stop           # Stop the service
```


### ูุงฺู ฺฉ ุณูุงุฑุดุงุช

- **phi-4-mini**: ุจุชุฑู ุงุจุชุฏุงุฆ ูุงฺู - ุชุฒุ ูฺฉุง ูพฺพูฺฉุงุ ุงฺฺพ ฺฉูุงููน
- **qwen2.5-0.5b**: ุชุฒ ุชุฑู ุงููุฑูุณุ ฺฉู ุณ ฺฉู ูููุฑ ุงุณุชุนูุงู
- **gpt-oss-20b**: ุงุนููฐ ูุนุงุฑ ฺฉ ุฌูุงุจุงุชุ ุฒุงุฏ ูุณุงุฆู ฺฉ ุถุฑูุฑุช
- **deepseek-coder-1.3b**: ูพุฑูฺฏุฑุงููฺฏ ุงูุฑ ฺฉูฺ ฺฉ ฺฉุงููฺบ ฺฉ ู ุจุชุฑ

## ุฎุฑุงุจูฺบ ฺฉุง ุงุฒุงู

### "ูุงุคูฺุฑ ฺฉูุงูฺ ูฺบ ูู"

**ุญู:**

```powershell
# Restart your terminal after installation
# Or manually add to PATH (Windows)
$env:PATH += ";C:\Program Files\Microsoft\FoundryLocal"
```


### "ูุงฺู ููฺ ฺฉุฑู ูฺบ ูุงฺฉุงู"

**ุญู:**

```powershell
# Check available system memory
foundry service status

# Try a smaller model first
foundry model run phi-4-mini

# Check disk space for model downloads
# Models are stored in: %USERPROFILE%\.foundry\models (Windows)
```


### "ููฺฉู ูุณูน ูพุฑ ฺฉูฺฉุดู ุฑููุฒฺ"

**ุญู:**

```powershell
# Check if service is running
foundry service status

# Start service if needed
foundry service start

# Verify the port (default is 5273)
# Check for port conflicts with: netstat -an | findstr 5273
```


## ุงฺฏู ุงูุฏุงูุงุช

### ููุฑ ุงฺฏู ุงฺฉุดูุฒ

1. **ูุฎุชูู ูุงฺูุฒ ุงูุฑ ูพุฑุงููพูนุณ ฺฉ ุณุงุชฺพ ุชุฌุฑุจ ฺฉุฑฺบ**
2. **ุงูพู ฺูน ุงูพูฺฉุดู ูฺบ ุชุฑูู ฺฉุฑฺบ ุชุงฺฉ ูุฎุชูู ูุงฺูุฒ ุขุฒูุงุฆ ุฌุง ุณฺฉฺบ**
3. **ุงูพู ูพุฑุงููพูนุณ ุจูุงุฆฺบ ุงูุฑ ุฌูุงุจุงุช ุขุฒูุงุฆฺบ**
4. **ุณุดู 2: RAG ุงูพูฺฉุดูุฒ ุจูุงู ฺฉู ุฏุฑุงูุช ฺฉุฑฺบ**

### ุงฺูุงูุณฺ ูุฑููฺฏ ูพุงุชฺพ

1. **ุณุดู 2**: RAG (Retrieval-Augmented Generation) ฺฉ ุณุงุชฺพ AI ุญู ุจูุงุฆฺบ
2. **ุณุดู 3**: ูุฎุชูู ุงููพู ุณูุฑุณ ูุงฺูุฒ ฺฉุง ููุงุฒู ฺฉุฑฺบ
3. **ุณุดู 4**: ุฌุฏุฏ ุชุฑู ูุงฺูุฒ ฺฉ ุณุงุชฺพ ฺฉุงู ฺฉุฑฺบ
4. **ุณุดู 5**: ูููน ุงุฌููน AI ุณุณูนูุฒ ุจูุงุฆฺบ

## ูุงุญูู ฺฉ ูุชุบุฑุงุช (ุงุฎุชุงุฑ)

ุฒุงุฏ ุฌุฏุฏ ุงุณุชุนูุงู ฺฉ ูุ ุขูพ  ูุงุญูู ฺฉ ูุชุบุฑุงุช ุณูน ฺฉุฑ ุณฺฉุช ฺบ:

| ูุชุบุฑ | ููุตุฏ | ูุซุงู |
|-------|-------|-------|
| `FOUNDRY_LOCAL_ALIAS` | ุงุณุชุนูุงู ฺฉุฑู ฺฉ ู ฺูุงููน ูุงฺู | `phi-4-mini` |
| `FOUNDRY_LOCAL_ENDPOINT` | ุงูฺ ูพูุงุฆููน URL ฺฉู ุงููุฑุฑุงุฆฺ ฺฉุฑฺบ | `http://localhost:5273/v1` |

ุงูพู ูพุฑูุฌฺฉูน ฺุงุฆุฑฺฉูนุฑ ูฺบ `.env` ูุงุฆู ุจูุงุฆฺบ:
```
FOUNDRY_LOCAL_ALIAS=phi-4-mini
FOUNDRY_LOCAL_ENDPOINT=auto
```


## ุงุถุงู ูุณุงุฆู

### ุฏุณุชุงูุฒุงุช

- [ูุงุคูฺุฑ ููฺฉู ูพุงุฆุชฺพูู SDK ุญูุงู](https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/reference/reference-sdk?pivots=programming-language-python)
- [ูุงุคูฺุฑ ููฺฉู ุงูุณูนุงูุดู ฺฏุงุฆฺ](https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/install)
- [ูุงฺู ฺฉูนูุงฺฏ](https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/models)

### ูููู ฺฉูฺ

- **ุณุดู01 ูพุงุฆุชฺพูู ูููู**: `Workshop/samples/session01/chat_bootstrap.py` - ุงุณูนุฑููฺฏ ฺฉ ุณุงุชฺพ ูฺฉูู ฺูน ุงูพ
- **ุณุดู01 ูููน ุจฺฉ**: `Workshop/notebooks/session01_chat_bootstrap.ipynb` - ุงููนุฑุงฺฉูนู ูนููนูุฑู  
- [ูุงฺูู08 ูููู 01](../Module08/samples/01/README.md) - REST ฺูน ฺฉูุฆฺฉ ุงุณูนุงุฑูน
- [ูุงฺูู08 ูููู 02](../Module08/samples/02/README.md) - OpenAI SDK ุงููนฺฏุฑุดู
- [ูุงฺูู08 ูููู 03](../Module08/samples/03/README.md) - ูุงฺู ฺุณฺฉูุฑ ุงูุฑ ุจูฺ ูุงุฑฺฉูฺฏ

### ฺฉููููน

- [ูุงุคูฺุฑ ููฺฉู ฺฏูน ุจ ฺุณฺฉุดูุฒ](https://github.com/microsoft/Foundry-Local/discussions)
- [Azure AI ฺฉููููน](https://techcommunity.microsoft.com/category/artificialintelligence)

---

**ุณุดู ฺฉุง ุฏูุฑุงู**: 30 ูููน ุนูู + 15 ูููน ุณูุงู ู ุฌูุงุจ  
**ูุดฺฉู ฺฉ ุณุทุญ**: ุงุจุชุฏุงุฆ  
**ุถุฑูุฑุงุช**: ููฺูุฒ 11/macOS 11+, ูพุงุฆุชฺพูู 3.10+, ุงฺูู ุฑุณุงุฆ

## ูุฑฺฉุดุงูพ ฺฉ ูุซุงู ููุธุฑูุงู

### ุญูู ุฏูุง ฺฉุง ุณุงู ู ุณุจุงู

**ููุธุฑูุงู**: ุงฺฉ ุงููนุฑูพุฑุงุฆุฒ IT ูนู ฺฉู ุญุณุงุณ ููุงุฒู ฺฉ ุฑุงุฆ ฺฉู ูพุฑูุณุณ ฺฉุฑู ฺฉ ู ฺูุงุฆุณ ูพุฑ AI ุงููุฑูุณ ฺฉุง ุฌุงุฆุฒ ูู ฺฉ ุถุฑูุฑุช ุ ุจุบุฑ ฺูนุง ฺฉู ุจุฑูู ุณุฑูุณุฒ ูพุฑ ุจฺพุฌ

**ุขูพ ฺฉุง ููุตุฏ**:  ุธุงุฑ ฺฉุฑฺบ ฺฉ ููุงู AI ูุงฺูุฒ ูุนุงุฑ ุฌูุงุจุงุช ูุฑุงู ฺฉุฑ ุณฺฉุช ฺบุ ุณุจ ุณฺฉูฺ ููนูุณ ฺฉ ุณุงุชฺพุ ุฌุจฺฉ ูฺฉูู ฺูนุง ูพุฑุงุฆูุณ ุจุฑูุฑุงุฑ ุฑฺฉฺพุช ฺบ

### ูนุณูน ูพุฑุงููพูนุณ

ุงูพู ุณูน ุงูพ ฺฉ ุชุตุฏู ฺฉ ู ุงู ูพุฑุงููพูนุณ ฺฉุง ุงุณุชุนูุงู ฺฉุฑฺบ:

```json
[
    "List two benefits of local inference.",
    "Summarize why keeping data on device improves privacy.",
    "Give one trade-off when choosing a small model over a large model."
]
```


### ฺฉุงูุงุจ ฺฉ ูุนุงุฑ

- โ ุชูุงู ูพุฑุงููพูนุณ 2 ุณฺฉูฺ ุณ ฺฉู ููุช ูฺบ ุฌูุงุจุงุช ุญุงุตู ฺฉุฑุช ฺบ
- โ ฺฉูุฆ ฺูนุง ุขูพ ฺฉ ููุงู ูุดู ุณ ุจุงุฑ ูฺบ ุฌุงุชุง
- โ ุฌูุงุจุงุช ูุชุนูู ุงูุฑ ูุฏุฏฺฏุงุฑ ฺบ
- โ ุขูพ ฺฉ ฺูน ุงูพูฺฉุดู ููุงุฑ ุทุฑู ุณ ฺฉุงู ฺฉุฑุช 

 ุชุตุฏู ูู ุจูุงุช  ฺฉ ุขูพ ฺฉุง ูุงุคูฺุฑ ููฺฉู ุณูน ุงูพ ุณุดูุฒ 2-6 ูฺบ ุงฺูุงูุณฺ ูุฑฺฉุดุงูพุณ ฺฉ ู ุชุงุฑ 

---

<!-- CO-OP TRANSLATOR DISCLAIMER START -->
**ฺุณฺฉููุฑ**:  
 ุฏุณุชุงูุฒ AI ุชุฑุฌู ุณุฑูุณ [Co-op Translator](https://github.com/Azure/co-op-translator) ฺฉุง ุงุณุชุนูุงู ฺฉุฑุช ูุฆ ุชุฑุฌู ฺฉ ฺฏุฆ  ู ุฏุฑุณุชฺฏ ฺฉ ู ฺฉูุดุด ฺฉุฑุช ฺบุ ูฺฉู ุจุฑุง ฺฉุฑู ุขฺฏุง ุฑฺบ ฺฉ ุฎูุฏฺฉุงุฑ ุชุฑุฌู ูฺบ ุบูุทุงฺบ ุง ุบุฑ ุฏุฑุณุชุงฺบ ู ุณฺฉุช ฺบ ุงุตู ุฏุณุชุงูุฒ ฺฉู ุงุณ ฺฉ ุงุตู ุฒุจุงู ูฺบ ูุณุชูุฏ ุฐุฑุน ุณูุฌฺพุง ุฌุงูุง ฺุง ุงู ูุนูููุงุช ฺฉ ูุ ูพุด ูุฑ ุงูุณุงู ุชุฑุฌู ฺฉ ุณูุงุฑุด ฺฉ ุฌุงุช  ู ุงุณ ุชุฑุฌู ฺฉ ุงุณุชุนูุงู ุณ ูพุฏุง ูู ูุงู ฺฉุณ ุจฺพ ุบูุท ูู ุง ุบูุท ุชุดุฑุญ ฺฉ ุฐู ุฏุงุฑ ูฺบ ฺบ
<!-- CO-OP TRANSLATOR DISCLAIMER END -->