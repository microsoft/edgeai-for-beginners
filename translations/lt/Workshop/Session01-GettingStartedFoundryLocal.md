# Sesija 1: PradÅ¾ia su Foundry Local

## Santrauka

SuÅ¾inokite, kaip Ä¯diegti, konfigÅ«ruoti ir paleisti pirmuosius AI modelius naudojant Microsoft Foundry Local. Å i praktinÄ— sesija suteikia Å¾ingsnis po Å¾ingsnio Ä¯vadÄ… Ä¯ vietinÄ¯ modeliÅ³ naudojimÄ… â€“ nuo diegimo iki pirmosios pokalbiÅ³ programos kÅ«rimo naudojant tokius modelius kaip Phi-4, Qwen ir DeepSeek.

## Mokymosi tikslai

Po Å¡ios sesijos jÅ«s:

- **Ä®diegsite ir konfigÅ«ruosite**: Nustatysite Foundry Local su tinkamu diegimo patikrinimu
- **Ä®valdysite CLI operacijas**: Naudosite Foundry Local CLI modeliÅ³ valdymui ir diegimui
- **Paleisite pirmÄ…jÄ¯ modelÄ¯**: SÄ—kmingai paleisite ir sÄ…veikausite su vietiniu AI modeliu
- **Sukursite pokalbiÅ³ programÄ…**: Sukursite pagrindinÄ™ pokalbiÅ³ programÄ… naudodami Foundry Local Python SDK
- **Suprasite vietinÄ¯ AI**: Ä®gysite pagrindines Å¾inias apie vietinÄ¯ modeliÅ³ naudojimÄ… ir valdymÄ…

## Reikalavimai

### Sistemos reikalavimai

- **Windows**: Windows 11 (22H2 ar naujesnÄ—) ARBA **macOS**: macOS 11+ (ribota palaikymas)
- **RAM**: maÅ¾iausiai 8GB, rekomenduojama 16GB+
- **Saugykla**: maÅ¾iausiai 10GB laisvos vietos modeliams
- **Python**: Ä¯diegta 3.10 ar naujesnÄ— versija
- **Administratoriaus teisÄ—s**: administratoriaus teisÄ—s diegimui

### KÅ«rimo aplinka

- Visual Studio Code su Python plÄ—tiniu (rekomenduojama)
- KomandinÄ—s eilutÄ—s prieiga (PowerShell Windows, Terminal macOS)
- Git, skirtas saugyklÅ³ klonavimui (neprivaloma)

## Seminaro eiga (30 minuÄiÅ³)

### 1 Å¾ingsnis: Foundry Local diegimas (5 minutÄ—s)

#### Windows diegimas

Ä®diekite Foundry Local naudodami Windows paketÅ³ tvarkyklÄ™:

```powershell
# Install via winget (recommended)
winget install Microsoft.FoundryLocal
```

Alternatyva: AtsisiÅ³skite tiesiogiai iÅ¡ [Microsoft Learn](https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/install)

#### macOS diegimas (ribota palaikymas)

> [!NOTE] 
> macOS palaikymas Å¡iuo metu yra perÅ¾iÅ«ros stadijoje. Patikrinkite oficialiÄ… dokumentacijÄ… dÄ—l naujausios informacijos.

Jei Ä¯manoma, Ä¯diekite naudodami Homebrew:

```bash
# If Homebrew formula is available
brew update
brew install foundry-local

# Or manual download (check official docs for latest)
curl -L -o foundry-local.tar.gz "https://download.microsoft.com/foundry-local/latest/macos/foundry-local.tar.gz"
tar -xzf foundry-local.tar.gz
sudo ./install.sh
```

**Alternatyva macOS vartotojams:**
- Naudokite Windows 11 VM (Parallels/UTM) ir sekite Windows diegimo Å¾ingsnius
- Paleiskite per konteinerÄ¯, jei Ä¯manoma, ir konfigÅ«ruokite `FOUNDRY_LOCAL_ENDPOINT`

### 2 Å¾ingsnis: Diegimo patikrinimas (3 minutÄ—s)

Po diegimo, iÅ¡ naujo paleiskite terminalÄ… ir patikrinkite, ar Foundry Local veikia:

```powershell
# Check if Foundry Local is installed correctly
foundry --version

# View available commands
foundry --help
```

TikÄ—tinas rezultatas turÄ—tÅ³ rodyti versijos informacijÄ… ir galimus komandas.

### 3 Å¾ingsnis: Python aplinkos nustatymas (5 minutÄ—s)

Sukurkite dedikuotÄ… Python aplinkÄ… Å¡iam seminarui:

**Windows:**
```powershell
# Create virtual environment
py -m venv .venv

# Activate environment
.\.venv\Scripts\Activate.ps1

# Upgrade pip and install dependencies
python -m pip install --upgrade pip
pip install foundry-local-sdk openai
```

**macOS/Linux:**
```bash
# Create virtual environment
python3 -m venv .venv

# Activate environment
source .venv/bin/activate

# Upgrade pip and install dependencies
python -m pip install --upgrade pip
pip install foundry-local-sdk openai
```

### 4 Å¾ingsnis: Pirmojo modelio paleidimas (7 minutÄ—s)

Dabar paleiskime pirmÄ…jÄ¯ AI modelÄ¯ vietoje!

#### PradÄ—kite nuo Phi-4 Mini (rekomenduojamas pirmasis modelis)

```powershell
# Download and start phi-4-mini (lightweight, fast)
foundry model run phi-4-mini

# Test the model with a simple prompt
foundry model run phi-4-mini --prompt "Hello, introduce yourself in one sentence"
```

> [!TIP]
> Å i komanda atsisiunÄia modelÄ¯ (pirmÄ… kartÄ…) ir automatiÅ¡kai paleidÅ¾ia Foundry Local paslaugÄ….

#### Patikrinkite, kas veikia

```powershell
# List available models (shows downloaded models)
foundry model list

# Check service status
foundry service status

# See what models are cached locally
foundry cache list
```

#### IÅ¡bandykite kitus modelius

Kai phi-4-mini veikia, eksperimentuokite su kitais modeliais:

```powershell
# Larger model with better capabilities
foundry model run gpt-oss-20b --prompt "Explain edge AI in simple terms"

# Fast, efficient model
foundry model run qwen2.5-0.5b --prompt "What are the benefits of local AI inference?"
```

### 5 Å¾ingsnis: Sukurkite pirmÄ…jÄ… pokalbiÅ³ programÄ… (10 minuÄiÅ³)

Dabar sukurkime Python programÄ…, kuri naudoja kÄ… tik paleistus modelius.

#### Sukurkite pokalbiÅ³ scenarijÅ³

Sukurkite naujÄ… failÄ… pavadinimu `my_first_chat.py` (arba naudokite pateiktÄ… pavyzdÄ¯):

```python
#!/usr/bin/env python3
"""
My First Foundry Local Chat Application
Using FoundryLocalManager for automatic service management
"""

import os
from foundry_local import FoundryLocalManager
from openai import OpenAI

def main():
    # Get model alias from environment or use default
    alias = os.getenv("FOUNDRY_LOCAL_ALIAS", "phi-4-mini")
    
    try:
        # Initialize Foundry Local Manager (auto-starts service, downloads model)
        manager = FoundryLocalManager(alias)
        
        # Create OpenAI client pointing to local endpoint
        client = OpenAI(
            base_url=manager.endpoint,
            api_key=manager.api_key or "not-needed"
        )
        
        # Get the actual model ID for this alias
        model_id = manager.get_model_info(alias).id
        
        print("ğŸ¤– Welcome to your first local AI chat!")
        print(f"ï¿½ Using model: {alias} -> {model_id}")
        print(f"ğŸŒ Endpoint: {manager.endpoint}")
        print("ï¿½ğŸ’¡ Type 'quit' to exit\n")
        
    except Exception as e:
        print(f"âŒ Failed to initialize Foundry Local: {e}")
        print("ğŸ’¡ Make sure Foundry Local is installed: foundry --version")
        return
    
    while True:
        # Get user input
        user_message = input("You: ").strip()
        
        if user_message.lower() in ['quit', 'exit', 'bye']:
            print("ğŸ‘‹ Goodbye!")
            break
            
        if not user_message:
            continue
            
        try:
            # Send message to local AI model
            response = client.chat.completions.create(
                model=model_id,
                messages=[
                    {"role": "system", "content": "You are a helpful AI assistant running locally."},
                    {"role": "user", "content": user_message}
                ],
                max_tokens=200,
                temperature=0.7
            )
            
            # Display the response
            ai_response = response.choices[0].message.content
            print(f"ğŸ¤– AI: {ai_response}\n")
            
        except Exception as e:
            print(f"âŒ Error: {e}")
            print("ğŸ’¡ Check service status: foundry service status\n")

if __name__ == "__main__":
    main()
```

> [!TIP]
> **SusijÄ™ pavyzdÅ¾iai**: DÄ—l sudÄ—tingesnio naudojimo Å¾r.:
>
> - **Python pavyzdys**: `Workshop/samples/session01/chat_bootstrap.py` - Apima srautinÄ¯ atsakymÄ… ir klaidÅ³ tvarkymÄ…
> - **Jupyter Notebook**: `Workshop/notebooks/session01_chat_bootstrap.ipynb` - Interaktyvi versija su iÅ¡samiais paaiÅ¡kinimais

#### IÅ¡bandykite savo pokalbiÅ³ programÄ…

```powershell
# No need to manually start models - FoundryLocalManager handles this!
# Just run your chat application
python my_first_chat.py
```

Alternatyva: Naudokite pateiktus pavyzdÅ¾ius tiesiogiai

```powershell
# Try the complete sample with streaming support
cd Workshop/samples
python -m session01.chat_bootstrap "Your question here"
```

Arba tyrinÄ—kite interaktyvÅ³ uÅ¾raÅ¡Å³ knygelÄ™
Atidarykite Workshop/notebooks/session01_chat_bootstrap.ipynb VS Code

IÅ¡bandykite Å¡iuos pokalbiÅ³ pavyzdÅ¾ius:

- "Kas yra Microsoft Foundry Local?"
- "IÅ¡vardinkite 3 privalumus, kai AI modeliai veikia vietoje"
- "PadÄ—kite man suprasti edge AI"

## KÄ… pasiekÄ—te

Sveikiname! JÅ«s sÄ—kmingai:

1. âœ… **Ä®diegÄ—te Foundry Local** ir patikrinote, kad jis veikia
2. âœ… **Paleidote pirmÄ…jÄ¯ AI modelÄ¯** (phi-4-mini) vietoje
3. âœ… **IÅ¡bandÄ—te skirtingus modelius** per komandÅ³ eilutÄ™
4. âœ… **SukÅ«rÄ—te pokalbiÅ³ programÄ…**, kuri jungiasi prie jÅ«sÅ³ vietinio AI
5. âœ… **PatyrÄ—te vietinÄ¯ AI naudojimÄ…** be debesÅ³ priklausomybÄ—s

## Supratimas, kas Ä¯vyko

### Vietinis AI naudojimas

- JÅ«sÅ³ AI modeliai veikia visiÅ¡kai jÅ«sÅ³ kompiuteryje
- Duomenys nÄ—ra siunÄiami Ä¯ debesÄ¯
- Atsakymai generuojami vietoje naudojant jÅ«sÅ³ CPU/GPU
- UÅ¾tikrinamas privatumas ir saugumas

### ModeliÅ³ valdymas

- `foundry model run` atsisiunÄia ir paleidÅ¾ia modelius
- **FoundryLocalManager SDK** automatiÅ¡kai tvarko paslaugos paleidimÄ… ir modeliÅ³ Ä¯krovimÄ…
- Modeliai saugomi vietoje, kad bÅ«tÅ³ galima naudoti ateityje
- Galima atsisiÅ³sti kelis modelius, taÄiau paprastai vienu metu veikia tik vienas
- Paslauga automatiÅ¡kai valdo modeliÅ³ gyvavimo ciklÄ…

### SDK ir CLI metodai

- **CLI metodas**: Rankinis modeliÅ³ valdymas su `foundry model run <model>`
- **SDK metodas**: Automatinis paslaugos ir modeliÅ³ valdymas su `FoundryLocalManager(alias)`
- **Rekomendacija**: Naudokite SDK programoms, CLI testavimui ir tyrinÄ—jimui

## DaÅ¾niausiai naudojamos komandos

### EsminÄ—s CLI komandos

```powershell
# Installation & Setup
foundry --version              # Check installation
foundry --help                 # View all commands

# Model Management
foundry model list             # List available models
foundry model run <model>      # Download and start a model
foundry model run <model> --prompt "text"  # One-shot prompt
foundry cache list             # Show downloaded models

# Service Management
foundry service status         # Check if service is running
foundry service start          # Start the service manually
foundry service stop           # Stop the service
```

### ModeliÅ³ rekomendacijos

- **phi-4-mini**: Geriausias pradinis modelis â€“ greitas, lengvas, gera kokybÄ—
- **qwen2.5-0.5b**: GreiÄiausias atsakymÅ³ generavimas, minimalus atminties naudojimas
- **gpt-oss-20b**: AukÅ¡tesnÄ—s kokybÄ—s atsakymai, reikalauja daugiau resursÅ³
- **deepseek-coder-1.3b**: Optimizuotas programavimui ir kodavimo uÅ¾duotims

## TrikÄiÅ³ Å¡alinimas

### "Foundry komanda nerasta"

**Sprendimas:**

```powershell
# Restart your terminal after installation
# Or manually add to PATH (Windows)
$env:PATH += ";C:\Program Files\Microsoft\FoundryLocal"
```

### "Modelio Ä¯krovimas nepavyko"

**Sprendimas:**

```powershell
# Check available system memory
foundry service status

# Try a smaller model first
foundry model run phi-4-mini

# Check disk space for model downloads
# Models are stored in: %USERPROFILE%\.foundry\models (Windows)
```

### "RyÅ¡ys su localhost atmestas"

**Sprendimas:**

```powershell
# Check if service is running
foundry service status

# Start service if needed
foundry service start

# Verify the port (default is 5273)
# Check for port conflicts with: netstat -an | findstr 5273
```

## Kiti Å¾ingsniai

### Tiesioginiai veiksmai

1. **Eksperimentuokite** su skirtingais modeliais ir uÅ¾klausomis
2. **Modifikuokite** savo pokalbiÅ³ programÄ…, kad iÅ¡bandytumÄ—te skirtingus modelius
3. **Sukurkite** savo uÅ¾klausas ir testuokite atsakymus
4. **TyrinÄ—kite** 2 sesijÄ…: RAG programÅ³ kÅ«rimas

### PaÅ¾angus mokymosi kelias

1. **Sesija 2**: AI sprendimÅ³ kÅ«rimas su RAG (Retrieval-Augmented Generation)
2. **Sesija 3**: SkirtingÅ³ atvirojo kodo modeliÅ³ palyginimas
3. **Sesija 4**: Darbas su paÅ¾angiausiais modeliais
4. **Sesija 5**: DaugiaagentiniÅ³ AI sistemÅ³ kÅ«rimas

## Aplinkos kintamieji (neprivaloma)

DÄ—l paÅ¾angesnio naudojimo galite nustatyti Å¡iuos aplinkos kintamuosius:

| Kintamasis | Paskirtis | Pavyzdys |
|------------|-----------|----------|
| `FOUNDRY_LOCAL_ALIAS` | Numatytojo modelio naudojimas | `phi-4-mini` |
| `FOUNDRY_LOCAL_ENDPOINT` | Pakeisti endpoint URL | `http://localhost:5273/v1` |

Sukurkite `.env` failÄ… savo projekto kataloge:
```
FOUNDRY_LOCAL_ALIAS=phi-4-mini
FOUNDRY_LOCAL_ENDPOINT=auto
```

## Papildomi iÅ¡tekliai

### Dokumentacija

- [Foundry Local Python SDK nuoroda](https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/reference/reference-sdk?pivots=programming-language-python)
- [Foundry Local diegimo vadovas](https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/install)
- [ModeliÅ³ katalogas](https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/models)

### Pavyzdinis kodas

- **Session01 Python pavyzdys**: `Workshop/samples/session01/chat_bootstrap.py` - Pilna pokalbiÅ³ programa su srautu
- **Session01 Notebook**: `Workshop/notebooks/session01_chat_bootstrap.ipynb` - Interaktyvus vadovas  
- [Module08 Pavyzdys 01](../Module08/samples/01/README.md) - REST pokalbiÅ³ greitas startas
- [Module08 Pavyzdys 02](../Module08/samples/02/README.md) - OpenAI SDK integracija
- [Module08 Pavyzdys 03](../Module08/samples/03/README.md) - ModeliÅ³ atradimas ir palyginimas

### BendruomenÄ—

- [Foundry Local GitHub diskusijos](https://github.com/microsoft/Foundry-Local/discussions)
- [Azure AI bendruomenÄ—](https://techcommunity.microsoft.com/category/artificialintelligence)

---

**Sesijos trukmÄ—**: 30 minuÄiÅ³ praktika + 15 minuÄiÅ³ klausimai ir atsakymai  
**SudÄ—tingumo lygis**: Pradedantysis  
**Reikalavimai**: Windows 11/macOS 11+, Python 3.10+, administratoriaus teisÄ—s

## Seminaro pavyzdinÄ— situacija

### Realus kontekstas

**Situacija**: Ä®monÄ—s IT komanda turi Ä¯vertinti AI modeliÅ³ naudojimÄ… Ä¯renginiuose, kad galÄ—tÅ³ apdoroti jautrius darbuotojÅ³ atsiliepimus, nesiunÄiant duomenÅ³ Ä¯ iÅ¡orines paslaugas.

**JÅ«sÅ³ tikslas**: Pademonstruoti, kad vietiniai AI modeliai gali pateikti kokybiÅ¡kus atsakymus su maÅ¾esne nei sekundÄ—s vÄ—linimu, iÅ¡laikant visiÅ¡kÄ… duomenÅ³ privatumÄ….

### Testavimo uÅ¾klausos

Naudokite Å¡ias uÅ¾klausas, kad patikrintumÄ—te savo nustatymus:

```json
[
    "List two benefits of local inference.",
    "Summarize why keeping data on device improves privacy.",
    "Give one trade-off when choosing a small model over a large model."
]
```

### SÄ—kmÄ—s kriterijai

- âœ… Visi uÅ¾klausÅ³ atsakymai pateikiami per maÅ¾iau nei 2 sekundes
- âœ… Duomenys nepalieka jÅ«sÅ³ vietinio kompiuterio
- âœ… Atsakymai yra aktualÅ«s ir naudingi
- âœ… JÅ«sÅ³ pokalbiÅ³ programa veikia sklandÅ¾iai

Å is patikrinimas uÅ¾tikrina, kad jÅ«sÅ³ Foundry Local nustatymai yra pasiruoÅ¡Ä™ paÅ¾angiems seminarams 2â€“6 sesijose.

---

<!-- CO-OP TRANSLATOR DISCLAIMER START -->
**AtsakomybÄ—s apribojimas**:  
Å is dokumentas buvo iÅ¡verstas naudojant AI vertimo paslaugÄ… [Co-op Translator](https://github.com/Azure/co-op-translator). Nors siekiame tikslumo, praÅ¡ome atkreipti dÄ—mesÄ¯, kad automatiniai vertimai gali turÄ—ti klaidÅ³ ar netikslumÅ³. Originalus dokumentas jo gimtÄ…ja kalba turÄ—tÅ³ bÅ«ti laikomas autoritetingu Å¡altiniu. DÄ—l svarbios informacijos rekomenduojama profesionali Å¾mogaus vertimo paslauga. Mes neprisiimame atsakomybÄ—s uÅ¾ nesusipratimus ar neteisingus interpretavimus, atsiradusius naudojant Å¡Ä¯ vertimÄ….
<!-- CO-OP TRANSLATOR DISCLAIMER END -->