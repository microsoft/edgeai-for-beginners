<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "aa775a734bda4590ecbe3a94a3b62197",
  "translation_date": "2026-01-05T17:21:51+00:00",
  "source_file": "WorkshopForAgentic/translation/zh-cn/README.md",
  "language_code": "es"
}
-->
# ğŸ™ï¸ Taller del Estudio de Podcast AI

![logo](../../../../../translated_images/logo.8711e39dc8257d7b.es.png)

## Tu misiÃ³n

Â¡Bienvenido al **Estudio de Podcast AI**! EstÃ¡s a punto de lanzar tu propio podcast tecnolÃ³gico llamado "Future Bytes" â€” pero aquÃ­ hay un giro: construirÃ¡s un equipo de producciÃ³n impulsado por IA para ayudarte a crearlo. No mÃ¡s investigaciÃ³n interminable, redacciÃ³n de guiones y ediciÃ³n de audio. En cambio, te convertirÃ¡s en un productor de podcasts con sÃºper poderes de IA mediante programaciÃ³n.

## Historia de fondo

Imagina: tÃº y tus amigos quieren iniciar un podcast sobre las tendencias tecnolÃ³gicas mÃ¡s interesantes, pero todos estÃ¡n ocupados con estudios, trabajo o la vida. Â¿QuÃ© pasarÃ­a si pudieras construir un equipo de agentes de IA para hacer el trabajo pesado? Un agente se encarga de investigar temas, otro escribe guiones atractivos, y un tercero convierte el texto en conversaciones naturales y fluidas. Â¿Suena a ciencia ficciÃ³n? HagÃ¡moslo realidad.

## QuÃ© aprenderÃ¡s

Al final de este taller, sabrÃ¡s cÃ³mo:
- ğŸ¤– Desplegar tus propios modelos de IA locales (Â¡sin costo de API, ni dependencia en la nube!)
- ğŸ”§ Construir agentes de IA profesionales que colaboran en el mundo real
- ğŸ¬ Crear un flujo de producciÃ³n completo de podcast, desde la idea hasta el audio

## Tu viaje: un drama en tres actos

Como en cualquier buena historia, tenemos tres actos. Cada acto construye paso a paso tu Estudio de Podcast AI:

| CapÃ­tulo | Tu tarea | QuÃ© sucede | Habilidades desbloqueadas |
|---------|-----------|--------------|----------------|
| **Primer acto** | [Conoce a tu asistente de IA](01.BuildAIAgentWithSLM.md) | DescubrirÃ¡s cÃ³mo crear agentes de IA que pueden chatear, buscar en la web e incluso resolver problemas. Piensa en ellos como becarios investigadores que nunca duermen. | ğŸ¯ Construye tu primer agente<br>ğŸ› ï¸ Dale sÃºper poderes (Â¡herramientas!)<br>ğŸ§  EnsÃ©Ã±ale a pensar<br>ğŸŒ ConÃ©ctalo a internet |
| **Segundo acto** | [Forma tu equipo de producciÃ³n](02.AIAgentOrchestrationAndWorkflows.md) | Ahora se pone interesante: orquestarÃ¡s varios agentes de IA para que trabajen juntos como un verdadero equipo de podcast. Uno investiga, otro escribe, tÃº apruebasâ€”el trabajo en equipo hace que los sueÃ±os se cumplan. | ğŸ­ Coordina mÃºltiples agentes<br>ğŸ”„ Construye flujos de aprobaciÃ³n<br>ğŸ–¥ï¸ Usa la interfaz DevUI para pruebas<br>âœ‹ MantÃ©n el control humano |
| **Tercer acto** | [Trae tu podcast a la vida](03.Multi-SpeakerPodcastGenerationWithVibeVoice.md) | Gran final: convierte tus guiones de texto en audio real de podcast con voces realistas y diÃ¡logo natural. Â¡Tu podcast â€œFuture Bytesâ€ estÃ¡ listo para publicarse! | ğŸ¤ Magia de texto a voz<br>ğŸ‘¥ Voces de mÃºltiples hablantes<br>â±ï¸ Audio de formato largo<br>ğŸš€ Totalmente automatizado |

Cada acto desbloquea nuevas habilidades. Si eres valiente, puedes saltar entre ellos, pero recomendamos seguir el orden.

## Requisitos del entorno

Este taller soporta diversos entornos de hardware:
- **CPU**: adecuado para pruebas y uso a pequeÃ±a escala
- **GPU**: recomendado para producciÃ³n, mejora significativamente la velocidad de inferencia
- **NPU**: soporte para aceleraciÃ³n con unidades neuronales de prÃ³xima generaciÃ³n

## QuÃ© necesitas

### Lista de software âœ…
- **Python 3.10+** (tu lenguaje de programaciÃ³n)
- **Ollama** (para ejecutar modelos de IA en tu mÃ¡quina)
- **VS Code** (tu editor de cÃ³digo)
- **ExtensiÃ³n de Python** (para hacer VS Code mÃ¡s inteligente)
- **Git** (para obtener el cÃ³digo)

### RevisiÃ³n de hardware ğŸ’»
- **Â¿Puedo ejecutar esto?**: 8 GB de RAM, 10 GB de espacio disponible (funciona pero puede ser lento)
- **ConfiguraciÃ³n ideal**: 16 GB+ de RAM, una buena GPU (Â¡funciona sin problemas!)
- **Â¿Tienes NPU?**: Â¡Mucho mejor! Desbloquea rendimiento de prÃ³xima generaciÃ³n ğŸš€

## Construye tu estudio ğŸ¬

### Paso 1: Actualiza Python

AsegÃºrate de tener Python 3.10 o superior:

```bash
python --version
# Debe mostrar Python 3.10.x o una versiÃ³n superior
```

Â¿No tienes Python? ConsÃ­guelo en [python.org](https://python.org) â€” Â¡es gratis!

### Paso 2: ObtÃ©n Ollama (tu motor para modelos de IA)

Visita [ollama.ai](https://ollama.ai) para descargar Ollama segÃºn tu sistema operativo. PiÃ©nsalo como el motor que ejecuta IA localmente.

Verifica que estÃ© listo:

```bash
ollama --version
```

### Paso 3: Descarga tu cerebro de IA ğŸ§ 

Hora de obtener el modelo Qwen-3-8B (como contratar a tu primer asistente de IA):

```bash
ollama pull qwen3:8b
```

*Esto puede tomar algunos minutos. Â¡Tiempo perfecto para un cafÃ©! â˜•*

### Paso 4: Configura VS Code

Si aÃºn no lo tienes, instala [Visual Studio Code](https://code.visualstudio.com/). Es el mejor editor de cÃ³digo (y punto ğŸ˜„).

### Paso 5: ExtensiÃ³n de Python

En VS Code:
1. Presiona `Ctrl+Shift+X` (o `Cmd+Shift+X` en Mac)
2. Busca "Python"
3. Instala la extensiÃ³n oficial de Python de Microsoft

### Paso 6: Â¡Ya casi! ğŸ‰

De verdad, estÃ¡s listo. Â¡Vamos a crear algo de magia con IA!

### Paso 7: Instala Microsoft Agent Framework y paquetes relacionados ğŸ“¦

Instala todas las dependencias necesarias para el taller:

```bash
pip install -r ./Installations/requirements.txt -U
```

*Esto instalarÃ¡ Microsoft Agent Framework y todos los paquetes necesarios. TÃ³mate un cafÃ© â€” Â¡la primera instalaciÃ³n puede demorar un poco! â˜•*

## Instrucciones del taller

La estructura detallada del proyecto, pasos de configuraciÃ³n y ejecuciÃ³n se irÃ¡n explicando durante el taller.

## SoluciÃ³n de problemas (cuando las cosas salen mal) ğŸ”§

### "Â¡Ay, la descarga del modelo es muy lenta!"
**SoluciÃ³n**: Usa una VPN o configura un espejo para Ollama. A veces la red no acompaÃ±a.

### "Â¡Mi computadora estÃ¡ a punto de colapsar! Â¡No hay suficiente memoria!"
**SoluciÃ³n**: Cambia a un modelo mÃ¡s pequeÃ±o o ajusta el parÃ¡metro `num_ctx` para usar menos memoria. PiÃ©nsalo como poner a tu IA a dieta.

### "Â¿Puedo usar GPU para acelerar?"
**SoluciÃ³n**: Â¡Ollama detecta automÃ¡ticamente la GPU! Solo asegÃºrate de que el driver estÃ© actualizado. Â¡AceleraciÃ³n gratis! ğŸï¸

## Recursos adicionales (para los curiosos) ğŸ“š

- [DocumentaciÃ³n de Ollama](https://github.com/ollama/ollama) â€” profundiza en modelos de IA local
- [Microsoft Agent Framework](https://microsoft.github.io/autogen/) â€” aprende mÃ¡s sobre construir equipos de agentes
- [InformaciÃ³n del modelo Qwen](https://qwenlm.github.io/) â€” conoce el cerebro de tu asistente de IA

## Licencia

Licencia MIT â€” Â¡Crea cosas geniales, compÃ¡rtelas y haz el mundo mejor! ğŸŒ

## Â¿Quieres contribuir?

Â¿Encontraste un bug? Â¿Tienes ideas? Â¡Abre un Issue o PR! Nos encanta la comunidad. âœ¨

---

<!-- CO-OP TRANSLATOR DISCLAIMER START -->
**Aviso Legal**:
Este documento ha sido traducido utilizando el servicio de traducciÃ³n automÃ¡tica [Co-op Translator](https://github.com/Azure/co-op-translator). Aunque nos esforzamos por la precisiÃ³n, tenga en cuenta que las traducciones automatizadas pueden contener errores o imprecisiones. El documento original en su idioma nativo debe considerarse la fuente autorizada. Para informaciÃ³n crÃ­tica, se recomienda la traducciÃ³n profesional realizada por un humano. No nos hacemos responsables de cualquier malentendido o interpretaciÃ³n errÃ³nea derivada del uso de esta traducciÃ³n.
<!-- CO-OP TRANSLATOR DISCLAIMER END -->