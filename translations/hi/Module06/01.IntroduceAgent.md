# ‡§è‡§Ü‡§à ‡§è‡§ú‡•á‡§Ç‡§ü‡•ç‡§∏ ‡§î‡§∞ ‡§õ‡•ã‡§ü‡•á ‡§≠‡§æ‡§∑‡§æ ‡§Æ‡•â‡§°‡§≤: ‡§è‡§ï ‡§µ‡•ç‡§Ø‡§æ‡§™‡§ï ‡§Æ‡§æ‡§∞‡•ç‡§ó‡§¶‡§∞‡•ç‡§∂‡§ø‡§ï‡§æ

## ‡§™‡§∞‡§ø‡§ö‡§Ø

‡§á‡§∏ ‡§ü‡•ç‡§Ø‡•Ç‡§ü‡•ã‡§∞‡§ø‡§Ø‡§≤ ‡§Æ‡•á‡§Ç, ‡§π‡§Æ ‡§è‡§Ü‡§à ‡§è‡§ú‡•á‡§Ç‡§ü‡•ç‡§∏ ‡§î‡§∞ ‡§õ‡•ã‡§ü‡•á ‡§≠‡§æ‡§∑‡§æ ‡§Æ‡•â‡§°‡§≤ (SLMs) ‡§ï‡•á ‡§â‡§®‡•ç‡§®‡§§ ‡§ï‡§æ‡§∞‡•ç‡§Ø‡§æ‡§®‡•ç‡§µ‡§Ø‡§® ‡§∞‡§£‡§®‡•Ä‡§§‡§ø‡§Ø‡•ã‡§Ç ‡§ï‡•ã ‡§è‡§ú ‡§ï‡§Ç‡§™‡•ç‡§Ø‡•Ç‡§ü‡§ø‡§Ç‡§ó ‡§µ‡§æ‡§§‡§æ‡§µ‡§∞‡§£ ‡§ï‡•á ‡§≤‡§ø‡§è ‡§∏‡§Æ‡§ù‡•á‡§Ç‡§ó‡•á‡•§ ‡§π‡§Æ ‡§è‡§ú‡•á‡§Ç‡§ü‡§ø‡§ï ‡§è‡§Ü‡§à ‡§ï‡•á ‡§Æ‡•Ç‡§≤‡§≠‡•Ç‡§§ ‡§∏‡§ø‡§¶‡•ç‡§ß‡§æ‡§Ç‡§§‡•ã‡§Ç, SLM ‡§Ö‡§®‡•Å‡§ï‡•Ç‡§≤‡§® ‡§§‡§ï‡§®‡•Ä‡§ï‡•ã‡§Ç, ‡§∏‡§Ç‡§∏‡§æ‡§ß‡§®-‡§∏‡•Ä‡§Æ‡§ø‡§§ ‡§â‡§™‡§ï‡§∞‡§£‡•ã‡§Ç ‡§ï‡•á ‡§≤‡§ø‡§è ‡§µ‡•ç‡§Ø‡§æ‡§µ‡§π‡§æ‡§∞‡§ø‡§ï ‡§§‡•à‡§®‡§æ‡§§‡•Ä ‡§∞‡§£‡§®‡•Ä‡§§‡§ø‡§Ø‡•ã‡§Ç, ‡§î‡§∞ ‡§â‡§§‡•ç‡§™‡§æ‡§¶‡§®-‡§§‡•à‡§Ø‡§æ‡§∞ ‡§è‡§ú‡•á‡§Ç‡§ü ‡§∏‡§ø‡§∏‡•ç‡§ü‡§Æ ‡§¨‡§®‡§æ‡§®‡•á ‡§ï‡•á ‡§≤‡§ø‡§è Microsoft Agent Framework ‡§ï‡•ã ‡§ï‡§µ‡§∞ ‡§ï‡§∞‡•á‡§Ç‡§ó‡•á‡•§

2025 ‡§Æ‡•á‡§Ç ‡§ï‡•É‡§§‡•ç‡§∞‡§ø‡§Æ ‡§¨‡•Å‡§¶‡•ç‡§ß‡§ø‡§Æ‡§§‡•ç‡§§‡§æ ‡§ï‡§æ ‡§™‡§∞‡§ø‡§¶‡•É‡§∂‡•ç‡§Ø ‡§è‡§ï ‡§Æ‡§π‡§§‡•ç‡§µ‡§™‡•Ç‡§∞‡•ç‡§£ ‡§¨‡§¶‡§≤‡§æ‡§µ ‡§ï‡§æ ‡§Ö‡§®‡•Å‡§≠‡§µ ‡§ï‡§∞ ‡§∞‡§π‡§æ ‡§π‡•à‡•§ ‡§ú‡§¨‡§ï‡§ø 2023 ‡§ö‡•à‡§ü‡§¨‡•â‡§ü‡•ç‡§∏ ‡§ï‡§æ ‡§µ‡§∞‡•ç‡§∑ ‡§•‡§æ ‡§î‡§∞ 2024 ‡§Æ‡•á‡§Ç ‡§ï‡•ã-‡§™‡§æ‡§Ø‡§≤‡§ü‡•ç‡§∏ ‡§ï‡§æ ‡§â‡§õ‡§æ‡§≤ ‡§¶‡•á‡§ñ‡§æ ‡§ó‡§Ø‡§æ, 2025 ‡§è‡§Ü‡§à ‡§è‡§ú‡•á‡§Ç‡§ü‡•ç‡§∏ ‡§ï‡§æ ‡§π‡•à ‚Äî ‡§¨‡•Å‡§¶‡•ç‡§ß‡§ø‡§Æ‡§æ‡§® ‡§∏‡§ø‡§∏‡•ç‡§ü‡§Æ ‡§ú‡•ã ‡§∏‡•ã‡§ö‡§§‡•á ‡§π‡•à‡§Ç, ‡§§‡§∞‡•ç‡§ï ‡§ï‡§∞‡§§‡•á ‡§π‡•à‡§Ç, ‡§Ø‡•ã‡§ú‡§®‡§æ ‡§¨‡§®‡§æ‡§§‡•á ‡§π‡•à‡§Ç, ‡§â‡§™‡§ï‡§∞‡§£‡•ã‡§Ç ‡§ï‡§æ ‡§â‡§™‡§Ø‡•ã‡§ó ‡§ï‡§∞‡§§‡•á ‡§π‡•à‡§Ç, ‡§î‡§∞ ‡§®‡•ç‡§Ø‡•Ç‡§®‡§§‡§Æ ‡§Æ‡§æ‡§®‡§µ ‡§á‡§®‡§™‡•Å‡§ü ‡§ï‡•á ‡§∏‡§æ‡§• ‡§ï‡§æ‡§∞‡•ç‡§Ø‡•ã‡§Ç ‡§ï‡•ã ‡§®‡§ø‡§∑‡•ç‡§™‡§æ‡§¶‡§ø‡§§ ‡§ï‡§∞‡§§‡•á ‡§π‡•à‡§Ç, ‡§ú‡•ã ‡§ï‡•Å‡§∂‡§≤ ‡§õ‡•ã‡§ü‡•á ‡§≠‡§æ‡§∑‡§æ ‡§Æ‡•â‡§°‡§≤ ‡§¶‡•ç‡§µ‡§æ‡§∞‡§æ ‡§∏‡§Ç‡§ö‡§æ‡§≤‡§ø‡§§ ‡§π‡•ã‡§§‡•á ‡§π‡•à‡§Ç‡•§ Microsoft Agent Framework ‡§ë‡§´‡§≤‡§æ‡§á‡§® ‡§è‡§ú-‡§Ü‡§ß‡§æ‡§∞‡§ø‡§§ ‡§ï‡•ç‡§∑‡§Æ‡§§‡§æ‡§ì‡§Ç ‡§ï‡•á ‡§∏‡§æ‡§• ‡§á‡§® ‡§¨‡•Å‡§¶‡•ç‡§ß‡§ø‡§Æ‡§æ‡§® ‡§∏‡§ø‡§∏‡•ç‡§ü‡§Æ ‡§ï‡•ã ‡§¨‡§®‡§æ‡§®‡•á ‡§ï‡•á ‡§≤‡§ø‡§è ‡§è‡§ï ‡§™‡•ç‡§∞‡§Æ‡•Å‡§ñ ‡§∏‡§Æ‡§æ‡§ß‡§æ‡§® ‡§ï‡•á ‡§∞‡•Ç‡§™ ‡§Æ‡•á‡§Ç ‡§â‡§≠‡§∞‡§§‡§æ ‡§π‡•à‡•§

## ‡§∏‡•Ä‡§ñ‡§®‡•á ‡§ï‡•á ‡§â‡§¶‡•ç‡§¶‡•á‡§∂‡•ç‡§Ø

‡§á‡§∏ ‡§ü‡•ç‡§Ø‡•Ç‡§ü‡•ã‡§∞‡§ø‡§Ø‡§≤ ‡§ï‡•á ‡§Ö‡§Ç‡§§ ‡§§‡§ï, ‡§Ü‡§™:

- ü§ñ ‡§è‡§Ü‡§à ‡§è‡§ú‡•á‡§Ç‡§ü‡•ç‡§∏ ‡§î‡§∞ ‡§è‡§ú‡•á‡§Ç‡§ü‡§ø‡§ï ‡§∏‡§ø‡§∏‡•ç‡§ü‡§Æ ‡§ï‡•á ‡§Æ‡•Ç‡§≤‡§≠‡•Ç‡§§ ‡§∏‡§ø‡§¶‡•ç‡§ß‡§æ‡§Ç‡§§‡•ã‡§Ç ‡§ï‡•ã ‡§∏‡§Æ‡§ù ‡§™‡§æ‡§è‡§Ç‡§ó‡•á
- üî¨ ‡§õ‡•ã‡§ü‡•á ‡§≠‡§æ‡§∑‡§æ ‡§Æ‡•â‡§°‡§≤‡•ç‡§∏ ‡§ï‡•á ‡§≤‡§æ‡§≠‡•ã‡§Ç ‡§ï‡•ã ‡§¨‡§°‡§º‡•á ‡§≠‡§æ‡§∑‡§æ ‡§Æ‡•â‡§°‡§≤‡•ç‡§∏ ‡§ï‡•Ä ‡§§‡•Å‡§≤‡§®‡§æ ‡§Æ‡•á‡§Ç ‡§è‡§ú‡•á‡§Ç‡§ü‡§ø‡§ï ‡§Ö‡§®‡•Å‡§™‡•ç‡§∞‡§Ø‡•ã‡§ó‡•ã‡§Ç ‡§Æ‡•á‡§Ç ‡§™‡§π‡§ö‡§æ‡§® ‡§™‡§æ‡§è‡§Ç‡§ó‡•á
- üöÄ ‡§è‡§ú ‡§ï‡§Ç‡§™‡•ç‡§Ø‡•Ç‡§ü‡§ø‡§Ç‡§ó ‡§µ‡§æ‡§§‡§æ‡§µ‡§∞‡§£ ‡§ï‡•á ‡§≤‡§ø‡§è ‡§â‡§®‡•ç‡§®‡§§ SLM ‡§§‡•à‡§®‡§æ‡§§‡•Ä ‡§∞‡§£‡§®‡•Ä‡§§‡§ø‡§Ø‡•ã‡§Ç ‡§ï‡•ã ‡§∏‡•Ä‡§ñ ‡§™‡§æ‡§è‡§Ç‡§ó‡•á
- üì± ‡§µ‡§æ‡§∏‡•ç‡§§‡§µ‡§ø‡§ï ‡§¶‡•Å‡§®‡§ø‡§Ø‡§æ ‡§ï‡•á ‡§Ö‡§®‡•Å‡§™‡•ç‡§∞‡§Ø‡•ã‡§ó‡•ã‡§Ç ‡§ï‡•á ‡§≤‡§ø‡§è SLM-‡§∏‡§Ç‡§ö‡§æ‡§≤‡§ø‡§§ ‡§è‡§ú‡•á‡§Ç‡§ü‡•ç‡§∏ ‡§ï‡•ã ‡§≤‡§æ‡§ó‡•Ç ‡§ï‡§∞ ‡§™‡§æ‡§è‡§Ç‡§ó‡•á
- üèóÔ∏è Microsoft Agent Framework ‡§ï‡§æ ‡§â‡§™‡§Ø‡•ã‡§ó ‡§ï‡§∞‡§ï‡•á ‡§â‡§§‡•ç‡§™‡§æ‡§¶‡§®-‡§§‡•à‡§Ø‡§æ‡§∞ ‡§è‡§ú‡•á‡§Ç‡§ü‡•ç‡§∏ ‡§¨‡§®‡§æ ‡§™‡§æ‡§è‡§Ç‡§ó‡•á
- üåê ‡§∏‡•ç‡§•‡§æ‡§®‡•Ä‡§Ø LLM ‡§î‡§∞ SLM ‡§è‡§ï‡•Ä‡§ï‡§∞‡§£ ‡§ï‡•á ‡§∏‡§æ‡§• ‡§ë‡§´‡§≤‡§æ‡§á‡§® ‡§è‡§ú-‡§Ü‡§ß‡§æ‡§∞‡§ø‡§§ ‡§è‡§ú‡•á‡§Ç‡§ü‡•ç‡§∏ ‡§ï‡•ã ‡§§‡•à‡§®‡§æ‡§§ ‡§ï‡§∞ ‡§™‡§æ‡§è‡§Ç‡§ó‡•á
- üîß Microsoft Agent Framework ‡§ï‡•ã Foundry Local ‡§ï‡•á ‡§∏‡§æ‡§• ‡§è‡§ú ‡§§‡•à‡§®‡§æ‡§§‡•Ä ‡§ï‡•á ‡§≤‡§ø‡§è ‡§è‡§ï‡•Ä‡§ï‡•É‡§§ ‡§ï‡§∞ ‡§™‡§æ‡§è‡§Ç‡§ó‡•á

## ‡§è‡§Ü‡§à ‡§è‡§ú‡•á‡§Ç‡§ü‡•ç‡§∏ ‡§ï‡•ã ‡§∏‡§Æ‡§ù‡§®‡§æ: ‡§®‡•Ä‡§Ç‡§µ ‡§î‡§∞ ‡§µ‡§∞‡•ç‡§ó‡•Ä‡§ï‡§∞‡§£

### ‡§™‡§∞‡§ø‡§≠‡§æ‡§∑‡§æ ‡§î‡§∞ ‡§Æ‡•Å‡§ñ‡•ç‡§Ø ‡§∏‡§ø‡§¶‡•ç‡§ß‡§æ‡§Ç‡§§

‡§ï‡•É‡§§‡•ç‡§∞‡§ø‡§Æ ‡§¨‡•Å‡§¶‡•ç‡§ß‡§ø‡§Æ‡§§‡•ç‡§§‡§æ (AI) ‡§è‡§ú‡•á‡§Ç‡§ü ‡§è‡§ï ‡§ê‡§∏‡§æ ‡§∏‡§ø‡§∏‡•ç‡§ü‡§Æ ‡§Ø‡§æ ‡§™‡•ç‡§∞‡•ã‡§ó‡•ç‡§∞‡§æ‡§Æ ‡§π‡•à ‡§ú‡•ã ‡§â‡§™‡§Ø‡•ã‡§ó‡§ï‡§∞‡•ç‡§§‡§æ ‡§Ø‡§æ ‡§ï‡§ø‡§∏‡•Ä ‡§Ö‡§®‡•ç‡§Ø ‡§∏‡§ø‡§∏‡•ç‡§ü‡§Æ ‡§ï‡•Ä ‡§ì‡§∞ ‡§∏‡•á ‡§∏‡•ç‡§µ‡§æ‡§Ø‡§§‡•ç‡§§ ‡§∞‡•Ç‡§™ ‡§∏‡•á ‡§ï‡§æ‡§∞‡•ç‡§Ø‡•ã‡§Ç ‡§ï‡•ã ‡§ï‡§∞‡§®‡•á ‡§Æ‡•á‡§Ç ‡§∏‡§ï‡•ç‡§∑‡§Æ ‡§π‡•ã‡§§‡§æ ‡§π‡•à, ‡§Ö‡§™‡§®‡•á ‡§ï‡§æ‡§∞‡•ç‡§Ø‡§™‡•ç‡§∞‡§µ‡§æ‡§π ‡§ï‡•ã ‡§°‡§ø‡§ú‡§º‡§æ‡§á‡§® ‡§ï‡§∞‡§ï‡•á ‡§î‡§∞ ‡§â‡§™‡§≤‡§¨‡•ç‡§ß ‡§â‡§™‡§ï‡§∞‡§£‡•ã‡§Ç ‡§ï‡§æ ‡§â‡§™‡§Ø‡•ã‡§ó ‡§ï‡§∞‡§ï‡•á‡•§ ‡§™‡§æ‡§∞‡§Ç‡§™‡§∞‡§ø‡§ï ‡§è‡§Ü‡§à ‡§ï‡•á ‡§µ‡§ø‡§™‡§∞‡•Ä‡§§, ‡§ú‡•ã ‡§ï‡•á‡§µ‡§≤ ‡§Ü‡§™‡§ï‡•á ‡§∏‡§µ‡§æ‡§≤‡•ã‡§Ç ‡§ï‡§æ ‡§ú‡§µ‡§æ‡§¨ ‡§¶‡•á‡§§‡§æ ‡§π‡•à, ‡§è‡§ï ‡§è‡§ú‡•á‡§Ç‡§ü ‡§∏‡•ç‡§µ‡§§‡§Ç‡§§‡•ç‡§∞ ‡§∞‡•Ç‡§™ ‡§∏‡•á ‡§≤‡§ï‡•ç‡§∑‡•ç‡§Ø‡•ã‡§Ç ‡§ï‡•ã ‡§™‡•ç‡§∞‡§æ‡§™‡•ç‡§§ ‡§ï‡§∞‡§®‡•á ‡§ï‡•á ‡§≤‡§ø‡§è ‡§ï‡§æ‡§∞‡•ç‡§Ø ‡§ï‡§∞ ‡§∏‡§ï‡§§‡§æ ‡§π‡•à‡•§

### ‡§è‡§ú‡•á‡§Ç‡§ü ‡§µ‡§∞‡•ç‡§ó‡•Ä‡§ï‡§∞‡§£ ‡§¢‡§æ‡§Ç‡§ö‡§æ

‡§è‡§ú‡•á‡§Ç‡§ü ‡§ï‡•Ä ‡§∏‡•Ä‡§Æ‡§æ‡§ì‡§Ç ‡§ï‡•ã ‡§∏‡§Æ‡§ù‡§®‡§æ ‡§µ‡§ø‡§≠‡§ø‡§®‡•ç‡§® ‡§ï‡§Ç‡§™‡•ç‡§Ø‡•Ç‡§ü‡§ø‡§Ç‡§ó ‡§™‡§∞‡§ø‡§¶‡•É‡§∂‡•ç‡§Ø‡•ã‡§Ç ‡§ï‡•á ‡§≤‡§ø‡§è ‡§â‡§™‡§Ø‡•Å‡§ï‡•ç‡§§ ‡§è‡§ú‡•á‡§Ç‡§ü ‡§™‡•ç‡§∞‡§ï‡§æ‡§∞‡•ã‡§Ç ‡§ï‡§æ ‡§ö‡§Ø‡§® ‡§ï‡§∞‡§®‡•á ‡§Æ‡•á‡§Ç ‡§Æ‡§¶‡§¶ ‡§ï‡§∞‡§§‡§æ ‡§π‡•à:

- **üî¨ ‡§∏‡§∞‡§≤ ‡§∞‡§ø‡§´‡•ç‡§≤‡•á‡§ï‡•ç‡§∏ ‡§è‡§ú‡•á‡§Ç‡§ü‡•ç‡§∏**: ‡§®‡§ø‡§Ø‡§Æ-‡§Ü‡§ß‡§æ‡§∞‡§ø‡§§ ‡§∏‡§ø‡§∏‡•ç‡§ü‡§Æ ‡§ú‡•ã ‡§§‡§§‡•ç‡§ï‡§æ‡§≤ ‡§ß‡§æ‡§∞‡§£‡§æ‡§ì‡§Ç ‡§™‡§∞ ‡§™‡•ç‡§∞‡§§‡§ø‡§ï‡•ç‡§∞‡§ø‡§Ø‡§æ ‡§ï‡§∞‡§§‡•á ‡§π‡•à‡§Ç (‡§•‡§∞‡•ç‡§Æ‡•ã‡§∏‡•ç‡§ü‡•á‡§ü‡•ç‡§∏, ‡§¨‡•Å‡§®‡§ø‡§Ø‡§æ‡§¶‡•Ä ‡§∏‡•ç‡§µ‡§ö‡§æ‡§≤‡§®)
- **üì± ‡§Æ‡•â‡§°‡§≤-‡§Ü‡§ß‡§æ‡§∞‡§ø‡§§ ‡§è‡§ú‡•á‡§Ç‡§ü‡•ç‡§∏**: ‡§∏‡§ø‡§∏‡•ç‡§ü‡§Æ ‡§ú‡•ã ‡§Ü‡§Ç‡§§‡§∞‡§ø‡§ï ‡§∏‡•ç‡§•‡§ø‡§§‡§ø ‡§î‡§∞ ‡§Æ‡•á‡§Æ‡•ã‡§∞‡•Ä ‡§¨‡§®‡§æ‡§è ‡§∞‡§ñ‡§§‡•á ‡§π‡•à‡§Ç (‡§∞‡•ã‡§¨‡•ã‡§ü ‡§µ‡•à‡§ï‡•ç‡§Ø‡•Ç‡§Æ, ‡§®‡•á‡§µ‡§ø‡§ó‡•á‡§∂‡§® ‡§∏‡§ø‡§∏‡•ç‡§ü‡§Æ)
- **‚öñÔ∏è ‡§≤‡§ï‡•ç‡§∑‡•ç‡§Ø-‡§Ü‡§ß‡§æ‡§∞‡§ø‡§§ ‡§è‡§ú‡•á‡§Ç‡§ü‡•ç‡§∏**: ‡§∏‡§ø‡§∏‡•ç‡§ü‡§Æ ‡§ú‡•ã ‡§â‡§¶‡•ç‡§¶‡•á‡§∂‡•ç‡§Ø‡•ã‡§Ç ‡§ï‡•ã ‡§™‡•ç‡§∞‡§æ‡§™‡•ç‡§§ ‡§ï‡§∞‡§®‡•á ‡§ï‡•á ‡§≤‡§ø‡§è ‡§Ö‡§®‡•Å‡§ï‡•ç‡§∞‡§Æ‡•ã‡§Ç ‡§ï‡•Ä ‡§Ø‡•ã‡§ú‡§®‡§æ ‡§¨‡§®‡§æ‡§§‡•á ‡§π‡•à‡§Ç ‡§î‡§∞ ‡§®‡§ø‡§∑‡•ç‡§™‡§æ‡§¶‡§ø‡§§ ‡§ï‡§∞‡§§‡•á ‡§π‡•à‡§Ç (‡§∞‡•Ç‡§ü ‡§™‡•ç‡§≤‡§æ‡§®‡§∞‡•ç‡§∏, ‡§ü‡§æ‡§∏‡•ç‡§ï ‡§∂‡•á‡§°‡•ç‡§Ø‡•Ç‡§≤‡§∞‡•ç‡§∏)
- **üß† ‡§∏‡•Ä‡§ñ‡§®‡•á ‡§µ‡§æ‡§≤‡•á ‡§è‡§ú‡•á‡§Ç‡§ü‡•ç‡§∏**: ‡§Ö‡§®‡•Å‡§ï‡•Ç‡§≤‡§®‡§∂‡•Ä‡§≤ ‡§∏‡§ø‡§∏‡•ç‡§ü‡§Æ ‡§ú‡•ã ‡§∏‡§Æ‡§Ø ‡§ï‡•á ‡§∏‡§æ‡§• ‡§™‡•ç‡§∞‡§¶‡§∞‡•ç‡§∂‡§® ‡§Æ‡•á‡§Ç ‡§∏‡•Å‡§ß‡§æ‡§∞ ‡§ï‡§∞‡§§‡•á ‡§π‡•à‡§Ç (‡§∏‡§ø‡§´‡§æ‡§∞‡§ø‡§∂ ‡§™‡•ç‡§∞‡§£‡§æ‡§≤‡•Ä, ‡§µ‡•ç‡§Ø‡§ï‡•ç‡§§‡§ø‡§ó‡§§ ‡§∏‡§π‡§æ‡§Ø‡§ï)

### ‡§è‡§Ü‡§à ‡§è‡§ú‡•á‡§Ç‡§ü‡•ç‡§∏ ‡§ï‡•á ‡§Æ‡•Å‡§ñ‡•ç‡§Ø ‡§≤‡§æ‡§≠

‡§è‡§Ü‡§à ‡§è‡§ú‡•á‡§Ç‡§ü‡•ç‡§∏ ‡§ï‡§à ‡§Æ‡•å‡§≤‡§ø‡§ï ‡§≤‡§æ‡§≠ ‡§™‡•ç‡§∞‡§¶‡§æ‡§® ‡§ï‡§∞‡§§‡•á ‡§π‡•à‡§Ç ‡§ú‡•ã ‡§â‡§®‡•ç‡§π‡•á‡§Ç ‡§è‡§ú ‡§ï‡§Ç‡§™‡•ç‡§Ø‡•Ç‡§ü‡§ø‡§Ç‡§ó ‡§Ö‡§®‡•Å‡§™‡•ç‡§∞‡§Ø‡•ã‡§ó‡•ã‡§Ç ‡§ï‡•á ‡§≤‡§ø‡§è ‡§Ü‡§¶‡§∞‡•ç‡§∂ ‡§¨‡§®‡§æ‡§§‡•á ‡§π‡•à‡§Ç:

**‡§ë‡§™‡§∞‡•á‡§∂‡§®‡§≤ ‡§∏‡•ç‡§µ‡§æ‡§Ø‡§§‡•ç‡§§‡§§‡§æ**: ‡§è‡§ú‡•á‡§Ç‡§ü‡•ç‡§∏ ‡§µ‡§æ‡§∏‡•ç‡§§‡§µ‡§ø‡§ï ‡§∏‡§Æ‡§Ø ‡§Ö‡§®‡•Å‡§™‡•ç‡§∞‡§Ø‡•ã‡§ó‡•ã‡§Ç ‡§ï‡•á ‡§≤‡§ø‡§è ‡§®‡•ç‡§Ø‡•Ç‡§®‡§§‡§Æ ‡§Æ‡§æ‡§®‡§µ ‡§®‡§ø‡§ó‡§∞‡§æ‡§®‡•Ä ‡§ï‡•á ‡§∏‡§æ‡§• ‡§∏‡•ç‡§µ‡§§‡§Ç‡§§‡•ç‡§∞ ‡§ï‡§æ‡§∞‡•ç‡§Ø ‡§®‡§ø‡§∑‡•ç‡§™‡§æ‡§¶‡§® ‡§™‡•ç‡§∞‡§¶‡§æ‡§® ‡§ï‡§∞‡§§‡•á ‡§π‡•à‡§Ç‡•§ ‡§µ‡•á ‡§Ö‡§®‡•Å‡§ï‡•Ç‡§≤‡§®‡§∂‡•Ä‡§≤ ‡§µ‡•ç‡§Ø‡§µ‡§π‡§æ‡§∞ ‡§¨‡§®‡§æ‡§è ‡§∞‡§ñ‡§§‡•á ‡§π‡•Å‡§è ‡§∏‡§Ç‡§∏‡§æ‡§ß‡§®-‡§∏‡•Ä‡§Æ‡§ø‡§§ ‡§â‡§™‡§ï‡§∞‡§£‡•ã‡§Ç ‡§™‡§∞ ‡§§‡•à‡§®‡§æ‡§§‡•Ä ‡§ï‡•á ‡§≤‡§ø‡§è ‡§â‡§™‡§Ø‡•Å‡§ï‡•ç‡§§ ‡§π‡•à‡§Ç‡•§

**‡§§‡•à‡§®‡§æ‡§§‡•Ä ‡§≤‡§ö‡•Ä‡§≤‡§æ‡§™‡§®**: ‡§Ø‡•á ‡§∏‡§ø‡§∏‡•ç‡§ü‡§Æ ‡§ë‡§®-‡§°‡§ø‡§µ‡§æ‡§á‡§∏ ‡§è‡§Ü‡§à ‡§ï‡•ç‡§∑‡§Æ‡§§‡§æ‡§ì‡§Ç ‡§ï‡•ã ‡§á‡§Ç‡§ü‡§∞‡§®‡•á‡§ü ‡§ï‡§®‡•á‡§ï‡•ç‡§ü‡§ø‡§µ‡§ø‡§ü‡•Ä ‡§Ü‡§µ‡§∂‡•ç‡§Ø‡§ï‡§§‡§æ‡§ì‡§Ç ‡§ï‡•á ‡§¨‡§ø‡§®‡§æ ‡§∏‡§ï‡•ç‡§∑‡§Æ ‡§ï‡§∞‡§§‡•á ‡§π‡•à‡§Ç, ‡§∏‡•ç‡§•‡§æ‡§®‡•Ä‡§Ø ‡§™‡•ç‡§∞‡§∏‡§Ç‡§∏‡•ç‡§ï‡§∞‡§£ ‡§ï‡•á ‡§Æ‡§æ‡§ß‡•ç‡§Ø‡§Æ ‡§∏‡•á ‡§ó‡•ã‡§™‡§®‡•Ä‡§Ø‡§§‡§æ ‡§î‡§∞ ‡§∏‡•Å‡§∞‡§ï‡•ç‡§∑‡§æ ‡§ï‡•ã ‡§¨‡§¢‡§º‡§æ‡§§‡•á ‡§π‡•à‡§Ç, ‡§°‡•ã‡§Æ‡•á‡§®-‡§µ‡§ø‡§∂‡§ø‡§∑‡•ç‡§ü ‡§Ö‡§®‡•Å‡§™‡•ç‡§∞‡§Ø‡•ã‡§ó‡•ã‡§Ç ‡§ï‡•á ‡§≤‡§ø‡§è ‡§Ö‡§®‡•Å‡§ï‡•Ç‡§≤‡§ø‡§§ ‡§ï‡§ø‡§è ‡§ú‡§æ ‡§∏‡§ï‡§§‡•á ‡§π‡•à‡§Ç, ‡§î‡§∞ ‡§µ‡§ø‡§≠‡§ø‡§®‡•ç‡§® ‡§è‡§ú ‡§ï‡§Ç‡§™‡•ç‡§Ø‡•Ç‡§ü‡§ø‡§Ç‡§ó ‡§µ‡§æ‡§§‡§æ‡§µ‡§∞‡§£‡•ã‡§Ç ‡§ï‡•á ‡§≤‡§ø‡§è ‡§â‡§™‡§Ø‡•Å‡§ï‡•ç‡§§ ‡§π‡•à‡§Ç‡•§

**‡§≤‡§æ‡§ó‡§§ ‡§™‡•ç‡§∞‡§≠‡§æ‡§µ‡§∂‡•Ä‡§≤‡§§‡§æ**: ‡§è‡§ú‡•á‡§Ç‡§ü ‡§∏‡§ø‡§∏‡•ç‡§ü‡§Æ ‡§ï‡•ç‡§≤‡§æ‡§â‡§°-‡§Ü‡§ß‡§æ‡§∞‡§ø‡§§ ‡§∏‡§Æ‡§æ‡§ß‡§æ‡§®‡•ã‡§Ç ‡§ï‡•Ä ‡§§‡•Å‡§≤‡§®‡§æ ‡§Æ‡•á‡§Ç ‡§≤‡§æ‡§ó‡§§ ‡§™‡•ç‡§∞‡§≠‡§æ‡§µ‡•Ä ‡§§‡•à‡§®‡§æ‡§§‡•Ä ‡§™‡•ç‡§∞‡§¶‡§æ‡§® ‡§ï‡§∞‡§§‡•á ‡§π‡•à‡§Ç, ‡§è‡§ú ‡§Ö‡§®‡•Å‡§™‡•ç‡§∞‡§Ø‡•ã‡§ó‡•ã‡§Ç ‡§ï‡•á ‡§≤‡§ø‡§è ‡§™‡§∞‡§ø‡§ö‡§æ‡§≤‡§® ‡§≤‡§æ‡§ó‡§§ ‡§î‡§∞ ‡§¨‡•à‡§Ç‡§°‡§µ‡§ø‡§°‡•ç‡§• ‡§Ü‡§µ‡§∂‡•ç‡§Ø‡§ï‡§§‡§æ‡§ì‡§Ç ‡§ï‡•ã ‡§ï‡§Æ ‡§ï‡§∞‡§§‡•á ‡§π‡•à‡§Ç‡•§

## ‡§â‡§®‡•ç‡§®‡§§ ‡§õ‡•ã‡§ü‡•á ‡§≠‡§æ‡§∑‡§æ ‡§Æ‡•â‡§°‡§≤ ‡§∞‡§£‡§®‡•Ä‡§§‡§ø‡§Ø‡§æ‡§Å

### SLM (‡§õ‡•ã‡§ü‡•á ‡§≠‡§æ‡§∑‡§æ ‡§Æ‡•â‡§°‡§≤) ‡§ï‡•Ä ‡§Æ‡•Ç‡§≤ ‡§¨‡§æ‡§§‡•á‡§Ç

‡§è‡§ï ‡§õ‡•ã‡§ü‡§æ ‡§≠‡§æ‡§∑‡§æ ‡§Æ‡•â‡§°‡§≤ (SLM) ‡§è‡§ï ‡§≠‡§æ‡§∑‡§æ ‡§Æ‡•â‡§°‡§≤ ‡§π‡•à ‡§ú‡•ã ‡§è‡§ï ‡§∏‡§æ‡§Æ‡§æ‡§®‡•ç‡§Ø ‡§â‡§™‡§≠‡•ã‡§ï‡•ç‡§§‡§æ ‡§á‡§≤‡•á‡§ï‡•ç‡§ü‡•ç‡§∞‡•â‡§®‡§ø‡§ï ‡§°‡§ø‡§µ‡§æ‡§á‡§∏ ‡§™‡§∞ ‡§´‡§ø‡§ü ‡§π‡•ã ‡§∏‡§ï‡§§‡§æ ‡§π‡•à ‡§î‡§∞ ‡§è‡§ï ‡§â‡§™‡§Ø‡•ã‡§ó‡§ï‡§∞‡•ç‡§§‡§æ ‡§ï‡•Ä ‡§è‡§ú‡•á‡§Ç‡§ü‡§ø‡§ï ‡§Ö‡§®‡•Å‡§∞‡•ã‡§ß‡•ã‡§Ç ‡§ï‡•Ä ‡§∏‡•á‡§µ‡§æ ‡§ï‡§∞‡§§‡•á ‡§∏‡§Æ‡§Ø ‡§µ‡•ç‡§Ø‡§æ‡§µ‡§π‡§æ‡§∞‡§ø‡§ï ‡§∞‡•Ç‡§™ ‡§∏‡•á ‡§ï‡§Æ ‡§µ‡§ø‡§≤‡§Ç‡§¨‡§§‡§æ ‡§ï‡•á ‡§∏‡§æ‡§• ‡§Ö‡§®‡•Å‡§Æ‡§æ‡§® ‡§≤‡§ó‡§æ ‡§∏‡§ï‡§§‡§æ ‡§π‡•à‡•§ ‡§µ‡•ç‡§Ø‡§æ‡§µ‡§π‡§æ‡§∞‡§ø‡§ï ‡§∞‡•Ç‡§™ ‡§∏‡•á, SLMs ‡§Ü‡§Æ‡§§‡•å‡§∞ ‡§™‡§∞ 10 ‡§¨‡§ø‡§≤‡§ø‡§Ø‡§® ‡§∏‡•á ‡§ï‡§Æ ‡§™‡•à‡§∞‡§æ‡§Æ‡•Ä‡§ü‡§∞ ‡§µ‡§æ‡§≤‡•á ‡§Æ‡•â‡§°‡§≤ ‡§π‡•ã‡§§‡•á ‡§π‡•à‡§Ç‡•§

**‡§´‡•â‡§∞‡•ç‡§Æ‡•á‡§ü ‡§°‡§ø‡§∏‡•ç‡§ï‡§µ‡§∞‡•Ä ‡§´‡•Ä‡§ö‡§∞‡•ç‡§∏**: SLMs ‡§µ‡§ø‡§≠‡§ø‡§®‡•ç‡§® ‡§ï‡•ç‡§µ‡§æ‡§Ç‡§ü‡§æ‡§á‡§ú‡•á‡§∂‡§® ‡§∏‡•ç‡§§‡§∞‡•ã‡§Ç, ‡§ï‡•ç‡§∞‡•â‡§∏-‡§™‡•ç‡§≤‡•á‡§ü‡§´‡•â‡§∞‡•ç‡§Æ ‡§∏‡§Ç‡§ó‡§§‡§§‡§æ, ‡§µ‡§æ‡§∏‡•ç‡§§‡§µ‡§ø‡§ï ‡§∏‡§Æ‡§Ø ‡§™‡•ç‡§∞‡§¶‡§∞‡•ç‡§∂‡§® ‡§Ö‡§®‡•Å‡§ï‡•Ç‡§≤‡§®, ‡§î‡§∞ ‡§è‡§ú ‡§§‡•à‡§®‡§æ‡§§‡•Ä ‡§ï‡•ç‡§∑‡§Æ‡§§‡§æ‡§ì‡§Ç ‡§ï‡•á ‡§≤‡§ø‡§è ‡§â‡§®‡•ç‡§®‡§§ ‡§∏‡§Æ‡§∞‡•ç‡§•‡§® ‡§™‡•ç‡§∞‡§¶‡§æ‡§® ‡§ï‡§∞‡§§‡•á ‡§π‡•à‡§Ç‡•§ ‡§â‡§™‡§Ø‡•ã‡§ó‡§ï‡§∞‡•ç‡§§‡§æ ‡§∏‡•ç‡§•‡§æ‡§®‡•Ä‡§Ø ‡§™‡•ç‡§∞‡§∏‡§Ç‡§∏‡•ç‡§ï‡§∞‡§£ ‡§î‡§∞ ‡§¨‡•ç‡§∞‡§æ‡§â‡§ú‡§º‡§∞-‡§Ü‡§ß‡§æ‡§∞‡§ø‡§§ ‡§§‡•à‡§®‡§æ‡§§‡•Ä ‡§ï‡•á ‡§≤‡§ø‡§è WebGPU ‡§∏‡§Æ‡§∞‡•ç‡§•‡§® ‡§ï‡•á ‡§Æ‡§æ‡§ß‡•ç‡§Ø‡§Æ ‡§∏‡•á ‡§â‡§®‡•ç‡§®‡§§ ‡§ó‡•ã‡§™‡§®‡•Ä‡§Ø‡§§‡§æ ‡§§‡§ï ‡§™‡§π‡•Å‡§Å‡§ö ‡§∏‡§ï‡§§‡•á ‡§π‡•à‡§Ç‡•§

**‡§ï‡•ç‡§µ‡§æ‡§Ç‡§ü‡§æ‡§á‡§ú‡•á‡§∂‡§® ‡§∏‡•ç‡§§‡§∞ ‡§∏‡§Ç‡§ó‡•ç‡§∞‡§π**: ‡§≤‡•ã‡§ï‡§™‡•ç‡§∞‡§ø‡§Ø SLM ‡§´‡•â‡§∞‡•ç‡§Æ‡•á‡§ü‡•ç‡§∏ ‡§Æ‡•á‡§Ç ‡§Æ‡•ã‡§¨‡§æ‡§á‡§≤ ‡§Ö‡§®‡•Å‡§™‡•ç‡§∞‡§Ø‡•ã‡§ó‡•ã‡§Ç ‡§Æ‡•á‡§Ç ‡§∏‡§Ç‡§§‡•Å‡§≤‡§ø‡§§ ‡§∏‡§Ç‡§™‡•Ä‡§°‡§º‡§® ‡§ï‡•á ‡§≤‡§ø‡§è Q4_K_M, ‡§ó‡•Å‡§£‡§µ‡§§‡•ç‡§§‡§æ-‡§ï‡•á‡§Ç‡§¶‡•ç‡§∞‡§ø‡§§ ‡§è‡§ú ‡§§‡•à‡§®‡§æ‡§§‡•Ä ‡§ï‡•á ‡§≤‡§ø‡§è Q5_K_S ‡§∂‡•ç‡§∞‡•É‡§Ç‡§ñ‡§≤‡§æ, ‡§∂‡§ï‡•ç‡§§‡§ø‡§∂‡§æ‡§≤‡•Ä ‡§è‡§ú ‡§â‡§™‡§ï‡§∞‡§£‡•ã‡§Ç ‡§™‡§∞ ‡§≤‡§ó‡§≠‡§ó-‡§Æ‡•Ç‡§≤ ‡§∏‡§ü‡•Ä‡§ï‡§§‡§æ ‡§ï‡•á ‡§≤‡§ø‡§è Q8_0, ‡§î‡§∞ ‡§Ö‡§≤‡•ç‡§ü‡•ç‡§∞‡§æ-‡§≤‡•ã ‡§∏‡§Ç‡§∏‡§æ‡§ß‡§® ‡§™‡§∞‡§ø‡§¶‡•É‡§∂‡•ç‡§Ø‡•ã‡§Ç ‡§ï‡•á ‡§≤‡§ø‡§è Q2_K ‡§ú‡•à‡§∏‡•á ‡§™‡•ç‡§∞‡§Ø‡•ã‡§ó‡§æ‡§§‡•ç‡§Æ‡§ï ‡§´‡•â‡§∞‡•ç‡§Æ‡•á‡§ü‡•ç‡§∏ ‡§∂‡§æ‡§Æ‡§ø‡§≤ ‡§π‡•à‡§Ç‡•§

### GGUF (‡§ú‡§®‡§∞‡§≤ GGML ‡§Ø‡•Ç‡§®‡§ø‡§µ‡§∞‡•ç‡§∏‡§≤ ‡§´‡•â‡§∞‡•ç‡§Æ‡•á‡§ü) SLM ‡§§‡•à‡§®‡§æ‡§§‡•Ä ‡§ï‡•á ‡§≤‡§ø‡§è

GGUF CPU ‡§î‡§∞ ‡§è‡§ú ‡§â‡§™‡§ï‡§∞‡§£‡•ã‡§Ç ‡§™‡§∞ ‡§ï‡•ç‡§µ‡§æ‡§Ç‡§ü‡§æ‡§á‡§ú‡•ç‡§° SLMs ‡§ï‡•ã ‡§§‡•à‡§®‡§æ‡§§ ‡§ï‡§∞‡§®‡•á ‡§ï‡•á ‡§≤‡§ø‡§è ‡§™‡•ç‡§∞‡§æ‡§•‡§Æ‡§ø‡§ï ‡§´‡•â‡§∞‡•ç‡§Æ‡•á‡§ü ‡§ï‡•á ‡§∞‡•Ç‡§™ ‡§Æ‡•á‡§Ç ‡§ï‡§æ‡§∞‡•ç‡§Ø ‡§ï‡§∞‡§§‡§æ ‡§π‡•à, ‡§µ‡§ø‡§∂‡•á‡§∑ ‡§∞‡•Ç‡§™ ‡§∏‡•á ‡§è‡§ú‡•á‡§Ç‡§ü‡§ø‡§ï ‡§Ö‡§®‡•Å‡§™‡•ç‡§∞‡§Ø‡•ã‡§ó‡•ã‡§Ç ‡§ï‡•á ‡§≤‡§ø‡§è ‡§Ö‡§®‡•Å‡§ï‡•Ç‡§≤‡§ø‡§§:

**‡§è‡§ú‡•á‡§Ç‡§ü-‡§ë‡§™‡•ç‡§ü‡§ø‡§Æ‡§æ‡§á‡§ú‡§º‡•ç‡§° ‡§´‡•Ä‡§ö‡§∞‡•ç‡§∏**: ‡§´‡•â‡§∞‡•ç‡§Æ‡•á‡§ü SLM ‡§∞‡•Ç‡§™‡§æ‡§Ç‡§§‡§∞‡§£ ‡§î‡§∞ ‡§§‡•à‡§®‡§æ‡§§‡•Ä ‡§ï‡•á ‡§≤‡§ø‡§è ‡§µ‡•ç‡§Ø‡§æ‡§™‡§ï ‡§∏‡§Ç‡§∏‡§æ‡§ß‡§® ‡§™‡•ç‡§∞‡§¶‡§æ‡§® ‡§ï‡§∞‡§§‡§æ ‡§π‡•à, ‡§â‡§™‡§ï‡§∞‡§£ ‡§ï‡•â‡§≤‡§ø‡§Ç‡§ó, ‡§∏‡§Ç‡§∞‡§ö‡§ø‡§§ ‡§Ü‡§â‡§ü‡§™‡•Å‡§ü ‡§ú‡§®‡§∞‡•á‡§∂‡§®, ‡§î‡§∞ ‡§Æ‡§≤‡•ç‡§ü‡•Ä-‡§ü‡§∞‡•ç‡§® ‡§µ‡§æ‡§∞‡•ç‡§§‡§æ‡§≤‡§æ‡§™‡•ã‡§Ç ‡§ï‡•á ‡§≤‡§ø‡§è ‡§â‡§®‡•ç‡§®‡§§ ‡§∏‡§Æ‡§∞‡•ç‡§•‡§® ‡§ï‡•á ‡§∏‡§æ‡§•‡•§ ‡§ï‡•ç‡§∞‡•â‡§∏-‡§™‡•ç‡§≤‡•á‡§ü‡§´‡•â‡§∞‡•ç‡§Æ ‡§∏‡§Ç‡§ó‡§§‡§§‡§æ ‡§µ‡§ø‡§≠‡§ø‡§®‡•ç‡§® ‡§è‡§ú ‡§â‡§™‡§ï‡§∞‡§£‡•ã‡§Ç ‡§™‡§∞ ‡§∏‡•Å‡§∏‡§Ç‡§ó‡§§ ‡§è‡§ú‡•á‡§Ç‡§ü ‡§µ‡•ç‡§Ø‡§µ‡§π‡§æ‡§∞ ‡§∏‡•Å‡§®‡§ø‡§∂‡•ç‡§ö‡§ø‡§§ ‡§ï‡§∞‡§§‡•Ä ‡§π‡•à‡•§

**‡§™‡•ç‡§∞‡§¶‡§∞‡•ç‡§∂‡§® ‡§Ö‡§®‡•Å‡§ï‡•Ç‡§≤‡§®**: GGUF ‡§è‡§ú‡•á‡§Ç‡§ü ‡§µ‡§∞‡•ç‡§ï‡§´‡§º‡•ç‡§≤‡•ã ‡§ï‡•á ‡§≤‡§ø‡§è ‡§ï‡•Å‡§∂‡§≤ ‡§Æ‡•á‡§Æ‡•ã‡§∞‡•Ä ‡§â‡§™‡§Ø‡•ã‡§ó ‡§∏‡§ï‡•ç‡§∑‡§Æ ‡§ï‡§∞‡§§‡§æ ‡§π‡•à, ‡§Æ‡§≤‡•ç‡§ü‡•Ä-‡§è‡§ú‡•á‡§Ç‡§ü ‡§∏‡§ø‡§∏‡•ç‡§ü‡§Æ ‡§ï‡•á ‡§≤‡§ø‡§è ‡§ó‡§§‡§ø‡§∂‡•Ä‡§≤ ‡§Æ‡•â‡§°‡§≤ ‡§≤‡•ã‡§°‡§ø‡§Ç‡§ó ‡§ï‡§æ ‡§∏‡§Æ‡§∞‡•ç‡§•‡§® ‡§ï‡§∞‡§§‡§æ ‡§π‡•à, ‡§î‡§∞ ‡§µ‡§æ‡§∏‡•ç‡§§‡§µ‡§ø‡§ï ‡§∏‡§Æ‡§Ø ‡§è‡§ú‡•á‡§Ç‡§ü ‡§á‡§Ç‡§ü‡§∞‡•à‡§ï‡•ç‡§∂‡§® ‡§ï‡•á ‡§≤‡§ø‡§è ‡§Ö‡§®‡•Å‡§ï‡•Ç‡§≤‡§ø‡§§ ‡§Ö‡§®‡•Å‡§Æ‡§æ‡§® ‡§™‡•ç‡§∞‡§¶‡§æ‡§® ‡§ï‡§∞‡§§‡§æ ‡§π‡•à‡•§

### ‡§è‡§ú-‡§ë‡§™‡•ç‡§ü‡§ø‡§Æ‡§æ‡§á‡§ú‡§º‡•ç‡§° SLM ‡§´‡•ç‡§∞‡•á‡§Æ‡§µ‡§∞‡•ç‡§ï‡•ç‡§∏

#### Llama.cpp ‡§è‡§ú‡•á‡§Ç‡§ü‡•ç‡§∏ ‡§ï‡•á ‡§≤‡§ø‡§è ‡§Ö‡§®‡•Å‡§ï‡•Ç‡§≤‡§®

Llama.cpp ‡§è‡§ú‡•á‡§Ç‡§ü‡§ø‡§ï SLM ‡§§‡•à‡§®‡§æ‡§§‡•Ä ‡§ï‡•á ‡§≤‡§ø‡§è ‡§µ‡§ø‡§∂‡•á‡§∑ ‡§∞‡•Ç‡§™ ‡§∏‡•á ‡§Ö‡§®‡•Å‡§ï‡•Ç‡§≤‡§ø‡§§ ‡§ï‡•ç‡§µ‡§æ‡§Ç‡§ü‡§æ‡§á‡§ú‡•á‡§∂‡§® ‡§§‡§ï‡§®‡•Ä‡§ï‡•ã‡§Ç ‡§™‡•ç‡§∞‡§¶‡§æ‡§® ‡§ï‡§∞‡§§‡§æ ‡§π‡•à:

**‡§è‡§ú‡•á‡§Ç‡§ü-‡§µ‡§ø‡§∂‡§ø‡§∑‡•ç‡§ü ‡§ï‡•ç‡§µ‡§æ‡§Ç‡§ü‡§æ‡§á‡§ú‡•á‡§∂‡§®**: ‡§´‡•ç‡§∞‡•á‡§Æ‡§µ‡§∞‡•ç‡§ï Q4_0 (‡§Æ‡•ã‡§¨‡§æ‡§á‡§≤ ‡§è‡§ú‡•á‡§Ç‡§ü ‡§§‡•à‡§®‡§æ‡§§‡•Ä ‡§ï‡•á ‡§≤‡§ø‡§è 75% ‡§Ü‡§ï‡§æ‡§∞ ‡§Æ‡•á‡§Ç ‡§ï‡§Æ‡•Ä ‡§ï‡•á ‡§∏‡§æ‡§• ‡§á‡§∑‡•ç‡§ü‡§§‡§Æ), Q5_1 (‡§è‡§ú ‡§Ö‡§®‡•Å‡§Æ‡§æ‡§® ‡§è‡§ú‡•á‡§Ç‡§ü‡•ç‡§∏ ‡§ï‡•á ‡§≤‡§ø‡§è ‡§ó‡•Å‡§£‡§µ‡§§‡•ç‡§§‡§æ-‡§∏‡§Ç‡§™‡•Ä‡§°‡§º‡§® ‡§∏‡§Ç‡§§‡•Å‡§≤‡§®), ‡§î‡§∞ Q8_0 (‡§â‡§§‡•ç‡§™‡§æ‡§¶‡§® ‡§è‡§ú‡•á‡§Ç‡§ü ‡§∏‡§ø‡§∏‡•ç‡§ü‡§Æ ‡§ï‡•á ‡§≤‡§ø‡§è ‡§≤‡§ó‡§≠‡§ó-‡§Æ‡•Ç‡§≤ ‡§ó‡•Å‡§£‡§µ‡§§‡•ç‡§§‡§æ) ‡§ï‡§æ ‡§∏‡§Æ‡§∞‡•ç‡§•‡§® ‡§ï‡§∞‡§§‡§æ ‡§π‡•à‡•§ ‡§â‡§®‡•ç‡§®‡§§ ‡§´‡•â‡§∞‡•ç‡§Æ‡•á‡§ü‡•ç‡§∏ ‡§ö‡§∞‡§Æ ‡§è‡§ú ‡§™‡§∞‡§ø‡§¶‡•É‡§∂‡•ç‡§Ø‡•ã‡§Ç ‡§ï‡•á ‡§≤‡§ø‡§è ‡§Ö‡§≤‡•ç‡§ü‡•ç‡§∞‡§æ-‡§ï‡§Ç‡§™‡•ç‡§∞‡•á‡§∏‡•ç‡§° ‡§è‡§ú‡•á‡§Ç‡§ü‡•ç‡§∏ ‡§∏‡§ï‡•ç‡§∑‡§Æ ‡§ï‡§∞‡§§‡•á ‡§π‡•à‡§Ç‡•§

**‡§ï‡§æ‡§∞‡•ç‡§Ø‡§æ‡§®‡•ç‡§µ‡§Ø‡§® ‡§≤‡§æ‡§≠**: SIMD ‡§§‡•ç‡§µ‡§∞‡§£ ‡§ï‡•á ‡§∏‡§æ‡§• CPU-‡§ë‡§™‡•ç‡§ü‡§ø‡§Æ‡§æ‡§á‡§ú‡§º‡•ç‡§° ‡§Ö‡§®‡•Å‡§Æ‡§æ‡§® ‡§Æ‡•á‡§Æ‡•ã‡§∞‡•Ä-‡§ï‡•Å‡§∂‡§≤ ‡§è‡§ú‡•á‡§Ç‡§ü ‡§®‡§ø‡§∑‡•ç‡§™‡§æ‡§¶‡§® ‡§™‡•ç‡§∞‡§¶‡§æ‡§® ‡§ï‡§∞‡§§‡§æ ‡§π‡•à‡•§ x86, ARM, ‡§î‡§∞ Apple Silicon ‡§Ü‡§∞‡•ç‡§ï‡§ø‡§ü‡•á‡§ï‡•ç‡§ö‡§∞ ‡§Æ‡•á‡§Ç ‡§ï‡•ç‡§∞‡•â‡§∏-‡§™‡•ç‡§≤‡•á‡§ü‡§´‡•â‡§∞‡•ç‡§Æ ‡§∏‡§Ç‡§ó‡§§‡§§‡§æ ‡§∏‡§æ‡§∞‡•ç‡§µ‡§≠‡•å‡§Æ‡§ø‡§ï ‡§è‡§ú‡•á‡§Ç‡§ü ‡§§‡•à‡§®‡§æ‡§§‡•Ä ‡§ï‡•ç‡§∑‡§Æ‡§§‡§æ‡§ì‡§Ç ‡§ï‡•ã ‡§∏‡§ï‡•ç‡§∑‡§Æ ‡§ï‡§∞‡§§‡•Ä ‡§π‡•à‡•§

#### Apple MLX ‡§´‡•ç‡§∞‡•á‡§Æ‡§µ‡§∞‡•ç‡§ï SLM ‡§è‡§ú‡•á‡§Ç‡§ü‡•ç‡§∏ ‡§ï‡•á ‡§≤‡§ø‡§è

Apple MLX Apple Silicon ‡§â‡§™‡§ï‡§∞‡§£‡•ã‡§Ç ‡§™‡§∞ SLM-‡§∏‡§Ç‡§ö‡§æ‡§≤‡§ø‡§§ ‡§è‡§ú‡•á‡§Ç‡§ü‡•ç‡§∏ ‡§ï‡•á ‡§≤‡§ø‡§è ‡§µ‡§ø‡§∂‡•á‡§∑ ‡§∞‡•Ç‡§™ ‡§∏‡•á ‡§°‡§ø‡§ú‡§º‡§æ‡§á‡§® ‡§ï‡§ø‡§Ø‡§æ ‡§ó‡§Ø‡§æ ‡§¶‡•á‡§∂‡•Ä ‡§Ö‡§®‡•Å‡§ï‡•Ç‡§≤‡§® ‡§™‡•ç‡§∞‡§¶‡§æ‡§® ‡§ï‡§∞‡§§‡§æ ‡§π‡•à:

**Apple Silicon ‡§è‡§ú‡•á‡§Ç‡§ü ‡§Ö‡§®‡•Å‡§ï‡•Ç‡§≤‡§®**: ‡§´‡•ç‡§∞‡•á‡§Æ‡§µ‡§∞‡•ç‡§ï ‡§è‡§ï‡•Ä‡§ï‡•É‡§§ ‡§Æ‡•á‡§Æ‡•ã‡§∞‡•Ä ‡§Ü‡§∞‡•ç‡§ï‡§ø‡§ü‡•á‡§ï‡•ç‡§ö‡§∞ ‡§ï‡§æ ‡§â‡§™‡§Ø‡•ã‡§ó ‡§ï‡§∞‡§§‡§æ ‡§π‡•à ‡§ú‡§ø‡§∏‡§Æ‡•á‡§Ç ‡§Æ‡•á‡§ü‡§≤ ‡§™‡•ç‡§∞‡§¶‡§∞‡•ç‡§∂‡§® ‡§∂‡•á‡§°‡§∞‡•ç‡§∏ ‡§è‡§ï‡•Ä‡§ï‡§∞‡§£, ‡§è‡§ú‡•á‡§Ç‡§ü ‡§Ö‡§®‡•Å‡§Æ‡§æ‡§® ‡§ï‡•á ‡§≤‡§ø‡§è ‡§∏‡•ç‡§µ‡§ö‡§æ‡§≤‡§ø‡§§ ‡§Æ‡§ø‡§∂‡•ç‡§∞‡§ø‡§§ ‡§∏‡§ü‡•Ä‡§ï‡§§‡§æ, ‡§î‡§∞ ‡§Æ‡§≤‡•ç‡§ü‡•Ä-‡§è‡§ú‡•á‡§Ç‡§ü ‡§∏‡§ø‡§∏‡•ç‡§ü‡§Æ ‡§ï‡•á ‡§≤‡§ø‡§è ‡§Ö‡§®‡•Å‡§ï‡•Ç‡§≤‡§ø‡§§ ‡§Æ‡•á‡§Æ‡•ã‡§∞‡•Ä ‡§¨‡•à‡§Ç‡§°‡§µ‡§ø‡§°‡•ç‡§• ‡§∂‡§æ‡§Æ‡§ø‡§≤ ‡§π‡•à‡•§ M-‡§∏‡•Ä‡§∞‡•Ä‡§ú ‡§ö‡§ø‡§™‡•ç‡§∏ ‡§™‡§∞ SLM ‡§è‡§ú‡•á‡§Ç‡§ü‡•ç‡§∏ ‡§Ö‡§∏‡§æ‡§ß‡§æ‡§∞‡§£ ‡§™‡•ç‡§∞‡§¶‡§∞‡•ç‡§∂‡§® ‡§¶‡§ø‡§ñ‡§æ‡§§‡•á ‡§π‡•à‡§Ç‡•§

**‡§µ‡§ø‡§ï‡§æ‡§∏ ‡§∏‡•Å‡§µ‡§ø‡§ß‡§æ‡§è‡§Å**: ‡§è‡§ú‡•á‡§Ç‡§ü-‡§µ‡§ø‡§∂‡§ø‡§∑‡•ç‡§ü ‡§Ö‡§®‡•Å‡§ï‡•Ç‡§≤‡§® ‡§ï‡•á ‡§∏‡§æ‡§• Python ‡§î‡§∞ Swift API ‡§∏‡§Æ‡§∞‡•ç‡§•‡§®, ‡§è‡§ú‡•á‡§Ç‡§ü ‡§∏‡•Ä‡§ñ‡§®‡•á ‡§ï‡•á ‡§≤‡§ø‡§è ‡§∏‡•ç‡§µ‡§ö‡§æ‡§≤‡§ø‡§§ ‡§≠‡§ø‡§®‡•ç‡§®‡§§‡§æ, ‡§î‡§∞ Apple ‡§µ‡§ø‡§ï‡§æ‡§∏ ‡§â‡§™‡§ï‡§∞‡§£‡•ã‡§Ç ‡§ï‡•á ‡§∏‡§æ‡§• ‡§∏‡§π‡§ú ‡§è‡§ï‡•Ä‡§ï‡§∞‡§£ ‡§µ‡•ç‡§Ø‡§æ‡§™‡§ï ‡§è‡§ú‡•á‡§Ç‡§ü ‡§µ‡§ø‡§ï‡§æ‡§∏ ‡§µ‡§æ‡§§‡§æ‡§µ‡§∞‡§£ ‡§™‡•ç‡§∞‡§¶‡§æ‡§® ‡§ï‡§∞‡§§‡•á ‡§π‡•à‡§Ç‡•§

#### ONNX Runtime ‡§ï‡•ç‡§∞‡•â‡§∏-‡§™‡•ç‡§≤‡•á‡§ü‡§´‡•â‡§∞‡•ç‡§Æ SLM ‡§è‡§ú‡•á‡§Ç‡§ü‡•ç‡§∏ ‡§ï‡•á ‡§≤‡§ø‡§è

ONNX Runtime ‡§è‡§ï ‡§∏‡§æ‡§∞‡•ç‡§µ‡§≠‡•å‡§Æ‡§ø‡§ï ‡§Ö‡§®‡•Å‡§Æ‡§æ‡§® ‡§á‡§Ç‡§ú‡§® ‡§™‡•ç‡§∞‡§¶‡§æ‡§® ‡§ï‡§∞‡§§‡§æ ‡§π‡•à ‡§ú‡•ã SLM ‡§è‡§ú‡•á‡§Ç‡§ü‡•ç‡§∏ ‡§ï‡•ã ‡§µ‡§ø‡§≠‡§ø‡§®‡•ç‡§® ‡§π‡§æ‡§∞‡•ç‡§°‡§µ‡•á‡§Ø‡§∞ ‡§™‡•ç‡§≤‡•á‡§ü‡§´‡•â‡§∞‡•ç‡§Æ ‡§î‡§∞ ‡§ë‡§™‡§∞‡•á‡§ü‡§ø‡§Ç‡§ó ‡§∏‡§ø‡§∏‡•ç‡§ü‡§Æ ‡§Æ‡•á‡§Ç ‡§∏‡•Å‡§∏‡§Ç‡§ó‡§§ ‡§∞‡•Ç‡§™ ‡§∏‡•á ‡§ö‡§≤‡§æ‡§®‡•á ‡§Æ‡•á‡§Ç ‡§∏‡§ï‡•ç‡§∑‡§Æ ‡§¨‡§®‡§æ‡§§‡§æ ‡§π‡•à:

**‡§∏‡§æ‡§∞‡•ç‡§µ‡§≠‡•å‡§Æ‡§ø‡§ï ‡§§‡•à‡§®‡§æ‡§§‡•Ä**: ONNX Runtime Windows, Linux, macOS, iOS, ‡§î‡§∞ Android ‡§™‡•ç‡§≤‡•á‡§ü‡§´‡•â‡§∞‡•ç‡§Æ ‡§Æ‡•á‡§Ç ‡§∏‡•Å‡§∏‡§Ç‡§ó‡§§ SLM ‡§è‡§ú‡•á‡§Ç‡§ü ‡§µ‡•ç‡§Ø‡§µ‡§π‡§æ‡§∞ ‡§∏‡•Å‡§®‡§ø‡§∂‡•ç‡§ö‡§ø‡§§ ‡§ï‡§∞‡§§‡§æ ‡§π‡•à‡•§ ‡§Ø‡§π ‡§ï‡•ç‡§∞‡•â‡§∏-‡§™‡•ç‡§≤‡•á‡§ü‡§´‡•â‡§∞‡•ç‡§Æ ‡§∏‡§Ç‡§ó‡§§‡§§‡§æ ‡§°‡•á‡§µ‡§≤‡§™‡§∞‡•ç‡§∏ ‡§ï‡•ã ‡§è‡§ï ‡§¨‡§æ‡§∞ ‡§≤‡§ø‡§ñ‡§®‡•á ‡§î‡§∞ ‡§π‡§∞ ‡§ú‡§ó‡§π ‡§§‡•à‡§®‡§æ‡§§ ‡§ï‡§∞‡§®‡•á ‡§Æ‡•á‡§Ç ‡§∏‡§ï‡•ç‡§∑‡§Æ ‡§¨‡§®‡§æ‡§§‡•Ä ‡§π‡•à, ‡§ú‡§ø‡§∏‡§∏‡•á ‡§¨‡§π‡•Å-‡§™‡•ç‡§≤‡•á‡§ü‡§´‡•â‡§∞‡•ç‡§Æ ‡§Ö‡§®‡•Å‡§™‡•ç‡§∞‡§Ø‡•ã‡§ó‡•ã‡§Ç ‡§ï‡•á ‡§≤‡§ø‡§è ‡§µ‡§ø‡§ï‡§æ‡§∏ ‡§î‡§∞ ‡§∞‡§ñ‡§∞‡§ñ‡§æ‡§µ ‡§ï‡§æ ‡§ì‡§µ‡§∞‡§π‡•á‡§° ‡§ï‡§æ‡§´‡•Ä ‡§ï‡§Æ ‡§π‡•ã ‡§ú‡§æ‡§§‡§æ ‡§π‡•à‡•§

**‡§π‡§æ‡§∞‡•ç‡§°‡§µ‡•á‡§Ø‡§∞ ‡§§‡•ç‡§µ‡§∞‡§£ ‡§µ‡§ø‡§ï‡§≤‡•ç‡§™**: ‡§´‡•ç‡§∞‡•á‡§Æ‡§µ‡§∞‡•ç‡§ï ‡§µ‡§ø‡§≠‡§ø‡§®‡•ç‡§® ‡§π‡§æ‡§∞‡•ç‡§°‡§µ‡•á‡§Ø‡§∞ ‡§ï‡•â‡§®‡•ç‡§´‡§º‡§ø‡§ó‡§∞‡•á‡§∂‡§® ‡§ï‡•á ‡§≤‡§ø‡§è ‡§Ö‡§®‡•Å‡§ï‡•Ç‡§≤‡§ø‡§§ ‡§®‡§ø‡§∑‡•ç‡§™‡§æ‡§¶‡§® ‡§™‡•ç‡§∞‡§¶‡§æ‡§§‡§æ ‡§™‡•ç‡§∞‡§¶‡§æ‡§® ‡§ï‡§∞‡§§‡§æ ‡§π‡•à, ‡§ú‡§ø‡§∏‡§Æ‡•á‡§Ç CPU (Intel, AMD, ARM), GPU (NVIDIA CUDA, AMD ROCm), ‡§î‡§∞ ‡§µ‡§ø‡§∂‡•á‡§∑ ‡§è‡§ï‡•ç‡§∏‡•á‡§≤‡•á‡§∞‡•á‡§ü‡§∞ (Intel VPU, Qualcomm NPU) ‡§∂‡§æ‡§Æ‡§ø‡§≤ ‡§π‡•à‡§Ç‡•§ SLM ‡§è‡§ú‡•á‡§Ç‡§ü‡•ç‡§∏ ‡§ï‡•ã ‡§ï‡•ã‡§° ‡§™‡§∞‡§ø‡§µ‡§∞‡•ç‡§§‡§®‡•ã‡§Ç ‡§ï‡•á ‡§¨‡§ø‡§®‡§æ ‡§â‡§™‡§≤‡§¨‡•ç‡§ß ‡§∏‡§∞‡•ç‡§µ‡•ã‡§§‡•ç‡§§‡§Æ ‡§π‡§æ‡§∞‡•ç‡§°‡§µ‡•á‡§Ø‡§∞ ‡§ï‡§æ ‡§∏‡•ç‡§µ‡§ö‡§æ‡§≤‡§ø‡§§ ‡§∞‡•Ç‡§™ ‡§∏‡•á ‡§≤‡§æ‡§≠ ‡§â‡§†‡§æ‡§®‡•á ‡§Æ‡•á‡§Ç ‡§∏‡§ï‡•ç‡§∑‡§Æ ‡§ï‡§ø‡§Ø‡§æ ‡§ú‡§æ ‡§∏‡§ï‡§§‡§æ ‡§π‡•à‡•§

**‡§â‡§§‡•ç‡§™‡§æ‡§¶‡§®-‡§§‡•à‡§Ø‡§æ‡§∞ ‡§∏‡•Å‡§µ‡§ø‡§ß‡§æ‡§è‡§Å**: ONNX Runtime ‡§â‡§§‡•ç‡§™‡§æ‡§¶‡§® ‡§è‡§ú‡•á‡§Ç‡§ü ‡§§‡•à‡§®‡§æ‡§§‡•Ä ‡§ï‡•á ‡§≤‡§ø‡§è ‡§Ü‡§µ‡§∂‡•ç‡§Ø‡§ï ‡§è‡§Ç‡§ü‡§∞‡§™‡•ç‡§∞‡§æ‡§á‡§ú‡§º-‡§ó‡•ç‡§∞‡•á‡§° ‡§∏‡•Å‡§µ‡§ø‡§ß‡§æ‡§è‡§Å ‡§™‡•ç‡§∞‡§¶‡§æ‡§® ‡§ï‡§∞‡§§‡§æ ‡§π‡•à, ‡§ú‡§ø‡§∏‡§Æ‡•á‡§Ç ‡§§‡•á‡§ú‡§º ‡§Ö‡§®‡•Å‡§Æ‡§æ‡§® ‡§ï‡•á ‡§≤‡§ø‡§è ‡§ó‡•ç‡§∞‡§æ‡§´ ‡§Ö‡§®‡•Å‡§ï‡•Ç‡§≤‡§®, ‡§∏‡§Ç‡§∏‡§æ‡§ß‡§®-‡§∏‡•Ä‡§Æ‡§ø‡§§ ‡§µ‡§æ‡§§‡§æ‡§µ‡§∞‡§£ ‡§ï‡•á ‡§≤‡§ø‡§è ‡§Æ‡•á‡§Æ‡•ã‡§∞‡•Ä ‡§™‡•ç‡§∞‡§¨‡§Ç‡§ß‡§®, ‡§î‡§∞ ‡§™‡•ç‡§∞‡§¶‡§∞‡•ç‡§∂‡§® ‡§µ‡§ø‡§∂‡•ç‡§≤‡•á‡§∑‡§£ ‡§ï‡•á ‡§≤‡§ø‡§è ‡§µ‡•ç‡§Ø‡§æ‡§™‡§ï ‡§™‡•ç‡§∞‡•ã‡§´‡§æ‡§á‡§≤‡§ø‡§Ç‡§ó ‡§â‡§™‡§ï‡§∞‡§£ ‡§∂‡§æ‡§Æ‡§ø‡§≤ ‡§π‡•à‡§Ç‡•§ ‡§´‡•ç‡§∞‡•á‡§Æ‡§µ‡§∞‡•ç‡§ï Python ‡§î‡§∞ C++ APIs ‡§¶‡•ã‡§®‡•ã‡§Ç ‡§ï‡§æ ‡§∏‡§Æ‡§∞‡•ç‡§•‡§® ‡§ï‡§∞‡§§‡§æ ‡§π‡•à, ‡§ú‡•ã ‡§≤‡§ö‡•Ä‡§≤‡•á ‡§è‡§ï‡•Ä‡§ï‡§∞‡§£ ‡§ï‡•Ä ‡§Ö‡§®‡•Å‡§Æ‡§§‡§ø ‡§¶‡•á‡§§‡§æ ‡§π‡•à‡•§
- Microsoft Agent Framework ‡§á‡§Ç‡§ü‡•Ä‡§ó‡•ç‡§∞‡•á‡§∂‡§® ‡§ï‡§æ ‡§™‡§∞‡•Ä‡§ï‡•ç‡§∑‡§£ ‡§ï‡§∞‡•á‡§Ç  
- ‡§ë‡§´‡§≤‡§æ‡§á‡§® ‡§ë‡§™‡§∞‡•á‡§∂‡§® ‡§ï‡•ç‡§∑‡§Æ‡§§‡§æ‡§ì‡§Ç ‡§ï‡•Ä ‡§ú‡§æ‡§Ç‡§ö ‡§ï‡§∞‡•á‡§Ç  
- ‡§´‡•á‡§≤‡§ì‡§µ‡§∞ ‡§™‡§∞‡§ø‡§¶‡•É‡§∂‡•ç‡§Ø‡•ã‡§Ç ‡§î‡§∞ ‡§§‡•ç‡§∞‡•Å‡§ü‡§ø ‡§π‡•à‡§Ç‡§°‡§≤‡§ø‡§Ç‡§ó ‡§ï‡§æ ‡§™‡§∞‡•Ä‡§ï‡•ç‡§∑‡§£ ‡§ï‡§∞‡•á‡§Ç  
- ‡§è‡§ú‡•á‡§Ç‡§ü ‡§µ‡§∞‡•ç‡§ï‡§´‡§º‡•ç‡§≤‡•ã ‡§ï‡§æ ‡§è‡§Ç‡§°-‡§ü‡•Ç-‡§è‡§Ç‡§° ‡§∏‡§§‡•ç‡§Ø‡§æ‡§™‡§® ‡§ï‡§∞‡•á‡§Ç  

**Foundry Local ‡§ï‡•á ‡§∏‡§æ‡§• ‡§§‡•Å‡§≤‡§®‡§æ**:

| ‡§´‡•Ä‡§ö‡§∞ | Foundry Local | Ollama |
|------|---------------|--------|
| **‡§≤‡§ï‡•ç‡§∑‡§ø‡§§ ‡§â‡§™‡§Ø‡•ã‡§ó ‡§ï‡§æ ‡§Æ‡§æ‡§Æ‡§≤‡§æ** | ‡§è‡§Ç‡§ü‡§∞‡§™‡•ç‡§∞‡§æ‡§á‡§ú‡§º ‡§â‡§§‡•ç‡§™‡§æ‡§¶‡§® | ‡§µ‡§ø‡§ï‡§æ‡§∏ ‡§î‡§∞ ‡§∏‡§Æ‡•Å‡§¶‡§æ‡§Ø |
| **‡§Æ‡•â‡§°‡§≤ ‡§á‡§ï‡•ã‡§∏‡§ø‡§∏‡•ç‡§ü‡§Æ** | Microsoft ‡§¶‡•ç‡§µ‡§æ‡§∞‡§æ ‡§ï‡•ç‡§Ø‡•Ç‡§∞‡•á‡§ü‡•á‡§° | ‡§µ‡•ç‡§Ø‡§æ‡§™‡§ï ‡§∏‡§Æ‡•Å‡§¶‡§æ‡§Ø |
| **‡§π‡§æ‡§∞‡•ç‡§°‡§µ‡•á‡§Ø‡§∞ ‡§ë‡§™‡•ç‡§ü‡§ø‡§Æ‡§æ‡§á‡§ú‡§º‡•á‡§∂‡§®** | ‡§∏‡•ç‡§µ‡§ö‡§æ‡§≤‡§ø‡§§ (CUDA/NPU/CPU) | ‡§Æ‡•à‡§®‡•Å‡§Ö‡§≤ ‡§ï‡•â‡§®‡•ç‡§´‡§º‡§ø‡§ó‡§∞‡•á‡§∂‡§® |
| **‡§è‡§Ç‡§ü‡§∞‡§™‡•ç‡§∞‡§æ‡§á‡§ú‡§º ‡§´‡•Ä‡§ö‡§∞‡•ç‡§∏** | ‡§Ö‡§Ç‡§§‡§∞‡•ç‡§®‡§ø‡§π‡§ø‡§§ ‡§Æ‡•â‡§®‡§ø‡§ü‡§∞‡§ø‡§Ç‡§ó, ‡§∏‡•Å‡§∞‡§ï‡•ç‡§∑‡§æ | ‡§∏‡§æ‡§Æ‡•Å‡§¶‡§æ‡§Ø‡§ø‡§ï ‡§â‡§™‡§ï‡§∞‡§£ |
| **‡§°‡§ø‡§™‡•ç‡§≤‡•â‡§Ø‡§Æ‡•á‡§Ç‡§ü ‡§ú‡§ü‡§ø‡§≤‡§§‡§æ** | ‡§∏‡§∞‡§≤ (winget ‡§á‡§Ç‡§∏‡•ç‡§ü‡•â‡§≤) | ‡§∏‡§∞‡§≤ (curl ‡§á‡§Ç‡§∏‡•ç‡§ü‡•â‡§≤) |
| **API ‡§∏‡§Ç‡§ó‡§§‡§§‡§æ** | OpenAI + ‡§è‡§ï‡•ç‡§∏‡§ü‡•á‡§Ç‡§∂‡§® | OpenAI ‡§Æ‡§æ‡§®‡§ï |
| **‡§∏‡§™‡•ã‡§∞‡•ç‡§ü** | Microsoft ‡§Ü‡§ß‡§ø‡§ï‡§æ‡§∞‡§ø‡§ï | ‡§∏‡§æ‡§Æ‡•Å‡§¶‡§æ‡§Ø‡§ø‡§ï-‡§ö‡§æ‡§≤‡§ø‡§§ |
| **‡§∏‡§∞‡•ç‡§µ‡§∂‡•ç‡§∞‡•á‡§∑‡•ç‡§† ‡§â‡§™‡§Ø‡•ã‡§ó ‡§ï‡•á ‡§≤‡§ø‡§è** | ‡§â‡§§‡•ç‡§™‡§æ‡§¶‡§® ‡§è‡§ú‡•á‡§Ç‡§ü | ‡§™‡•ç‡§∞‡•ã‡§ü‡•ã‡§ü‡§æ‡§á‡§™‡§ø‡§Ç‡§ó, ‡§Ö‡§®‡•Å‡§∏‡§Ç‡§ß‡§æ‡§® |

**Ollama ‡§ï‡§¨ ‡§ö‡•Å‡§®‡•á‡§Ç**:
- **‡§µ‡§ø‡§ï‡§æ‡§∏ ‡§î‡§∞ ‡§™‡•ç‡§∞‡•ã‡§ü‡•ã‡§ü‡§æ‡§á‡§™‡§ø‡§Ç‡§ó**: ‡§µ‡§ø‡§≠‡§ø‡§®‡•ç‡§® ‡§Æ‡•â‡§°‡§≤‡•ã‡§Ç ‡§ï‡•á ‡§∏‡§æ‡§• ‡§§‡•á‡§ú‡§º‡•Ä ‡§∏‡•á ‡§™‡•ç‡§∞‡§Ø‡•ã‡§ó ‡§ï‡§∞‡§®‡§æ  
- **‡§∏‡§æ‡§Æ‡•Å‡§¶‡§æ‡§Ø‡§ø‡§ï ‡§Æ‡•â‡§°‡§≤**: ‡§®‡§µ‡•Ä‡§®‡§§‡§Æ ‡§∏‡§æ‡§Æ‡•Å‡§¶‡§æ‡§Ø‡§ø‡§ï ‡§Ø‡•ã‡§ó‡§¶‡§æ‡§® ‡§µ‡§æ‡§≤‡•á ‡§Æ‡•â‡§°‡§≤‡•ã‡§Ç ‡§§‡§ï ‡§™‡§π‡•Å‡§Ç‡§ö  
- **‡§∂‡•à‡§ï‡•ç‡§∑‡§ø‡§ï ‡§â‡§™‡§Ø‡•ã‡§ó**: AI ‡§è‡§ú‡•á‡§Ç‡§ü ‡§µ‡§ø‡§ï‡§æ‡§∏ ‡§∏‡•Ä‡§ñ‡§®‡•á ‡§î‡§∞ ‡§∏‡§ø‡§ñ‡§æ‡§®‡•á ‡§ï‡•á ‡§≤‡§ø‡§è  
- **‡§Ö‡§®‡•Å‡§∏‡§Ç‡§ß‡§æ‡§® ‡§™‡§∞‡§ø‡§Ø‡•ã‡§ú‡§®‡§æ‡§è‡§Ç**: ‡§µ‡§ø‡§µ‡§ø‡§ß ‡§Æ‡•â‡§°‡§≤ ‡§è‡§ï‡•ç‡§∏‡•á‡§∏ ‡§ï‡•Ä ‡§Ü‡§µ‡§∂‡•ç‡§Ø‡§ï‡§§‡§æ ‡§µ‡§æ‡§≤‡•á ‡§Ö‡§ï‡§æ‡§¶‡§Æ‡§ø‡§ï ‡§Ö‡§®‡•Å‡§∏‡§Ç‡§ß‡§æ‡§®  
- **‡§ï‡§∏‡•ç‡§ü‡§Æ ‡§Æ‡•â‡§°‡§≤**: ‡§ï‡§∏‡•ç‡§ü‡§Æ ‡§´‡§æ‡§á‡§®-‡§ü‡•ç‡§Ø‡•Ç‡§® ‡§ï‡§ø‡§è ‡§ó‡§è ‡§Æ‡•â‡§°‡§≤‡•ã‡§Ç ‡§ï‡§æ ‡§®‡§ø‡§∞‡•ç‡§Æ‡§æ‡§£ ‡§î‡§∞ ‡§™‡§∞‡•Ä‡§ï‡•ç‡§∑‡§£  

### VLLM: ‡§â‡§ö‡•ç‡§ö-‡§™‡•ç‡§∞‡§¶‡§∞‡•ç‡§∂‡§® SLM ‡§è‡§ú‡•á‡§Ç‡§ü ‡§á‡§Ç‡§´‡§∞‡•á‡§Ç‡§∏

VLLM (‡§¨‡§π‡•Å‡§§ ‡§¨‡§°‡§º‡•á ‡§≠‡§æ‡§∑‡§æ ‡§Æ‡•â‡§°‡§≤ ‡§á‡§Ç‡§´‡§∞‡•á‡§Ç‡§∏) ‡§è‡§ï ‡§â‡§ö‡•ç‡§ö-‡§•‡•ç‡§∞‡•Ç‡§™‡•Å‡§ü, ‡§Æ‡•á‡§Æ‡•ã‡§∞‡•Ä-‡§ï‡•Å‡§∂‡§≤ ‡§á‡§Ç‡§´‡§∞‡•á‡§Ç‡§∏ ‡§á‡§Ç‡§ú‡§® ‡§™‡•ç‡§∞‡§¶‡§æ‡§® ‡§ï‡§∞‡§§‡§æ ‡§π‡•à, ‡§ú‡•ã ‡§¨‡§°‡§º‡•á ‡§™‡•à‡§Æ‡§æ‡§®‡•á ‡§™‡§∞ ‡§â‡§§‡•ç‡§™‡§æ‡§¶‡§® SLM ‡§°‡§ø‡§™‡•ç‡§≤‡•â‡§Ø‡§Æ‡•á‡§Ç‡§ü ‡§ï‡•á ‡§≤‡§ø‡§è ‡§µ‡§ø‡§∂‡•á‡§∑ ‡§∞‡•Ç‡§™ ‡§∏‡•á ‡§Ö‡§®‡•Å‡§ï‡•Ç‡§≤‡§ø‡§§ ‡§π‡•à‡•§ ‡§ú‡§π‡§æ‡§Ç Foundry Local ‡§â‡§™‡§Ø‡•ã‡§ó ‡§Æ‡•á‡§Ç ‡§Ü‡§∏‡§æ‡§®‡•Ä ‡§™‡§∞ ‡§ï‡•á‡§Ç‡§¶‡•ç‡§∞‡§ø‡§§ ‡§π‡•à ‡§î‡§∞ Ollama ‡§∏‡§æ‡§Æ‡•Å‡§¶‡§æ‡§Ø‡§ø‡§ï ‡§Æ‡•â‡§°‡§≤‡•ã‡§Ç ‡§™‡§∞ ‡§ú‡•ã‡§∞ ‡§¶‡•á‡§§‡§æ ‡§π‡•à, VLLM ‡§â‡§ö‡•ç‡§ö-‡§™‡•ç‡§∞‡§¶‡§∞‡•ç‡§∂‡§® ‡§™‡§∞‡§ø‡§¶‡•É‡§∂‡•ç‡§Ø‡•ã‡§Ç ‡§Æ‡•á‡§Ç ‡§â‡§§‡•ç‡§ï‡•É‡§∑‡•ç‡§ü ‡§π‡•à, ‡§ú‡§ø‡§∏‡§Æ‡•á‡§Ç ‡§Ö‡§ß‡§ø‡§ï‡§§‡§Æ ‡§•‡•ç‡§∞‡•Ç‡§™‡•Å‡§ü ‡§î‡§∞ ‡§ï‡•Å‡§∂‡§≤ ‡§∏‡§Ç‡§∏‡§æ‡§ß‡§® ‡§â‡§™‡§Ø‡•ã‡§ó ‡§ï‡•Ä ‡§Ü‡§µ‡§∂‡•ç‡§Ø‡§ï‡§§‡§æ ‡§π‡•ã‡§§‡•Ä ‡§π‡•à‡•§

**‡§Æ‡•Å‡§ñ‡•ç‡§Ø ‡§Ü‡§∞‡•ç‡§ï‡§ø‡§ü‡•á‡§ï‡•ç‡§ö‡§∞ ‡§î‡§∞ ‡§´‡•Ä‡§ö‡§∞‡•ç‡§∏**:
- **PagedAttention**: ‡§ï‡•Å‡§∂‡§≤ ‡§ß‡•ç‡§Ø‡§æ‡§® ‡§ó‡§£‡§®‡§æ ‡§ï‡•á ‡§≤‡§ø‡§è ‡§ï‡•ç‡§∞‡§æ‡§Ç‡§§‡§ø‡§ï‡§æ‡§∞‡•Ä ‡§Æ‡•á‡§Æ‡•ã‡§∞‡•Ä ‡§™‡•ç‡§∞‡§¨‡§Ç‡§ß‡§®  
- **‡§°‡§æ‡§Ø‡§®‡§æ‡§Æ‡§ø‡§ï ‡§¨‡•à‡§ö‡§ø‡§Ç‡§ó**: ‡§á‡§Ç‡§ü‡•á‡§≤‡§ø‡§ú‡•á‡§Ç‡§ü ‡§Ö‡§®‡•Å‡§∞‡•ã‡§ß ‡§¨‡•à‡§ö‡§ø‡§Ç‡§ó ‡§ï‡•á ‡§≤‡§ø‡§è ‡§á‡§∑‡•ç‡§ü‡§§‡§Æ ‡§•‡•ç‡§∞‡•Ç‡§™‡•Å‡§ü  
- **GPU ‡§ë‡§™‡•ç‡§ü‡§ø‡§Æ‡§æ‡§á‡§ú‡§º‡•á‡§∂‡§®**: ‡§â‡§®‡•ç‡§®‡§§ CUDA ‡§ï‡§∞‡•ç‡§®‡§≤ ‡§î‡§∞ ‡§ü‡•á‡§Ç‡§∏‡§∞ ‡§™‡•à‡§∞‡•á‡§≤‡§≤‡§ø‡§ú‡§º‡•ç‡§Æ ‡§∏‡§™‡•ã‡§∞‡•ç‡§ü  
- **OpenAI ‡§∏‡§Ç‡§ó‡§§‡§§‡§æ**: ‡§∏‡§π‡§ú ‡§á‡§Ç‡§ü‡•Ä‡§ó‡•ç‡§∞‡•á‡§∂‡§® ‡§ï‡•á ‡§≤‡§ø‡§è ‡§™‡•Ç‡§∞‡•ç‡§£ API ‡§∏‡§Ç‡§ó‡§§‡§§‡§æ  
- **‡§∏‡•ç‡§™‡•á‡§ï‡•Å‡§≤‡•á‡§ü‡§ø‡§µ ‡§°‡§ø‡§ï‡•ã‡§°‡§ø‡§Ç‡§ó**: ‡§â‡§®‡•ç‡§®‡§§ ‡§á‡§Ç‡§´‡§∞‡•á‡§Ç‡§∏ ‡§§‡•ç‡§µ‡§∞‡§£ ‡§§‡§ï‡§®‡•Ä‡§ï  
- **‡§ï‡•ç‡§µ‡§æ‡§Ç‡§ü‡§æ‡§á‡§ú‡§º‡•á‡§∂‡§® ‡§∏‡§™‡•ã‡§∞‡•ç‡§ü**: ‡§Æ‡•á‡§Æ‡•ã‡§∞‡•Ä ‡§¶‡§ï‡•ç‡§∑‡§§‡§æ ‡§ï‡•á ‡§≤‡§ø‡§è INT4, INT8, ‡§î‡§∞ FP16 ‡§ï‡•ç‡§µ‡§æ‡§Ç‡§ü‡§æ‡§á‡§ú‡§º‡•á‡§∂‡§®  

#### ‡§á‡§Ç‡§∏‡•ç‡§ü‡•â‡§≤‡•á‡§∂‡§® ‡§î‡§∞ ‡§∏‡•á‡§ü‡§Ö‡§™

**‡§á‡§Ç‡§∏‡•ç‡§ü‡•â‡§≤‡•á‡§∂‡§® ‡§µ‡§ø‡§ï‡§≤‡•ç‡§™**:  
```bash
# Standard installation
pip install vllm

# With additional dependencies for agent frameworks
pip install vllm[agent] openai

# Docker deployment for production
docker pull vllm/vllm-openai:latest

# From source for latest features
git clone https://github.com/vllm-project/vllm.git
cd vllm
pip install -e .
```
  
**‡§è‡§ú‡•á‡§Ç‡§ü ‡§µ‡§ø‡§ï‡§æ‡§∏ ‡§ï‡•á ‡§≤‡§ø‡§è ‡§§‡•ç‡§µ‡§∞‡§ø‡§§ ‡§∂‡•Å‡§∞‡•Å‡§Ü‡§§**:  
```bash
# Start VLLM server with SLM model
python -m vllm.entrypoints.openai.api_server \
    --model microsoft/Phi-3.5-mini-instruct \
    --trust-remote-code \
    --max-model-len 4096 \
    --gpu-memory-utilization 0.8

# Alternative: Start with Qwen2.5 for lightweight agents
python -m vllm.entrypoints.openai.api_server \
    --model Qwen/Qwen2.5-0.5B-Instruct \
    --trust-remote-code \
    --max-model-len 2048 \
    --tensor-parallel-size 1

# Test API endpoint
curl http://localhost:8000/v1/models

# Test chat completion
curl http://localhost:8000/v1/chat/completions \
    -H "Content-Type: application/json" \
    -d '{
        "model": "microsoft/Phi-3.5-mini-instruct",
        "messages": [{"role": "user", "content": "Hello!"}]
    }'
```
  

#### ‡§è‡§ú‡•á‡§Ç‡§ü ‡§´‡•ç‡§∞‡•á‡§Æ‡§µ‡§∞‡•ç‡§ï ‡§á‡§Ç‡§ü‡•Ä‡§ó‡•ç‡§∞‡•á‡§∂‡§®

**Microsoft Agent Framework ‡§ï‡•á ‡§∏‡§æ‡§• VLLM**:  
```python
from microsoft_agent_framework import Agent, Config
import openai
import subprocess
import time
import requests
from typing import Optional, Dict, Any

class VLLMManager:
    def __init__(self, model_name: str, 
                 host: str = "localhost", 
                 port: int = 8000,
                 gpu_memory_utilization: float = 0.8,
                 max_model_len: int = 4096):
        self.model_name = model_name
        self.host = host
        self.port = port
        self.base_url = f"http://{host}:{port}"
        self.gpu_memory_utilization = gpu_memory_utilization
        self.max_model_len = max_model_len
        self.process = None
        self.client = None
        
    def start_server(self) -> bool:
        """Start VLLM server with optimized settings for agents."""
        try:
            cmd = [
                "python", "-m", "vllm.entrypoints.openai.api_server",
                "--model", self.model_name,
                "--host", self.host,
                "--port", str(self.port),
                "--gpu-memory-utilization", str(self.gpu_memory_utilization),
                "--max-model-len", str(self.max_model_len),
                "--trust-remote-code",
                "--disable-log-requests",  # Reduce logging for agents
                "--served-model-name", self.get_served_model_name()
            ]
            
            self.process = subprocess.Popen(cmd, 
                stdout=subprocess.PIPE, 
                stderr=subprocess.PIPE)
            
            # Wait for server to start
            max_retries = 30
            for _ in range(max_retries):
                if self.health_check():
                    self.client = openai.OpenAI(base_url=f"{self.base_url}/v1")
                    return True
                time.sleep(2)
                
            return False
            
        except Exception as e:
            print(f"Failed to start VLLM server: {e}")
            return False
    
    def get_served_model_name(self) -> str:
        """Get a clean model name for serving."""
        return self.model_name.replace("/", "--")
    
    def health_check(self) -> bool:
        """Check if VLLM server is healthy."""
        try:
            response = requests.get(f"{self.base_url}/health", timeout=5)
            return response.status_code == 200
        except:
            return False
    
    def get_openai_client(self) -> openai.OpenAI:
        """Get OpenAI-compatible client for VLLM."""
        if not self.client:
            self.client = openai.OpenAI(base_url=f"{self.base_url}/v1")
        return self.client
    
    def get_model_info(self) -> Dict[str, Any]:
        """Get model information and statistics."""
        try:
            response = requests.get(f"{self.base_url}/v1/models")
            if response.status_code == 200:
                return response.json()
        except:
            pass
        return {}
    
    def shutdown(self):
        """Shutdown VLLM server."""
        if self.process:
            self.process.terminate()
            self.process.wait()

# Initialize VLLM for high-performance agents
vllm_manager = VLLMManager("microsoft/Phi-3.5-mini-instruct")
if vllm_manager.start_server():
    print("VLLM server started successfully")
    
    # Configure agent with VLLM backend
    agent_config = Config(
        name="vllm-performance-agent",
        model_provider="vllm",
        model_id=vllm_manager.get_served_model_name(),
        endpoint=f"{vllm_manager.base_url}/v1",
        api_key="none"  # VLLM doesn't require API key
    )
    
    agent = Agent(config=agent_config)
else:
    print("Failed to start VLLM server")
```
  
**‡§â‡§ö‡•ç‡§ö-‡§•‡•ç‡§∞‡•Ç‡§™‡•Å‡§ü ‡§Æ‡§≤‡•ç‡§ü‡•Ä-‡§è‡§ú‡•á‡§Ç‡§ü ‡§∏‡•á‡§ü‡§Ö‡§™**:  
```python
import asyncio
from concurrent.futures import ThreadPoolExecutor
from microsoft_agent_framework import Agent, Config
import openai

class VLLMHighThroughputManager:
    def __init__(self):
        self.model_configs = {
            "lightweight": {
                "model": "Qwen/Qwen2.5-0.5B-Instruct",
                "port": 8000,
                "max_model_len": 2048,
                "gpu_memory_utilization": 0.3
            },
            "balanced": {
                "model": "microsoft/Phi-3.5-mini-instruct",
                "port": 8001,
                "max_model_len": 4096,
                "gpu_memory_utilization": 0.5
            },
            "capable": {
                "model": "meta-llama/Llama-3.2-3B-Instruct",
                "port": 8002,
                "max_model_len": 8192,
                "gpu_memory_utilization": 0.7
            }
        }
        self.managers = {}
        self.agents = {}
        self.client_pool = {}
        
    async def initialize_all_models(self):
        """Initialize all VLLM models in parallel."""
        initialization_tasks = []
        
        for category, config in self.model_configs.items():
            task = self._initialize_model(category, config)
            initialization_tasks.append(task)
        
        results = await asyncio.gather(*initialization_tasks, return_exceptions=True)
        
        successful_inits = 0
        for i, result in enumerate(results):
            category = list(self.model_configs.keys())[i]
            if isinstance(result, Exception):
                print(f"Failed to initialize {category}: {result}")
            else:
                successful_inits += 1
                print(f"Successfully initialized {category} model")
        
        return successful_inits
    
    async def _initialize_model(self, category: str, config: Dict[str, Any]):
        """Initialize a single VLLM model instance."""
        manager = VLLMManager(
            model_name=config["model"],
            port=config["port"],
            max_model_len=config["max_model_len"],
            gpu_memory_utilization=config["gpu_memory_utilization"]
        )
        
        # Start server in thread to avoid blocking
        loop = asyncio.get_event_loop()
        with ThreadPoolExecutor() as executor:
            success = await loop.run_in_executor(executor, manager.start_server)
        
        if success:
            self.managers[category] = manager
            
            # Create agent
            agent_config = Config(
                name=f"vllm-{category}-agent",
                model_provider="vllm",
                model_id=manager.get_served_model_name(),
                endpoint=f"{manager.base_url}/v1",
                api_key="none"
            )
            
            self.agents[category] = Agent(config=agent_config)
            
            # Create client pool for high throughput
            self.client_pool[category] = [
                openai.OpenAI(base_url=f"{manager.base_url}/v1")
                for _ in range(5)  # 5 clients per model for parallelism
            ]
            
            return True
        else:
            raise Exception(f"Failed to start VLLM server for {category}")
    
    def get_optimal_agent(self, request_complexity: str, current_load: Dict[str, int]) -> str:
        """Select optimal agent based on request complexity and current load."""
        complexity_mapping = {
            "simple": "lightweight",
            "moderate": "balanced", 
            "complex": "capable"
        }
        
        preferred_category = complexity_mapping.get(request_complexity, "balanced")
        
        # Check if preferred agent is available and not overloaded
        if (preferred_category in self.agents and 
            current_load.get(preferred_category, 0) < 10):  # Max 10 concurrent per agent
            return preferred_category
        
        # Fallback to least loaded available agent
        available_agents = [(cat, load) for cat, load in current_load.items() 
                          if cat in self.agents and load < 10]
        
        if available_agents:
            return min(available_agents, key=lambda x: x[1])[0]
        
        return "balanced"  # Default fallback
    
    async def process_batch_requests(self, requests: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """Process multiple requests in parallel for maximum throughput."""
        current_load = {cat: 0 for cat in self.agents.keys()}
        tasks = []
        
        for request in requests:
            # Determine optimal agent
            complexity = request.get("complexity", "moderate")
            agent_category = self.get_optimal_agent(complexity, current_load)
            current_load[agent_category] += 1
            
            # Create processing task
            task = self._process_single_request(request, agent_category)
            tasks.append(task)
        
        # Process all requests in parallel
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # Format results
        formatted_results = []
        for i, result in enumerate(results):
            if isinstance(result, Exception):
                formatted_results.append({
                    "request_id": requests[i].get("id", i),
                    "status": "error",
                    "error": str(result)
                })
            else:
                formatted_results.append(result)
        
        return formatted_results
    
    async def _process_single_request(self, request: Dict[str, Any], agent_category: str) -> Dict[str, Any]:
        """Process a single request with the specified agent."""
        start_time = time.time()
        
        try:
            agent = self.agents[agent_category]
            response = await agent.chat_async(request["message"])
            
            processing_time = time.time() - start_time
            
            return {
                "request_id": request.get("id"),
                "status": "success",
                "response": response,
                "agent_used": agent_category,
                "processing_time": processing_time
            }
            
        except Exception as e:
            return {
                "request_id": request.get("id"),
                "status": "error",
                "error": str(e),
                "agent_used": agent_category,
                "processing_time": time.time() - start_time
            }

# High-throughput usage example
throughput_manager = VLLMHighThroughputManager()

# Initialize all models
initialized_count = await throughput_manager.initialize_all_models()
print(f"Initialized {initialized_count} models")

# Process batch requests
batch_requests = [
    {"id": 1, "message": "Simple question", "complexity": "simple"},
    {"id": 2, "message": "Complex analysis needed", "complexity": "complex"},
    {"id": 3, "message": "Moderate difficulty task", "complexity": "moderate"}
]

results = await throughput_manager.process_batch_requests(batch_requests)
for result in results:
    print(f"Request {result['request_id']}: {result['status']} in {result.get('processing_time', 0):.2f}s")
```
  

#### ‡§â‡§§‡•ç‡§™‡§æ‡§¶‡§® ‡§°‡§ø‡§™‡•ç‡§≤‡•â‡§Ø‡§Æ‡•á‡§Ç‡§ü ‡§™‡•à‡§ü‡§∞‡•ç‡§®

**‡§è‡§Ç‡§ü‡§∞‡§™‡•ç‡§∞‡§æ‡§á‡§ú‡§º VLLM ‡§â‡§§‡•ç‡§™‡§æ‡§¶‡§® ‡§∏‡•á‡§µ‡§æ**:  
```python
import asyncio
import logging
import time
from typing import Dict, List, Optional
from dataclasses import dataclass
from microsoft_agent_framework import Agent, Config
import uvicorn
from fastapi import FastAPI, HTTPException, BackgroundTasks
from pydantic import BaseModel

@dataclass
class VLLMServerConfig:
    model_name: str
    port: int
    gpu_memory_utilization: float
    max_model_len: int
    tensor_parallel_size: int = 1
    quantization: Optional[str] = None

class AgentRequest(BaseModel):
    message: str
    agent_type: str = "general"
    priority: str = "normal"
    timeout: int = 30

class VLLMProductionService:
    def __init__(self, server_configs: Dict[str, VLLMServerConfig]):
        self.server_configs = server_configs
        self.managers = {}
        self.agents = {}
        self.metrics = {
            "requests_processed": 0,
            "requests_failed": 0,
            "total_processing_time": 0,
            "agent_usage": {name: 0 for name in server_configs.keys()},
            "throughput_per_minute": 0
        }
        self.request_queue = asyncio.Queue(maxsize=1000)
        self.processing_workers = []
        self.app = FastAPI(title="VLLM Agent Service")
        self._setup_routes()
        
    async def initialize_production_environment(self):
        """Initialize all VLLM servers for production."""
        logging.info("Initializing VLLM production environment...")
        
        initialization_tasks = []
        for name, config in self.server_configs.items():
            task = self._initialize_server(name, config)
            initialization_tasks.append(task)
        
        results = await asyncio.gather(*initialization_tasks, return_exceptions=True)
        
        successful_servers = 0
        for i, result in enumerate(results):
            server_name = list(self.server_configs.keys())[i]
            if isinstance(result, Exception):
                logging.error(f"Failed to initialize {server_name}: {result}")
            else:
                successful_servers += 1
                logging.info(f"Successfully initialized {server_name}")
        
        if successful_servers == 0:
            raise Exception("No VLLM servers could be initialized")
        
        # Start processing workers
        self.processing_workers = [
            asyncio.create_task(self._processing_worker(i))
            for i in range(min(4, successful_servers))  # 4 workers max
        ]
        
        logging.info(f"Production environment ready with {successful_servers} servers")
        return successful_servers
    
    async def _initialize_server(self, name: str, config: VLLMServerConfig):
        """Initialize a single VLLM server."""
        manager = VLLMManager(
            model_name=config.model_name,
            port=config.port,
            gpu_memory_utilization=config.gpu_memory_utilization,
            max_model_len=config.max_model_len
        )
        
        # Add quantization if specified
        if config.quantization:
            # This would be added to the manager's start command
            pass
        
        success = manager.start_server()
        if success:
            self.managers[name] = manager
            
            # Create production agent
            agent_config = Config(
                name=f"vllm-production-{name}",
                model_provider="vllm",
                model_id=manager.get_served_model_name(),
                endpoint=f"{manager.base_url}/v1",
                api_key="none",
                timeout=30.0
            )
            
            agent = Agent(config=agent_config)
            
            # Add production tools
            self._add_production_tools(agent, name)
            
            self.agents[name] = agent
            return True
        else:
            raise Exception(f"Failed to start VLLM server for {name}")
    
    def _add_production_tools(self, agent: Agent, server_type: str):
        """Add production tools based on server type."""
        if server_type == "customer_service":
            @agent.tool
            def escalate_to_human(issue: str, customer_id: str) -> str:
                """Escalate complex issues to human agents."""
                return f"Escalated issue for customer {customer_id}: {issue}"
            
            @agent.tool
            def lookup_order_status(order_id: str) -> dict:
                """Look up order status from production database."""
                # Production database lookup
                return {"order_id": order_id, "status": "shipped", "eta": "2 days"}
        
        elif server_type == "technical_support":
            @agent.tool
            def run_system_diagnostics(system_id: str) -> dict:
                """Run comprehensive system diagnostics."""
                return {"system_id": system_id, "status": "healthy", "issues": []}
            
            @agent.tool
            def create_incident_report(description: str, severity: str) -> str:
                """Create incident report in production system."""
                incident_id = f"INC-{hash(description) % 100000:05d}"
                return f"Created incident {incident_id} with severity {severity}"
    
    def _setup_routes(self):
        """Set up FastAPI routes for production service."""
        @self.app.post("/chat")
        async def chat_endpoint(request: AgentRequest, background_tasks: BackgroundTasks):
            try:
                # Add request to queue
                await self.request_queue.put({
                    "request": request,
                    "timestamp": time.time(),
                    "future": asyncio.Future()
                })
                
                # Wait for processing (with timeout)
                result = await asyncio.wait_for(
                    self._wait_for_result(request),
                    timeout=request.timeout
                )
                
                return result
                
            except asyncio.TimeoutError:
                raise HTTPException(status_code=408, detail="Request timeout")
            except Exception as e:
                raise HTTPException(status_code=500, detail=str(e))
        
        @self.app.get("/health")
        async def health_endpoint():
            return await self.get_health_status()
        
        @self.app.get("/metrics")
        async def metrics_endpoint():
            return self.get_production_metrics()
    
    async def _processing_worker(self, worker_id: int):
        """Background worker for processing agent requests."""
        logging.info(f"Starting processing worker {worker_id}")
        
        while True:
            try:
                # Get request from queue
                queue_item = await self.request_queue.get()
                request_data = queue_item["request"]
                request_future = queue_item["future"]
                
                # Select appropriate agent
                agent_name = self._select_agent(request_data.agent_type)
                
                if agent_name not in self.agents:
                    request_future.set_exception(Exception(f"Agent {agent_name} not available"))
                    continue
                
                # Process request
                start_time = time.time()
                try:
                    agent = self.agents[agent_name]
                    response = await agent.chat_async(request_data.message)
                    
                    processing_time = time.time() - start_time
                    
                    # Update metrics
                    self.metrics["requests_processed"] += 1
                    self.metrics["total_processing_time"] += processing_time
                    self.metrics["agent_usage"][agent_name] += 1
                    
                    result = {
                        "response": response,
                        "agent_used": agent_name,
                        "processing_time": processing_time,
                        "worker_id": worker_id
                    }
                    
                    request_future.set_result(result)
                    
                except Exception as e:
                    self.metrics["requests_failed"] += 1
                    request_future.set_exception(e)
                
                finally:
                    self.request_queue.task_done()
                    
            except Exception as e:
                logging.error(f"Worker {worker_id} error: {e}")
                await asyncio.sleep(1)
    
    def _select_agent(self, agent_type: str) -> str:
        """Select appropriate agent based on request type."""
        agent_mapping = {
            "customer_service": "customer_service",
            "technical": "technical_support",
            "general": "general_purpose"
        }
        
        return agent_mapping.get(agent_type, "general_purpose")
    
    async def _wait_for_result(self, request: AgentRequest):
        """Wait for request processing to complete."""
        # This is simplified - in production you'd track futures properly
        await asyncio.sleep(0.1)  # Placeholder
        return {"response": "Processed", "status": "success"}
    
    async def get_health_status(self) -> dict:
        """Get comprehensive health status of all services."""
        health_status = {
            "overall_status": "healthy",
            "servers": {},
            "queue_size": self.request_queue.qsize(),
            "active_workers": len([w for w in self.processing_workers if not w.done()]),
            "timestamp": time.time()
        }
        
        unhealthy_servers = 0
        for name, manager in self.managers.items():
            try:
                is_healthy = manager.health_check()
                health_status["servers"][name] = {
                    "status": "healthy" if is_healthy else "unhealthy",
                    "endpoint": manager.base_url,
                    "model": manager.model_name
                }
                if not is_healthy:
                    unhealthy_servers += 1
            except Exception as e:
                health_status["servers"][name] = {
                    "status": "error",
                    "error": str(e)
                }
                unhealthy_servers += 1
        
        if unhealthy_servers > 0:
            health_status["overall_status"] = "degraded" if unhealthy_servers < len(self.managers) else "unhealthy"
        
        return health_status
    
    def get_production_metrics(self) -> dict:
        """Get production performance metrics."""
        total_requests = self.metrics["requests_processed"] + self.metrics["requests_failed"]
        avg_processing_time = (
            self.metrics["total_processing_time"] / self.metrics["requests_processed"]
            if self.metrics["requests_processed"] > 0 else 0
        )
        
        success_rate = (
            self.metrics["requests_processed"] / total_requests * 100
            if total_requests > 0 else 0
        )
        
        return {
            "total_requests": total_requests,
            "successful_requests": self.metrics["requests_processed"],
            "failed_requests": self.metrics["requests_failed"],
            "success_rate_percent": success_rate,
            "average_processing_time_seconds": avg_processing_time,
            "agent_usage_distribution": self.metrics["agent_usage"],
            "queue_size": self.request_queue.qsize()
        }
    
    async def start_production_server(self, host: str = "0.0.0.0", port: int = 8080):
        """Start the production FastAPI server."""
        config = uvicorn.Config(
            self.app,
            host=host,
            port=port,
            log_level="info",
            workers=1  # Single worker for simplicity
        )
        server = uvicorn.Server(config)
        await server.serve()

# Production deployment example
production_configs = {
    "customer_service": VLLMServerConfig(
        model_name="microsoft/Phi-3.5-mini-instruct",
        port=8000,
        gpu_memory_utilization=0.4,
        max_model_len=4096
    ),
    "technical_support": VLLMServerConfig(
        model_name="meta-llama/Llama-3.2-3B-Instruct",
        port=8001,
        gpu_memory_utilization=0.6,
        max_model_len=8192
    ),
    "general_purpose": VLLMServerConfig(
        model_name="Qwen/Qwen2.5-1.5B-Instruct",
        port=8002,
        gpu_memory_utilization=0.3,
        max_model_len=2048
    )
}

production_service = VLLMProductionService(production_configs)

# Initialize and start production service
# await production_service.initialize_production_environment()
# await production_service.start_production_server()
```
  

#### ‡§è‡§Ç‡§ü‡§∞‡§™‡•ç‡§∞‡§æ‡§á‡§ú‡§º ‡§´‡•Ä‡§ö‡§∞‡•ç‡§∏ ‡§î‡§∞ ‡§Æ‡•â‡§®‡§ø‡§ü‡§∞‡§ø‡§Ç‡§ó

**‡§â‡§®‡•ç‡§®‡§§ VLLM ‡§™‡•ç‡§∞‡§¶‡§∞‡•ç‡§∂‡§® ‡§Æ‡•â‡§®‡§ø‡§ü‡§∞‡§ø‡§Ç‡§ó**:  
```python
import psutil
import nvidia_ml_py3 as nvml
from dataclasses import dataclass
from typing import List, Dict, Optional
import json
import asyncio

@dataclass
class PerformanceMetrics:
    timestamp: float
    requests_per_second: float
    average_latency_ms: float
    gpu_utilization_percent: float
    gpu_memory_used_gb: float
    cpu_utilization_percent: float
    memory_used_gb: float
    queue_length: int
    active_requests: int

class VLLMAdvancedMonitoring:
    def __init__(self, vllm_managers: Dict[str, VLLMManager]):
        self.managers = vllm_managers
        self.metrics_history = []
        self.alert_thresholds = {
            "gpu_utilization_max": 95,
            "gpu_memory_max_gb": 10,
            "latency_max_ms": 3000,
            "queue_length_max": 50,
            "error_rate_max_percent": 10
        }
        
        # Initialize NVIDIA ML for GPU monitoring
        try:
            nvml.nvmlInit()
            self.gpu_monitoring_available = True
            self.gpu_count = nvml.nvmlDeviceGetCount()
        except:
            self.gpu_monitoring_available = False
            self.gpu_count = 0
    
    async def collect_comprehensive_metrics(self) -> Dict[str, PerformanceMetrics]:
        """Collect detailed performance metrics for all VLLM instances."""
        all_metrics = {}
        
        for name, manager in self.managers.items():
            try:
                metrics = await self._collect_single_instance_metrics(name, manager)
                all_metrics[name] = metrics
            except Exception as e:
                logging.error(f"Failed to collect metrics for {name}: {e}")
                # Create error metrics
                all_metrics[name] = PerformanceMetrics(
                    timestamp=time.time(),
                    requests_per_second=0,
                    average_latency_ms=0,
                    gpu_utilization_percent=0,
                    gpu_memory_used_gb=0,
                    cpu_utilization_percent=0,
                    memory_used_gb=0,
                    queue_length=0,
                    active_requests=0
                )
        
        return all_metrics
    
    async def _collect_single_instance_metrics(self, name: str, manager: VLLMManager) -> PerformanceMetrics:
        """Collect metrics for a single VLLM instance."""
        timestamp = time.time()
        
        # Get VLLM-specific metrics via API
        vllm_stats = await self._get_vllm_stats(manager)
        
        # Get system metrics
        cpu_percent = psutil.cpu_percent(interval=0.1)
        memory_info = psutil.virtual_memory()
        memory_used_gb = memory_info.used / (1024**3)
        
        # Get GPU metrics if available
        gpu_utilization = 0
        gpu_memory_used = 0
        
        if self.gpu_monitoring_available and self.gpu_count > 0:
            try:
                # Assuming first GPU for simplicity
                handle = nvml.nvmlDeviceGetHandleByIndex(0)
                gpu_util = nvml.nvmlDeviceGetUtilizationRates(handle)
                gpu_utilization = gpu_util.gpu
                
                gpu_mem = nvml.nvmlDeviceGetMemoryInfo(handle)
                gpu_memory_used = gpu_mem.used / (1024**3)
                
            except Exception as e:
                logging.warning(f"GPU monitoring failed: {e}")
        
        return PerformanceMetrics(
            timestamp=timestamp,
            requests_per_second=vllm_stats.get("requests_per_second", 0),
            average_latency_ms=vllm_stats.get("average_latency_ms", 0),
            gpu_utilization_percent=gpu_utilization,
            gpu_memory_used_gb=gpu_memory_used,
            cpu_utilization_percent=cpu_percent,
            memory_used_gb=memory_used_gb,
            queue_length=vllm_stats.get("queue_length", 0),
            active_requests=vllm_stats.get("active_requests", 0)
        )
    
    async def _get_vllm_stats(self, manager: VLLMManager) -> dict:
        """Get VLLM-specific statistics via API calls."""
        try:
            # Test inference to measure latency
            start_time = time.time()
            client = manager.get_openai_client()
            
            response = await asyncio.wait_for(
                asyncio.to_thread(
                    client.chat.completions.create,
                    model=manager.get_served_model_name(),
                    messages=[{"role": "user", "content": "ping"}],
                    max_tokens=1
                ),
                timeout=5.0
            )
            
            latency_ms = (time.time() - start_time) * 1000
            
            return {
                "average_latency_ms": latency_ms,
                "requests_per_second": 1000 / latency_ms if latency_ms > 0 else 0,
                "queue_length": 0,  # Would need to be exposed by VLLM
                "active_requests": 1  # Approximation
            }
            
        except Exception as e:
            logging.warning(f"Failed to get VLLM stats: {e}")
            return {
                "average_latency_ms": 0,
                "requests_per_second": 0,
                "queue_length": 0,
                "active_requests": 0
            }
    
    def generate_performance_report(self, time_window_minutes: int = 60) -> dict:
        """Generate comprehensive performance report."""
        cutoff_time = time.time() - (time_window_minutes * 60)
        recent_metrics = [
            metrics for metrics in self.metrics_history
            if any(m.timestamp > cutoff_time for m in metrics.values())
        ]
        
        if not recent_metrics:
            return {"error": "No recent metrics available"}
        
        report = {
            "time_window_minutes": time_window_minutes,
            "total_samples": len(recent_metrics),
            "instances": {}
        }
        
        # Analyze each instance
        for instance_name in self.managers.keys():
            instance_metrics = [
                metrics[instance_name] for metrics in recent_metrics
                if instance_name in metrics
            ]
            
            if instance_metrics:
                report["instances"][instance_name] = {
                    "avg_latency_ms": sum(m.average_latency_ms for m in instance_metrics) / len(instance_metrics),
                    "max_latency_ms": max(m.average_latency_ms for m in instance_metrics),
                    "avg_gpu_utilization": sum(m.gpu_utilization_percent for m in instance_metrics) / len(instance_metrics),
                    "avg_requests_per_second": sum(m.requests_per_second for m in instance_metrics) / len(instance_metrics),
                    "max_queue_length": max(m.queue_length for m in instance_metrics),
                    "availability_percent": (len(instance_metrics) / len(recent_metrics)) * 100
                }
        
        return report
    
    async def auto_scaling_recommendations(self) -> List[dict]:
        """Generate auto-scaling recommendations based on performance metrics."""
        recommendations = []
        
        if not self.metrics_history:
            return recommendations
        
        latest_metrics = self.metrics_history[-1]
        
        for instance_name, metrics in latest_metrics.items():
            # High latency recommendation
            if metrics.average_latency_ms > self.alert_thresholds["latency_max_ms"]:
                recommendations.append({
                    "instance": instance_name,
                    "type": "scale_up",
                    "reason": f"High latency: {metrics.average_latency_ms:.0f}ms",
                    "suggestion": "Consider adding tensor parallelism or increasing GPU memory"
                })
            
            # High GPU utilization recommendation
            if metrics.gpu_utilization_percent > self.alert_thresholds["gpu_utilization_max"]:
                recommendations.append({
                    "instance": instance_name,
                    "type": "scale_out",
                    "reason": f"High GPU utilization: {metrics.gpu_utilization_percent:.1f}%",
                    "suggestion": "Consider adding additional GPU instances"
                })
            
            # Low utilization recommendation
            if (metrics.gpu_utilization_percent < 20 and 
                metrics.requests_per_second < 1):
                recommendations.append({
                    "instance": instance_name,
                    "type": "scale_down",
                    "reason": f"Low utilization: {metrics.gpu_utilization_percent:.1f}% GPU, {metrics.requests_per_second:.1f} RPS",
                    "suggestion": "Consider consolidating workloads or reducing resources"
                })
        
        return recommendations

# Advanced monitoring setup
monitoring = VLLMAdvancedMonitoring({
    "customer_service": vllm_manager,
    # Add other managers as needed
})

async def advanced_monitoring_loop():
    """Advanced monitoring with auto-scaling recommendations."""
    while True:
        try:
            # Collect metrics
            metrics = await monitoring.collect_comprehensive_metrics()
            monitoring.metrics_history.append(metrics)
            
            # Keep only last 1000 entries
            if len(monitoring.metrics_history) > 1000:
                monitoring.metrics_history = monitoring.metrics_history[-1000:]
            
            # Generate recommendations every 5 minutes
            if len(monitoring.metrics_history) % 10 == 0:  # Every 10th collection (5 minutes if collecting every 30s)
                recommendations = await monitoring.auto_scaling_recommendations()
                
                if recommendations:
                    logging.info(f"Auto-scaling recommendations: {recommendations}")
            
            # Generate performance report every hour
            if len(monitoring.metrics_history) % 120 == 0:  # Every 120th collection (1 hour)
                report = monitoring.generate_performance_report(60)
                logging.info(f"Performance report: {json.dumps(report, indent=2)}")
            
        except Exception as e:
            logging.error(f"Advanced monitoring error: {e}")
        
        await asyncio.sleep(30)  # Collect metrics every 30 seconds

# Start advanced monitoring
# asyncio.create_task(advanced_monitoring_loop())
```
  

#### ‡§â‡§®‡•ç‡§®‡§§ ‡§ï‡•â‡§®‡•ç‡§´‡§º‡§ø‡§ó‡§∞‡•á‡§∂‡§® ‡§î‡§∞ ‡§ë‡§™‡•ç‡§ü‡§ø‡§Æ‡§æ‡§á‡§ú‡§º‡•á‡§∂‡§®

**‡§â‡§§‡•ç‡§™‡§æ‡§¶‡§® VLLM ‡§ï‡•â‡§®‡•ç‡§´‡§º‡§ø‡§ó‡§∞‡•á‡§∂‡§® ‡§ü‡•á‡§Æ‡•ç‡§™‡§≤‡•á‡§ü‡•ç‡§∏**:  
```python
from enum import Enum
from typing import Dict, Any

class DeploymentScenario(Enum):
    DEVELOPMENT = "development"
    STAGING = "staging"
    PRODUCTION_LOW = "production_low"
    PRODUCTION_HIGH = "production_high"
    ENTERPRISE = "enterprise"

class VLLMConfigTemplates:
    """Production-ready VLLM configuration templates."""
    
    @staticmethod
    def get_config_template(scenario: DeploymentScenario) -> Dict[str, Any]:
        """Get optimized configuration for deployment scenario."""
        
        templates = {
            DeploymentScenario.DEVELOPMENT: {
                "gpu_memory_utilization": 0.6,
                "max_model_len": 2048,
                "tensor_parallel_size": 1,
                "pipeline_parallel_size": 1,
                "quantization": None,
                "enable_prefix_caching": False,
                "max_num_seqs": 32,
                "max_num_batched_tokens": 2048
            },
            
            DeploymentScenario.STAGING: {
                "gpu_memory_utilization": 0.8,
                "max_model_len": 4096,
                "tensor_parallel_size": 1,
                "pipeline_parallel_size": 1,
                "quantization": "awq",
                "enable_prefix_caching": True,
                "max_num_seqs": 64,
                "max_num_batched_tokens": 4096
            },
            
            DeploymentScenario.PRODUCTION_LOW: {
                "gpu_memory_utilization": 0.85,
                "max_model_len": 4096,
                "tensor_parallel_size": 1,
                "pipeline_parallel_size": 1,
                "quantization": "awq",
                "enable_prefix_caching": True,
                "max_num_seqs": 128,
                "max_num_batched_tokens": 8192,
                "enable_chunked_prefill": True
            },
            
            DeploymentScenario.PRODUCTION_HIGH: {
                "gpu_memory_utilization": 0.9,
                "max_model_len": 8192,
                "tensor_parallel_size": 2,
                "pipeline_parallel_size": 1,
                "quantization": "awq",
                "enable_prefix_caching": True,
                "max_num_seqs": 256,
                "max_num_batched_tokens": 16384,
                "enable_chunked_prefill": True,
                "speculative_model": "small_draft_model"
            },
            
            DeploymentScenario.ENTERPRISE: {
                "gpu_memory_utilization": 0.95,
                "max_model_len": 16384,
                "tensor_parallel_size": 4,
                "pipeline_parallel_size": 2,
                "quantization": "awq",
                "enable_prefix_caching": True,
                "max_num_seqs": 512,
                "max_num_batched_tokens": 32768,
                "enable_chunked_prefill": True,
                "speculative_model": "optimized_draft_model",
                "guided_decoding_backend": "outlines"
            }
        }
        
        return templates[scenario]
    
    @staticmethod
    def generate_vllm_command(model_name: str, 
                             scenario: DeploymentScenario,
                             port: int = 8000,
                             host: str = "0.0.0.0") -> List[str]:
        """Generate optimized VLLM command for deployment scenario."""
        
        config = VLLMConfigTemplates.get_config_template(scenario)
        
        cmd = [
            "python", "-m", "vllm.entrypoints.openai.api_server",
            "--model", model_name,
            "--host", host,
            "--port", str(port),
            "--gpu-memory-utilization", str(config["gpu_memory_utilization"]),
            "--max-model-len", str(config["max_model_len"]),
            "--tensor-parallel-size", str(config["tensor_parallel_size"]),
            "--max-num-seqs", str(config["max_num_seqs"]),
            "--max-num-batched-tokens", str(config["max_num_batched_tokens"]),
            "--trust-remote-code",
            "--disable-log-requests"
        ]
        
        # Add optional parameters
        if config.get("quantization"):
            cmd.extend(["--quantization", config["quantization"]])
        
        if config.get("enable_prefix_caching"):
            cmd.append("--enable-prefix-caching")
        
        if config.get("enable_chunked_prefill"):
            cmd.append("--enable-chunked-prefill")
        
        if config.get("pipeline_parallel_size", 1) > 1:
            cmd.extend(["--pipeline-parallel-size", str(config["pipeline_parallel_size"])])
        
        if config.get("speculative_model"):
            cmd.extend(["--speculative-model", config["speculative_model"]])
        
        return cmd

# Usage examples
dev_cmd = VLLMConfigTemplates.generate_vllm_command(
    "microsoft/Phi-3.5-mini-instruct",
    DeploymentScenario.DEVELOPMENT,
    port=8000
)

prod_cmd = VLLMConfigTemplates.generate_vllm_command(
    "microsoft/Phi-3.5-mini-instruct",
    DeploymentScenario.PRODUCTION_HIGH,
    port=8001
)

print(f"Development command: {' '.join(dev_cmd)}")
print(f"Production command: {' '.join(prod_cmd)}")
```
  
**VLLM ‡§ï‡•á ‡§≤‡§ø‡§è ‡§â‡§§‡•ç‡§™‡§æ‡§¶‡§® ‡§°‡§ø‡§™‡•ç‡§≤‡•â‡§Ø‡§Æ‡•á‡§Ç‡§ü ‡§ö‡•á‡§ï‡§≤‡§ø‡§∏‡•ç‡§ü**:

‚úÖ **‡§π‡§æ‡§∞‡•ç‡§°‡§µ‡•á‡§Ø‡§∞ ‡§ë‡§™‡•ç‡§ü‡§ø‡§Æ‡§æ‡§á‡§ú‡§º‡•á‡§∂‡§®**:  
- ‡§Æ‡§≤‡•ç‡§ü‡•Ä-GPU ‡§∏‡•á‡§ü‡§Ö‡§™ ‡§ï‡•á ‡§≤‡§ø‡§è ‡§ü‡•á‡§Ç‡§∏‡§∞ ‡§™‡•à‡§∞‡•á‡§≤‡§≤‡§ø‡§ú‡§º‡•ç‡§Æ ‡§ï‡•â‡§®‡•ç‡§´‡§º‡§ø‡§ó‡§∞ ‡§ï‡§∞‡•á‡§Ç  
- ‡§Æ‡•á‡§Æ‡•ã‡§∞‡•Ä ‡§¶‡§ï‡•ç‡§∑‡§§‡§æ ‡§ï‡•á ‡§≤‡§ø‡§è ‡§ï‡•ç‡§µ‡§æ‡§Ç‡§ü‡§æ‡§á‡§ú‡§º‡•á‡§∂‡§® (AWQ/GPTQ) ‡§∏‡§ï‡•ç‡§∑‡§Æ ‡§ï‡§∞‡•á‡§Ç  
- GPU ‡§Æ‡•á‡§Æ‡•ã‡§∞‡•Ä ‡§â‡§™‡§Ø‡•ã‡§ó ‡§ï‡•ã ‡§á‡§∑‡•ç‡§ü‡§§‡§Æ ‡§∏‡•ç‡§§‡§∞ (85-95%) ‡§™‡§∞ ‡§∏‡•á‡§ü ‡§ï‡§∞‡•á‡§Ç  
- ‡§•‡•ç‡§∞‡•Ç‡§™‡•Å‡§ü ‡§ï‡•á ‡§≤‡§ø‡§è ‡§â‡§™‡§Ø‡•Å‡§ï‡•ç‡§§ ‡§¨‡•à‡§ö ‡§∏‡§æ‡§á‡§ú‡§º ‡§ï‡•â‡§®‡•ç‡§´‡§º‡§ø‡§ó‡§∞ ‡§ï‡§∞‡•á‡§Ç  

‚úÖ **‡§™‡•ç‡§∞‡§¶‡§∞‡•ç‡§∂‡§® ‡§ü‡•ç‡§Ø‡•Ç‡§®‡§ø‡§Ç‡§ó**:  
- ‡§¨‡§æ‡§∞-‡§¨‡§æ‡§∞ ‡§™‡•Ç‡§õ‡•á ‡§ú‡§æ‡§®‡•á ‡§µ‡§æ‡§≤‡•á ‡§™‡•ç‡§∞‡§∂‡•ç‡§®‡•ã‡§Ç ‡§ï‡•á ‡§≤‡§ø‡§è ‡§™‡•ç‡§∞‡•Ä‡§´‡§ø‡§ï‡•ç‡§∏ ‡§ï‡•à‡§∂‡§ø‡§Ç‡§ó ‡§∏‡§ï‡•ç‡§∑‡§Æ ‡§ï‡§∞‡•á‡§Ç  
- ‡§≤‡§Ç‡§¨‡•á ‡§Ö‡§®‡•Å‡§ï‡•ç‡§∞‡§Æ‡•ã‡§Ç ‡§ï‡•á ‡§≤‡§ø‡§è ‡§ö‡§Ç‡§ï‡•á‡§° ‡§™‡•ç‡§∞‡•Ä‡§´‡§ø‡§≤ ‡§ï‡•â‡§®‡•ç‡§´‡§º‡§ø‡§ó‡§∞ ‡§ï‡§∞‡•á‡§Ç  
- ‡§§‡•á‡§ú‡§º ‡§á‡§Ç‡§´‡§∞‡•á‡§Ç‡§∏ ‡§ï‡•á ‡§≤‡§ø‡§è ‡§∏‡•ç‡§™‡•á‡§ï‡•Å‡§≤‡•á‡§ü‡§ø‡§µ ‡§°‡§ø‡§ï‡•ã‡§°‡§ø‡§Ç‡§ó ‡§∏‡•á‡§ü ‡§ï‡§∞‡•á‡§Ç  
- ‡§π‡§æ‡§∞‡•ç‡§°‡§µ‡•á‡§Ø‡§∞ ‡§ï‡•á ‡§Ü‡§ß‡§æ‡§∞ ‡§™‡§∞ max_num_seqs ‡§ï‡•ã ‡§ë‡§™‡•ç‡§ü‡§ø‡§Æ‡§æ‡§á‡§ú‡§º ‡§ï‡§∞‡•á‡§Ç  

‚úÖ **‡§â‡§§‡•ç‡§™‡§æ‡§¶‡§® ‡§´‡•Ä‡§ö‡§∞‡•ç‡§∏**:  
- ‡§∏‡•ç‡§µ‡§æ‡§∏‡•ç‡§•‡•ç‡§Ø ‡§Æ‡•â‡§®‡§ø‡§ü‡§∞‡§ø‡§Ç‡§ó ‡§î‡§∞ ‡§Æ‡•á‡§ü‡•ç‡§∞‡§ø‡§ï‡•ç‡§∏ ‡§∏‡§Ç‡§ó‡•ç‡§∞‡§π ‡§∏‡•á‡§ü ‡§ï‡§∞‡•á‡§Ç  
- ‡§∏‡•ç‡§µ‡§ö‡§æ‡§≤‡§ø‡§§ ‡§™‡•Å‡§®‡§É ‡§Ü‡§∞‡§Ç‡§≠ ‡§î‡§∞ ‡§´‡•á‡§≤‡§ì‡§µ‡§∞ ‡§ï‡•â‡§®‡•ç‡§´‡§º‡§ø‡§ó‡§∞ ‡§ï‡§∞‡•á‡§Ç  
- ‡§Ö‡§®‡•Å‡§∞‡•ã‡§ß ‡§ï‡§§‡§æ‡§∞‡§¨‡§¶‡•ç‡§ß ‡§î‡§∞ ‡§≤‡•ã‡§° ‡§¨‡•à‡§≤‡•á‡§Ç‡§∏‡§ø‡§Ç‡§ó ‡§≤‡§æ‡§ó‡•Ç ‡§ï‡§∞‡•á‡§Ç  
- ‡§µ‡•ç‡§Ø‡§æ‡§™‡§ï ‡§≤‡•â‡§ó‡§ø‡§Ç‡§ó ‡§î‡§∞ ‡§Ö‡§≤‡§∞‡•ç‡§ü‡§ø‡§Ç‡§ó ‡§∏‡•á‡§ü ‡§ï‡§∞‡•á‡§Ç  

‚úÖ **‡§∏‡•Å‡§∞‡§ï‡•ç‡§∑‡§æ ‡§î‡§∞ ‡§µ‡§ø‡§∂‡•ç‡§µ‡§∏‡§®‡•Ä‡§Ø‡§§‡§æ**:  
- ‡§´‡§º‡§æ‡§Ø‡§∞‡§µ‡•â‡§≤ ‡§®‡§ø‡§Ø‡§Æ ‡§î‡§∞ ‡§è‡§ï‡•ç‡§∏‡•á‡§∏ ‡§ï‡§Ç‡§ü‡•ç‡§∞‡•ã‡§≤ ‡§ï‡•â‡§®‡•ç‡§´‡§º‡§ø‡§ó‡§∞ ‡§ï‡§∞‡•á‡§Ç  
- API ‡§¶‡§∞ ‡§∏‡•Ä‡§Æ‡§ø‡§§ ‡§î‡§∞ ‡§™‡•ç‡§∞‡§Æ‡§æ‡§£‡•Ä‡§ï‡§∞‡§£ ‡§∏‡•á‡§ü ‡§ï‡§∞‡•á‡§Ç  
- ‡§ó‡•ç‡§∞‡•á‡§∏‡§´‡•Å‡§≤ ‡§∂‡§ü‡§°‡§æ‡§â‡§® ‡§î‡§∞ ‡§ï‡•ç‡§≤‡•Ä‡§®‡§Ö‡§™ ‡§≤‡§æ‡§ó‡•Ç ‡§ï‡§∞‡•á‡§Ç  
- ‡§¨‡•à‡§ï‡§Ö‡§™ ‡§î‡§∞ ‡§Ü‡§™‡§¶‡§æ ‡§µ‡§∏‡•Ç‡§≤‡•Ä ‡§ï‡•â‡§®‡•ç‡§´‡§º‡§ø‡§ó‡§∞ ‡§ï‡§∞‡•á‡§Ç  

‚úÖ **‡§á‡§Ç‡§ü‡•Ä‡§ó‡•ç‡§∞‡•á‡§∂‡§® ‡§™‡§∞‡•Ä‡§ï‡•ç‡§∑‡§£**:  
- Microsoft Agent Framework ‡§á‡§Ç‡§ü‡•Ä‡§ó‡•ç‡§∞‡•á‡§∂‡§® ‡§ï‡§æ ‡§™‡§∞‡•Ä‡§ï‡•ç‡§∑‡§£ ‡§ï‡§∞‡•á‡§Ç  
- ‡§â‡§ö‡•ç‡§ö-‡§•‡•ç‡§∞‡•Ç‡§™‡•Å‡§ü ‡§™‡§∞‡§ø‡§¶‡•É‡§∂‡•ç‡§Ø‡•ã‡§Ç ‡§ï‡•ã ‡§∏‡§§‡•ç‡§Ø‡§æ‡§™‡§ø‡§§ ‡§ï‡§∞‡•á‡§Ç  
- ‡§´‡•á‡§≤‡§ì‡§µ‡§∞ ‡§î‡§∞ ‡§∞‡§ø‡§ï‡§µ‡§∞‡•Ä ‡§™‡•ç‡§∞‡§ï‡•ç‡§∞‡§ø‡§Ø‡§æ‡§ì‡§Ç ‡§ï‡§æ ‡§™‡§∞‡•Ä‡§ï‡•ç‡§∑‡§£ ‡§ï‡§∞‡•á‡§Ç  
- ‡§≤‡•ã‡§° ‡§ï‡•á ‡§§‡§π‡§§ ‡§™‡•ç‡§∞‡§¶‡§∞‡•ç‡§∂‡§® ‡§ï‡§æ ‡§¨‡•á‡§Ç‡§ö‡§Æ‡§æ‡§∞‡•ç‡§ï ‡§ï‡§∞‡•á‡§Ç  

**‡§Ö‡§®‡•ç‡§Ø ‡§∏‡§Æ‡§æ‡§ß‡§æ‡§®‡•ã‡§Ç ‡§ï‡•á ‡§∏‡§æ‡§• ‡§§‡•Å‡§≤‡§®‡§æ**:

| ‡§´‡•Ä‡§ö‡§∞ | VLLM | Foundry Local | Ollama |
|------|------|---------------|--------|
| **‡§≤‡§ï‡•ç‡§∑‡§ø‡§§ ‡§â‡§™‡§Ø‡•ã‡§ó ‡§ï‡§æ ‡§Æ‡§æ‡§Æ‡§≤‡§æ** | ‡§â‡§ö‡•ç‡§ö-‡§•‡•ç‡§∞‡•Ç‡§™‡•Å‡§ü ‡§â‡§§‡•ç‡§™‡§æ‡§¶‡§® | ‡§è‡§Ç‡§ü‡§∞‡§™‡•ç‡§∞‡§æ‡§á‡§ú‡§º ‡§â‡§™‡§Ø‡•ã‡§ó ‡§Æ‡•á‡§Ç ‡§Ü‡§∏‡§æ‡§®‡•Ä | ‡§µ‡§ø‡§ï‡§æ‡§∏ ‡§î‡§∞ ‡§∏‡§Æ‡•Å‡§¶‡§æ‡§Ø |
| **‡§™‡•ç‡§∞‡§¶‡§∞‡•ç‡§∂‡§®** | ‡§Ö‡§ß‡§ø‡§ï‡§§‡§Æ ‡§•‡•ç‡§∞‡•Ç‡§™‡•Å‡§ü | ‡§∏‡§Ç‡§§‡•Å‡§≤‡§ø‡§§ | ‡§Ö‡§ö‡•ç‡§õ‡§æ |
| **‡§Æ‡•á‡§Æ‡•ã‡§∞‡•Ä ‡§¶‡§ï‡•ç‡§∑‡§§‡§æ** | PagedAttention ‡§ë‡§™‡•ç‡§ü‡§ø‡§Æ‡§æ‡§á‡§ú‡§º‡•á‡§∂‡§® | ‡§∏‡•ç‡§µ‡§ö‡§æ‡§≤‡§ø‡§§ ‡§ë‡§™‡•ç‡§ü‡§ø‡§Æ‡§æ‡§á‡§ú‡§º‡•á‡§∂‡§® | ‡§Æ‡§æ‡§®‡§ï |
| **‡§∏‡•á‡§ü‡§Ö‡§™ ‡§ú‡§ü‡§ø‡§≤‡§§‡§æ** | ‡§â‡§ö‡•ç‡§ö (‡§ï‡§à ‡§™‡•à‡§∞‡§æ‡§Æ‡•Ä‡§ü‡§∞) | ‡§ï‡§Æ (‡§∏‡•ç‡§µ‡§ö‡§æ‡§≤‡§ø‡§§) | ‡§ï‡§Æ (‡§∏‡§∞‡§≤) |
| **‡§∏‡•ç‡§ï‡•á‡§≤‡•á‡§¨‡§ø‡§≤‡§ø‡§ü‡•Ä** | ‡§â‡§§‡•ç‡§ï‡•É‡§∑‡•ç‡§ü (‡§ü‡•á‡§Ç‡§∏‡§∞/‡§™‡§æ‡§á‡§™‡§≤‡§æ‡§á‡§® ‡§™‡•à‡§∞‡•á‡§≤‡§≤) | ‡§Ö‡§ö‡•ç‡§õ‡§æ | ‡§∏‡•Ä‡§Æ‡§ø‡§§ |
| **‡§ï‡•ç‡§µ‡§æ‡§Ç‡§ü‡§æ‡§á‡§ú‡§º‡•á‡§∂‡§®** | ‡§â‡§®‡•ç‡§®‡§§ (AWQ, GPTQ, FP8) | ‡§∏‡•ç‡§µ‡§ö‡§æ‡§≤‡§ø‡§§ | ‡§Æ‡§æ‡§®‡§ï GGUF |
| **‡§è‡§Ç‡§ü‡§∞‡§™‡•ç‡§∞‡§æ‡§á‡§ú‡§º ‡§´‡•Ä‡§ö‡§∞‡•ç‡§∏** | ‡§ï‡§∏‡•ç‡§ü‡§Æ ‡§á‡§Ç‡§™‡•ç‡§≤‡•Ä‡§Æ‡•á‡§Ç‡§ü‡•á‡§∂‡§® ‡§Ü‡§µ‡§∂‡•ç‡§Ø‡§ï | ‡§Ö‡§Ç‡§§‡§∞‡•ç‡§®‡§ø‡§π‡§ø‡§§ | ‡§∏‡§æ‡§Æ‡•Å‡§¶‡§æ‡§Ø‡§ø‡§ï ‡§â‡§™‡§ï‡§∞‡§£ |
| **‡§∏‡§∞‡•ç‡§µ‡§∂‡•ç‡§∞‡•á‡§∑‡•ç‡§† ‡§â‡§™‡§Ø‡•ã‡§ó ‡§ï‡•á ‡§≤‡§ø‡§è** | ‡§â‡§ö‡•ç‡§ö-‡§∏‡•ç‡§§‡§∞‡•Ä‡§Ø ‡§â‡§§‡•ç‡§™‡§æ‡§¶‡§® ‡§è‡§ú‡•á‡§Ç‡§ü | ‡§è‡§Ç‡§ü‡§∞‡§™‡•ç‡§∞‡§æ‡§á‡§ú‡§º ‡§â‡§§‡•ç‡§™‡§æ‡§¶‡§® | ‡§µ‡§ø‡§ï‡§æ‡§∏ |

**VLLM ‡§ï‡§¨ ‡§ö‡•Å‡§®‡•á‡§Ç**:
- **‡§â‡§ö‡•ç‡§ö-‡§•‡•ç‡§∞‡•Ç‡§™‡•Å‡§ü ‡§Ü‡§µ‡§∂‡•ç‡§Ø‡§ï‡§§‡§æ‡§è‡§Ç**: ‡§™‡•ç‡§∞‡§§‡§ø ‡§∏‡•á‡§ï‡§Ç‡§° ‡§∏‡•à‡§ï‡§°‡§º‡•ã‡§Ç ‡§Ö‡§®‡•Å‡§∞‡•ã‡§ß‡•ã‡§Ç ‡§ï‡•ã ‡§∏‡§Ç‡§∏‡§æ‡§ß‡§ø‡§§ ‡§ï‡§∞‡§®‡§æ  
- **‡§¨‡§°‡§º‡•á ‡§™‡•à‡§Æ‡§æ‡§®‡•á ‡§™‡§∞ ‡§°‡§ø‡§™‡•ç‡§≤‡•â‡§Ø‡§Æ‡•á‡§Ç‡§ü**: ‡§Æ‡§≤‡•ç‡§ü‡•Ä-GPU, ‡§Æ‡§≤‡•ç‡§ü‡•Ä-‡§®‡•ã‡§° ‡§°‡§ø‡§™‡•ç‡§≤‡•â‡§Ø‡§Æ‡•á‡§Ç‡§ü  
- **‡§™‡•ç‡§∞‡§¶‡§∞‡•ç‡§∂‡§® ‡§Æ‡§π‡§§‡•ç‡§µ‡§™‡•Ç‡§∞‡•ç‡§£**: ‡§¨‡§°‡§º‡•á ‡§™‡•à‡§Æ‡§æ‡§®‡•á ‡§™‡§∞ ‡§â‡§™-‡§∏‡•á‡§ï‡§Ç‡§° ‡§™‡•ç‡§∞‡§§‡§ø‡§ï‡•ç‡§∞‡§ø‡§Ø‡§æ ‡§∏‡§Æ‡§Ø  
- **‡§â‡§®‡•ç‡§®‡§§ ‡§ë‡§™‡•ç‡§ü‡§ø‡§Æ‡§æ‡§á‡§ú‡§º‡•á‡§∂‡§®**: ‡§ï‡§∏‡•ç‡§ü‡§Æ ‡§ï‡•ç‡§µ‡§æ‡§Ç‡§ü‡§æ‡§á‡§ú‡§º‡•á‡§∂‡§® ‡§î‡§∞ ‡§¨‡•à‡§ö‡§ø‡§Ç‡§ó ‡§ï‡•Ä ‡§Ü‡§µ‡§∂‡•ç‡§Ø‡§ï‡§§‡§æ  
- **‡§∏‡§Ç‡§∏‡§æ‡§ß‡§® ‡§¶‡§ï‡•ç‡§∑‡§§‡§æ**: ‡§Æ‡§π‡§Ç‡§ó‡•á GPU ‡§π‡§æ‡§∞‡•ç‡§°‡§µ‡•á‡§Ø‡§∞ ‡§ï‡§æ ‡§Ö‡§ß‡§ø‡§ï‡§§‡§Æ ‡§â‡§™‡§Ø‡•ã‡§ó  

## ‡§µ‡§æ‡§∏‡•ç‡§§‡§µ‡§ø‡§ï ‡§¶‡•Å‡§®‡§ø‡§Ø‡§æ ‡§ï‡•á SLM ‡§è‡§ú‡•á‡§Ç‡§ü ‡§Ö‡§®‡•Å‡§™‡•ç‡§∞‡§Ø‡•ã‡§ó

### ‡§ó‡•ç‡§∞‡§æ‡§π‡§ï ‡§∏‡•á‡§µ‡§æ SLM ‡§è‡§ú‡•á‡§Ç‡§ü
- **SLM ‡§ï‡•ç‡§∑‡§Æ‡§§‡§æ‡§è‡§Ç**: ‡§ñ‡§æ‡§§‡§æ ‡§ñ‡•ã‡§ú, ‡§™‡§æ‡§∏‡§µ‡§∞‡•ç‡§° ‡§∞‡•Ä‡§∏‡•á‡§ü, ‡§ë‡§∞‡•ç‡§°‡§∞ ‡§∏‡•ç‡§•‡§ø‡§§‡§ø ‡§ú‡§æ‡§Ç‡§ö  
- **‡§≤‡§æ‡§ó‡§§ ‡§≤‡§æ‡§≠**: LLM ‡§è‡§ú‡•á‡§Ç‡§ü‡•ã‡§Ç ‡§ï‡•Ä ‡§§‡•Å‡§≤‡§®‡§æ ‡§Æ‡•á‡§Ç ‡§á‡§Ç‡§´‡§∞‡•á‡§Ç‡§∏ ‡§≤‡§æ‡§ó‡§§ ‡§Æ‡•á‡§Ç 10 ‡§ó‡•Å‡§®‡§æ ‡§ï‡§Æ‡•Ä  
- **‡§™‡•ç‡§∞‡§¶‡§∞‡•ç‡§∂‡§®**: ‡§®‡§ø‡§Ø‡§Æ‡§ø‡§§ ‡§™‡•ç‡§∞‡§∂‡•ç‡§®‡•ã‡§Ç ‡§ï‡•á ‡§≤‡§ø‡§è ‡§§‡•á‡§ú‡§º ‡§™‡•ç‡§∞‡§§‡§ø‡§ï‡•ç‡§∞‡§ø‡§Ø‡§æ ‡§∏‡§Æ‡§Ø ‡§î‡§∞ ‡§∏‡•Å‡§∏‡§Ç‡§ó‡§§ ‡§ó‡•Å‡§£‡§µ‡§§‡•ç‡§§‡§æ  

### ‡§µ‡•ç‡§Ø‡§æ‡§™‡§æ‡§∞ ‡§™‡•ç‡§∞‡§ï‡•ç‡§∞‡§ø‡§Ø‡§æ SLM ‡§è‡§ú‡•á‡§Ç‡§ü
- **‡§á‡§®‡§µ‡•â‡§á‡§∏ ‡§™‡•ç‡§∞‡•ã‡§∏‡•á‡§∏‡§ø‡§Ç‡§ó ‡§è‡§ú‡•á‡§Ç‡§ü**: ‡§°‡•á‡§ü‡§æ ‡§®‡§ø‡§ï‡§æ‡§≤‡•á‡§Ç, ‡§ú‡§æ‡§®‡§ï‡§æ‡§∞‡•Ä ‡§∏‡§§‡•ç‡§Ø‡§æ‡§™‡§ø‡§§ ‡§ï‡§∞‡•á‡§Ç, ‡§Ö‡§®‡•Å‡§Æ‡•ã‡§¶‡§® ‡§ï‡•á ‡§≤‡§ø‡§è ‡§∞‡•Ç‡§ü ‡§ï‡§∞‡•á‡§Ç  
- **‡§à‡§Æ‡•á‡§≤ ‡§™‡•ç‡§∞‡§¨‡§Ç‡§ß‡§® ‡§è‡§ú‡•á‡§Ç‡§ü**: ‡§∏‡•ç‡§µ‡§ö‡§æ‡§≤‡§ø‡§§ ‡§∞‡•Ç‡§™ ‡§∏‡•á ‡§µ‡§∞‡•ç‡§ó‡•Ä‡§ï‡•É‡§§ ‡§ï‡§∞‡•á‡§Ç, ‡§™‡•ç‡§∞‡§æ‡§•‡§Æ‡§ø‡§ï‡§§‡§æ ‡§¶‡•á‡§Ç, ‡§â‡§§‡•ç‡§§‡§∞ ‡§ï‡§æ ‡§Æ‡§∏‡•å‡§¶‡§æ ‡§§‡•à‡§Ø‡§æ‡§∞ ‡§ï‡§∞‡•á‡§Ç  
- **‡§∂‡•á‡§°‡•ç‡§Ø‡•Ç‡§≤‡§ø‡§Ç‡§ó ‡§è‡§ú‡•á‡§Ç‡§ü**: ‡§Æ‡•Ä‡§ü‡§ø‡§Ç‡§ó‡•ç‡§∏ ‡§ï‡§æ ‡§∏‡§Æ‡§®‡•ç‡§µ‡§Ø ‡§ï‡§∞‡•á‡§Ç, ‡§ï‡•à‡§≤‡•á‡§Ç‡§°‡§∞ ‡§™‡•ç‡§∞‡§¨‡§Ç‡§ß‡§ø‡§§ ‡§ï‡§∞‡•á‡§Ç, ‡§∞‡§ø‡§Æ‡§æ‡§á‡§Ç‡§°‡§∞ ‡§≠‡•á‡§ú‡•á‡§Ç  

### ‡§µ‡•ç‡§Ø‡§ï‡•ç‡§§‡§ø‡§ó‡§§ SLM ‡§°‡§ø‡§ú‡§ø‡§ü‡§≤ ‡§∏‡§π‡§æ‡§Ø‡§ï
- **‡§ï‡§æ‡§∞‡•ç‡§Ø ‡§™‡•ç‡§∞‡§¨‡§Ç‡§ß‡§® ‡§è‡§ú‡•á‡§Ç‡§ü**: ‡§ü‡•Ç-‡§°‡•Ç ‡§∏‡•Ç‡§ö‡•Ä ‡§ï‡•ã ‡§ï‡•Å‡§∂‡§≤‡§§‡§æ‡§™‡•Ç‡§∞‡•ç‡§µ‡§ï ‡§¨‡§®‡§æ‡§è‡§Ç, ‡§Ö‡§™‡§°‡•á‡§ü ‡§ï‡§∞‡•á‡§Ç, ‡§µ‡•ç‡§Ø‡§µ‡§∏‡•ç‡§•‡§ø‡§§ ‡§ï‡§∞‡•á‡§Ç  
- **‡§∏‡•Ç‡§ö‡§®‡§æ ‡§∏‡§Ç‡§ó‡•ç‡§∞‡§π ‡§è‡§ú‡•á‡§Ç‡§ü**: ‡§µ‡§ø‡§∑‡§Ø‡•ã‡§Ç ‡§™‡§∞ ‡§∂‡•ã‡§ß ‡§ï‡§∞‡•á‡§Ç, ‡§∏‡•ç‡§•‡§æ‡§®‡•Ä‡§Ø ‡§∞‡•Ç‡§™ ‡§∏‡•á ‡§®‡§ø‡§∑‡•ç‡§ï‡§∞‡•ç‡§∑‡•ã‡§Ç ‡§ï‡§æ ‡§∏‡§æ‡§∞‡§æ‡§Ç‡§∂ ‡§¨‡§®‡§æ‡§è‡§Ç  
- **‡§∏‡§Ç‡§ö‡§æ‡§∞ ‡§è‡§ú‡•á‡§Ç‡§ü**: ‡§à‡§Æ‡•á‡§≤, ‡§∏‡§Ç‡§¶‡•á‡§∂, ‡§∏‡•ã‡§∂‡§≤ ‡§Æ‡•Ä‡§°‡§ø‡§Ø‡§æ ‡§™‡•ã‡§∏‡•ç‡§ü ‡§®‡§ø‡§ú‡•Ä ‡§§‡•å‡§∞ ‡§™‡§∞ ‡§§‡•à‡§Ø‡§æ‡§∞ ‡§ï‡§∞‡•á‡§Ç  

### ‡§ü‡•ç‡§∞‡•á‡§°‡§ø‡§Ç‡§ó ‡§î‡§∞ ‡§µ‡§ø‡§§‡•ç‡§§‡•Ä‡§Ø SLM ‡§è‡§ú‡•á‡§Ç‡§ü
- **‡§Æ‡§æ‡§∞‡•ç‡§ï‡•á‡§ü ‡§Æ‡•â‡§®‡§ø‡§ü‡§∞‡§ø‡§Ç‡§ó ‡§è‡§ú‡•á‡§Ç‡§ü**: ‡§µ‡§æ‡§∏‡•ç‡§§‡§µ‡§ø‡§ï ‡§∏‡§Æ‡§Ø ‡§Æ‡•á‡§Ç ‡§ï‡•Ä‡§Æ‡§§‡•ã‡§Ç ‡§ï‡•ã ‡§ü‡•ç‡§∞‡•à‡§ï ‡§ï‡§∞‡•á‡§Ç, ‡§∞‡•Å‡§ù‡§æ‡§®‡•ã‡§Ç ‡§ï‡•Ä ‡§™‡§π‡§ö‡§æ‡§® ‡§ï‡§∞‡•á‡§Ç  
- **‡§∞‡§ø‡§™‡•ã‡§∞‡•ç‡§ü ‡§ú‡§®‡§∞‡•á‡§∂‡§® ‡§è‡§ú‡•á‡§Ç‡§ü**: ‡§¶‡•à‡§®‡§ø‡§ï/‡§∏‡§æ‡§™‡•ç‡§§‡§æ‡§π‡§ø‡§ï ‡§∏‡§æ‡§∞‡§æ‡§Ç‡§∂ ‡§∏‡•ç‡§µ‡§ö‡§æ‡§≤‡§ø‡§§ ‡§∞‡•Ç‡§™ ‡§∏‡•á ‡§¨‡§®‡§æ‡§è‡§Ç  
- **‡§ú‡•ã‡§ñ‡§ø‡§Æ ‡§Æ‡•Ç‡§≤‡•ç‡§Ø‡§æ‡§Ç‡§ï‡§® ‡§è‡§ú‡•á‡§Ç‡§ü**: ‡§∏‡•ç‡§•‡§æ‡§®‡•Ä‡§Ø ‡§°‡•á‡§ü‡§æ ‡§ï‡§æ ‡§â‡§™‡§Ø‡•ã‡§ó ‡§ï‡§∞‡§ï‡•á ‡§™‡•ã‡§∞‡•ç‡§ü‡§´‡•ã‡§≤‡§ø‡§Ø‡•ã ‡§∏‡•ç‡§•‡§ø‡§§‡§ø ‡§ï‡§æ ‡§Æ‡•Ç‡§≤‡•ç‡§Ø‡§æ‡§Ç‡§ï‡§® ‡§ï‡§∞‡•á‡§Ç  

### ‡§∏‡•ç‡§µ‡§æ‡§∏‡•ç‡§•‡•ç‡§Ø ‡§∏‡•á‡§µ‡§æ ‡§∏‡§Æ‡§∞‡•ç‡§•‡§® SLM ‡§è‡§ú‡•á‡§Ç‡§ü
- **‡§Æ‡§∞‡•Ä‡§ú ‡§∂‡•á‡§°‡•ç‡§Ø‡•Ç‡§≤‡§ø‡§Ç‡§ó ‡§è‡§ú‡•á‡§Ç‡§ü**: ‡§Ö‡§™‡•â‡§á‡§Ç‡§ü‡§Æ‡•á‡§Ç‡§ü ‡§ï‡§æ ‡§∏‡§Æ‡§®‡•ç‡§µ‡§Ø ‡§ï‡§∞‡•á‡§Ç, ‡§∏‡•ç‡§µ‡§ö‡§æ‡§≤‡§ø‡§§ ‡§∞‡§ø‡§Æ‡§æ‡§á‡§Ç‡§°‡§∞ ‡§≠‡•á‡§ú‡•á‡§Ç  
- **‡§°‡•â‡§ï‡•ç‡§Ø‡•Ç‡§Æ‡•á‡§Ç‡§ü‡•á‡§∂‡§® ‡§è‡§ú‡•á‡§Ç‡§ü**: ‡§∏‡•ç‡§•‡§æ‡§®‡•Ä‡§Ø ‡§∞‡•Ç‡§™ ‡§∏‡•á ‡§Æ‡•á‡§°‡§ø‡§ï‡§≤ ‡§∏‡§æ‡§∞‡§æ‡§Ç‡§∂, ‡§∞‡§ø‡§™‡•ã‡§∞‡•ç‡§ü ‡§§‡•à‡§Ø‡§æ‡§∞ ‡§ï‡§∞‡•á‡§Ç  
- **‡§™‡•ç‡§∞‡§ø‡§∏‡•ç‡§ï‡•ç‡§∞‡§ø‡§™‡•ç‡§∂‡§® ‡§™‡•ç‡§∞‡§¨‡§Ç‡§ß‡§® ‡§è‡§ú‡•á‡§Ç‡§ü**: ‡§∞‡§ø‡§´‡§ø‡§≤‡•ç‡§∏ ‡§ï‡•ã ‡§ü‡•ç‡§∞‡•à‡§ï ‡§ï‡§∞‡•á‡§Ç, ‡§®‡§ø‡§ú‡•Ä ‡§§‡•å‡§∞ ‡§™‡§∞ ‡§á‡§Ç‡§ü‡§∞‡•à‡§ï‡•ç‡§∂‡§® ‡§ï‡•Ä ‡§ú‡§æ‡§Ç‡§ö ‡§ï‡§∞‡•á‡§Ç  

## Microsoft Agent Framework: ‡§â‡§§‡•ç‡§™‡§æ‡§¶‡§®-‡§§‡•à‡§Ø‡§æ‡§∞ ‡§è‡§ú‡•á‡§Ç‡§ü ‡§µ‡§ø‡§ï‡§æ‡§∏

### ‡§Ö‡§µ‡§≤‡•ã‡§ï‡§® ‡§î‡§∞ ‡§Ü‡§∞‡•ç‡§ï‡§ø‡§ü‡•á‡§ï‡•ç‡§ö‡§∞

Microsoft Agent Framework ‡§è‡§ï ‡§µ‡•ç‡§Ø‡§æ‡§™‡§ï, ‡§è‡§Ç‡§ü‡§∞‡§™‡•ç‡§∞‡§æ‡§á‡§ú‡§º-‡§ó‡•ç‡§∞‡•á‡§° ‡§™‡•ç‡§≤‡•á‡§ü‡§´‡§º‡•â‡§∞‡•ç‡§Æ ‡§™‡•ç‡§∞‡§¶‡§æ‡§® ‡§ï‡§∞‡§§‡§æ ‡§π‡•à, ‡§ú‡•ã AI ‡§è‡§ú‡•á‡§Ç‡§ü‡•ã‡§Ç ‡§ï‡•ã ‡§¨‡§®‡§æ‡§®‡•á, ‡§§‡•à‡§®‡§æ‡§§ ‡§ï‡§∞‡§®‡•á ‡§î‡§∞ ‡§™‡•ç‡§∞‡§¨‡§Ç‡§ß‡§ø‡§§ ‡§ï‡§∞‡§®‡•á ‡§ï‡•á ‡§≤‡§ø‡§è ‡§°‡§ø‡§ú‡§º‡§æ‡§á‡§® ‡§ï‡§ø‡§Ø‡§æ ‡§ó‡§Ø‡§æ ‡§π‡•à, ‡§ú‡•ã ‡§ï‡•ç‡§≤‡§æ‡§â‡§° ‡§î‡§∞ ‡§ë‡§´‡§≤‡§æ‡§á‡§® ‡§è‡§ú ‡§µ‡§æ‡§§‡§æ‡§µ‡§∞‡§£ ‡§¶‡•ã‡§®‡•ã‡§Ç ‡§Æ‡•á‡§Ç ‡§ï‡§æ‡§Æ ‡§ï‡§∞ ‡§∏‡§ï‡§§‡•á ‡§π‡•à‡§Ç‡•§ ‡§Ø‡§π ‡§´‡•ç‡§∞‡•á‡§Æ‡§µ‡§∞‡•ç‡§ï ‡§µ‡§ø‡§∂‡•á‡§∑ ‡§∞‡•Ç‡§™ ‡§∏‡•á ‡§õ‡•ã‡§ü‡•á ‡§≠‡§æ‡§∑‡§æ ‡§Æ‡•â‡§°‡§≤‡•ã‡§Ç ‡§î‡§∞ ‡§è‡§ú ‡§ï‡§Ç‡§™‡•ç‡§Ø‡•Ç‡§ü‡§ø‡§Ç‡§ó ‡§™‡§∞‡§ø‡§¶‡•É‡§∂‡•ç‡§Ø‡•ã‡§Ç ‡§ï‡•á ‡§∏‡§æ‡§• ‡§∏‡§π‡§ú‡§§‡§æ ‡§∏‡•á ‡§ï‡§æ‡§Æ ‡§ï‡§∞‡§®‡•á ‡§ï‡•á ‡§≤‡§ø‡§è ‡§°‡§ø‡§ú‡§º‡§æ‡§á‡§® ‡§ï‡§ø‡§Ø‡§æ ‡§ó‡§Ø‡§æ ‡§π‡•à, ‡§ú‡•ã ‡§ó‡•ã‡§™‡§®‡•Ä‡§Ø‡§§‡§æ-‡§∏‡§Ç‡§µ‡•á‡§¶‡§®‡§∂‡•Ä‡§≤ ‡§î‡§∞ ‡§∏‡§Ç‡§∏‡§æ‡§ß‡§®-‡§∏‡•Ä‡§Æ‡§ø‡§§ ‡§°‡§ø‡§™‡•ç‡§≤‡•â‡§Ø‡§Æ‡•á‡§Ç‡§ü ‡§ï‡•á ‡§≤‡§ø‡§è ‡§Ü‡§¶‡§∞‡•ç‡§∂ ‡§π‡•à‡•§

**‡§Æ‡•Å‡§ñ‡•ç‡§Ø ‡§´‡•ç‡§∞‡•á‡§Æ‡§µ‡§∞‡•ç‡§ï ‡§ò‡§ü‡§ï**:
- **‡§è‡§ú‡•á‡§Ç‡§ü ‡§∞‡§®‡§ü‡§æ‡§á‡§Æ**: ‡§è‡§ú ‡§°‡§ø‡§µ‡§æ‡§á‡§∏ ‡§ï‡•á ‡§≤‡§ø‡§è ‡§Ö‡§®‡•Å‡§ï‡•Ç‡§≤‡§ø‡§§ ‡§π‡§≤‡•ç‡§ï‡§æ ‡§®‡§ø‡§∑‡•ç‡§™‡§æ‡§¶‡§® ‡§µ‡§æ‡§§‡§æ‡§µ‡§∞‡§£  
- **‡§ü‡•Ç‡§≤ ‡§á‡§Ç‡§ü‡•Ä‡§ó‡•ç‡§∞‡•á‡§∂‡§® ‡§∏‡§ø‡§∏‡•ç‡§ü‡§Æ**: ‡§¨‡§æ‡§π‡§∞‡•Ä ‡§∏‡•á‡§µ‡§æ‡§ì‡§Ç ‡§î‡§∞ API ‡§ï‡•ã ‡§ú‡•ã‡§°‡§º‡§®‡•á ‡§ï‡•á ‡§≤‡§ø‡§è ‡§è‡§ï‡•ç‡§∏‡§ü‡•á‡§Ç‡§∏‡§ø‡§¨‡§≤ ‡§™‡•ç‡§≤‡§ó‡§á‡§® ‡§Ü‡§∞‡•ç‡§ï‡§ø‡§ü‡•á‡§ï‡•ç‡§ö‡§∞  
- **‡§∏‡•ç‡§ü‡•á‡§ü ‡§Æ‡•à‡§®‡•á‡§ú‡§Æ‡•á‡§Ç‡§ü**: ‡§∏‡§§‡•ç‡§∞‡•ã‡§Ç ‡§ï‡•á ‡§¨‡•Ä‡§ö ‡§∏‡•ç‡§•‡§æ‡§Ø‡•Ä ‡§è‡§ú‡•á‡§Ç‡§ü ‡§Æ‡•á‡§Æ‡•ã‡§∞‡•Ä ‡§î‡§∞ ‡§∏‡§Ç‡§¶‡§∞‡•ç‡§≠ ‡§™‡•ç‡§∞‡§¨‡§Ç‡§ß‡§®  
- **‡§∏‡•Å‡§∞‡§ï‡•ç‡§∑‡§æ ‡§™‡§∞‡§§**: ‡§è‡§Ç‡§ü‡§∞‡§™‡•ç‡§∞‡§æ‡§á‡§ú‡§º ‡§°‡§ø‡§™‡•ç‡§≤‡•â‡§Ø‡§Æ‡•á‡§Ç‡§ü ‡§ï‡•á ‡§≤‡§ø‡§è ‡§Ö‡§Ç‡§§‡§∞‡•ç‡§®‡§ø‡§π‡§ø‡§§ ‡§∏‡•Å‡§∞‡§ï‡•ç‡§∑‡§æ ‡§®‡§ø‡§Ø‡§Ç‡§§‡•ç‡§∞‡§£  
- **‡§ë‡§∞‡•ç‡§ï‡•á‡§∏‡•ç‡§ü‡•ç‡§∞‡•á‡§∂‡§® ‡§á‡§Ç‡§ú‡§®**: ‡§Æ‡§≤‡•ç‡§ü‡•Ä-‡§è‡§ú‡•á‡§Ç‡§ü ‡§∏‡§Æ‡§®‡•ç‡§µ‡§Ø ‡§î‡§∞ ‡§µ‡§∞‡•ç‡§ï‡§´‡§º‡•ç‡§≤‡•ã ‡§™‡•ç‡§∞‡§¨‡§Ç‡§ß‡§®  

### ‡§è‡§ú ‡§°‡§ø‡§™‡•ç‡§≤‡•â‡§Ø‡§Æ‡•á‡§Ç‡§ü ‡§ï‡•á ‡§≤‡§ø‡§è ‡§™‡•ç‡§∞‡§Æ‡•Å‡§ñ ‡§´‡•Ä‡§ö‡§∞‡•ç‡§∏

**‡§ë‡§´‡§≤‡§æ‡§á‡§®-‡§™‡•ç‡§∞‡§•‡§Æ ‡§Ü‡§∞‡•ç‡§ï‡§ø‡§ü‡•á‡§ï‡•ç‡§ö‡§∞**: Microsoft Agent Framework ‡§ï‡•ã ‡§ë‡§´‡§≤‡§æ‡§á‡§®-‡§™‡•ç‡§∞‡§•‡§Æ ‡§∏‡§ø‡§¶‡•ç‡§ß‡§æ‡§Ç‡§§‡•ã‡§Ç ‡§ï‡•á ‡§∏‡§æ‡§• ‡§°‡§ø‡§ú‡§º‡§æ‡§á‡§® ‡§ï‡§ø‡§Ø‡§æ ‡§ó‡§Ø‡§æ ‡§π‡•à, ‡§ú‡§ø‡§∏‡§∏‡•á ‡§è‡§ú‡•á‡§Ç‡§ü ‡§¨‡§ø‡§®‡§æ ‡§á‡§Ç‡§ü‡§∞‡§®‡•á‡§ü ‡§ï‡§®‡•á‡§ï‡•ç‡§ü‡§ø‡§µ‡§ø‡§ü‡•Ä ‡§ï‡•á ‡§™‡•ç‡§∞‡§≠‡§æ‡§µ‡•Ä ‡§¢‡§Ç‡§ó ‡§∏‡•á ‡§ï‡§æ‡§Æ ‡§ï‡§∞ ‡§∏‡§ï‡§§‡•á ‡§π‡•à‡§Ç‡•§ ‡§á‡§∏‡§Æ‡•á‡§Ç ‡§∏‡•ç‡§•‡§æ‡§®‡•Ä‡§Ø ‡§Æ‡•â‡§°‡§≤ ‡§á‡§Ç‡§´‡§∞‡•á‡§Ç‡§∏, ‡§ï‡•à‡§∂‡•ç‡§° ‡§®‡•â‡§≤‡•á‡§ú ‡§¨‡•á‡§∏, ‡§ë‡§´‡§≤‡§æ‡§á‡§® ‡§ü‡•Ç‡§≤ ‡§®‡§ø‡§∑‡•ç‡§™‡§æ‡§¶‡§®, ‡§î‡§∞ ‡§ï‡•ç‡§≤‡§æ‡§â‡§° ‡§∏‡•á‡§µ‡§æ‡§ì‡§Ç ‡§ï‡•Ä ‡§Ö‡§®‡•Å‡§™‡§≤‡§¨‡•ç‡§ß‡§§‡§æ ‡§ï‡•á ‡§¶‡•å‡§∞‡§æ‡§® ‡§ó‡•ç‡§∞‡•á‡§∏‡§´‡•Å‡§≤ ‡§°‡§ø‡§ó‡•ç‡§∞‡•á‡§°‡•á‡§∂‡§® ‡§∂‡§æ‡§Æ‡§ø‡§≤ ‡§π‡•à‡•§

**‡§∏‡§Ç‡§∏‡§æ‡§ß‡§® ‡§ë‡§™‡•ç‡§ü‡§ø‡§Æ‡§æ‡§á‡§ú‡§º‡•á‡§∂‡§®**: ‡§´‡•ç‡§∞‡•á‡§Æ‡§µ‡§∞‡•ç‡§ï SLMs ‡§ï‡•á ‡§≤‡§ø‡§è ‡§∏‡•ç‡§µ‡§ö‡§æ‡§≤‡§ø‡§§ ‡§Æ‡•á‡§Æ‡•ã‡§∞‡•Ä ‡§ë‡§™‡•ç‡§ü‡§ø‡§Æ‡§æ‡§á‡§ú‡§º‡•á‡§∂‡§®, ‡§è‡§ú ‡§°‡§ø‡§µ‡§æ‡§á‡§∏ ‡§ï‡•á ‡§≤‡§ø‡§è CPU/GPU ‡§≤‡•ã‡§° ‡§¨‡•à‡§≤‡•á‡§Ç‡§∏‡§ø‡§Ç‡§ó, ‡§â‡§™‡§≤‡§¨‡•ç‡§ß ‡§∏‡§Ç‡§∏‡§æ‡§ß‡§®‡•ã‡§Ç ‡§ï‡•á ‡§Ü‡§ß‡§æ‡§∞ ‡§™‡§∞ ‡§Ö‡§®‡•Å‡§ï‡•Ç‡§≤‡•Ä ‡§Æ‡•â‡§°‡§≤ ‡§ö‡§Ø‡§®, ‡§î‡§∞ ‡§Æ‡•ã‡§¨‡§æ‡§á‡§≤ ‡§°‡§ø‡§™‡•ç‡§≤‡•â‡§Ø‡§Æ‡•á‡§Ç‡§ü ‡§ï‡•á ‡§≤‡§ø‡§è ‡§™‡§æ‡§µ‡§∞-‡§ï‡•Å‡§∂‡§≤ ‡§á‡§Ç‡§´‡§∞‡•á‡§Ç‡§∏ ‡§™‡•à‡§ü‡§∞‡•ç‡§® ‡§™‡•ç‡§∞‡§¶‡§æ‡§® ‡§ï‡§∞‡§§‡§æ ‡§π‡•à‡•§

**‡§∏‡•Å‡§∞‡§ï‡•ç‡§∑‡§æ ‡§î‡§∞ ‡§ó‡•ã‡§™‡§®‡•Ä‡§Ø‡§§‡§æ**: ‡§è‡§Ç‡§ü‡§∞‡§™‡•ç‡§∞‡§æ‡§á‡§ú‡§º-‡§ó‡•ç‡§∞‡•á‡§° ‡§∏‡•Å‡§∞‡§ï‡•ç‡§∑‡§æ ‡§´‡•Ä‡§ö‡§∞‡•ç‡§∏ ‡§Æ‡•á‡§Ç ‡§ó‡•ã‡§™‡§®‡•Ä‡§Ø‡§§‡§æ ‡§¨‡§®‡§æ‡§è ‡§∞‡§ñ‡§®‡•á ‡§ï‡•á ‡§≤‡§ø‡§è ‡§∏‡•ç‡§•‡§æ‡§®‡•Ä‡§Ø ‡§°‡•á‡§ü‡§æ ‡§™‡•ç‡§∞‡•ã‡§∏‡•á‡§∏‡§ø‡§Ç‡§ó, ‡§è‡§®‡•ç‡§ï‡•ç‡§∞‡§ø‡§™‡•ç‡§ü‡•á‡§° ‡§è‡§ú‡•á‡§Ç‡§ü ‡§∏‡§Ç‡§ö‡§æ‡§∞ ‡§ö‡•à‡§®‡§≤, ‡§è‡§ú‡•á‡§Ç‡§ü ‡§ï‡•ç‡§∑‡§Æ‡§§‡§æ‡§ì‡§Ç ‡§ï‡•á ‡§≤‡§ø‡§è ‡§≠‡•Ç‡§Æ‡§ø‡§ï‡§æ-‡§Ü‡§ß‡§æ‡§∞‡§ø‡§§ ‡§è‡§ï‡•ç‡§∏‡•á‡§∏ ‡§ï‡§Ç‡§ü‡•ç‡§∞‡•ã‡§≤, ‡§î‡§∞ ‡§Ö‡§®‡•Å‡§™‡§æ‡§≤‡§® ‡§Ü‡§µ‡§∂‡•ç‡§Ø‡§ï‡§§‡§æ‡§ì‡§Ç ‡§ï‡•á ‡§≤‡§ø‡§è ‡§ë‡§°‡§ø‡§ü ‡§≤‡•â‡§ó‡§ø‡§Ç‡§ó ‡§∂‡§æ‡§Æ‡§ø‡§≤ ‡§π‡•à‡§Ç‡•§

### Foundry Local ‡§ï‡•á ‡§∏‡§æ‡§• ‡§á‡§Ç‡§ü‡•Ä‡§ó‡•ç‡§∞‡•á‡§∂‡§®

Microsoft Agent Framework Foundry Local ‡§ï‡•á ‡§∏‡§æ‡§• ‡§∏‡§π‡§ú‡§§‡§æ ‡§∏‡•á ‡§á‡§Ç‡§ü‡•Ä‡§ó‡•ç‡§∞‡•á‡§ü ‡§π‡•ã‡§§‡§æ ‡§π‡•à, ‡§ú‡§ø‡§∏‡§∏‡•á ‡§è‡§ï ‡§∏‡§Ç‡§™‡•Ç‡§∞‡•ç‡§£ ‡§è‡§ú AI ‡§∏‡§Æ‡§æ‡§ß‡§æ‡§® ‡§™‡•ç‡§∞‡§¶‡§æ‡§® ‡§π‡•ã‡§§‡§æ ‡§π‡•à:

**‡§∏‡•ç‡§µ‡§ö‡§æ‡§≤‡§ø‡§§ ‡§Æ‡•â‡§°‡§≤ ‡§°‡§ø‡§∏‡•ç‡§ï‡§µ‡§∞‡•Ä**: ‡§´‡•ç‡§∞‡•á‡§Æ‡§µ‡§∞‡•ç‡§ï ‡§∏‡•ç‡§µ‡§ö‡§æ‡§≤‡§ø‡§§ ‡§∞‡•Ç‡§™ ‡§∏‡•á Foundry Local ‡§á‡§Ç‡§∏‡•ç‡§ü‡•á‡§Ç‡§∏ ‡§ï‡§æ ‡§™‡§§‡§æ ‡§≤‡§ó‡§æ‡§§‡§æ ‡§π‡•à, ‡§â‡§™‡§≤‡§¨‡•ç‡§ß SLM ‡§Æ‡•â‡§°‡§≤‡•ã‡§Ç ‡§∏‡•á ‡§ú‡•Å‡§°‡§º‡§§‡§æ ‡§π‡•à, ‡§î‡§∞ ‡§è‡§ú‡•á‡§Ç‡§ü ‡§Ü‡§µ‡§∂‡•ç‡§Ø‡§ï‡§§‡§æ‡§ì‡§Ç ‡§î‡§∞ ‡§π‡§æ‡§∞‡•ç‡§°‡§µ‡•á‡§Ø‡§∞ ‡§ï‡•ç‡§∑‡§Æ‡§§‡§æ‡§ì‡§Ç ‡§ï‡•á ‡§Ü‡§ß‡§æ‡§∞ ‡§™‡§∞ ‡§á‡§∑‡•ç‡§ü‡§§‡§Æ ‡§Æ‡•â‡§°‡§≤ ‡§ï‡§æ ‡§ö‡§Ø‡§® ‡§ï‡§∞‡§§‡§æ ‡§π‡•à‡•§

**‡§°‡§æ‡§Ø‡§®‡§æ‡§Æ‡§ø‡§ï ‡§Æ‡•â‡§°‡§≤ ‡§≤‡•ã‡§°‡§ø‡§Ç‡§ó**: ‡§è‡§ú‡•á‡§Ç‡§ü ‡§µ‡§ø‡§∂‡§ø‡§∑‡•ç‡§ü ‡§ï‡§æ‡§∞‡•ç‡§Ø‡•ã‡§Ç ‡§ï‡•á ‡§≤‡§ø‡§è ‡§µ‡§ø‡§≠‡§ø‡§®‡•ç‡§® SLMs ‡§ï‡•ã ‡§°‡§æ‡§Ø‡§®‡§æ‡§Æ‡§ø‡§ï ‡§∞‡•Ç‡§™ ‡§∏‡•á ‡§≤‡•ã‡§° ‡§ï‡§∞ ‡§∏‡§ï‡§§‡•á ‡§π‡•à‡§Ç, ‡§ú‡§ø‡§∏‡§∏‡•á ‡§Æ‡§≤‡•ç‡§ü‡•Ä-‡§Æ‡•â‡§°‡§≤ ‡§è‡§ú‡•á‡§Ç‡§ü ‡§∏‡§ø‡§∏‡•ç‡§ü‡§Æ ‡§∏‡§ï‡•ç‡§∑‡§Æ ‡§π‡•ã‡§§‡§æ ‡§π‡•à, ‡§ú‡§π‡§æ‡§Ç ‡§µ‡§ø‡§≠‡§ø‡§®‡•ç‡§® ‡§Æ‡•â‡§°‡§≤ ‡§µ‡§ø‡§≠‡§ø‡§®‡•ç‡§® ‡§™‡•ç‡§∞‡§ï‡§æ‡§∞ ‡§ï‡•á ‡§Ö‡§®‡•Å‡§∞‡•ã‡§ß‡•ã‡§Ç ‡§ï‡•ã ‡§∏‡§Ç‡§≠‡§æ‡§≤‡§§‡•á ‡§π‡•à‡§Ç, ‡§î‡§∞ ‡§â‡§™‡§≤‡§¨‡•ç‡§ß‡§§‡§æ ‡§î‡§∞ ‡§™‡•ç‡§∞‡§¶‡§∞‡•ç‡§∂‡§® ‡§ï‡•á ‡§Ü‡§ß‡§æ‡§∞ ‡§™‡§∞ ‡§Æ‡•â‡§°‡§≤‡•ã‡§Ç ‡§ï‡•á ‡§¨‡•Ä‡§ö ‡§∏‡•ç‡§µ‡§ö‡§æ‡§≤‡§ø‡§§ ‡§´‡•á‡§≤‡§ì‡§µ‡§∞ ‡§π‡•ã‡§§‡§æ ‡§π‡•à‡•§

**‡§™‡•ç‡§∞‡§¶‡§∞‡•ç‡§∂‡§® ‡§ë‡§™‡•ç‡§ü‡§ø‡§Æ‡§æ‡§á‡§ú‡§º‡•á‡§∂‡§®**: ‡§è‡§ï‡•Ä‡§ï‡•É‡§§ ‡§ï‡•à‡§∂‡§ø‡§Ç‡§ó ‡§§‡§Ç‡§§‡•ç‡§∞ ‡§Æ‡•â‡§°‡§≤ ‡§≤‡•ã‡§°‡§ø‡§Ç‡§ó ‡§∏‡§Æ‡§Ø ‡§ï‡•ã ‡§ï‡§Æ ‡§ï‡§∞‡§§‡§æ ‡§π‡•à, ‡§ï‡§®‡•á‡§ï‡•ç‡§∂‡§® ‡§™‡•Ç‡§≤‡§ø‡§Ç‡§ó Foundry Local ‡§ï‡•á API ‡§ï‡•â‡§≤ ‡§ï‡•ã ‡§ë‡§™‡•ç‡§ü‡§ø‡§Æ‡§æ‡§á‡§ú‡§º ‡§ï‡§∞‡§§‡§æ ‡§π‡•à, ‡§î‡§∞ ‡§á‡§Ç‡§ü‡•á‡§≤‡§ø‡§ú‡•á‡§Ç‡§ü ‡§¨‡•à‡§ö‡§ø‡§Ç‡§ó ‡§ï‡§à ‡§è‡§ú‡•á‡§Ç‡§ü ‡§Ö‡§®‡•Å‡§∞‡•ã‡§ß‡•ã‡§Ç ‡§ï‡•á ‡§≤‡§ø‡§è ‡§•‡•ç‡§∞‡•Ç‡§™‡•Å‡§ü ‡§Æ‡•á‡§Ç ‡§∏‡•Å‡§ß‡§æ‡§∞ ‡§ï‡§∞‡§§‡§æ ‡§π‡•à‡•§

### Microsoft Agent Framework ‡§ï‡•á ‡§∏‡§æ‡§• ‡§è‡§ú‡•á‡§Ç‡§ü ‡§¨‡§®‡§æ‡§®‡§æ

#### ‡§è‡§ú‡•á‡§Ç‡§ü ‡§™‡§∞‡§ø‡§≠‡§æ‡§∑‡§æ ‡§î‡§∞ ‡§ï‡•â‡§®‡•ç‡§´‡§º‡§ø‡§ó‡§∞‡•á‡§∂‡§®

```python
from microsoft_agent_framework import Agent, Tool, Config
from foundry_local import FoundryLocalManager

# Configure agent with Foundry Local integration
config = Config(
    name="customer-service-agent",
    model_provider="foundry-local",
    model_alias="phi-4-mini",
    max_tokens=512,
    temperature=0.1,
    offline_mode=True
)

# Initialize Foundry Local connection
foundry = FoundryLocalManager("phi-4-mini")

# Create agent instance
agent = Agent(
    config=config,
    model_endpoint=foundry.endpoint,
    api_key=foundry.api_key
)
```
  
#### ‡§è‡§ú ‡§™‡§∞‡§ø‡§¶‡•É‡§∂‡•ç‡§Ø‡•ã‡§Ç ‡§ï‡•á ‡§≤‡§ø‡§è ‡§ü‡•Ç‡§≤ ‡§á‡§Ç‡§ü‡•Ä‡§ó‡•ç‡§∞‡•á‡§∂‡§®

```python
# Define tools for offline operation
@agent.tool
def lookup_customer_info(customer_id: str) -> dict:
    """Look up customer information from local database."""
    # Local database query - works offline
    return local_db.get_customer(customer_id)

@agent.tool
def create_support_ticket(issue: str, priority: str) -> str:
    """Create a support ticket in local system."""
    # Local ticket creation with sync when online
    ticket_id = local_system.create_ticket(issue, priority)
    return f"Ticket {ticket_id} created successfully"

@agent.tool
def schedule_callback(customer_id: str, preferred_time: str) -> str:
    """Schedule a callback for the customer."""
    # Local scheduling with calendar integration
    return local_calendar.schedule(customer_id, preferred_time)
```
  
#### ‡§Æ‡§≤‡•ç‡§ü‡•Ä-‡§è‡§ú‡•á‡§Ç‡§ü ‡§ë‡§∞‡•ç‡§ï‡•á‡§∏‡•ç‡§ü‡•ç‡§∞‡•á‡§∂‡§®

```python
from microsoft_agent_framework import AgentOrchestrator

# Create specialized agents for different domains
scheduling_agent = Agent(
    config=Config(
        name="scheduling-agent",
        model_alias="qwen2.5-0.5b",  # Lightweight for simple tasks
        specialized_for="scheduling"
    )
)

technical_support_agent = Agent(
    config=Config(
        name="technical-agent",
        model_alias="phi-4-mini",  # More capable for complex issues
        specialized_for="technical_support"
    )
)

# Orchestrate multiple agents
orchestrator = AgentOrchestrator([
    scheduling_agent,
    technical_support_agent
])

# Route requests based on intent
result = orchestrator.process_request(
    "I need to schedule a callback for a technical issue",
    routing_strategy="intent-based"
)
```
  

### ‡§â‡§®‡•ç‡§®‡§§ ‡§è‡§ú ‡§°‡§ø‡§™‡•ç‡§≤‡•â‡§Ø‡§Æ‡•á‡§Ç‡§ü ‡§™‡•à‡§ü‡§∞‡•ç‡§®

#### ‡§™‡§¶‡§æ‡§®‡•Å‡§ï‡•ç‡§∞‡§Æ‡§ø‡§§ ‡§è‡§ú‡•á‡§Ç‡§ü ‡§Ü‡§∞‡•ç‡§ï‡§ø‡§ü‡•á‡§ï‡•ç‡§ö‡§∞

**‡§∏‡•ç‡§•‡§æ‡§®‡•Ä‡§Ø ‡§è‡§ú‡•á‡§Ç‡§ü ‡§ï‡•ç‡§≤‡§∏‡•ç‡§ü‡§∞**: ‡§è‡§ú ‡§°‡§ø‡§µ‡§æ‡§á‡§∏ ‡§™‡§∞ ‡§ï‡§à ‡§µ‡§ø‡§∂‡•á‡§∑‡•Ä‡§ï‡•É‡§§ SLM ‡§è‡§ú‡•á‡§Ç‡§ü ‡§§‡•à‡§®‡§æ‡§§ ‡§ï‡§∞‡•á‡§Ç, ‡§™‡•ç‡§∞‡§§‡•ç‡§Ø‡•á‡§ï ‡§µ‡§ø‡§∂‡§ø‡§∑‡•ç‡§ü ‡§ï‡§æ‡§∞‡•ç‡§Ø‡•ã‡§Ç ‡§ï‡•á ‡§≤‡§ø‡§è ‡§Ö‡§®‡•Å‡§ï‡•Ç‡§≤‡§ø‡§§‡•§ ‡§∏‡§∞‡§≤ ‡§∞‡•Ç‡§ü‡§ø‡§Ç‡§ó ‡§î‡§∞ ‡§∂‡•á‡§°‡•ç‡§Ø‡•Ç‡§≤‡§ø‡§Ç‡§ó ‡§ï‡•á ‡§≤‡§ø‡§è Qwen2.5-0.5B ‡§ú‡•à‡§∏‡•á ‡§π‡§≤‡•ç‡§ï‡•á ‡§Æ‡•â‡§°‡§≤ ‡§ï‡§æ ‡§â‡§™‡§Ø‡•ã‡§ó ‡§ï‡§∞‡•á‡§Ç, ‡§ó‡•ç‡§∞‡§æ‡§π‡§ï ‡§∏‡•á‡§µ‡§æ ‡§î‡§∞ ‡§°‡•â‡§ï‡•ç‡§Ø‡•Ç‡§Æ‡•á‡§Ç‡§ü‡•á‡§∂‡§® ‡§ï‡•á ‡§≤‡§ø‡§è Phi-4-Mini ‡§ú‡•à‡§∏‡•á ‡§Æ‡§ß‡•ç‡§Ø‡§Æ ‡§Æ‡•â‡§°‡§≤, ‡§î‡§∞ ‡§ú‡§ü‡§ø‡§≤ ‡§§‡§∞‡•ç‡§ï ‡§ï‡•á ‡§≤‡§ø‡§è ‡§¨‡§°‡§º‡•á ‡§Æ‡•â‡§°‡§≤ ‡§ï‡§æ ‡§â‡§™‡§Ø‡•ã‡§ó ‡§ï‡§∞‡•á‡§Ç ‡§ú‡§¨ ‡§∏‡§Ç‡§∏‡§æ‡§ß‡§® ‡§Ö‡§®‡•Å‡§Æ‡§§‡§ø ‡§¶‡•á‡§Ç‡•§

**‡§è‡§ú-‡§ü‡•Ç-‡§ï‡•ç‡§≤‡§æ‡§â‡§° ‡§∏‡§Æ‡§®‡•ç‡§µ‡§Ø**: ‡§¨‡•Å‡§¶‡•ç‡§ß‡§ø‡§Æ‡§æ‡§® ‡§è‡§∏‡•ç‡§ï‡•á‡§≤‡•á‡§∂‡§® ‡§™‡•à‡§ü‡§∞‡•ç‡§® ‡§≤‡§æ‡§ó‡•Ç ‡§ï‡§∞‡•á‡§Ç ‡§ú‡§π‡§æ‡§Ç ‡§∏‡•ç‡§•‡§æ‡§®‡•Ä‡§Ø ‡§è‡§ú‡•á‡§Ç‡§ü ‡§®‡§ø‡§Ø‡§Æ‡§ø‡§§ ‡§ï‡§æ‡§∞‡•ç‡§Ø‡•ã‡§Ç ‡§ï‡•ã ‡§∏‡§Ç‡§≠‡§æ‡§≤‡§§‡•á ‡§π‡•à‡§Ç, ‡§ï‡•ç‡§≤‡§æ‡§â‡§° ‡§è‡§ú‡•á‡§Ç‡§ü ‡§ï‡§®‡•á‡§ï‡•ç‡§ü‡§ø‡§µ‡§ø‡§ü‡•Ä ‡§ï‡•Ä ‡§Ö‡§®‡•Å‡§Æ‡§§‡§ø ‡§Æ‡§ø‡§≤‡§®‡•á ‡§™‡§∞ ‡§ú‡§ü‡§ø‡§≤ ‡§§‡§∞‡•ç‡§ï ‡§™‡•ç‡§∞‡§¶‡§æ‡§® ‡§ï‡§∞‡§§‡•á ‡§π‡•à‡§Ç, ‡§î‡§∞ ‡§è‡§ú ‡§î‡§∞ ‡§ï‡•ç‡§≤‡§æ‡§â‡§° ‡§™‡•ç‡§∞‡•ã‡§∏‡•á‡§∏‡§ø‡§Ç‡§ó ‡§ï‡•á ‡§¨‡•Ä‡§ö ‡§∏‡§π‡§ú ‡§π‡•à‡§Ç‡§°‡§ë‡§´ ‡§®‡§ø‡§∞‡§Ç‡§§‡§∞‡§§‡§æ ‡§¨‡§®‡§æ‡§è ‡§∞‡§ñ‡§§‡§æ ‡§π‡•à‡•§

#### ‡§°‡§ø‡§™‡•ç‡§≤‡•â‡§Ø‡§Æ‡•á‡§Ç‡§ü ‡§ï‡•â‡§®‡•ç‡§´‡§º‡§ø‡§ó‡§∞‡•á‡§∂‡§®

**‡§∏‡§ø‡§Ç‡§ó‡§≤ ‡§°‡§ø‡§µ‡§æ‡§á‡§∏ ‡§°‡§ø‡§™‡•ç‡§≤‡•â‡§Ø‡§Æ‡•á‡§Ç‡§ü**:  
```yaml
deployment:
  type: single-device
  hardware: edge-device
  models:
    - alias: "phi-4-mini"
      primary: true
      tasks: ["conversation", "reasoning"]
    - alias: "qwen2.5-0.5b"
      secondary: true
      tasks: ["routing", "classification"]
  agents:
    - name: "primary-agent"
      model: "phi-4-mini"
      tools: ["database", "calendar", "email"]
```
  
**‡§µ‡§ø‡§§‡§∞‡§ø‡§§ ‡§è‡§ú ‡§°‡§ø‡§™‡•ç‡§≤‡•â‡§Ø‡§Æ‡•á‡§Ç‡§ü**:  
```yaml
deployment:
  type: distributed-edge
  nodes:
    - id: "edge-1"
      agents: ["customer-service", "scheduling"]
      models: ["phi-4-mini"]
    - id: "edge-2"
      agents: ["technical-support", "documentation"]
      models: ["qwen2.5-coder-0.5b"]
  coordination:
    load_balancing: true
    failover: automatic
```
  

### ‡§è‡§ú ‡§è‡§ú‡•á‡§Ç‡§ü‡•ã‡§Ç ‡§ï‡•á ‡§≤‡§ø‡§è ‡§™‡•ç‡§∞‡§¶‡§∞‡•ç‡§∂‡§® ‡§ë‡§™‡•ç‡§ü‡§ø‡§Æ‡§æ‡§á‡§ú‡§º‡•á‡§∂‡§®

#### ‡§Æ‡•â‡§°‡§≤ ‡§ö‡§Ø‡§® ‡§∞‡§£‡§®‡•Ä‡§§‡§ø‡§Ø‡§æ‡§Ç

**‡§ï‡§æ‡§∞‡•ç‡§Ø-‡§Ü‡§ß‡§æ‡§∞‡§ø‡§§ ‡§Æ‡•â‡§°‡§≤ ‡§Ö‡§∏‡§æ‡§á‡§®‡§Æ‡•á‡§Ç‡§ü**: Microsoft Agent Framework ‡§ï‡§æ‡§∞‡•ç‡§Ø ‡§ï‡•Ä ‡§ú‡§ü‡§ø‡§≤‡§§‡§æ ‡§î‡§∞ ‡§Ü‡§µ‡§∂‡•ç‡§Ø‡§ï‡§§‡§æ‡§ì‡§Ç ‡§ï‡•á ‡§Ü‡§ß‡§æ‡§∞ ‡§™‡§∞ ‡§¨‡•Å‡§¶‡•ç‡§ß‡§ø‡§Æ‡§æ‡§® ‡§Æ‡•â‡§°‡§≤ ‡§ö‡§Ø‡§® ‡§∏‡§ï‡•ç‡§∑‡§Æ ‡§ï‡§∞‡§§‡§æ ‡§π‡•à:

- **‡§∏‡§∞‡§≤ ‡§ï‡§æ‡§∞‡•ç‡§Ø** (Q&A, ‡§∞‡•Ç‡§ü‡§ø‡§Ç‡§ó): Qwen2.5-0.5B (500MB, <100ms ‡§™‡•ç‡§∞‡§§‡§ø‡§ï‡•ç‡§∞‡§ø‡§Ø‡§æ)  
- **‡§Æ‡§ß‡•ç‡§Ø‡§Æ ‡§ï‡§æ‡§∞‡•ç‡§Ø** (‡§ó‡•ç‡§∞‡§æ‡§π‡§ï ‡§∏‡•á‡§µ‡§æ, ‡§∂‡•á‡§°‡•ç‡§Ø‡•Ç‡§≤‡§ø‡§Ç‡§ó): Phi-4-Mini (2.4GB, 200-500ms ‡§™‡•ç‡§∞‡§§‡§ø‡§ï‡•ç‡§∞‡§ø‡§Ø‡§æ)  
- **‡§ú‡§ü‡§ø‡§≤ ‡§ï‡§æ‡§∞‡•ç‡§Ø** (‡§§‡§ï‡§®‡•Ä‡§ï‡•Ä ‡§µ‡§ø‡§∂‡•ç‡§≤‡•á‡§∑‡§£, ‡§Ø‡•ã‡§ú‡§®‡§æ): Phi-4 (7GB, 1-3s ‡§™‡•ç‡§∞‡§§‡§ø‡§ï‡•ç‡§∞‡§ø‡§Ø‡§æ ‡§ú‡§¨ ‡§∏‡§Ç‡§∏‡§æ‡§ß‡§® ‡§Ö‡§®‡•Å‡§Æ‡§§‡§ø ‡§¶‡•á‡§Ç)  

**‡§°‡§æ‡§Ø‡§®‡§æ‡§Æ‡§ø‡§ï ‡§Æ‡•â‡§°‡§≤ ‡§∏‡•ç‡§µ‡§ø‡§ö‡§ø‡§Ç‡§ó**: ‡§è‡§ú‡•á‡§Ç‡§ü ‡§µ‡§∞‡•ç‡§§‡§Æ‡§æ‡§® ‡§∏‡§ø‡§∏‡•ç‡§ü‡§Æ ‡§≤‡•ã‡§°, ‡§ï‡§æ‡§∞‡•ç‡§Ø ‡§ï‡•Ä ‡§ú‡§ü‡§ø‡§≤‡§§‡§æ ‡§Æ‡•Ç‡§≤‡•ç‡§Ø‡§æ‡§Ç‡§ï‡§®, ‡§â‡§™‡§Ø‡•ã‡§ó‡§ï‡§∞‡•ç‡§§‡§æ ‡§™‡•ç‡§∞‡§æ‡§•‡§Æ‡§ø‡§ï‡§§‡§æ ‡§∏‡•ç‡§§‡§∞, ‡§î‡§∞ ‡§â‡§™‡§≤‡§¨‡•ç‡§ß ‡§π‡§æ‡§∞‡•ç‡§°‡§µ‡•á‡§Ø‡§∞ ‡§∏‡§Ç‡§∏‡§æ‡§ß‡§®‡•ã‡§Ç ‡§ï‡•á ‡§Ü‡§ß‡§æ‡§∞ ‡§™‡§∞ ‡§Æ‡•â‡§°‡§≤‡•ã‡§Ç ‡§ï‡•á ‡§¨‡•Ä‡§ö ‡§∏‡•ç‡§µ‡§ø‡§ö ‡§ï‡§∞ ‡§∏‡§ï‡§§‡•á ‡§π‡•à‡§Ç‡•§

#### ‡§Æ‡•á‡§Æ‡•ã‡§∞‡•Ä ‡§î‡§∞ ‡§∏‡§Ç‡§∏‡§æ‡§ß‡§® ‡§™‡•ç‡§∞‡§¨‡§Ç‡§ß‡§®

```python
# Configure resource constraints for edge deployment
resource_config = ResourceConfig(
    max_memory_usage="4GB",
    max_concurrent_agents=3,
    model_cache_size="2GB",
    auto_unload_idle_models=True,
    power_management=True
)

agent = Agent(
    config=config,
    resource_limits=resource_config
)
```
  

### ‡§è‡§Ç‡§ü‡§∞‡§™‡•ç‡§∞‡§æ‡§á‡§ú‡§º ‡§á‡§Ç‡§ü‡•Ä‡§ó‡•ç‡§∞‡•á‡§∂‡§® ‡§™‡•à‡§ü‡§∞‡•ç‡§®

#### ‡§∏‡•Å‡§∞‡§ï‡•ç‡§∑‡§æ ‡§î‡§∞ ‡§Ö‡§®‡•Å‡§™‡§æ‡§≤‡§®

**‡§∏‡•ç‡§•‡§æ‡§®‡•Ä‡§Ø ‡§°‡•á‡§ü‡§æ ‡§™‡•ç‡§∞‡•ã‡§∏‡•á‡§∏‡§ø‡§Ç‡§ó**: ‡§∏‡§≠‡•Ä ‡§è‡§ú‡•á‡§Ç‡§ü ‡§™‡•ç‡§∞‡•ã‡§∏‡•á‡§∏‡§ø‡§Ç‡§ó ‡§∏‡•ç‡§•‡§æ‡§®‡•Ä‡§Ø ‡§∞‡•Ç‡§™ ‡§∏‡•á ‡§π‡•ã‡§§‡•Ä ‡§π‡•à, ‡§ú‡§ø‡§∏‡§∏‡•á ‡§∏‡§Ç‡§µ‡•á‡§¶‡§®‡§∂‡•Ä‡§≤ ‡§°‡•á‡§ü‡§æ ‡§ï‡§≠‡•Ä ‡§≠‡•Ä ‡§è‡§ú ‡§°‡§ø‡§µ‡§æ‡§á‡§∏ ‡§∏‡•á ‡§¨‡§æ‡§π‡§∞ ‡§®‡§π‡•Ä‡§Ç ‡§ú‡§æ‡§§‡§æ‡•§ ‡§á‡§∏‡§Æ‡•á‡§Ç ‡§ó‡•ç‡§∞‡§æ‡§π‡§ï ‡§ú‡§æ‡§®‡§ï‡§æ‡§∞‡•Ä ‡§ï‡•Ä ‡§∏‡•Å‡§∞‡§ï‡•ç‡§∑‡§æ, ‡§∏‡•ç‡§µ‡§æ‡§∏‡•ç‡§•‡•ç‡§Ø ‡§∏‡•á‡§µ‡§æ ‡§è‡§ú‡•á‡§Ç‡§ü‡•ã‡§Ç ‡§ï‡•á ‡§≤‡§ø‡§è HIPAA ‡§Ö‡§®‡•Å‡§™‡§æ‡§≤‡§®, ‡§¨‡•à‡§Ç‡§ï‡§ø‡§Ç‡§ó ‡§è‡§ú‡•á‡§Ç‡§ü‡•ã‡§Ç ‡§ï‡•á ‡§≤‡§ø‡§è ‡§µ‡§ø‡§§‡•ç‡§§‡•Ä‡§Ø ‡§°‡•á‡§ü‡§æ ‡§∏‡•Å‡§∞‡§ï‡•ç‡§∑‡§æ, ‡§î‡§∞ ‡§Ø‡•Ç‡§∞‡•ã‡§™‡•Ä‡§Ø ‡§°‡§ø‡§™‡•ç‡§≤‡•â‡§Ø‡§Æ‡•á‡§Ç‡§ü ‡§ï‡•á ‡§≤‡§ø‡§è GDPR ‡§Ö‡§®‡•Å‡§™‡§æ‡§≤‡§® ‡§∂‡§æ‡§Æ‡§ø‡§≤ ‡§π‡•à‡•§

**‡§è‡§ï‡•ç‡§∏‡•á‡§∏ ‡§ï‡§Ç‡§ü‡•ç‡§∞‡•ã‡§≤**: ‡§≠‡•Ç‡§Æ‡§ø‡§ï‡§æ-‡§Ü‡§ß‡§æ‡§∞‡§ø‡§§ ‡§Ö‡§®‡•Å‡§Æ‡§§‡§ø‡§Ø‡§æ‡§Ç ‡§®‡§ø‡§Ø‡§Ç‡§§‡•ç‡§∞‡§ø‡§§ ‡§ï‡§∞‡§§‡•Ä ‡§π‡•à‡§Ç ‡§ï‡§ø ‡§è‡§ú‡•á‡§Ç‡§ü ‡§ï‡•å‡§® ‡§∏‡•á ‡§â‡§™‡§ï‡§∞‡§£ ‡§è‡§ï‡•ç‡§∏‡•á‡§∏ ‡§ï‡§∞ ‡§∏‡§ï‡§§‡•á ‡§π‡•à‡§Ç, ‡§è‡§ú‡•á‡§Ç‡§ü ‡§á‡§Ç‡§ü‡§∞‡•à‡§ï‡•ç‡§∂‡§® ‡§ï‡•á ‡§≤‡§ø‡§è ‡§â‡§™‡§Ø‡•ã‡§ó‡§ï‡§∞‡•ç‡§§‡§æ ‡§™‡•ç‡§∞‡§Æ‡§æ‡§£‡•Ä‡§ï‡§∞‡§£, ‡§î‡§∞ ‡§∏‡§≠‡•Ä ‡§è‡§ú‡•á‡§Ç‡§ü ‡§ï‡•ç‡§∞‡§ø‡§Ø‡§æ‡§ì‡§Ç ‡§î‡§∞ ‡§®‡§ø‡§∞‡•ç‡§£‡§Ø‡•ã‡§Ç ‡§ï‡•á ‡§≤‡§ø‡§è ‡§ë‡§°‡§ø‡§ü ‡§ü‡•ç‡§∞‡•á‡§≤‡•ç‡§∏‡•§

#### ‡§Æ‡•â‡§®‡§ø‡§ü‡§∞‡§ø‡§Ç‡§ó ‡§î‡§∞ ‡§ë‡§¨‡•ç‡§ú‡§º‡§∞‡•ç‡§µ‡•á‡§¨‡§ø‡§≤‡§ø‡§ü‡•Ä

```python
from microsoft_agent_framework import AgentMonitor

# Set up monitoring for edge agents
monitor = AgentMonitor(
    metrics=["response_time", "success_rate", "resource_usage"],
    alerts=[
        {"metric": "response_time", "threshold": "2s", "action": "scale_down_model"},
        {"metric": "memory_usage", "threshold": "80%", "action": "unload_idle_agents"}
    ],
    local_storage=True  # Store metrics locally for offline operation
)

agent.add_monitor(monitor)
```
  

### ‡§µ‡§æ‡§∏‡•ç‡§§‡§µ‡§ø‡§ï ‡§¶‡•Å‡§®‡§ø‡§Ø‡§æ ‡§ï‡•á ‡§ï‡§æ‡§∞‡•ç‡§Ø‡§æ‡§®‡•ç‡§µ‡§Ø‡§® ‡§â‡§¶‡§æ‡§π‡§∞‡§£

#### ‡§∞‡§ø‡§ü‡•á‡§≤ ‡§è‡§ú ‡§è‡§ú‡•á‡§Ç‡§ü ‡§∏‡§ø‡§∏‡•ç‡§ü‡§Æ

```python
# Retail kiosk agent for in-store customer assistance
retail_agent = Agent(
    config=Config(
        name="retail-assistant",
        model_alias="phi-4-mini",
        context="You are a helpful retail assistant in an electronics store."
    )
)

@retail_agent.tool
def check_inventory(product_sku: str) -> dict:
    """Check local inventory for a product."""
    return local_inventory.lookup(product_sku)

@retail_agent.tool
def find_alternatives(product_category: str) -> list:
    """Find alternative products in the same category."""
    return local_catalog.find_similar(product_category)

@retail_agent.tool
def create_price_quote(items: list) -> dict:
    """Generate a price quote for multiple items."""
    return pricing_engine.calculate_quote(items)
```
  
#### ‡§∏‡•ç‡§µ‡§æ‡§∏‡•ç‡§•‡•ç‡§Ø ‡§∏‡•á‡§µ‡§æ ‡§∏‡§Æ‡§∞‡•ç‡§•‡§® ‡§è‡§ú‡•á‡§Ç‡§ü

```python
# HIPAA-compliant patient support agent
healthcare_agent = Agent(
    config=Config(
        name="patient-support",
        model_alias="phi-4-mini",
        privacy_mode=True,  # Enhanced privacy for healthcare
        compliance=["HIPAA"]
    )
)

@healthcare_agent.tool
def check_appointment_availability(provider_id: str, date_range: str) -> list:
    """Check appointment slots with healthcare provider."""
    return local_scheduling.get_availability(provider_id, date_range)

@healthcare_agent.tool
def access_patient_portal(patient_id: str, auth_token: str) -> dict:
    """Secure access to patient information."""
    if security.validate_token(auth_token):
        return patient_portal.get_summary(patient_id)
    return {"error": "Authentication failed"}
```
  

### Microsoft Agent Framework ‡§ï‡•á ‡§≤‡§ø‡§è ‡§∏‡§∞‡•ç‡§µ‡•ã‡§§‡•ç‡§§‡§Æ ‡§™‡•ç‡§∞‡§•‡§æ‡§è‡§Ç

#### ‡§µ‡§ø‡§ï‡§æ‡§∏ ‡§¶‡§ø‡§∂‡§æ‡§®‡§ø‡§∞‡•ç‡§¶‡•á‡§∂

1. **‡§∏‡§∞‡§≤ ‡§∂‡•Å‡§∞‡•Å‡§Ü‡§§ ‡§ï‡§∞‡•á‡§Ç**: ‡§ú‡§ü‡§ø‡§≤ ‡§Æ‡§≤‡•ç‡§ü‡•Ä-‡§è‡§ú‡•á‡§Ç‡§ü ‡§∏‡§ø‡§∏‡•ç‡§ü‡§Æ ‡§¨‡§®‡§æ‡§®‡•á ‡§∏‡•á ‡§™‡§π‡§≤‡•á ‡§∏‡§ø‡§Ç‡§ó‡§≤-‡§è‡§ú‡•á‡§Ç‡§ü ‡§™‡§∞‡§ø‡§¶‡•É‡§∂‡•ç‡§Ø‡•ã‡§Ç ‡§∏‡•á ‡§∂‡•Å‡§∞‡•Ç ‡§ï‡§∞‡•á‡§Ç  
2. **‡§Æ‡•â‡§°‡§≤ ‡§∞‡§æ‡§á‡§ü-‡§∏‡§æ‡§á
**‡§è‡§ú‡•á‡§Ç‡§ü ‡§§‡•à‡§®‡§æ‡§§‡•Ä ‡§ï‡•á ‡§≤‡§ø‡§è ‡§´‡•ç‡§∞‡•á‡§Æ‡§µ‡§∞‡•ç‡§ï ‡§ö‡§Ø‡§®**: ‡§≤‡§ï‡•ç‡§∑‡•ç‡§Ø ‡§π‡§æ‡§∞‡•ç‡§°‡§µ‡•á‡§Ø‡§∞ ‡§î‡§∞ ‡§è‡§ú‡•á‡§Ç‡§ü ‡§Ü‡§µ‡§∂‡•ç‡§Ø‡§ï‡§§‡§æ‡§ì‡§Ç ‡§ï‡•á ‡§Ü‡§ß‡§æ‡§∞ ‡§™‡§∞ ‡§Ö‡§®‡•Å‡§ï‡•Ç‡§≤‡§® ‡§´‡•ç‡§∞‡•á‡§Æ‡§µ‡§∞‡•ç‡§ï ‡§ö‡•Å‡§®‡•á‡§Ç‡•§ CPU-‡§Ö‡§®‡•Å‡§ï‡•Ç‡§≤‡§ø‡§§ ‡§è‡§ú‡•á‡§Ç‡§ü ‡§§‡•à‡§®‡§æ‡§§‡•Ä ‡§ï‡•á ‡§≤‡§ø‡§è Llama.cpp ‡§ï‡§æ ‡§â‡§™‡§Ø‡•ã‡§ó ‡§ï‡§∞‡•á‡§Ç, Apple Silicon ‡§è‡§ú‡•á‡§Ç‡§ü ‡§Ö‡§®‡•Å‡§™‡•ç‡§∞‡§Ø‡•ã‡§ó‡•ã‡§Ç ‡§ï‡•á ‡§≤‡§ø‡§è Apple MLX ‡§î‡§∞ ‡§ï‡•ç‡§∞‡•â‡§∏-‡§™‡•ç‡§≤‡•á‡§ü‡§´‡§º‡•â‡§∞‡•ç‡§Æ ‡§è‡§ú‡•á‡§Ç‡§ü ‡§∏‡§Ç‡§ó‡§§‡§§‡§æ ‡§ï‡•á ‡§≤‡§ø‡§è ONNX ‡§ï‡§æ ‡§â‡§™‡§Ø‡•ã‡§ó ‡§ï‡§∞‡•á‡§Ç‡•§

## ‡§µ‡•ç‡§Ø‡§æ‡§µ‡§π‡§æ‡§∞‡§ø‡§ï SLM ‡§è‡§ú‡•á‡§Ç‡§ü ‡§∞‡•Ç‡§™‡§æ‡§Ç‡§§‡§∞‡§£ ‡§î‡§∞ ‡§â‡§™‡§Ø‡•ã‡§ó ‡§ï‡•á ‡§Æ‡§æ‡§Æ‡§≤‡•á

### ‡§µ‡§æ‡§∏‡•ç‡§§‡§µ‡§ø‡§ï ‡§¶‡•Å‡§®‡§ø‡§Ø‡§æ ‡§ï‡•á ‡§è‡§ú‡•á‡§Ç‡§ü ‡§§‡•à‡§®‡§æ‡§§‡•Ä ‡§™‡§∞‡§ø‡§¶‡•É‡§∂‡•ç‡§Ø

**‡§Æ‡•ã‡§¨‡§æ‡§á‡§≤ ‡§è‡§ú‡•á‡§Ç‡§ü ‡§Ö‡§®‡•Å‡§™‡•ç‡§∞‡§Ø‡•ã‡§ó**: ‡§∏‡•ç‡§Æ‡§æ‡§∞‡•ç‡§ü‡§´‡•ã‡§® ‡§è‡§ú‡•á‡§Ç‡§ü ‡§Ö‡§®‡•Å‡§™‡•ç‡§∞‡§Ø‡•ã‡§ó‡•ã‡§Ç ‡§ï‡•á ‡§≤‡§ø‡§è Q4_K ‡§™‡•ç‡§∞‡§æ‡§∞‡•Ç‡§™ ‡§®‡•ç‡§Ø‡•Ç‡§®‡§§‡§Æ ‡§Æ‡•á‡§Æ‡•ã‡§∞‡•Ä ‡§â‡§™‡§Ø‡•ã‡§ó ‡§ï‡•á ‡§∏‡§æ‡§• ‡§â‡§§‡•ç‡§ï‡•É‡§∑‡•ç‡§ü ‡§π‡•à, ‡§ú‡§¨‡§ï‡§ø Q8_0 ‡§ü‡•à‡§¨‡§≤‡•á‡§ü-‡§Ü‡§ß‡§æ‡§∞‡§ø‡§§ ‡§è‡§ú‡•á‡§Ç‡§ü ‡§∏‡§ø‡§∏‡•ç‡§ü‡§Æ ‡§ï‡•á ‡§≤‡§ø‡§è ‡§∏‡§Ç‡§§‡•Å‡§≤‡§ø‡§§ ‡§™‡•ç‡§∞‡§¶‡§∞‡•ç‡§∂‡§® ‡§™‡•ç‡§∞‡§¶‡§æ‡§® ‡§ï‡§∞‡§§‡§æ ‡§π‡•à‡•§ Q5_K ‡§™‡•ç‡§∞‡§æ‡§∞‡•Ç‡§™ ‡§Æ‡•ã‡§¨‡§æ‡§á‡§≤ ‡§â‡§§‡•ç‡§™‡§æ‡§¶‡§ï‡§§‡§æ ‡§è‡§ú‡•á‡§Ç‡§ü‡•ã‡§Ç ‡§ï‡•á ‡§≤‡§ø‡§è ‡§â‡§ö‡•ç‡§ö ‡§ó‡•Å‡§£‡§µ‡§§‡•ç‡§§‡§æ ‡§™‡•ç‡§∞‡§¶‡§æ‡§® ‡§ï‡§∞‡§§‡§æ ‡§π‡•à‡•§

**‡§°‡•á‡§∏‡•ç‡§ï‡§ü‡•â‡§™ ‡§î‡§∞ ‡§è‡§ú ‡§è‡§ú‡•á‡§Ç‡§ü ‡§ï‡§Ç‡§™‡•ç‡§Ø‡•Ç‡§ü‡§ø‡§Ç‡§ó**: Q5_K ‡§°‡•á‡§∏‡•ç‡§ï‡§ü‡•â‡§™ ‡§è‡§ú‡•á‡§Ç‡§ü ‡§Ö‡§®‡•Å‡§™‡•ç‡§∞‡§Ø‡•ã‡§ó‡•ã‡§Ç ‡§ï‡•á ‡§≤‡§ø‡§è ‡§á‡§∑‡•ç‡§ü‡§§‡§Æ ‡§™‡•ç‡§∞‡§¶‡§∞‡•ç‡§∂‡§® ‡§™‡•ç‡§∞‡§¶‡§æ‡§® ‡§ï‡§∞‡§§‡§æ ‡§π‡•à, Q8_0 ‡§µ‡§∞‡•ç‡§ï‡§∏‡•ç‡§ü‡•á‡§∂‡§® ‡§è‡§ú‡•á‡§Ç‡§ü ‡§µ‡§æ‡§§‡§æ‡§µ‡§∞‡§£ ‡§ï‡•á ‡§≤‡§ø‡§è ‡§â‡§ö‡•ç‡§ö ‡§ó‡•Å‡§£‡§µ‡§§‡•ç‡§§‡§æ ‡§µ‡§æ‡§≤‡•Ä ‡§á‡§®‡§´‡•á‡§∞‡•á‡§Ç‡§∏ ‡§™‡•ç‡§∞‡§¶‡§æ‡§® ‡§ï‡§∞‡§§‡§æ ‡§π‡•à, ‡§î‡§∞ Q4_K ‡§è‡§ú ‡§è‡§ú‡•á‡§Ç‡§ü ‡§â‡§™‡§ï‡§∞‡§£‡•ã‡§Ç ‡§™‡§∞ ‡§ï‡•Å‡§∂‡§≤ ‡§™‡•ç‡§∞‡§∏‡§Ç‡§∏‡•ç‡§ï‡§∞‡§£ ‡§∏‡§ï‡•ç‡§∑‡§Æ ‡§ï‡§∞‡§§‡§æ ‡§π‡•à‡•§

**‡§Ö‡§®‡•Å‡§∏‡§Ç‡§ß‡§æ‡§® ‡§î‡§∞ ‡§™‡•ç‡§∞‡§Ø‡•ã‡§ó‡§æ‡§§‡•ç‡§Æ‡§ï ‡§è‡§ú‡•á‡§Ç‡§ü**: ‡§â‡§®‡•ç‡§®‡§§ ‡§ï‡•ç‡§µ‡§æ‡§Ç‡§ü‡§æ‡§á‡§ú‡•á‡§∂‡§® ‡§™‡•ç‡§∞‡§æ‡§∞‡•Ç‡§™ ‡§Ö‡§§‡•ç‡§Ø‡§ß‡§ø‡§ï ‡§∏‡§Ç‡§∏‡§æ‡§ß‡§® ‡§∏‡•Ä‡§Æ‡§æ‡§ì‡§Ç ‡§ï‡•Ä ‡§Ü‡§µ‡§∂‡•ç‡§Ø‡§ï‡§§‡§æ ‡§µ‡§æ‡§≤‡•á ‡§∂‡•à‡§ï‡•ç‡§∑‡§£‡§ø‡§ï ‡§Ö‡§®‡•Å‡§∏‡§Ç‡§ß‡§æ‡§® ‡§î‡§∞ ‡§™‡•ç‡§∞‡•Ç‡§´-‡§ë‡§´-‡§ï‡•â‡§®‡•ç‡§∏‡•á‡§™‡•ç‡§ü ‡§è‡§ú‡•á‡§Ç‡§ü ‡§Ö‡§®‡•Å‡§™‡•ç‡§∞‡§Ø‡•ã‡§ó‡•ã‡§Ç ‡§ï‡•á ‡§≤‡§ø‡§è ‡§Ö‡§≤‡•ç‡§ü‡•ç‡§∞‡§æ-‡§≤‡•ã ‡§™‡•ç‡§∞‡§ø‡§∏‡§ø‡§ú‡§® ‡§è‡§ú‡•á‡§Ç‡§ü ‡§á‡§®‡§´‡•á‡§∞‡•á‡§Ç‡§∏ ‡§ï‡§æ ‡§Ö‡§®‡•ç‡§µ‡•á‡§∑‡§£ ‡§ï‡§∞‡§®‡•á ‡§Æ‡•á‡§Ç ‡§∏‡§ï‡•ç‡§∑‡§Æ ‡§¨‡§®‡§æ‡§§‡•á ‡§π‡•à‡§Ç‡•§

### SLM ‡§è‡§ú‡•á‡§Ç‡§ü ‡§™‡•ç‡§∞‡§¶‡§∞‡•ç‡§∂‡§® ‡§¨‡•á‡§Ç‡§ö‡§Æ‡§æ‡§∞‡•ç‡§ï

**‡§è‡§ú‡•á‡§Ç‡§ü ‡§á‡§®‡§´‡•á‡§∞‡•á‡§Ç‡§∏ ‡§ó‡§§‡§ø**: Q4_K ‡§Æ‡•ã‡§¨‡§æ‡§á‡§≤ CPUs ‡§™‡§∞ ‡§∏‡§¨‡§∏‡•á ‡§§‡•á‡§ú‡§º ‡§è‡§ú‡•á‡§Ç‡§ü ‡§™‡•ç‡§∞‡§§‡§ø‡§ï‡•ç‡§∞‡§ø‡§Ø‡§æ ‡§∏‡§Æ‡§Ø ‡§™‡•ç‡§∞‡§æ‡§™‡•ç‡§§ ‡§ï‡§∞‡§§‡§æ ‡§π‡•à, Q5_K ‡§∏‡§æ‡§Æ‡§æ‡§®‡•ç‡§Ø ‡§è‡§ú‡•á‡§Ç‡§ü ‡§Ö‡§®‡•Å‡§™‡•ç‡§∞‡§Ø‡•ã‡§ó‡•ã‡§Ç ‡§ï‡•á ‡§≤‡§ø‡§è ‡§∏‡§Ç‡§§‡•Å‡§≤‡§ø‡§§ ‡§ó‡§§‡§ø-‡§ó‡•Å‡§£‡§µ‡§§‡•ç‡§§‡§æ ‡§Ö‡§®‡•Å‡§™‡§æ‡§§ ‡§™‡•ç‡§∞‡§¶‡§æ‡§® ‡§ï‡§∞‡§§‡§æ ‡§π‡•à, Q8_0 ‡§ú‡§ü‡§ø‡§≤ ‡§è‡§ú‡•á‡§Ç‡§ü ‡§ï‡§æ‡§∞‡•ç‡§Ø‡•ã‡§Ç ‡§ï‡•á ‡§≤‡§ø‡§è ‡§â‡§ö‡•ç‡§ö ‡§ó‡•Å‡§£‡§µ‡§§‡•ç‡§§‡§æ ‡§™‡•ç‡§∞‡§¶‡§æ‡§® ‡§ï‡§∞‡§§‡§æ ‡§π‡•à, ‡§î‡§∞ ‡§™‡•ç‡§∞‡§Ø‡•ã‡§ó‡§æ‡§§‡•ç‡§Æ‡§ï ‡§™‡•ç‡§∞‡§æ‡§∞‡•Ç‡§™ ‡§µ‡§ø‡§∂‡•á‡§∑ ‡§è‡§ú‡•á‡§Ç‡§ü ‡§π‡§æ‡§∞‡•ç‡§°‡§µ‡•á‡§Ø‡§∞ ‡§ï‡•á ‡§≤‡§ø‡§è ‡§Ö‡§ß‡§ø‡§ï‡§§‡§Æ ‡§•‡•ç‡§∞‡•Ç‡§™‡•Å‡§ü ‡§™‡•ç‡§∞‡§¶‡§æ‡§® ‡§ï‡§∞‡§§‡•á ‡§π‡•à‡§Ç‡•§

**‡§è‡§ú‡•á‡§Ç‡§ü ‡§Æ‡•á‡§Æ‡•ã‡§∞‡•Ä ‡§Ü‡§µ‡§∂‡•ç‡§Ø‡§ï‡§§‡§æ‡§è‡§Å**: ‡§è‡§ú‡•á‡§Ç‡§ü‡•ã‡§Ç ‡§ï‡•á ‡§≤‡§ø‡§è ‡§ï‡•ç‡§µ‡§æ‡§Ç‡§ü‡§æ‡§á‡§ú‡•á‡§∂‡§® ‡§∏‡•ç‡§§‡§∞ Q2_K (‡§õ‡•ã‡§ü‡•á ‡§è‡§ú‡•á‡§Ç‡§ü ‡§Æ‡•â‡§°‡§≤ ‡§ï‡•á ‡§≤‡§ø‡§è 500MB ‡§∏‡•á ‡§ï‡§Æ) ‡§∏‡•á Q8_0 (‡§Æ‡•Ç‡§≤ ‡§Ü‡§ï‡§æ‡§∞ ‡§ï‡§æ ‡§≤‡§ó‡§≠‡§ó 50%) ‡§§‡§ï ‡§π‡•ã‡§§‡•á ‡§π‡•à‡§Ç, ‡§î‡§∞ ‡§∏‡§Ç‡§∏‡§æ‡§ß‡§®-‡§∏‡•Ä‡§Æ‡§ø‡§§ ‡§è‡§ú‡•á‡§Ç‡§ü ‡§µ‡§æ‡§§‡§æ‡§µ‡§∞‡§£ ‡§ï‡•á ‡§≤‡§ø‡§è ‡§Ö‡§ß‡§ø‡§ï‡§§‡§Æ ‡§∏‡§Ç‡§™‡•Ä‡§°‡§º‡§® ‡§™‡•ç‡§∞‡§æ‡§™‡•ç‡§§ ‡§ï‡§∞‡§®‡•á ‡§µ‡§æ‡§≤‡•á ‡§™‡•ç‡§∞‡§Ø‡•ã‡§ó‡§æ‡§§‡•ç‡§Æ‡§ï ‡§ï‡•â‡§®‡•ç‡§´‡§º‡§ø‡§ó‡§∞‡•á‡§∂‡§®‡•§

## SLM ‡§è‡§ú‡•á‡§Ç‡§ü‡•ã‡§Ç ‡§ï‡•á ‡§≤‡§ø‡§è ‡§ö‡•Å‡§®‡•å‡§§‡§ø‡§Ø‡§æ‡§Å ‡§î‡§∞ ‡§µ‡§ø‡§ö‡§æ‡§∞

### ‡§è‡§ú‡•á‡§Ç‡§ü ‡§∏‡§ø‡§∏‡•ç‡§ü‡§Æ ‡§Æ‡•á‡§Ç ‡§™‡•ç‡§∞‡§¶‡§∞‡•ç‡§∂‡§® ‡§∏‡§Æ‡§ù‡•å‡§§‡•á

SLM ‡§è‡§ú‡•á‡§Ç‡§ü ‡§§‡•à‡§®‡§æ‡§§‡•Ä ‡§Æ‡•á‡§Ç ‡§Æ‡•â‡§°‡§≤ ‡§Ü‡§ï‡§æ‡§∞, ‡§è‡§ú‡•á‡§Ç‡§ü ‡§™‡•ç‡§∞‡§§‡§ø‡§ï‡•ç‡§∞‡§ø‡§Ø‡§æ ‡§ó‡§§‡§ø, ‡§î‡§∞ ‡§Ü‡§â‡§ü‡§™‡•Å‡§ü ‡§ó‡•Å‡§£‡§µ‡§§‡•ç‡§§‡§æ ‡§ï‡•á ‡§¨‡•Ä‡§ö ‡§∏‡§Æ‡§ù‡•å‡§§‡•á ‡§ï‡§æ ‡§∏‡§æ‡§µ‡§ß‡§æ‡§®‡•Ä‡§™‡•Ç‡§∞‡•ç‡§µ‡§ï ‡§µ‡§ø‡§ö‡§æ‡§∞ ‡§ï‡§∞‡§®‡§æ ‡§∂‡§æ‡§Æ‡§ø‡§≤ ‡§π‡•à‡•§ ‡§ú‡§¨‡§ï‡§ø Q4_K ‡§Æ‡•ã‡§¨‡§æ‡§á‡§≤ ‡§è‡§ú‡•á‡§Ç‡§ü‡•ã‡§Ç ‡§ï‡•á ‡§≤‡§ø‡§è ‡§Ö‡§∏‡§æ‡§ß‡§æ‡§∞‡§£ ‡§ó‡§§‡§ø ‡§î‡§∞ ‡§¶‡§ï‡•ç‡§∑‡§§‡§æ ‡§™‡•ç‡§∞‡§¶‡§æ‡§® ‡§ï‡§∞‡§§‡§æ ‡§π‡•à, Q8_0 ‡§ú‡§ü‡§ø‡§≤ ‡§è‡§ú‡•á‡§Ç‡§ü ‡§ï‡§æ‡§∞‡•ç‡§Ø‡•ã‡§Ç ‡§ï‡•á ‡§≤‡§ø‡§è ‡§â‡§ö‡•ç‡§ö ‡§ó‡•Å‡§£‡§µ‡§§‡•ç‡§§‡§æ ‡§™‡•ç‡§∞‡§¶‡§æ‡§® ‡§ï‡§∞‡§§‡§æ ‡§π‡•à‡•§ Q5_K ‡§Ö‡§ß‡§ø‡§ï‡§æ‡§Ç‡§∂ ‡§∏‡§æ‡§Æ‡§æ‡§®‡•ç‡§Ø ‡§è‡§ú‡•á‡§Ç‡§ü ‡§Ö‡§®‡•Å‡§™‡•ç‡§∞‡§Ø‡•ã‡§ó‡•ã‡§Ç ‡§ï‡•á ‡§≤‡§ø‡§è ‡§è‡§ï ‡§Æ‡§ß‡•ç‡§Ø ‡§Æ‡§æ‡§∞‡•ç‡§ó ‡§™‡•ç‡§∞‡§¶‡§æ‡§® ‡§ï‡§∞‡§§‡§æ ‡§π‡•à‡•§

### SLM ‡§è‡§ú‡•á‡§Ç‡§ü‡•ã‡§Ç ‡§ï‡•á ‡§≤‡§ø‡§è ‡§π‡§æ‡§∞‡•ç‡§°‡§µ‡•á‡§Ø‡§∞ ‡§∏‡§Ç‡§ó‡§§‡§§‡§æ

‡§µ‡§ø‡§≠‡§ø‡§®‡•ç‡§® ‡§è‡§ú ‡§â‡§™‡§ï‡§∞‡§£‡•ã‡§Ç ‡§Æ‡•á‡§Ç SLM ‡§è‡§ú‡•á‡§Ç‡§ü ‡§§‡•à‡§®‡§æ‡§§‡•Ä ‡§ï‡•á ‡§≤‡§ø‡§è ‡§Ö‡§≤‡§ó-‡§Ö‡§≤‡§ó ‡§ï‡•ç‡§∑‡§Æ‡§§‡§æ‡§è‡§Å ‡§π‡•ã‡§§‡•Ä ‡§π‡•à‡§Ç‡•§ Q4_K ‡§∏‡§∞‡§≤ ‡§è‡§ú‡•á‡§Ç‡§ü‡•ã‡§Ç ‡§ï‡•á ‡§≤‡§ø‡§è ‡§¨‡•Å‡§®‡§ø‡§Ø‡§æ‡§¶‡•Ä ‡§™‡•ç‡§∞‡•ã‡§∏‡•á‡§∏‡§∞ ‡§™‡§∞ ‡§ï‡•Å‡§∂‡§≤‡§§‡§æ ‡§∏‡•á ‡§ö‡§≤‡§§‡§æ ‡§π‡•à, Q5_K ‡§∏‡§Ç‡§§‡•Å‡§≤‡§ø‡§§ ‡§è‡§ú‡•á‡§Ç‡§ü ‡§™‡•ç‡§∞‡§¶‡§∞‡•ç‡§∂‡§® ‡§ï‡•á ‡§≤‡§ø‡§è ‡§Æ‡§ß‡•ç‡§Ø‡§Æ ‡§ï‡§Ç‡§™‡•ç‡§Ø‡•Ç‡§ü‡•á‡§∂‡§®‡§≤ ‡§∏‡§Ç‡§∏‡§æ‡§ß‡§®‡•ã‡§Ç ‡§ï‡•Ä ‡§Ü‡§µ‡§∂‡•ç‡§Ø‡§ï‡§§‡§æ ‡§π‡•ã‡§§‡•Ä ‡§π‡•à, ‡§î‡§∞ Q8_0 ‡§â‡§®‡•ç‡§®‡§§ ‡§è‡§ú‡•á‡§Ç‡§ü ‡§ï‡•ç‡§∑‡§Æ‡§§‡§æ‡§ì‡§Ç ‡§ï‡•á ‡§≤‡§ø‡§è ‡§â‡§ö‡•ç‡§ö-‡§∏‡•ç‡§§‡§∞‡•Ä‡§Ø ‡§π‡§æ‡§∞‡•ç‡§°‡§µ‡•á‡§Ø‡§∞ ‡§∏‡•á ‡§≤‡§æ‡§≠ ‡§â‡§†‡§æ‡§§‡§æ ‡§π‡•à‡•§

### SLM ‡§è‡§ú‡•á‡§Ç‡§ü ‡§∏‡§ø‡§∏‡•ç‡§ü‡§Æ ‡§Æ‡•á‡§Ç ‡§∏‡•Å‡§∞‡§ï‡•ç‡§∑‡§æ ‡§î‡§∞ ‡§ó‡•ã‡§™‡§®‡•Ä‡§Ø‡§§‡§æ

SLM ‡§è‡§ú‡•á‡§Ç‡§ü ‡§∏‡•ç‡§•‡§æ‡§®‡•Ä‡§Ø ‡§™‡•ç‡§∞‡§∏‡§Ç‡§∏‡•ç‡§ï‡§∞‡§£ ‡§ï‡•ã ‡§∏‡§ï‡•ç‡§∑‡§Æ ‡§ï‡§∞‡§§‡•á ‡§π‡•à‡§Ç ‡§ú‡§ø‡§∏‡§∏‡•á ‡§ó‡•ã‡§™‡§®‡•Ä‡§Ø‡§§‡§æ ‡§Æ‡•á‡§Ç ‡§∏‡•Å‡§ß‡§æ‡§∞ ‡§π‡•ã‡§§‡§æ ‡§π‡•à, ‡§≤‡•á‡§ï‡§ø‡§® ‡§è‡§ú ‡§µ‡§æ‡§§‡§æ‡§µ‡§∞‡§£ ‡§Æ‡•á‡§Ç ‡§è‡§ú‡•á‡§Ç‡§ü ‡§Æ‡•â‡§°‡§≤ ‡§î‡§∞ ‡§°‡•á‡§ü‡§æ ‡§ï‡•Ä ‡§∏‡•Å‡§∞‡§ï‡•ç‡§∑‡§æ ‡§ï‡•á ‡§≤‡§ø‡§è ‡§â‡§ö‡§ø‡§§ ‡§∏‡•Å‡§∞‡§ï‡•ç‡§∑‡§æ ‡§â‡§™‡§æ‡§Ø ‡§≤‡§æ‡§ó‡•Ç ‡§ï‡§∞‡§®‡•á ‡§ï‡•Ä ‡§Ü‡§µ‡§∂‡•ç‡§Ø‡§ï‡§§‡§æ ‡§π‡•ã‡§§‡•Ä ‡§π‡•à‡•§ ‡§Ø‡§π ‡§µ‡§ø‡§∂‡•á‡§∑ ‡§∞‡•Ç‡§™ ‡§∏‡•á ‡§Æ‡§π‡§§‡•ç‡§µ‡§™‡•Ç‡§∞‡•ç‡§£ ‡§π‡•à ‡§ú‡§¨ ‡§â‡§ö‡•ç‡§ö-‡§™‡•ç‡§∞‡§ø‡§∏‡§ø‡§ú‡§® ‡§è‡§ú‡•á‡§Ç‡§ü ‡§™‡•ç‡§∞‡§æ‡§∞‡•Ç‡§™‡•ã‡§Ç ‡§ï‡•ã ‡§è‡§Ç‡§ü‡§∞‡§™‡•ç‡§∞‡§æ‡§á‡§ú‡§º ‡§µ‡§æ‡§§‡§æ‡§µ‡§∞‡§£ ‡§Æ‡•á‡§Ç ‡§Ø‡§æ ‡§∏‡§Ç‡§ï‡•Å‡§ö‡§ø‡§§ ‡§è‡§ú‡•á‡§Ç‡§ü ‡§™‡•ç‡§∞‡§æ‡§∞‡•Ç‡§™‡•ã‡§Ç ‡§ï‡•ã ‡§∏‡§Ç‡§µ‡•á‡§¶‡§®‡§∂‡•Ä‡§≤ ‡§°‡•á‡§ü‡§æ ‡§ï‡•ã ‡§∏‡§Ç‡§≠‡§æ‡§≤‡§®‡•á ‡§µ‡§æ‡§≤‡•á ‡§Ö‡§®‡•Å‡§™‡•ç‡§∞‡§Ø‡•ã‡§ó‡•ã‡§Ç ‡§Æ‡•á‡§Ç ‡§§‡•à‡§®‡§æ‡§§ ‡§ï‡§ø‡§Ø‡§æ ‡§ú‡§æ‡§§‡§æ ‡§π‡•à‡•§

## SLM ‡§è‡§ú‡•á‡§Ç‡§ü ‡§µ‡§ø‡§ï‡§æ‡§∏ ‡§Æ‡•á‡§Ç ‡§≠‡§µ‡§ø‡§∑‡•ç‡§Ø ‡§ï‡•Ä ‡§™‡•ç‡§∞‡§µ‡•É‡§§‡•ç‡§§‡§ø‡§Ø‡§æ‡§Å

SLM ‡§è‡§ú‡•á‡§Ç‡§ü ‡§™‡§∞‡§ø‡§¶‡•É‡§∂‡•ç‡§Ø ‡§∏‡§Ç‡§™‡•Ä‡§°‡§º‡§® ‡§§‡§ï‡§®‡•Ä‡§ï‡•ã‡§Ç, ‡§Ö‡§®‡•Å‡§ï‡•Ç‡§≤‡§® ‡§µ‡§ø‡§ß‡§ø‡§Ø‡•ã‡§Ç, ‡§î‡§∞ ‡§è‡§ú ‡§§‡•à‡§®‡§æ‡§§‡•Ä ‡§∞‡§£‡§®‡•Ä‡§§‡§ø‡§Ø‡•ã‡§Ç ‡§Æ‡•á‡§Ç ‡§™‡•ç‡§∞‡§ó‡§§‡§ø ‡§ï‡•á ‡§∏‡§æ‡§• ‡§µ‡§ø‡§ï‡§∏‡§ø‡§§ ‡§π‡•ã‡§§‡§æ ‡§∞‡§π‡§§‡§æ ‡§π‡•à‡•§ ‡§≠‡§µ‡§ø‡§∑‡•ç‡§Ø ‡§ï‡•á ‡§µ‡§ø‡§ï‡§æ‡§∏ ‡§Æ‡•á‡§Ç ‡§è‡§ú‡•á‡§Ç‡§ü ‡§Æ‡•â‡§°‡§≤ ‡§ï‡•á ‡§≤‡§ø‡§è ‡§Ö‡§ß‡§ø‡§ï ‡§ï‡•Å‡§∂‡§≤ ‡§ï‡•ç‡§µ‡§æ‡§Ç‡§ü‡§æ‡§á‡§ú‡•á‡§∂‡§® ‡§è‡§≤‡•ç‡§ó‡•ã‡§∞‡§ø‡§¶‡§Æ, ‡§è‡§ú‡•á‡§Ç‡§ü ‡§µ‡§∞‡•ç‡§ï‡§´‡§º‡•ç‡§≤‡•ã ‡§ï‡•á ‡§≤‡§ø‡§è ‡§¨‡•á‡§π‡§§‡§∞ ‡§∏‡§Ç‡§™‡•Ä‡§°‡§º‡§® ‡§µ‡§ø‡§ß‡§ø‡§Ø‡§æ‡§Å, ‡§î‡§∞ ‡§è‡§ú‡•á‡§Ç‡§ü ‡§™‡•ç‡§∞‡§∏‡§Ç‡§∏‡•ç‡§ï‡§∞‡§£ ‡§ï‡•á ‡§≤‡§ø‡§è ‡§è‡§ú ‡§π‡§æ‡§∞‡•ç‡§°‡§µ‡•á‡§Ø‡§∞ ‡§è‡§ï‡•ç‡§∏‡•á‡§≤‡•á‡§∞‡•á‡§ü‡§∞ ‡§ï‡•á ‡§∏‡§æ‡§• ‡§¨‡•á‡§π‡§§‡§∞ ‡§è‡§ï‡•Ä‡§ï‡§∞‡§£ ‡§∂‡§æ‡§Æ‡§ø‡§≤ ‡§π‡•à‡§Ç‡•§

**SLM ‡§è‡§ú‡•á‡§Ç‡§ü‡•ã‡§Ç ‡§ï‡•á ‡§≤‡§ø‡§è ‡§¨‡§æ‡§ú‡§º‡§æ‡§∞ ‡§ï‡•Ä ‡§≠‡§µ‡§ø‡§∑‡•ç‡§Ø‡§µ‡§æ‡§£‡§ø‡§Ø‡§æ‡§Å**: ‡§π‡§æ‡§≤‡§ø‡§Ø‡§æ ‡§∂‡•ã‡§ß ‡§ï‡•á ‡§Ö‡§®‡•Å‡§∏‡§æ‡§∞, ‡§è‡§ú‡•á‡§Ç‡§ü-‡§∏‡§Ç‡§ö‡§æ‡§≤‡§ø‡§§ ‡§∏‡•ç‡§µ‡§ö‡§æ‡§≤‡§® 2027 ‡§§‡§ï ‡§è‡§Ç‡§ü‡§∞‡§™‡•ç‡§∞‡§æ‡§á‡§ú‡§º ‡§µ‡§∞‡•ç‡§ï‡§´‡§º‡•ç‡§≤‡•ã ‡§Æ‡•á‡§Ç 40‚Äì60% ‡§¶‡•ã‡§π‡§∞‡§æ‡§µ ‡§µ‡§æ‡§≤‡•á ‡§∏‡§Ç‡§ú‡•ç‡§û‡§æ‡§®‡§æ‡§§‡•ç‡§Æ‡§ï ‡§ï‡§æ‡§∞‡•ç‡§Ø‡•ã‡§Ç ‡§ï‡•ã ‡§∏‡§Æ‡§æ‡§™‡•ç‡§§ ‡§ï‡§∞ ‡§∏‡§ï‡§§‡§æ ‡§π‡•à, ‡§ú‡§ø‡§∏‡§Æ‡•á‡§Ç SLMs ‡§á‡§∏ ‡§™‡§∞‡§ø‡§µ‡§∞‡•ç‡§§‡§® ‡§ï‡§æ ‡§®‡•á‡§§‡•É‡§§‡•ç‡§µ ‡§ï‡§∞‡•á‡§Ç‡§ó‡•á ‡§ï‡•ç‡§Ø‡•ã‡§Ç‡§ï‡§ø ‡§µ‡•á ‡§≤‡§æ‡§ó‡§§ ‡§™‡•ç‡§∞‡§≠‡§æ‡§µ‡•Ä ‡§î‡§∞ ‡§§‡•à‡§®‡§æ‡§§‡•Ä ‡§Æ‡•á‡§Ç ‡§≤‡§ö‡•Ä‡§≤‡•á ‡§π‡•à‡§Ç‡•§

**SLM ‡§è‡§ú‡•á‡§Ç‡§ü‡•ã‡§Ç ‡§Æ‡•á‡§Ç ‡§§‡§ï‡§®‡•Ä‡§ï‡•Ä ‡§™‡•ç‡§∞‡§µ‡•É‡§§‡•ç‡§§‡§ø‡§Ø‡§æ‡§Å**:
- **‡§µ‡§ø‡§∂‡•á‡§∑‡•Ä‡§ï‡•É‡§§ SLM ‡§è‡§ú‡•á‡§Ç‡§ü**: ‡§µ‡§ø‡§∂‡•á‡§∑ ‡§è‡§ú‡•á‡§Ç‡§ü ‡§ï‡§æ‡§∞‡•ç‡§Ø‡•ã‡§Ç ‡§î‡§∞ ‡§â‡§¶‡•ç‡§Ø‡•ã‡§ó‡•ã‡§Ç ‡§ï‡•á ‡§≤‡§ø‡§è ‡§™‡•ç‡§∞‡§∂‡§ø‡§ï‡•ç‡§∑‡§ø‡§§ ‡§°‡•ã‡§Æ‡•á‡§®-‡§µ‡§ø‡§∂‡§ø‡§∑‡•ç‡§ü ‡§Æ‡•â‡§°‡§≤
- **‡§è‡§ú ‡§è‡§ú‡•á‡§Ç‡§ü ‡§ï‡§Ç‡§™‡•ç‡§Ø‡•Ç‡§ü‡§ø‡§Ç‡§ó**: ‡§¨‡•á‡§π‡§§‡§∞ ‡§ó‡•ã‡§™‡§®‡•Ä‡§Ø‡§§‡§æ ‡§î‡§∞ ‡§ï‡§Æ ‡§µ‡§ø‡§≤‡§Ç‡§¨‡§§‡§æ ‡§ï‡•á ‡§∏‡§æ‡§• ‡§ë‡§®-‡§°‡§ø‡§µ‡§æ‡§á‡§∏ ‡§è‡§ú‡•á‡§Ç‡§ü ‡§ï‡•ç‡§∑‡§Æ‡§§‡§æ‡§è‡§Å
- **‡§è‡§ú‡•á‡§Ç‡§ü ‡§ë‡§∞‡•ç‡§ï‡•á‡§∏‡•ç‡§ü‡•ç‡§∞‡•á‡§∂‡§®**: ‡§ï‡§à SLM ‡§è‡§ú‡•á‡§Ç‡§ü‡•ã‡§Ç ‡§ï‡•á ‡§¨‡•Ä‡§ö ‡§¨‡•á‡§π‡§§‡§∞ ‡§∏‡§Æ‡§®‡•ç‡§µ‡§Ø, ‡§ó‡§§‡§ø‡§∂‡•Ä‡§≤ ‡§∞‡•Ç‡§ü‡§ø‡§Ç‡§ó ‡§î‡§∞ ‡§≤‡•ã‡§° ‡§¨‡•à‡§≤‡•á‡§Ç‡§∏‡§ø‡§Ç‡§ó
- **‡§≤‡•ã‡§ï‡§§‡§Ç‡§§‡•ç‡§∞‡•Ä‡§ï‡§∞‡§£**: SLM ‡§≤‡§ö‡•Ä‡§≤‡§æ‡§™‡§® ‡§∏‡§Ç‡§ó‡§†‡§®‡•ã‡§Ç ‡§Æ‡•á‡§Ç ‡§è‡§ú‡•á‡§Ç‡§ü ‡§µ‡§ø‡§ï‡§æ‡§∏ ‡§Æ‡•á‡§Ç ‡§µ‡•ç‡§Ø‡§æ‡§™‡§ï ‡§≠‡§æ‡§ó‡•Ä‡§¶‡§æ‡§∞‡•Ä ‡§ï‡•ã ‡§∏‡§ï‡•ç‡§∑‡§Æ ‡§¨‡§®‡§æ‡§§‡§æ ‡§π‡•à

## SLM ‡§è‡§ú‡•á‡§Ç‡§ü‡•ã‡§Ç ‡§ï‡•á ‡§∏‡§æ‡§• ‡§∂‡•Å‡§∞‡•Å‡§Ü‡§§ ‡§ï‡§∞‡§®‡§æ

### ‡§ö‡§∞‡§£ 1: Microsoft Agent Framework ‡§µ‡§æ‡§§‡§æ‡§µ‡§∞‡§£ ‡§∏‡•á‡§ü ‡§ï‡§∞‡•á‡§Ç

**‡§°‡§ø‡§™‡•á‡§Ç‡§°‡•á‡§Ç‡§∏‡•Ä ‡§á‡§Ç‡§∏‡•ç‡§ü‡•â‡§≤ ‡§ï‡§∞‡•á‡§Ç**:
```bash
# Install Microsoft Agent Framework
pip install microsoft-agent-framework

# Install Foundry Local SDK for edge deployment
pip install foundry-local-sdk

# Install additional dependencies for edge agents
pip install openai asyncio
```

**Foundry Local ‡§™‡•ç‡§∞‡§æ‡§∞‡§Ç‡§≠ ‡§ï‡§∞‡•á‡§Ç**:
```bash
# Start Foundry Local service
foundry service start

# Load default model for agent development
foundry model run phi-4-mini
```

### ‡§ö‡§∞‡§£ 2: ‡§è‡§ú‡•á‡§Ç‡§ü ‡§Ö‡§®‡•Å‡§™‡•ç‡§∞‡§Ø‡•ã‡§ó‡•ã‡§Ç ‡§ï‡•á ‡§≤‡§ø‡§è ‡§Ö‡§™‡§®‡§æ SLM ‡§ö‡•Å‡§®‡•á‡§Ç
Microsoft Agent Framework ‡§ï‡•á ‡§≤‡§ø‡§è ‡§≤‡•ã‡§ï‡§™‡•ç‡§∞‡§ø‡§Ø ‡§µ‡§ø‡§ï‡§≤‡•ç‡§™:
- **Microsoft Phi-4 Mini (3.8B)**: ‡§∏‡§æ‡§Æ‡§æ‡§®‡•ç‡§Ø ‡§è‡§ú‡•á‡§Ç‡§ü ‡§ï‡§æ‡§∞‡•ç‡§Ø‡•ã‡§Ç ‡§ï‡•á ‡§≤‡§ø‡§è ‡§â‡§§‡•ç‡§ï‡•É‡§∑‡•ç‡§ü, ‡§∏‡§Ç‡§§‡•Å‡§≤‡§ø‡§§ ‡§™‡•ç‡§∞‡§¶‡§∞‡•ç‡§∂‡§® ‡§ï‡•á ‡§∏‡§æ‡§•
- **Qwen2.5-0.5B (0.5B)**: ‡§∏‡§∞‡§≤ ‡§∞‡•Ç‡§ü‡§ø‡§Ç‡§ó ‡§î‡§∞ ‡§µ‡§∞‡•ç‡§ó‡•Ä‡§ï‡§∞‡§£ ‡§è‡§ú‡•á‡§Ç‡§ü‡•ã‡§Ç ‡§ï‡•á ‡§≤‡§ø‡§è ‡§Ö‡§§‡•ç‡§Ø‡§ß‡§ø‡§ï ‡§ï‡•Å‡§∂‡§≤
- **Qwen2.5-Coder-0.5B (0.5B)**: ‡§ï‡•ã‡§°-‡§∏‡§Ç‡§¨‡§Ç‡§ß‡§ø‡§§ ‡§è‡§ú‡•á‡§Ç‡§ü ‡§ï‡§æ‡§∞‡•ç‡§Ø‡•ã‡§Ç ‡§ï‡•á ‡§≤‡§ø‡§è ‡§µ‡§ø‡§∂‡•á‡§∑‡•Ä‡§ï‡•É‡§§
- **Phi-4 (7B)**: ‡§ú‡§ü‡§ø‡§≤ ‡§è‡§ú ‡§™‡§∞‡§ø‡§¶‡•É‡§∂‡•ç‡§Ø‡•ã‡§Ç ‡§ï‡•á ‡§≤‡§ø‡§è ‡§â‡§®‡•ç‡§®‡§§ ‡§§‡§∞‡•ç‡§ï ‡§ú‡§¨ ‡§∏‡§Ç‡§∏‡§æ‡§ß‡§® ‡§Ö‡§®‡•Å‡§Æ‡§§‡§ø ‡§¶‡•á‡§§‡•á ‡§π‡•à‡§Ç

### ‡§ö‡§∞‡§£ 3: Microsoft Agent Framework ‡§ï‡•á ‡§∏‡§æ‡§• ‡§Ö‡§™‡§®‡§æ ‡§™‡§π‡§≤‡§æ ‡§è‡§ú‡•á‡§Ç‡§ü ‡§¨‡§®‡§æ‡§è‡§Ç

**‡§¨‡•á‡§∏‡§ø‡§ï ‡§è‡§ú‡•á‡§Ç‡§ü ‡§∏‡•á‡§ü‡§Ö‡§™**:
```python
from microsoft_agent_framework import Agent, Config
from foundry_local import FoundryLocalManager

# Initialize Foundry Local connection
foundry = FoundryLocalManager("phi-4-mini")

# Create agent configuration
config = Config(
    name="my-first-agent",
    model_provider="foundry-local",
    model_alias="phi-4-mini",
    offline_mode=True
)

# Create and configure agent
agent = Agent(
    config=config,
    model_endpoint=foundry.endpoint,
    api_key=foundry.api_key
)

# Define a simple tool
@agent.tool
def get_current_time() -> str:
    """Get the current time."""
    from datetime import datetime
    return datetime.now().strftime("%Y-%m-%d %H:%M:%S")

# Test the agent
response = agent.chat("What time is it?")
print(response)
```

### ‡§ö‡§∞‡§£ 4: ‡§è‡§ú‡•á‡§Ç‡§ü ‡§ï‡§æ ‡§¶‡§æ‡§Ø‡§∞‡§æ ‡§î‡§∞ ‡§Ü‡§µ‡§∂‡•ç‡§Ø‡§ï‡§§‡§æ‡§è‡§Å ‡§™‡§∞‡§ø‡§≠‡§æ‡§∑‡§ø‡§§ ‡§ï‡§∞‡•á‡§Ç
Microsoft Agent Framework ‡§ï‡§æ ‡§â‡§™‡§Ø‡•ã‡§ó ‡§ï‡§∞‡§ï‡•á ‡§ï‡•á‡§Ç‡§¶‡•ç‡§∞‡§ø‡§§, ‡§Ö‡§ö‡•ç‡§õ‡•Ä ‡§§‡§∞‡§π ‡§∏‡•á ‡§™‡§∞‡§ø‡§≠‡§æ‡§∑‡§ø‡§§ ‡§è‡§ú‡•á‡§Ç‡§ü ‡§Ö‡§®‡•Å‡§™‡•ç‡§∞‡§Ø‡•ã‡§ó‡•ã‡§Ç ‡§∏‡•á ‡§∂‡•Å‡§∞‡•Å‡§Ü‡§§ ‡§ï‡§∞‡•á‡§Ç:
- **‡§è‡§ï‡§≤ ‡§°‡•ã‡§Æ‡•á‡§® ‡§è‡§ú‡•á‡§Ç‡§ü**: ‡§ó‡•ç‡§∞‡§æ‡§π‡§ï ‡§∏‡•á‡§µ‡§æ ‡§Ø‡§æ ‡§∂‡•á‡§°‡•ç‡§Ø‡•Ç‡§≤‡§ø‡§Ç‡§ó ‡§Ø‡§æ ‡§Ö‡§®‡•Å‡§∏‡§Ç‡§ß‡§æ‡§®
- **‡§∏‡•ç‡§™‡§∑‡•ç‡§ü ‡§è‡§ú‡•á‡§Ç‡§ü ‡§â‡§¶‡•ç‡§¶‡•á‡§∂‡•ç‡§Ø**: ‡§è‡§ú‡•á‡§Ç‡§ü ‡§™‡•ç‡§∞‡§¶‡§∞‡•ç‡§∂‡§® ‡§ï‡•á ‡§≤‡§ø‡§è ‡§µ‡§ø‡§∂‡§ø‡§∑‡•ç‡§ü, ‡§Æ‡§æ‡§™‡§®‡•á ‡§Ø‡•ã‡§ó‡•ç‡§Ø ‡§≤‡§ï‡•ç‡§∑‡•ç‡§Ø
- **‡§∏‡•Ä‡§Æ‡§ø‡§§ ‡§ü‡•Ç‡§≤ ‡§è‡§ï‡•Ä‡§ï‡§∞‡§£**: ‡§™‡•ç‡§∞‡§æ‡§∞‡§Ç‡§≠‡§ø‡§ï ‡§è‡§ú‡•á‡§Ç‡§ü ‡§§‡•à‡§®‡§æ‡§§‡•Ä ‡§ï‡•á ‡§≤‡§ø‡§è ‡§Ö‡§ß‡§ø‡§ï‡§§‡§Æ 3-5 ‡§ü‡•Ç‡§≤
- **‡§™‡§∞‡§ø‡§≠‡§æ‡§∑‡§ø‡§§ ‡§è‡§ú‡•á‡§Ç‡§ü ‡§∏‡•Ä‡§Æ‡§æ‡§è‡§Å**: ‡§ú‡§ü‡§ø‡§≤ ‡§™‡§∞‡§ø‡§¶‡•É‡§∂‡•ç‡§Ø‡•ã‡§Ç ‡§ï‡•á ‡§≤‡§ø‡§è ‡§∏‡•ç‡§™‡§∑‡•ç‡§ü ‡§è‡§∏‡•ç‡§ï‡•á‡§≤‡•á‡§∂‡§® ‡§™‡§•
- **‡§è‡§ú-‡§™‡•ç‡§∞‡§•‡§Æ ‡§°‡§ø‡§ú‡§º‡§æ‡§á‡§®**: ‡§ë‡§´‡§º‡§≤‡§æ‡§á‡§® ‡§ï‡§æ‡§∞‡•ç‡§Ø‡§ï‡•ç‡§∑‡§Æ‡§§‡§æ ‡§î‡§∞ ‡§∏‡•ç‡§•‡§æ‡§®‡•Ä‡§Ø ‡§™‡•ç‡§∞‡§∏‡§Ç‡§∏‡•ç‡§ï‡§∞‡§£ ‡§ï‡•ã ‡§™‡•ç‡§∞‡§æ‡§•‡§Æ‡§ø‡§ï‡§§‡§æ ‡§¶‡•á‡§Ç

### ‡§ö‡§∞‡§£ 5: Microsoft Agent Framework ‡§ï‡•á ‡§∏‡§æ‡§• ‡§è‡§ú ‡§§‡•à‡§®‡§æ‡§§‡•Ä ‡§≤‡§æ‡§ó‡•Ç ‡§ï‡§∞‡•á‡§Ç

**‡§∏‡§Ç‡§∏‡§æ‡§ß‡§® ‡§ï‡•â‡§®‡•ç‡§´‡§º‡§ø‡§ó‡§∞‡•á‡§∂‡§®**:
```python
from microsoft_agent_framework import ResourceConfig

# Configure for edge deployment
resource_config = ResourceConfig(
    max_memory_usage="2GB",
    max_concurrent_agents=2,
    model_cache_size="1GB",
    auto_unload_idle_models=True,
    power_management=True
)

agent = Agent(
    config=config,
    resource_limits=resource_config
)
```

**‡§è‡§ú ‡§è‡§ú‡•á‡§Ç‡§ü‡•ã‡§Ç ‡§ï‡•á ‡§≤‡§ø‡§è ‡§∏‡•Å‡§∞‡§ï‡•ç‡§∑‡§æ ‡§â‡§™‡§æ‡§Ø ‡§§‡•à‡§®‡§æ‡§§ ‡§ï‡§∞‡•á‡§Ç**:
- **‡§∏‡•ç‡§•‡§æ‡§®‡•Ä‡§Ø ‡§á‡§®‡§™‡•Å‡§ü ‡§Æ‡§æ‡§®‡•ç‡§Ø‡§§‡§æ**: ‡§ï‡•ç‡§≤‡§æ‡§â‡§° ‡§®‡§ø‡§∞‡•ç‡§≠‡§∞‡§§‡§æ ‡§ï‡•á ‡§¨‡§ø‡§®‡§æ ‡§Ö‡§®‡•Å‡§∞‡•ã‡§ß‡•ã‡§Ç ‡§ï‡•Ä ‡§ú‡§æ‡§Å‡§ö ‡§ï‡§∞‡•á‡§Ç
- **‡§ë‡§´‡§º‡§≤‡§æ‡§á‡§® ‡§Ü‡§â‡§ü‡§™‡•Å‡§ü ‡§´‡§º‡§ø‡§≤‡•ç‡§ü‡§∞‡§ø‡§Ç‡§ó**: ‡§∏‡•Å‡§®‡§ø‡§∂‡•ç‡§ö‡§ø‡§§ ‡§ï‡§∞‡•á‡§Ç ‡§ï‡§ø ‡§™‡•ç‡§∞‡§§‡§ø‡§ï‡•ç‡§∞‡§ø‡§Ø‡§æ‡§è‡§Å ‡§∏‡•ç‡§•‡§æ‡§®‡•Ä‡§Ø ‡§∞‡•Ç‡§™ ‡§∏‡•á ‡§ó‡•Å‡§£‡§µ‡§§‡•ç‡§§‡§æ ‡§Æ‡§æ‡§®‡§ï‡•ã‡§Ç ‡§ï‡•ã ‡§™‡•Ç‡§∞‡§æ ‡§ï‡§∞‡§§‡•Ä ‡§π‡•à‡§Ç
- **‡§è‡§ú ‡§∏‡•Å‡§∞‡§ï‡•ç‡§∑‡§æ ‡§®‡§ø‡§Ø‡§Ç‡§§‡•ç‡§∞‡§£**: ‡§á‡§Ç‡§ü‡§∞‡§®‡•á‡§ü ‡§ï‡§®‡•á‡§ï‡•ç‡§ü‡§ø‡§µ‡§ø‡§ü‡•Ä ‡§ï‡•Ä ‡§Ü‡§µ‡§∂‡•ç‡§Ø‡§ï‡§§‡§æ ‡§ï‡•á ‡§¨‡§ø‡§®‡§æ ‡§∏‡•Å‡§∞‡§ï‡•ç‡§∑‡§æ ‡§≤‡§æ‡§ó‡•Ç ‡§ï‡§∞‡•á‡§Ç
- **‡§∏‡•ç‡§•‡§æ‡§®‡•Ä‡§Ø ‡§®‡§ø‡§ó‡§∞‡§æ‡§®‡•Ä**: ‡§™‡•ç‡§∞‡§¶‡§∞‡•ç‡§∂‡§® ‡§ï‡•ã ‡§ü‡•ç‡§∞‡•à‡§ï ‡§ï‡§∞‡•á‡§Ç ‡§î‡§∞ ‡§è‡§ú ‡§ü‡•á‡§≤‡•Ä‡§Æ‡•á‡§ü‡•ç‡§∞‡•Ä ‡§ï‡§æ ‡§â‡§™‡§Ø‡•ã‡§ó ‡§ï‡§∞‡§ï‡•á ‡§∏‡§Æ‡§∏‡•ç‡§Ø‡§æ‡§ì‡§Ç ‡§ï‡•ã ‡§´‡§º‡•ç‡§≤‡•à‡§ó ‡§ï‡§∞‡•á‡§Ç

### ‡§ö‡§∞‡§£ 6: ‡§è‡§ú ‡§è‡§ú‡•á‡§Ç‡§ü ‡§™‡•ç‡§∞‡§¶‡§∞‡•ç‡§∂‡§® ‡§ï‡•ã ‡§Æ‡§æ‡§™‡•á‡§Ç ‡§î‡§∞ ‡§Ö‡§®‡•Å‡§ï‡•Ç‡§≤‡§ø‡§§ ‡§ï‡§∞‡•á‡§Ç
- **‡§è‡§ú‡•á‡§Ç‡§ü ‡§ï‡§æ‡§∞‡•ç‡§Ø ‡§™‡•Ç‡§∞‡•ç‡§£‡§§‡§æ ‡§¶‡§∞**: ‡§ë‡§´‡§º‡§≤‡§æ‡§á‡§® ‡§™‡§∞‡§ø‡§¶‡•É‡§∂‡•ç‡§Ø‡•ã‡§Ç ‡§Æ‡•á‡§Ç ‡§∏‡§´‡§≤‡§§‡§æ ‡§¶‡§∞ ‡§ï‡•Ä ‡§®‡§ø‡§ó‡§∞‡§æ‡§®‡•Ä ‡§ï‡§∞‡•á‡§Ç
- **‡§è‡§ú‡•á‡§Ç‡§ü ‡§™‡•ç‡§∞‡§§‡§ø‡§ï‡•ç‡§∞‡§ø‡§Ø‡§æ ‡§∏‡§Æ‡§Ø**: ‡§è‡§ú ‡§§‡•à‡§®‡§æ‡§§‡•Ä ‡§ï‡•á ‡§≤‡§ø‡§è ‡§â‡§™-‡§∏‡•á‡§ï‡§Ç‡§° ‡§™‡•ç‡§∞‡§§‡§ø‡§ï‡•ç‡§∞‡§ø‡§Ø‡§æ ‡§∏‡§Æ‡§Ø ‡§∏‡•Å‡§®‡§ø‡§∂‡•ç‡§ö‡§ø‡§§ ‡§ï‡§∞‡•á‡§Ç
- **‡§∏‡§Ç‡§∏‡§æ‡§ß‡§® ‡§â‡§™‡§Ø‡•ã‡§ó**: ‡§è‡§ú ‡§â‡§™‡§ï‡§∞‡§£‡•ã‡§Ç ‡§™‡§∞ ‡§Æ‡•á‡§Æ‡•ã‡§∞‡•Ä, CPU, ‡§î‡§∞ ‡§¨‡•à‡§ü‡§∞‡•Ä ‡§â‡§™‡§Ø‡•ã‡§ó ‡§ï‡•ã ‡§ü‡•ç‡§∞‡•à‡§ï ‡§ï‡§∞‡•á‡§Ç
- **‡§≤‡§æ‡§ó‡§§ ‡§¶‡§ï‡•ç‡§∑‡§§‡§æ**: ‡§ï‡•ç‡§≤‡§æ‡§â‡§°-‡§Ü‡§ß‡§æ‡§∞‡§ø‡§§ ‡§µ‡§ø‡§ï‡§≤‡•ç‡§™‡•ã‡§Ç ‡§ï‡•Ä ‡§§‡•Å‡§≤‡§®‡§æ ‡§Æ‡•á‡§Ç ‡§è‡§ú ‡§§‡•à‡§®‡§æ‡§§‡•Ä ‡§≤‡§æ‡§ó‡§§ ‡§ï‡•Ä ‡§§‡•Å‡§≤‡§®‡§æ ‡§ï‡§∞‡•á‡§Ç
- **‡§ë‡§´‡§º‡§≤‡§æ‡§á‡§® ‡§µ‡§ø‡§∂‡•ç‡§µ‡§∏‡§®‡•Ä‡§Ø‡§§‡§æ**: ‡§®‡•á‡§ü‡§µ‡§∞‡•ç‡§ï ‡§Ü‡§â‡§ü‡•á‡§ú ‡§ï‡•á ‡§¶‡•å‡§∞‡§æ‡§® ‡§è‡§ú‡•á‡§Ç‡§ü ‡§™‡•ç‡§∞‡§¶‡§∞‡•ç‡§∂‡§® ‡§ï‡•ã ‡§Æ‡§æ‡§™‡•á‡§Ç

## SLM ‡§è‡§ú‡•á‡§Ç‡§ü ‡§ï‡§æ‡§∞‡•ç‡§Ø‡§æ‡§®‡•ç‡§µ‡§Ø‡§® ‡§ï‡•á ‡§≤‡§ø‡§è ‡§Æ‡•Å‡§ñ‡•ç‡§Ø ‡§¨‡§æ‡§§‡•á‡§Ç

1. **‡§è‡§ú‡•á‡§Ç‡§ü‡•ã‡§Ç ‡§ï‡•á ‡§≤‡§ø‡§è SLM ‡§™‡§∞‡•ç‡§Ø‡§æ‡§™‡•ç‡§§ ‡§π‡•à‡§Ç**: ‡§Ö‡§ß‡§ø‡§ï‡§æ‡§Ç‡§∂ ‡§è‡§ú‡•á‡§Ç‡§ü ‡§ï‡§æ‡§∞‡•ç‡§Ø‡•ã‡§Ç ‡§ï‡•á ‡§≤‡§ø‡§è, ‡§õ‡•ã‡§ü‡•á ‡§Æ‡•â‡§°‡§≤ ‡§¨‡§°‡§º‡•á ‡§Æ‡•â‡§°‡§≤ ‡§ï‡•á ‡§∏‡§Æ‡§æ‡§® ‡§™‡•ç‡§∞‡§¶‡§∞‡•ç‡§∂‡§® ‡§ï‡§∞‡§§‡•á ‡§π‡•à‡§Ç ‡§î‡§∞ ‡§Æ‡§π‡§§‡•ç‡§µ‡§™‡•Ç‡§∞‡•ç‡§£ ‡§≤‡§æ‡§≠ ‡§™‡•ç‡§∞‡§¶‡§æ‡§® ‡§ï‡§∞‡§§‡•á ‡§π‡•à‡§Ç
2. **‡§è‡§ú‡•á‡§Ç‡§ü‡•ã‡§Ç ‡§Æ‡•á‡§Ç ‡§≤‡§æ‡§ó‡§§ ‡§¶‡§ï‡•ç‡§∑‡§§‡§æ**: SLM ‡§è‡§ú‡•á‡§Ç‡§ü ‡§ö‡§≤‡§æ‡§®‡•á ‡§ï‡•á ‡§≤‡§ø‡§è 10-30x ‡§∏‡§∏‡•ç‡§§‡§æ, ‡§â‡§®‡•ç‡§π‡•á‡§Ç ‡§µ‡•ç‡§Ø‡§æ‡§™‡§ï ‡§§‡•à‡§®‡§æ‡§§‡•Ä ‡§ï‡•á ‡§≤‡§ø‡§è ‡§Ü‡§∞‡•ç‡§•‡§ø‡§ï ‡§∞‡•Ç‡§™ ‡§∏‡•á ‡§µ‡•ç‡§Ø‡§µ‡§π‡§æ‡§∞‡•ç‡§Ø ‡§¨‡§®‡§æ‡§§‡§æ ‡§π‡•à
3. **‡§è‡§ú‡•á‡§Ç‡§ü‡•ã‡§Ç ‡§ï‡•á ‡§≤‡§ø‡§è ‡§µ‡§ø‡§∂‡•á‡§∑‡§ú‡•ç‡§û‡§§‡§æ ‡§ï‡§æ‡§Æ ‡§ï‡§∞‡§§‡•Ä ‡§π‡•à**: ‡§µ‡§ø‡§∂‡§ø‡§∑‡•ç‡§ü ‡§è‡§ú‡•á‡§Ç‡§ü ‡§Ö‡§®‡•Å‡§™‡•ç‡§∞‡§Ø‡•ã‡§ó‡•ã‡§Ç ‡§Æ‡•á‡§Ç ‡§´‡§æ‡§á‡§®-‡§ü‡•ç‡§Ø‡•Ç‡§® ‡§ï‡§ø‡§è ‡§ó‡§è SLM ‡§Ö‡§ï‡•ç‡§∏‡§∞ ‡§∏‡§æ‡§Æ‡§æ‡§®‡•ç‡§Ø-‡§â‡§¶‡•ç‡§¶‡•á‡§∂‡•ç‡§Ø LLMs ‡§∏‡•á ‡§¨‡•á‡§π‡§§‡§∞ ‡§™‡•ç‡§∞‡§¶‡§∞‡•ç‡§∂‡§® ‡§ï‡§∞‡§§‡•á ‡§π‡•à‡§Ç
4. **‡§π‡§æ‡§á‡§¨‡•ç‡§∞‡§ø‡§° ‡§è‡§ú‡•á‡§Ç‡§ü ‡§Ü‡§∞‡•ç‡§ï‡§ø‡§ü‡•á‡§ï‡•ç‡§ö‡§∞**: ‡§®‡§ø‡§Ø‡§Æ‡§ø‡§§ ‡§è‡§ú‡•á‡§Ç‡§ü ‡§ï‡§æ‡§∞‡•ç‡§Ø‡•ã‡§Ç ‡§ï‡•á ‡§≤‡§ø‡§è SLM ‡§ï‡§æ ‡§â‡§™‡§Ø‡•ã‡§ó ‡§ï‡§∞‡•á‡§Ç, ‡§ú‡§ü‡§ø‡§≤ ‡§§‡§∞‡•ç‡§ï ‡§ï‡•á ‡§≤‡§ø‡§è ‡§Ü‡§µ‡§∂‡•ç‡§Ø‡§ï ‡§π‡•ã‡§®‡•á ‡§™‡§∞ LLM ‡§ï‡§æ ‡§â‡§™‡§Ø‡•ã‡§ó ‡§ï‡§∞‡•á‡§Ç
5. **Microsoft Agent Framework ‡§â‡§§‡•ç‡§™‡§æ‡§¶‡§® ‡§§‡•à‡§®‡§æ‡§§‡•Ä ‡§∏‡§ï‡•ç‡§∑‡§Æ ‡§ï‡§∞‡§§‡§æ ‡§π‡•à**: ‡§è‡§ú ‡§è‡§ú‡•á‡§Ç‡§ü‡•ã‡§Ç ‡§ï‡•ã ‡§¨‡§®‡§æ‡§®‡•á, ‡§§‡•à‡§®‡§æ‡§§ ‡§ï‡§∞‡§®‡•á, ‡§î‡§∞ ‡§™‡•ç‡§∞‡§¨‡§Ç‡§ß‡§ø‡§§ ‡§ï‡§∞‡§®‡•á ‡§ï‡•á ‡§≤‡§ø‡§è ‡§è‡§Ç‡§ü‡§∞‡§™‡•ç‡§∞‡§æ‡§á‡§ú‡§º-‡§ó‡•ç‡§∞‡•á‡§° ‡§ü‡•Ç‡§≤ ‡§™‡•ç‡§∞‡§¶‡§æ‡§® ‡§ï‡§∞‡§§‡§æ ‡§π‡•à
6. **‡§è‡§ú-‡§™‡•ç‡§∞‡§•‡§Æ ‡§°‡§ø‡§ú‡§º‡§æ‡§á‡§® ‡§∏‡§ø‡§¶‡•ç‡§ß‡§æ‡§Ç‡§§**: ‡§ë‡§´‡§º‡§≤‡§æ‡§á‡§®-‡§∏‡§ï‡•ç‡§∑‡§Æ ‡§è‡§ú‡•á‡§Ç‡§ü ‡§∏‡•ç‡§•‡§æ‡§®‡•Ä‡§Ø ‡§™‡•ç‡§∞‡§∏‡§Ç‡§∏‡•ç‡§ï‡§∞‡§£ ‡§ï‡•á ‡§∏‡§æ‡§• ‡§ó‡•ã‡§™‡§®‡•Ä‡§Ø‡§§‡§æ ‡§î‡§∞ ‡§µ‡§ø‡§∂‡•ç‡§µ‡§∏‡§®‡•Ä‡§Ø‡§§‡§æ ‡§∏‡•Å‡§®‡§ø‡§∂‡•ç‡§ö‡§ø‡§§ ‡§ï‡§∞‡§§‡•á ‡§π‡•à‡§Ç
7. **Foundry Local ‡§è‡§ï‡•Ä‡§ï‡§∞‡§£**: Microsoft Agent Framework ‡§î‡§∞ ‡§∏‡•ç‡§•‡§æ‡§®‡•Ä‡§Ø ‡§Æ‡•â‡§°‡§≤ ‡§á‡§®‡§´‡•á‡§∞‡•á‡§Ç‡§∏ ‡§ï‡•á ‡§¨‡•Ä‡§ö ‡§∏‡§π‡§ú ‡§ï‡§®‡•á‡§ï‡•ç‡§∂‡§®
8. **‡§≠‡§µ‡§ø‡§∑‡•ç‡§Ø SLM ‡§è‡§ú‡•á‡§Ç‡§ü ‡§π‡•à‡§Ç**: ‡§â‡§§‡•ç‡§™‡§æ‡§¶‡§® ‡§´‡•ç‡§∞‡•á‡§Æ‡§µ‡§∞‡•ç‡§ï ‡§ï‡•á ‡§∏‡§æ‡§• ‡§õ‡•ã‡§ü‡•á ‡§≠‡§æ‡§∑‡§æ ‡§Æ‡•â‡§°‡§≤ ‡§è‡§ú‡•á‡§Ç‡§ü‡§ø‡§ï AI ‡§ï‡§æ ‡§≠‡§µ‡§ø‡§∑‡•ç‡§Ø ‡§π‡•à‡§Ç, ‡§ú‡•ã ‡§≤‡•ã‡§ï‡§§‡§æ‡§Ç‡§§‡•ç‡§∞‡§ø‡§§ ‡§î‡§∞ ‡§ï‡•Å‡§∂‡§≤ ‡§è‡§ú‡•á‡§Ç‡§ü ‡§§‡•à‡§®‡§æ‡§§‡•Ä ‡§ï‡•ã ‡§∏‡§ï‡•ç‡§∑‡§Æ ‡§¨‡§®‡§æ‡§§‡•á ‡§π‡•à‡§Ç

## ‡§∏‡§Ç‡§¶‡§∞‡•ç‡§≠ ‡§î‡§∞ ‡§Ü‡§ó‡•á ‡§™‡§¢‡§º‡§æ‡§à

### ‡§Æ‡•Å‡§ñ‡•ç‡§Ø ‡§∂‡•ã‡§ß ‡§™‡§§‡•ç‡§∞ ‡§î‡§∞ ‡§™‡•ç‡§∞‡§ï‡§æ‡§∂‡§®

#### AI ‡§è‡§ú‡•á‡§Ç‡§ü ‡§î‡§∞ ‡§è‡§ú‡•á‡§Ç‡§ü‡§ø‡§ï ‡§∏‡§ø‡§∏‡•ç‡§ü‡§Æ
- **"Language Agents as Optimizable Graphs"** (2024) - ‡§è‡§ú‡•á‡§Ç‡§ü ‡§Ü‡§∞‡•ç‡§ï‡§ø‡§ü‡•á‡§ï‡•ç‡§ö‡§∞ ‡§î‡§∞ ‡§Ö‡§®‡•Å‡§ï‡•Ç‡§≤‡§® ‡§™‡§∞ ‡§Æ‡•å‡§≤‡§ø‡§ï ‡§∂‡•ã‡§ß
  - ‡§≤‡•á‡§ñ‡§ï: Wenyue Hua, Lishan Yang, ‡§Ü‡§¶‡§ø
  - ‡§≤‡§ø‡§Ç‡§ï: https://arxiv.org/abs/2402.16823
  - ‡§Æ‡•Å‡§ñ‡•ç‡§Ø ‡§Ö‡§Ç‡§§‡§∞‡•ç‡§¶‡•É‡§∑‡•ç‡§ü‡§ø: ‡§ó‡•ç‡§∞‡§æ‡§´-‡§Ü‡§ß‡§æ‡§∞‡§ø‡§§ ‡§è‡§ú‡•á‡§Ç‡§ü ‡§°‡§ø‡§ú‡§º‡§æ‡§á‡§® ‡§î‡§∞ ‡§Ö‡§®‡•Å‡§ï‡•Ç‡§≤‡§® ‡§∞‡§£‡§®‡•Ä‡§§‡§ø‡§Ø‡§æ‡§Å

- **"The Rise and Potential of Large Language Model Based Agents"** (2023)
  - ‡§≤‡•á‡§ñ‡§ï: Zhiheng Xi, Wenxiang Chen, ‡§Ü‡§¶‡§ø
  - ‡§≤‡§ø‡§Ç‡§ï: https://arxiv.org/abs/2309.07864
  - ‡§Æ‡•Å‡§ñ‡•ç‡§Ø ‡§Ö‡§Ç‡§§‡§∞‡•ç‡§¶‡•É‡§∑‡•ç‡§ü‡§ø: LLM-‡§Ü‡§ß‡§æ‡§∞‡§ø‡§§ ‡§è‡§ú‡•á‡§Ç‡§ü ‡§ï‡•ç‡§∑‡§Æ‡§§‡§æ‡§ì‡§Ç ‡§î‡§∞ ‡§Ö‡§®‡•Å‡§™‡•ç‡§∞‡§Ø‡•ã‡§ó‡•ã‡§Ç ‡§ï‡§æ ‡§µ‡•ç‡§Ø‡§æ‡§™‡§ï ‡§∏‡§∞‡•ç‡§µ‡•á‡§ï‡•ç‡§∑‡§£

- **"Cognitive Architectures for Language Agents"** (2024)
  - ‡§≤‡•á‡§ñ‡§ï: Theodore Sumers, Shunyu Yao, ‡§Ü‡§¶‡§ø
  - ‡§≤‡§ø‡§Ç‡§ï: https://arxiv.org/abs/2309.02427
  - ‡§Æ‡•Å‡§ñ‡•ç‡§Ø ‡§Ö‡§Ç‡§§‡§∞‡•ç‡§¶‡•É‡§∑‡•ç‡§ü‡§ø: ‡§¨‡•Å‡§¶‡•ç‡§ß‡§ø‡§Æ‡§æ‡§® ‡§è‡§ú‡•á‡§Ç‡§ü‡•ã‡§Ç ‡§ï‡•ã ‡§°‡§ø‡§ú‡§º‡§æ‡§á‡§® ‡§ï‡§∞‡§®‡•á ‡§ï‡•á ‡§≤‡§ø‡§è ‡§∏‡§Ç‡§ú‡•ç‡§û‡§æ‡§®‡§æ‡§§‡•ç‡§Æ‡§ï ‡§´‡•ç‡§∞‡•á‡§Æ‡§µ‡§∞‡•ç‡§ï

#### ‡§õ‡•ã‡§ü‡•á ‡§≠‡§æ‡§∑‡§æ ‡§Æ‡•â‡§°‡§≤ ‡§î‡§∞ ‡§Ö‡§®‡•Å‡§ï‡•Ç‡§≤‡§®
- **"Phi-3 Technical Report: A Highly Capable Language Model Locally on Your Phone"** (2024)
  - ‡§≤‡•á‡§ñ‡§ï: Microsoft Research Team
  - ‡§≤‡§ø‡§Ç‡§ï: https://arxiv.org/abs/2404.14219
  - ‡§Æ‡•Å‡§ñ‡•ç‡§Ø ‡§Ö‡§Ç‡§§‡§∞‡•ç‡§¶‡•É‡§∑‡•ç‡§ü‡§ø: SLM ‡§°‡§ø‡§ú‡§º‡§æ‡§á‡§® ‡§∏‡§ø‡§¶‡•ç‡§ß‡§æ‡§Ç‡§§ ‡§î‡§∞ ‡§Æ‡•ã‡§¨‡§æ‡§á‡§≤ ‡§§‡•à‡§®‡§æ‡§§‡•Ä ‡§∞‡§£‡§®‡•Ä‡§§‡§ø‡§Ø‡§æ‡§Å

- **"Qwen2.5 Technical Report"** (2024)
  - ‡§≤‡•á‡§ñ‡§ï: Alibaba Cloud Team
  - ‡§≤‡§ø‡§Ç‡§ï: https://arxiv.org/abs/2407.10671
  - ‡§Æ‡•Å‡§ñ‡•ç‡§Ø ‡§Ö‡§Ç‡§§‡§∞‡•ç‡§¶‡•É‡§∑‡•ç‡§ü‡§ø: ‡§â‡§®‡•ç‡§®‡§§ SLM ‡§™‡•ç‡§∞‡§∂‡§ø‡§ï‡•ç‡§∑‡§£ ‡§§‡§ï‡§®‡•Ä‡§ï ‡§î‡§∞ ‡§™‡•ç‡§∞‡§¶‡§∞‡•ç‡§∂‡§® ‡§Ö‡§®‡•Å‡§ï‡•Ç‡§≤‡§®

- **"TinyLlama: An Open-Source Small Language Model"** (2024)
  - ‡§≤‡•á‡§ñ‡§ï: Peiyuan Zhang, Guangtao Zeng, ‡§Ü‡§¶‡§ø
  - ‡§≤‡§ø‡§Ç‡§ï: https://arxiv.org/abs/2401.02385
  - ‡§Æ‡•Å‡§ñ‡•ç‡§Ø ‡§Ö‡§Ç‡§§‡§∞‡•ç‡§¶‡•É‡§∑‡•ç‡§ü‡§ø: ‡§Ö‡§≤‡•ç‡§ü‡•ç‡§∞‡§æ-‡§ï‡•â‡§Æ‡•ç‡§™‡•à‡§ï‡•ç‡§ü ‡§Æ‡•â‡§°‡§≤ ‡§°‡§ø‡§ú‡§º‡§æ‡§á‡§® ‡§î‡§∞ ‡§™‡•ç‡§∞‡§∂‡§ø‡§ï‡•ç‡§∑‡§£ ‡§¶‡§ï‡•ç‡§∑‡§§‡§æ

### ‡§Ü‡§ß‡§ø‡§ï‡§æ‡§∞‡§ø‡§ï ‡§¶‡§∏‡•ç‡§§‡§æ‡§µ‡•á‡§ú‡§º ‡§î‡§∞ ‡§´‡•ç‡§∞‡•á‡§Æ‡§µ‡§∞‡•ç‡§ï

#### Microsoft Agent Framework
- **‡§Ü‡§ß‡§ø‡§ï‡§æ‡§∞‡§ø‡§ï ‡§¶‡§∏‡•ç‡§§‡§æ‡§µ‡•á‡§ú‡§º**: https://docs.microsoft.com/en-us/azure/ai-services/agents/
- **GitHub ‡§∞‡§ø‡§™‡•â‡§ú‡§ø‡§ü‡§∞‡•Ä**: https://github.com/microsoft/agent-framework

#### Foundry Local
- **‡§™‡•ç‡§∞‡§æ‡§•‡§Æ‡§ø‡§ï ‡§∞‡§ø‡§™‡•â‡§ú‡§ø‡§ü‡§∞‡•Ä**: https://github.com/microsoft/foundry-local
- **‡§¶‡§∏‡•ç‡§§‡§æ‡§µ‡•á‡§ú‡§º**: https://github.com/microsoft/foundry-local/blob/main/docs/README.md


#### VLLM
- **‡§Æ‡•Å‡§ñ‡•ç‡§Ø ‡§∞‡§ø‡§™‡•â‡§ú‡§ø‡§ü‡§∞‡•Ä**: https://github.com/vllm-project/vllm
- **‡§¶‡§∏‡•ç‡§§‡§æ‡§µ‡•á‡§ú‡§º**: https://docs.vllm.ai/


#### Ollama
- **‡§Ü‡§ß‡§ø‡§ï‡§æ‡§∞‡§ø‡§ï ‡§µ‡•á‡§¨‡§∏‡§æ‡§á‡§ü**: https://ollama.ai/
- **GitHub ‡§∞‡§ø‡§™‡•â‡§ú‡§ø‡§ü‡§∞‡•Ä**: https://github.com/ollama/ollama

### ‡§Æ‡•â‡§°‡§≤ ‡§Ö‡§®‡•Å‡§ï‡•Ç‡§≤‡§® ‡§´‡•ç‡§∞‡•á‡§Æ‡§µ‡§∞‡•ç‡§ï

#### Llama.cpp
- **‡§∞‡§ø‡§™‡•â‡§ú‡§ø‡§ü‡§∞‡•Ä**: https://github.com/ggml-org/llama.cpp


#### Microsoft Olive
- **‡§¶‡§∏‡•ç‡§§‡§æ‡§µ‡•á‡§ú‡§º**: https://microsoft.github.io/Olive/
- **GitHub ‡§∞‡§ø‡§™‡•â‡§ú‡§ø‡§ü‡§∞‡•Ä**: https://github.com/microsoft/Olive

#### OpenVINO
- **‡§Ü‡§ß‡§ø‡§ï‡§æ‡§∞‡§ø‡§ï ‡§∏‡§æ‡§á‡§ü**: https://docs.openvino.ai/

#### Apple MLX
- **‡§∞‡§ø‡§™‡•â‡§ú‡§ø‡§ü‡§∞‡•Ä**: https://github.com/ml-explore/mlx

### ‡§â‡§¶‡•ç‡§Ø‡•ã‡§ó ‡§∞‡§ø‡§™‡•ã‡§∞‡•ç‡§ü ‡§î‡§∞ ‡§¨‡§æ‡§ú‡§º‡§æ‡§∞ ‡§µ‡§ø‡§∂‡•ç‡§≤‡•á‡§∑‡§£

#### AI ‡§è‡§ú‡•á‡§Ç‡§ü ‡§¨‡§æ‡§ú‡§º‡§æ‡§∞ ‡§Ö‡§®‡•Å‡§∏‡§Ç‡§ß‡§æ‡§®
- **"The State of AI Agents 2025"** - McKinsey Global Institute
  - ‡§≤‡§ø‡§Ç‡§ï: https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/ai-agents-2025
  - ‡§Æ‡•Å‡§ñ‡•ç‡§Ø ‡§Ö‡§Ç‡§§‡§∞‡•ç‡§¶‡•É‡§∑‡•ç‡§ü‡§ø: ‡§¨‡§æ‡§ú‡§º‡§æ‡§∞ ‡§™‡•ç‡§∞‡§µ‡•É‡§§‡•ç‡§§‡§ø‡§Ø‡§æ‡§Å ‡§î‡§∞ ‡§è‡§Ç‡§ü‡§∞‡§™‡•ç‡§∞‡§æ‡§á‡§ú‡§º ‡§Ö‡§™‡§®‡§æ‡§®‡•á ‡§ï‡•á ‡§™‡•à‡§ü‡§∞‡•ç‡§®

#### ‡§§‡§ï‡§®‡•Ä‡§ï‡•Ä ‡§¨‡•á‡§Ç‡§ö‡§Æ‡§æ‡§∞‡•ç‡§ï

- **"Edge AI Inference Benchmarks"** - MLPerf
  - ‡§≤‡§ø‡§Ç‡§ï: https://mlcommons.org/en/inference-edge/
  - ‡§Æ‡•Å‡§ñ‡•ç‡§Ø ‡§Ö‡§Ç‡§§‡§∞‡•ç‡§¶‡•É‡§∑‡•ç‡§ü‡§ø: ‡§è‡§ú ‡§§‡•à‡§®‡§æ‡§§‡•Ä ‡§ï‡•á ‡§≤‡§ø‡§è ‡§Æ‡§æ‡§®‡§ï‡•Ä‡§ï‡•É‡§§ ‡§™‡•ç‡§∞‡§¶‡§∞‡•ç‡§∂‡§® ‡§Æ‡•á‡§ü‡•ç‡§∞‡§ø‡§ï‡•ç‡§∏

### ‡§Æ‡§æ‡§®‡§ï ‡§î‡§∞ ‡§µ‡§ø‡§®‡§ø‡§∞‡•ç‡§¶‡•á‡§∂

#### ‡§Æ‡•â‡§°‡§≤ ‡§™‡•ç‡§∞‡§æ‡§∞‡•Ç‡§™ ‡§î‡§∞ ‡§Æ‡§æ‡§®‡§ï
- **ONNX (Open Neural Network Exchange)**: https://onnx.ai/
  - ‡§á‡§Ç‡§ü‡§∞‡§ë‡§™‡§∞‡•á‡§¨‡§ø‡§≤‡§ø‡§ü‡•Ä ‡§ï‡•á ‡§≤‡§ø‡§è ‡§ï‡•ç‡§∞‡•â‡§∏-‡§™‡•ç‡§≤‡•á‡§ü‡§´‡§º‡•â‡§∞‡•ç‡§Æ ‡§Æ‡•â‡§°‡§≤ ‡§™‡•ç‡§∞‡§æ‡§∞‡•Ç‡§™
- **GGUF ‡§µ‡§ø‡§®‡§ø‡§∞‡•ç‡§¶‡•á‡§∂**: https://github.com/ggerganov/ggml/blob/master/docs/gguf.md
  - CPU ‡§á‡§®‡§´‡•á‡§∞‡•á‡§Ç‡§∏ ‡§ï‡•á ‡§≤‡§ø‡§è ‡§ï‡•ç‡§µ‡§æ‡§Ç‡§ü‡§æ‡§á‡§ú‡•ç‡§° ‡§Æ‡•â‡§°‡§≤ ‡§™‡•ç‡§∞‡§æ‡§∞‡•Ç‡§™
- **OpenAI API ‡§µ‡§ø‡§®‡§ø‡§∞‡•ç‡§¶‡•á‡§∂**: https://platform.openai.com/docs/api-reference
  - ‡§≠‡§æ‡§∑‡§æ ‡§Æ‡•â‡§°‡§≤ ‡§è‡§ï‡•Ä‡§ï‡§∞‡§£ ‡§ï‡•á ‡§≤‡§ø‡§è ‡§Æ‡§æ‡§®‡§ï API ‡§™‡•ç‡§∞‡§æ‡§∞‡•Ç‡§™

#### ‡§∏‡•Å‡§∞‡§ï‡•ç‡§∑‡§æ ‡§î‡§∞ ‡§Ö‡§®‡•Å‡§™‡§æ‡§≤‡§®
- **NIST AI ‡§ú‡•ã‡§ñ‡§ø‡§Æ ‡§™‡•ç‡§∞‡§¨‡§Ç‡§ß‡§® ‡§´‡•ç‡§∞‡•á‡§Æ‡§µ‡§∞‡•ç‡§ï**: https://www.nist.gov/itl/ai-risk-management-framework
- **ISO/IEC 23053:2022 - AI ‡§∏‡§ø‡§∏‡•ç‡§ü‡§Æ**: AI ‡§∏‡§ø‡§∏‡•ç‡§ü‡§Æ ‡§î‡§∞ ‡§∏‡•Å‡§∞‡§ï‡•ç‡§∑‡§æ ‡§ï‡•á ‡§≤‡§ø‡§è ‡§´‡•ç‡§∞‡•á‡§Æ‡§µ‡§∞‡•ç‡§ï
- **IEEE AI ‡§Æ‡§æ‡§®‡§ï**: https://standards.ieee.org/industry-connections/ai/

SLM-‡§∏‡§Ç‡§ö‡§æ‡§≤‡§ø‡§§ ‡§è‡§ú‡•á‡§Ç‡§ü‡•ã‡§Ç ‡§ï‡•Ä ‡§ì‡§∞ ‡§¨‡§¶‡§≤‡§æ‡§µ AI ‡§§‡•à‡§®‡§æ‡§§‡•Ä ‡§ï‡•á ‡§™‡•ç‡§∞‡§§‡§ø ‡§π‡§Æ‡§æ‡§∞‡•á ‡§¶‡•É‡§∑‡•ç‡§ü‡§ø‡§ï‡•ã‡§£ ‡§Æ‡•á‡§Ç ‡§è‡§ï ‡§Æ‡•å‡§≤‡§ø‡§ï ‡§™‡§∞‡§ø‡§µ‡§∞‡•ç‡§§‡§® ‡§ï‡§æ ‡§™‡•ç‡§∞‡§§‡§ø‡§®‡§ø‡§ß‡§ø‡§§‡•ç‡§µ ‡§ï‡§∞‡§§‡§æ ‡§π‡•à‡•§ Microsoft Agent Framework, ‡§∏‡•ç‡§•‡§æ‡§®‡•Ä‡§Ø ‡§™‡•ç‡§≤‡•á‡§ü‡§´‡§º‡•â‡§∞‡•ç‡§Æ ‡§î‡§∞ ‡§ï‡•Å‡§∂‡§≤ ‡§õ‡•ã‡§ü‡•á ‡§≠‡§æ‡§∑‡§æ ‡§Æ‡•â‡§°‡§≤ ‡§ï‡•á ‡§∏‡§æ‡§• ‡§Æ‡§ø‡§≤‡§ï‡§∞, ‡§â‡§§‡•ç‡§™‡§æ‡§¶‡§®-‡§§‡•à‡§Ø‡§æ‡§∞ ‡§è‡§ú‡•á‡§Ç‡§ü‡•ã‡§Ç ‡§ï‡•ã ‡§¨‡§®‡§æ‡§®‡•á ‡§ï‡•á ‡§≤‡§ø‡§è ‡§è‡§ï ‡§∏‡§Ç‡§™‡•Ç‡§∞‡•ç‡§£ ‡§∏‡§Æ‡§æ‡§ß‡§æ‡§® ‡§™‡•ç‡§∞‡§¶‡§æ‡§® ‡§ï‡§∞‡§§‡§æ ‡§π‡•à ‡§ú‡•ã ‡§è‡§ú ‡§µ‡§æ‡§§‡§æ‡§µ‡§∞‡§£ ‡§Æ‡•á‡§Ç ‡§™‡•ç‡§∞‡§≠‡§æ‡§µ‡•Ä ‡§¢‡§Ç‡§ó ‡§∏‡•á ‡§ï‡§æ‡§Æ ‡§ï‡§∞‡§§‡•á ‡§π‡•à‡§Ç‡•§ ‡§¶‡§ï‡•ç‡§∑‡§§‡§æ, ‡§µ‡§ø‡§∂‡•á‡§∑‡§ú‡•ç‡§û‡§§‡§æ, ‡§î‡§∞ ‡§µ‡•ç‡§Ø‡§æ‡§µ‡§π‡§æ‡§∞‡§ø‡§ï ‡§â‡§™‡§Ø‡•ã‡§ó‡§ø‡§§‡§æ ‡§™‡§∞ ‡§ß‡•ç‡§Ø‡§æ‡§® ‡§ï‡•á‡§Ç‡§¶‡•ç‡§∞‡§ø‡§§ ‡§ï‡§∞‡§ï‡•á, ‡§Ø‡§π ‡§§‡§ï‡§®‡•Ä‡§ï‡•Ä ‡§∏‡•ç‡§ü‡•à‡§ï AI ‡§è‡§ú‡•á‡§Ç‡§ü‡•ã‡§Ç ‡§ï‡•ã ‡§π‡§∞ ‡§â‡§¶‡•ç‡§Ø‡•ã‡§ó ‡§î‡§∞ ‡§è‡§ú ‡§ï‡§Ç‡§™‡•ç‡§Ø‡•Ç‡§ü‡§ø‡§Ç‡§ó ‡§µ‡§æ‡§§‡§æ‡§µ‡§∞‡§£ ‡§Æ‡•á‡§Ç ‡§µ‡§æ‡§∏‡•ç‡§§‡§µ‡§ø‡§ï ‡§¶‡•Å‡§®‡§ø‡§Ø‡§æ ‡§ï‡•á ‡§Ö‡§®‡•Å‡§™‡•ç‡§∞‡§Ø‡•ã‡§ó‡•ã‡§Ç ‡§ï‡•á ‡§≤‡§ø‡§è ‡§Ö‡§ß‡§ø‡§ï ‡§∏‡•Å‡§≤‡§≠, ‡§ï‡§ø‡§´‡§æ‡§Ø‡§§‡•Ä, ‡§î‡§∞ ‡§™‡•ç‡§∞‡§≠‡§æ‡§µ‡•Ä ‡§¨‡§®‡§æ‡§§‡§æ ‡§π‡•à‡•§

‡§ú‡•à‡§∏‡•á-‡§ú‡•à‡§∏‡•á ‡§π‡§Æ 2025 ‡§§‡§ï ‡§Ü‡§ó‡•á ‡§¨‡§¢‡§º‡§§‡•á ‡§π‡•à‡§Ç, ‡§õ‡•ã‡§ü‡•á ‡§Æ‡•â‡§°‡§≤, ‡§™‡§∞‡§ø‡§∑‡•ç‡§ï‡•É‡§§ ‡§è‡§ú‡•á‡§Ç‡§ü ‡§´‡•ç‡§∞‡•á‡§Æ‡§µ‡§∞‡•ç‡§ï ‡§ú‡•à‡§∏‡•á Microsoft Agent Framework, ‡§î‡§∞ ‡§Æ‡§ú‡§¨‡•Ç‡§§ ‡§è‡§ú ‡§§‡•à‡§®‡§æ‡§§‡•Ä ‡§™‡•ç‡§≤‡•á‡§ü‡§´‡§º‡•â‡§∞‡•ç‡§Æ ‡§ï‡•á ‡§∏‡§Ç‡§Ø‡•ã‡§ú‡§® ‡§∏‡•á ‡§∏‡•ç‡§µ‡§æ‡§Ø‡§§‡•ç‡§§ ‡§∏‡§ø‡§∏‡•ç‡§ü‡§Æ ‡§ï‡•á ‡§≤‡§ø‡§è ‡§®‡§à ‡§∏‡§Ç‡§≠‡§æ‡§µ‡§®‡§æ‡§è‡§Å ‡§ñ‡•Å‡§≤‡•á‡§Ç‡§ó‡•Ä ‡§ú‡•ã ‡§è‡§ú ‡§â‡§™‡§ï‡§∞‡§£‡•ã‡§Ç ‡§™‡§∞ ‡§ï‡•Å‡§∂‡§≤‡§§‡§æ ‡§∏‡•á ‡§ï‡§æ‡§Æ ‡§ï‡§∞ ‡§∏‡§ï‡§§‡•á ‡§π‡•à‡§Ç, ‡§ó‡•ã‡§™‡§®‡•Ä‡§Ø‡§§‡§æ ‡§¨‡§®‡§æ‡§è ‡§∞‡§ñ‡§§‡•á ‡§π‡•à‡§Ç, ‡§≤‡§æ‡§ó‡§§ ‡§ï‡§Æ ‡§ï‡§∞‡§§‡•á ‡§π‡•à‡§Ç, ‡§î‡§∞ ‡§Ö‡§∏‡§æ‡§ß‡§æ‡§∞‡§£ ‡§â‡§™‡§Ø‡•ã‡§ó‡§ï‡§∞‡•ç‡§§‡§æ ‡§Ö‡§®‡•Å‡§≠‡§µ ‡§™‡•ç‡§∞‡§¶‡§æ‡§® ‡§ï‡§∞‡§§‡•á ‡§π‡•à‡§Ç‡•§

**‡§ï‡§æ‡§∞‡•ç‡§Ø‡§æ‡§®‡•ç‡§µ‡§Ø‡§® ‡§ï‡•á ‡§≤‡§ø‡§è ‡§Ö‡§ó‡§≤‡•á ‡§ï‡§¶‡§Æ**:
1. **‡§´‡§Ç‡§ï‡•ç‡§∂‡§® ‡§ï‡•â‡§≤‡§ø‡§Ç‡§ó ‡§ï‡§æ ‡§Ö‡§®‡•ç‡§µ‡•á‡§∑‡§£ ‡§ï‡§∞‡•á‡§Ç**: ‡§ú‡§æ‡§®‡•á‡§Ç ‡§ï‡§ø SLMs ‡§ü‡•Ç‡§≤ ‡§è‡§ï‡•Ä‡§ï‡§∞‡§£ ‡§î‡§∞ ‡§∏‡§Ç‡§∞‡§ö‡§ø‡§§ ‡§Ü‡§â‡§ü‡§™‡•Å‡§ü ‡§ï‡•ã ‡§ï‡•à‡§∏‡•á ‡§∏‡§Ç‡§≠‡§æ‡§≤‡§§‡•á ‡§π‡•à‡§Ç
2. **‡§Æ‡•â‡§°‡§≤ ‡§∏‡§Ç‡§¶‡§∞‡•ç‡§≠ ‡§™‡•ç‡§∞‡•ã‡§ü‡•ã‡§ï‡•â‡§≤ (MCP) ‡§Æ‡•á‡§Ç ‡§Æ‡§π‡§æ‡§∞‡§§ ‡§π‡§æ‡§∏‡§ø‡§≤ ‡§ï‡§∞‡•á‡§Ç**: ‡§â‡§®‡•ç‡§®‡§§ ‡§è‡§ú‡•á‡§Ç‡§ü ‡§∏‡§Ç‡§ö‡§æ‡§∞ ‡§™‡•à‡§ü‡§∞‡•ç‡§® ‡§ï‡•ã ‡§∏‡§Æ‡§ù‡•á‡§Ç
3. **‡§â‡§§‡•ç‡§™‡§æ‡§¶‡§® ‡§è‡§ú‡•á‡§Ç‡§ü ‡§¨‡§®‡§æ‡§è‡§Ç**: ‡§è‡§Ç‡§ü‡§∞‡§™‡•ç‡§∞‡§æ‡§á‡§ú‡§º-‡§ó‡•ç‡§∞‡•á‡§° ‡§§‡•à‡§®‡§æ‡§§‡•Ä ‡§ï‡•á ‡§≤‡§ø‡§è Microsoft Agent Framework ‡§ï‡§æ ‡§â‡§™‡§Ø‡•ã‡§ó ‡§ï‡§∞‡•á‡§Ç
4. **‡§è‡§ú ‡§ï‡•á ‡§≤‡§ø‡§è ‡§Ö‡§®‡•Å‡§ï‡•Ç‡§≤‡§ø‡§§ ‡§ï‡§∞‡•á‡§Ç**: ‡§∏‡§Ç‡§∏‡§æ‡§ß‡§®-‡§∏‡•Ä‡§Æ‡§ø‡§§ ‡§µ‡§æ‡§§‡§æ‡§µ‡§∞‡§£ ‡§ï‡•á ‡§≤‡§ø‡§è ‡§â‡§®‡•ç‡§®‡§§ ‡§Ö‡§®‡•Å‡§ï‡•Ç‡§≤‡§® ‡§§‡§ï‡§®‡•Ä‡§ï‡•ã‡§Ç ‡§ï‡•ã ‡§≤‡§æ‡§ó‡•Ç ‡§ï‡§∞‡•á‡§Ç

## ‚û°Ô∏è ‡§Ü‡§ó‡•á ‡§ï‡•ç‡§Ø‡§æ ‡§π‡•à

- [02: ‡§õ‡•ã‡§ü‡•á ‡§≠‡§æ‡§∑‡§æ ‡§Æ‡•â‡§°‡§≤ (SLMs) ‡§Æ‡•á‡§Ç ‡§´‡§Ç‡§ï‡•ç‡§∂‡§® ‡§ï‡•â‡§≤‡§ø‡§Ç‡§ó](./02.FunctionCalling.md)

---

**‡§Ö‡§∏‡•ç‡§µ‡•Ä‡§ï‡§∞‡§£**:  
‡§Ø‡§π ‡§¶‡§∏‡•ç‡§§‡§æ‡§µ‡•á‡§ú‡§º AI ‡§Ö‡§®‡•Å‡§µ‡§æ‡§¶ ‡§∏‡•á‡§µ‡§æ [Co-op Translator](https://github.com/Azure/co-op-translator) ‡§ï‡§æ ‡§â‡§™‡§Ø‡•ã‡§ó ‡§ï‡§∞‡§ï‡•á ‡§Ö‡§®‡•Å‡§µ‡§æ‡§¶‡§ø‡§§ ‡§ï‡§ø‡§Ø‡§æ ‡§ó‡§Ø‡§æ ‡§π‡•à‡•§ ‡§ú‡§¨‡§ï‡§ø ‡§π‡§Æ ‡§∏‡§ü‡•Ä‡§ï‡§§‡§æ ‡§ï‡•á ‡§≤‡§ø‡§è ‡§™‡•ç‡§∞‡§Ø‡§æ‡§∏ ‡§ï‡§∞‡§§‡•á ‡§π‡•à‡§Ç, ‡§ï‡•É‡§™‡§Ø‡§æ ‡§ß‡•ç‡§Ø‡§æ‡§® ‡§¶‡•á‡§Ç ‡§ï‡§ø ‡§∏‡•ç‡§µ‡§ö‡§æ‡§≤‡§ø‡§§ ‡§Ö‡§®‡•Å‡§µ‡§æ‡§¶ ‡§Æ‡•á‡§Ç ‡§§‡•ç‡§∞‡•Å‡§ü‡§ø‡§Ø‡§æ‡§Ç ‡§Ø‡§æ ‡§Ö‡§∂‡•Å‡§¶‡•ç‡§ß‡§ø‡§Ø‡§æ‡§Ç ‡§π‡•ã ‡§∏‡§ï‡§§‡•Ä ‡§π‡•à‡§Ç‡•§ ‡§Æ‡•Ç‡§≤ ‡§≠‡§æ‡§∑‡§æ ‡§Æ‡•á‡§Ç ‡§¶‡§∏‡•ç‡§§‡§æ‡§µ‡•á‡§ú‡§º ‡§ï‡•ã ‡§Ü‡§ß‡§ø‡§ï‡§æ‡§∞‡§ø‡§ï ‡§∏‡•ç‡§∞‡•ã‡§§ ‡§Æ‡§æ‡§®‡§æ ‡§ú‡§æ‡§®‡§æ ‡§ö‡§æ‡§π‡§ø‡§è‡•§ ‡§Æ‡§π‡§§‡•ç‡§µ‡§™‡•Ç‡§∞‡•ç‡§£ ‡§ú‡§æ‡§®‡§ï‡§æ‡§∞‡•Ä ‡§ï‡•á ‡§≤‡§ø‡§è, ‡§™‡•á‡§∂‡•á‡§µ‡§∞ ‡§Æ‡§æ‡§®‡§µ ‡§Ö‡§®‡•Å‡§µ‡§æ‡§¶ ‡§ï‡•Ä ‡§∏‡§ø‡§´‡§æ‡§∞‡§ø‡§∂ ‡§ï‡•Ä ‡§ú‡§æ‡§§‡•Ä ‡§π‡•à‡•§ ‡§á‡§∏ ‡§Ö‡§®‡•Å‡§µ‡§æ‡§¶ ‡§ï‡•á ‡§â‡§™‡§Ø‡•ã‡§ó ‡§∏‡•á ‡§â‡§§‡•ç‡§™‡§®‡•ç‡§® ‡§ï‡§ø‡§∏‡•Ä ‡§≠‡•Ä ‡§ó‡§≤‡§§‡§´‡§π‡§Æ‡•Ä ‡§Ø‡§æ ‡§ó‡§≤‡§§ ‡§µ‡•ç‡§Ø‡§æ‡§ñ‡•ç‡§Ø‡§æ ‡§ï‡•á ‡§≤‡§ø‡§è ‡§π‡§Æ ‡§â‡§§‡•ç‡§§‡§∞‡§¶‡§æ‡§Ø‡•Ä ‡§®‡§π‡•Ä‡§Ç ‡§π‡•à‡§Ç‡•§