# Sesija 1: Poƒçetak rada s Foundry Local

## Sa≈æetak

Nauƒçite kako instalirati, konfigurirati i pokrenuti svoje prve AI modele koristeƒái Microsoft Foundry Local. Ova praktiƒçna sesija pru≈æa korak-po-korak uvod u lokalnu inferenciju, od instalacije do izrade va≈°e prve aplikacije za chat koristeƒái modele poput Phi-4, Qwen i DeepSeek.

## Ciljevi uƒçenja

Na kraju ove sesije, moƒái ƒáete:

- **Instalirati i konfigurirati**: Postaviti Foundry Local uz pravilnu provjeru instalacije
- **Savladati CLI operacije**: Koristiti Foundry Local CLI za upravljanje modelima i njihovo postavljanje
- **Pokrenuti svoj prvi model**: Uspje≈°no postaviti i interaktirati s lokalnim AI modelom
- **Izraditi aplikaciju za chat**: Kreirati osnovnu aplikaciju za chat koristeƒái Foundry Local Python SDK
- **Razumjeti lokalni AI**: Shvatiti osnove lokalne inferencije i upravljanja modelima

## Preduvjeti

### Sistemski zahtjevi

- **Windows**: Windows 11 (22H2 ili noviji) ILI **macOS**: macOS 11+ (ograniƒçena podr≈°ka)
- **RAM**: Minimalno 8GB, preporuƒçeno 16GB+
- **Pohrana**: 10GB+ slobodnog prostora za modele
- **Python**: Verzija 3.10 ili novija
- **Administratorski pristup**: Privilegije administratora za instalaciju

### Razvojno okru≈æenje

- Visual Studio Code s Python ekstenzijom (preporuƒçeno)
- Pristup naredbenom retku (PowerShell na Windowsu, Terminal na macOS-u)
- Git za kloniranje repozitorija (opcionalno)

## Tijek radionice (30 minuta)

### Korak 1: Instalacija Foundry Local (5 minuta)

#### Instalacija na Windowsu

Instalirajte Foundry Local koristeƒái Windows upravitelj paketa:

```powershell
# Install via winget (recommended)
winget install Microsoft.FoundryLocal
```

Alternativa: Preuzmite direktno s [Microsoft Learn](https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/install)

#### Instalacija na macOS-u (ograniƒçena podr≈°ka)

> [!NOTE] 
> Podr≈°ka za macOS trenutno je u fazi pregleda. Provjerite slu≈æbenu dokumentaciju za najnovije informacije.

Ako je dostupno, instalirajte koristeƒái Homebrew:

```bash
# If Homebrew formula is available
brew update
brew install foundry-local

# Or manual download (check official docs for latest)
curl -L -o foundry-local.tar.gz "https://download.microsoft.com/foundry-local/latest/macos/foundry-local.tar.gz"
tar -xzf foundry-local.tar.gz
sudo ./install.sh
```

**Alternativa za korisnike macOS-a:**
- Koristite Windows 11 VM (Parallels/UTM) i slijedite korake za Windows
- Pokrenite putem kontejnera ako je dostupno i konfigurirajte `FOUNDRY_LOCAL_ENDPOINT`

### Korak 2: Provjera instalacije (3 minute)

Nakon instalacije, ponovno pokrenite terminal i provjerite radi li Foundry Local:

```powershell
# Check if Foundry Local is installed correctly
foundry --version

# View available commands
foundry --help
```

Oƒçekivani izlaz trebao bi prikazati informacije o verziji i dostupnim naredbama.

### Korak 3: Postavljanje Python okru≈æenja (5 minuta)

Kreirajte posveƒáeno Python okru≈æenje za ovu radionicu:

**Windows:**
```powershell
# Create virtual environment
py -m venv .venv

# Activate environment
.\.venv\Scripts\Activate.ps1

# Upgrade pip and install dependencies
python -m pip install --upgrade pip
pip install foundry-local-sdk openai
```

**macOS/Linux:**
```bash
# Create virtual environment
python3 -m venv .venv

# Activate environment
source .venv/bin/activate

# Upgrade pip and install dependencies
python -m pip install --upgrade pip
pip install foundry-local-sdk openai
```

### Korak 4: Pokrenite svoj prvi model (7 minuta)

Sada pokrenimo na≈° prvi AI model lokalno!

#### Poƒçetak s Phi-4 Mini (preporuƒçeni prvi model)

```powershell
# Download and start phi-4-mini (lightweight, fast)
foundry model run phi-4-mini

# Test the model with a simple prompt
foundry model run phi-4-mini --prompt "Hello, introduce yourself in one sentence"
```

> [!TIP]
> Ova naredba preuzima model (prvi put) i automatski pokreƒáe Foundry Local uslugu.

#### Provjerite ≈°to je pokrenuto

```powershell
# List available models (shows downloaded models)
foundry model list

# Check service status
foundry service status

# See what models are cached locally
foundry cache list
```

#### Isprobajte razliƒçite modele

Kada phi-4-mini radi, eksperimentirajte s drugim modelima:

```powershell
# Larger model with better capabilities
foundry model run gpt-oss-20b --prompt "Explain edge AI in simple terms"

# Fast, efficient model
foundry model run qwen2.5-0.5b --prompt "What are the benefits of local AI inference?"
```

### Korak 5: Izradite svoju prvu aplikaciju za chat (10 minuta)

Sada kreirajmo Python aplikaciju koja koristi modele koje smo upravo pokrenuli.

#### Kreirajte skriptu za chat

Kreirajte novu datoteku pod nazivom `my_first_chat.py` (ili koristite prilo≈æeni uzorak):

```python
#!/usr/bin/env python3
"""
My First Foundry Local Chat Application
Using FoundryLocalManager for automatic service management
"""

import os
from foundry_local import FoundryLocalManager
from openai import OpenAI

def main():
    # Get model alias from environment or use default
    alias = os.getenv("FOUNDRY_LOCAL_ALIAS", "phi-4-mini")
    
    try:
        # Initialize Foundry Local Manager (auto-starts service, downloads model)
        manager = FoundryLocalManager(alias)
        
        # Create OpenAI client pointing to local endpoint
        client = OpenAI(
            base_url=manager.endpoint,
            api_key=manager.api_key or "not-needed"
        )
        
        # Get the actual model ID for this alias
        model_id = manager.get_model_info(alias).id
        
        print("ü§ñ Welcome to your first local AI chat!")
        print(f"ÔøΩ Using model: {alias} -> {model_id}")
        print(f"üåê Endpoint: {manager.endpoint}")
        print("ÔøΩüí° Type 'quit' to exit\n")
        
    except Exception as e:
        print(f"‚ùå Failed to initialize Foundry Local: {e}")
        print("üí° Make sure Foundry Local is installed: foundry --version")
        return
    
    while True:
        # Get user input
        user_message = input("You: ").strip()
        
        if user_message.lower() in ['quit', 'exit', 'bye']:
            print("üëã Goodbye!")
            break
            
        if not user_message:
            continue
            
        try:
            # Send message to local AI model
            response = client.chat.completions.create(
                model=model_id,
                messages=[
                    {"role": "system", "content": "You are a helpful AI assistant running locally."},
                    {"role": "user", "content": user_message}
                ],
                max_tokens=200,
                temperature=0.7
            )
            
            # Display the response
            ai_response = response.choices[0].message.content
            print(f"ü§ñ AI: {ai_response}\n")
            
        except Exception as e:
            print(f"‚ùå Error: {e}")
            print("üí° Check service status: foundry service status\n")

if __name__ == "__main__":
    main()
```

> [!TIP]
> **Povezani primjeri**: Za naprednije kori≈°tenje, pogledajte:
>
> - **Python uzorak**: `Workshop/samples/session01/chat_bootstrap.py` - Ukljuƒçuje streaming odgovora i rukovanje gre≈°kama
> - **Jupyter Notebook**: `Workshop/notebooks/session01_chat_bootstrap.ipynb` - Interaktivna verzija s detaljnim obja≈°njenjima

#### Testirajte svoju aplikaciju za chat

```powershell
# No need to manually start models - FoundryLocalManager handles this!
# Just run your chat application
python my_first_chat.py
```

Alternativa: Koristite prilo≈æene uzorke direktno

```powershell
# Try the complete sample with streaming support
cd Workshop/samples
python -m session01.chat_bootstrap "Your question here"
```

Ili istra≈æite interaktivni notebook
Otvorite Workshop/notebooks/session01_chat_bootstrap.ipynb u VS Code

Isprobajte ove primjere razgovora:

- "≈†to je Microsoft Foundry Local?"
- "Navedite 3 prednosti pokretanja AI modela lokalno"
- "Pomozite mi razumjeti edge AI"

## ≈†to ste postigli

ƒåestitamo! Uspje≈°no ste:

1. ‚úÖ **Instalirali Foundry Local** i provjerili da radi
2. ‚úÖ **Pokrenuli svoj prvi AI model** (phi-4-mini) lokalno
3. ‚úÖ **Testirali razliƒçite modele** putem naredbenog retka
4. ‚úÖ **Izradili aplikaciju za chat** koja se povezuje s va≈°im lokalnim AI-jem
5. ‚úÖ **Iskusili lokalnu AI inferenciju** bez ovisnosti o oblaku

## Razumijevanje ≈°to se dogodilo

### Lokalna AI inferencija

- Va≈°i AI modeli rade potpuno na va≈°em raƒçunalu
- Nijedni podaci se ne ≈°alju u oblak
- Odgovori se generiraju lokalno koristeƒái va≈° CPU/GPU
- Privatnost i sigurnost su oƒçuvani

### Upravljanje modelima

- `foundry model run` preuzima i pokreƒáe modele
- **FoundryLocalManager SDK** automatski upravlja pokretanjem usluge i uƒçitavanjem modela
- Modeli se lokalno pohranjuju za buduƒáu upotrebu
- Vi≈°e modela mo≈æe biti preuzeto, ali obiƒçno se pokreƒáe samo jedan odjednom
- Usluga automatski upravlja ≈æivotnim ciklusom modela

### SDK vs CLI pristupi

- **CLI pristup**: Ruƒçno upravljanje modelima s `foundry model run <model>`
- **SDK pristup**: Automatsko upravljanje uslugom i modelima s `FoundryLocalManager(alias)`
- **Preporuka**: Koristite SDK za aplikacije, CLI za testiranje i istra≈æivanje

## Referenca za uobiƒçajene naredbe

### Osnovne CLI naredbe

```powershell
# Installation & Setup
foundry --version              # Check installation
foundry --help                 # View all commands

# Model Management
foundry model list             # List available models
foundry model run <model>      # Download and start a model
foundry model run <model> --prompt "text"  # One-shot prompt
foundry cache list             # Show downloaded models

# Service Management
foundry service status         # Check if service is running
foundry service start          # Start the service manually
foundry service stop           # Stop the service
```

### Preporuke za modele

- **phi-4-mini**: Najbolji poƒçetni model - brz, lagan, dobre kvalitete
- **qwen2.5-0.5b**: Najbr≈æa inferencija, minimalna potro≈°nja memorije
- **gpt-oss-20b**: Kvalitetniji odgovori, zahtijeva vi≈°e resursa
- **deepseek-coder-1.3b**: Optimiziran za programiranje i zadatke vezane uz kod

## Rje≈°avanje problema

### "Foundry naredba nije pronaƒëena"

**Rje≈°enje:**

```powershell
# Restart your terminal after installation
# Or manually add to PATH (Windows)
$env:PATH += ";C:\Program Files\Microsoft\FoundryLocal"
```

### "Model nije uspio uƒçitati"

**Rje≈°enje:**

```powershell
# Check available system memory
foundry service status

# Try a smaller model first
foundry model run phi-4-mini

# Check disk space for model downloads
# Models are stored in: %USERPROFILE%\.foundry\models (Windows)
```

### "Veza odbijena na localhostu"

**Rje≈°enje:**

```powershell
# Check if service is running
foundry service status

# Start service if needed
foundry service start

# Verify the port (default is 5273)
# Check for port conflicts with: netstat -an | findstr 5273
```

## Sljedeƒái koraci

### Neposredne sljedeƒáe akcije

1. **Eksperimentirajte** s razliƒçitim modelima i upitima
2. **Modificirajte** svoju aplikaciju za chat kako biste isprobali razliƒçite modele
3. **Kreirajte** vlastite upite i testirajte odgovore
4. **Istra≈æite** Sesiju 2: Izrada RAG aplikacija

### Napredni put uƒçenja

1. **Sesija 2**: Izradite AI rje≈°enja s RAG (Retrieval-Augmented Generation)
2. **Sesija 3**: Usporedite razliƒçite open-source modele
3. **Sesija 4**: Radite s najnovijim modelima
4. **Sesija 5**: Izradite AI sustave s vi≈°e agenata

## Varijable okru≈æenja (opcionalno)

Za naprednije kori≈°tenje, mo≈æete postaviti ove varijable okru≈æenja:

| Varijabla | Svrha | Primjer |
|-----------|-------|---------|
| `FOUNDRY_LOCAL_ALIAS` | Zadani model za kori≈°tenje | `phi-4-mini` |
| `FOUNDRY_LOCAL_ENDPOINT` | Prekoraƒçenje URL-a za endpoint | `http://localhost:5273/v1` |

Kreirajte `.env` datoteku u direktoriju va≈°eg projekta:
```
FOUNDRY_LOCAL_ALIAS=phi-4-mini
FOUNDRY_LOCAL_ENDPOINT=auto
```

## Dodatni resursi

### Dokumentacija

- [Foundry Local Python SDK Referenca](https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/reference/reference-sdk?pivots=programming-language-python)
- [Vodiƒç za instalaciju Foundry Local](https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/install)
- [Katalog modela](https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/models)

### Uzorci koda

- **Session01 Python uzorak**: `Workshop/samples/session01/chat_bootstrap.py` - Kompletna aplikacija za chat sa streamingom
- **Session01 Notebook**: `Workshop/notebooks/session01_chat_bootstrap.ipynb` - Interaktivni vodiƒç  
- [Module08 Sample 01](../Module08/samples/01/README.md) - REST Chat Quickstart
- [Module08 Sample 02](../Module08/samples/02/README.md) - Integracija OpenAI SDK-a
- [Module08 Sample 03](../Module08/samples/03/README.md) - Otkriƒáe modela i benchmarking

### Zajednica

- [Foundry Local GitHub Rasprave](https://github.com/microsoft/Foundry-Local/discussions)
- [Azure AI Zajednica](https://techcommunity.microsoft.com/category/artificialintelligence)

---

**Trajanje sesije**: 30 minuta praktiƒçnog rada + 15 minuta pitanja i odgovora  
**Razina te≈æine**: Poƒçetnik  
**Preduvjeti**: Windows 11/macOS 11+, Python 3.10+, administratorski pristup

## Primjer scenarija radionice

### Kontekst iz stvarnog svijeta

**Scenarij**: IT tim u poduzeƒáu treba procijeniti AI inferenciju na ureƒëaju za obradu osjetljivih povratnih informacija zaposlenika bez slanja podataka vanjskim servisima.

**Va≈° cilj**: Demonstrirati da lokalni AI modeli mogu pru≈æiti kvalitetne odgovore s latencijom manjom od sekunde uz potpuno oƒçuvanje privatnosti podataka.

### Testni upiti

Koristite ove upite za validaciju va≈°eg postava:

```json
[
    "List two benefits of local inference.",
    "Summarize why keeping data on device improves privacy.",
    "Give one trade-off when choosing a small model over a large model."
]
```

### Kriteriji uspjeha

- ‚úÖ Svi upiti dobivaju odgovore u manje od 2 sekunde
- ‚úÖ Nijedni podaci ne napu≈°taju va≈°e lokalno raƒçunalo
- ‚úÖ Odgovori su relevantni i korisni
- ‚úÖ Va≈°a aplikacija za chat radi glatko

Ova validacija osigurava da je va≈° Foundry Local postav spreman za napredne radionice u Sesijama 2-6.

---

<!-- CO-OP TRANSLATOR DISCLAIMER START -->
**Odricanje od odgovornosti**:  
Ovaj dokument je preveden koristeƒái AI uslugu za prevoƒëenje [Co-op Translator](https://github.com/Azure/co-op-translator). Iako nastojimo osigurati toƒçnost, imajte na umu da automatski prijevodi mogu sadr≈æavati pogre≈°ke ili netoƒçnosti. Izvorni dokument na izvornom jeziku treba smatrati autoritativnim izvorom. Za kljuƒçne informacije preporuƒçuje se profesionalni prijevod od strane ljudskog prevoditelja. Ne odgovaramo za nesporazume ili pogre≈°na tumaƒçenja koja mogu proizaƒái iz kori≈°tenja ovog prijevoda.
<!-- CO-OP TRANSLATOR DISCLAIMER END -->