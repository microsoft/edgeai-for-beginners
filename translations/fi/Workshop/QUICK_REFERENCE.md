# Ty√∂pajan n√§ytteet - Pikaopas

**Viimeksi p√§ivitetty**: 8. lokakuuta 2025

---

## üöÄ Pika-aloitus

```bash
# 1. Ensure Foundry Local is running
foundry service status
foundry model run phi-4-mini

# 2. Install dependencies
pip install -r Workshop/requirements.txt

# 3. Run a sample
cd Workshop/samples
python -m session01.chat_bootstrap "What is edge AI?"
```

---

## üìÇ N√§yteyleiskatsaus

| Istunto | N√§yte | Tarkoitus | Aika |
|---------|-------|-----------|------|
| 01 | `chat_bootstrap.py` | Peruschatti + suoratoisto | ~30s |
| 02 | `rag_pipeline.py` | RAG upotuksilla | ~45s |
| 02 | `rag_eval_ragas.py` | RAG-arviointi | ~60s |
| 03 | `benchmark_oss_models.py` | Mallien vertailu | ~2m |
| 04 | `model_compare.py` | SLM vs LLM | ~45s |
| 05 | `agents_orchestrator.py` | Moniagenttij√§rjestelm√§ | ~60s |
| 06 | `models_router.py` | Tarkoituksenmukainen reititys | ~45s |
| 06 | `models_pipeline.py` | Monivaiheinen putki | ~60s |

---

## üõ†Ô∏è Ymp√§rist√∂muuttujat

### V√§ltt√§m√§tt√∂m√§t
```bash
# Choose model
set FOUNDRY_LOCAL_ALIAS=phi-4-mini

# Override endpoint (optional)
set FOUNDRY_LOCAL_ENDPOINT=http://localhost:8000

# Show token usage
set SHOW_USAGE=1
```

### Istuntokohtaiset
```bash
# Session 02: RAG
set RAG_QUESTION="What is local inference?"
set EMBED_MODEL=sentence-transformers/all-MiniLM-L6-v2

# Session 03: Benchmarking
set BENCH_MODELS=phi-4-mini,qwen2.5-0.5b
set BENCH_ROUNDS=3
set BENCH_STREAM=1

# Session 04: Comparison
set SLM_ALIAS=phi-4-mini
set LLM_ALIAS=qwen2.5-7b

# Session 05: Agents
set AGENT_MODEL_PRIMARY=phi-4-mini
set AGENT_QUESTION="Why use edge AI?"

# Session 06: Pipeline
set PIPELINE_TASK="Your task here"
```

---

## ‚úÖ Vahvistus ja testaus

```bash
# Validate syntax and imports
python scripts/validate_samples.py

# Validate specific session
python scripts/validate_samples.py --session 01

# Run smoke tests
python scripts/test_samples.py --quick

# Verbose testing
python scripts/test_samples.py --verbose
```

---

## üêõ Vianm√§√§ritys

### Yhteysvirhe
```bash
# Check Foundry Local
foundry service status

# Start if needed
foundry service start
foundry model run phi-4-mini
```

### Tuontivirhe
```bash
# Install missing dependencies
pip install sentence-transformers ragas datasets

# Or install all
pip install -r Workshop/requirements.txt
```

### Mallia ei l√∂ydy
```bash
# List available models
foundry model ls

# Download model
foundry model download phi-4-mini
```

### Hidas suorituskyky
```bash
# Use smaller model
set FOUNDRY_LOCAL_ALIAS=qwen2.5-0.5b

# Reduce benchmark rounds
set BENCH_ROUNDS=1
```

---

## üìñ Yleiset mallit

### Peruschatti
```python
from workshop_utils import chat_once

text, usage = chat_once(
    'phi-4-mini',
    messages=[{"role": "user", "content": "Hello"}],
    max_tokens=100,
    temperature=0.7
)
```

### Asiakkaan haku
```python
from workshop_utils import get_client

manager, client, model_id = get_client(
    alias='phi-4-mini',
    endpoint=None  # Auto-detect
)
```

### Virheenk√§sittely
```python
try:
    manager, client, model_id = get_client(alias)
except Exception as e:
    print(f"[ERROR] Failed: {e}")
    print("[INFO] Check: foundry service status")
    sys.exit(1)
```

### Suoratoisto
```python
stream = client.chat.completions.create(
    model=model_id,
    messages=messages,
    stream=True
)

for chunk in stream:
    if chunk.choices[0].delta.content:
        print(chunk.choices[0].delta.content, end="", flush=True)
```

---

## üìä Mallin valinta

| Malli | Koko | Parhaimmillaan | Nopeus |
|-------|------|----------------|--------|
| `qwen2.5-0.5b` | 0.5B | Nopea luokittelu | ‚ö°‚ö°‚ö° |
| `qwen2.5-coder-0.5b` | 0.5B | Nopea koodin generointi | ‚ö°‚ö°‚ö° |
| `gemma-2-2b` | 2B | Luova kirjoittaminen | ‚ö°‚ö° |
| `phi-3.5-mini` | 3.5B | Koodi, refaktorointi | ‚ö°‚ö° |
| `phi-4-mini` | 4B | Yleinen, tiivistys | ‚ö°‚ö° |
| `qwen2.5-7b` | 7B | Monimutkainen p√§√§ttely | ‚ö° |

---

## üîó Resurssit

- **SDK-dokumentaatio**: https://github.com/microsoft/Foundry-Local/tree/main/sdk/python
- **Pikaopas**: `Workshop/FOUNDRY_SDK_QUICKREF.md`

---

## üí° Vinkkej√§

1. **V√§limuistiasiakkaat**: `workshop_utils` hoitaa v√§limuistin puolestasi
2. **K√§yt√§ pienempi√§ malleja**: Aloita `qwen2.5-0.5b`-mallilla testaukseen
3. **Ota k√§ytt√∂tilastot k√§ytt√∂√∂n**: Aseta `SHOW_USAGE=1` seurataksesi tokenien k√§ytt√∂√§
4. **Er√§k√§sittely**: K√§sittele useita kehotteita per√§kk√§in
5. **Pienenn√§ max_tokens**: V√§hent√§√§ viivett√§ nopeampia vastauksia varten

---

## üéØ N√§yteprosessit

### Testaa kaikki
```bash
python scripts/validate_samples.py
python scripts/test_samples.py --quick
```

### Mallien vertailu
```bash
cd samples
set BENCH_MODELS=phi-4-mini,qwen2.5-0.5b
set BENCH_ROUNDS=3
python -m session03.benchmark_oss_models
```

### RAG-putki
```bash
cd samples
set RAG_QUESTION="What is RAG?"
python -m session02.rag_pipeline
```

### Moniagenttij√§rjestelm√§
```bash
cd samples
set AGENT_QUESTION="Why edge AI for healthcare?"
python -m session05.agents_orchestrator
```

---

**Pika-apu**: Aja mik√§ tahansa n√§yte komennolla `--help` kansiosta `samples` tai tarkista docstring:
```bash
python -c "import session01.chat_bootstrap; help(session01.chat_bootstrap)"
```

---

**Kaikki n√§ytteet p√§ivitetty lokakuussa 2025 Foundry Local SDK:n parhaiden k√§yt√§nt√∂jen mukaisesti** ‚ú®

---

<!-- CO-OP TRANSLATOR DISCLAIMER START -->
**Vastuuvapauslauseke**:  
T√§m√§ asiakirja on k√§√§nnetty k√§ytt√§m√§ll√§ teko√§lypohjaista k√§√§nn√∂spalvelua [Co-op Translator](https://github.com/Azure/co-op-translator). Vaikka pyrimme tarkkuuteen, huomioithan, ett√§ automaattiset k√§√§nn√∂kset voivat sis√§lt√§√§ virheit√§ tai ep√§tarkkuuksia. Alkuper√§inen asiakirja sen alkuper√§isell√§ kielell√§ tulisi pit√§√§ ensisijaisena l√§hteen√§. Kriittisen tiedon osalta suositellaan ammattimaista ihmisk√§√§nn√∂st√§. Emme ole vastuussa v√§√§rink√§sityksist√§ tai virhetulkinnoista, jotka johtuvat t√§m√§n k√§√§nn√∂ksen k√§yt√∂st√§.
<!-- CO-OP TRANSLATOR DISCLAIMER END -->