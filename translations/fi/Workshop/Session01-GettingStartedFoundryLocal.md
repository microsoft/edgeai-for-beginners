<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "8c30436578b1bd604c48233ecdd39701",
  "translation_date": "2025-11-11T23:26:09+00:00",
  "source_file": "Workshop/Session01-GettingStartedFoundryLocal.md",
  "language_code": "fi"
}
-->
# Istunto 1: Aloitus Foundry Localin kanssa

## Tiivistelm√§

Opi asentamaan, konfiguroimaan ja suorittamaan ensimm√§iset teko√§lymallisi Microsoft Foundry Localin avulla. T√§m√§ k√§yt√§nn√∂nl√§heinen istunto tarjoaa vaiheittaisen johdannon paikalliseen inferenssiin, alkaen asennuksesta aina ensimm√§isen chat-sovelluksen rakentamiseen k√§ytt√§en malleja kuten Phi-4, Qwen ja DeepSeek.

## Oppimistavoitteet

Istunnon lopussa osaat:

- **Asentaa ja konfiguroida**: M√§√§ritt√§√§ Foundry Localin ja varmistaa asennuksen onnistuminen
- **Hallita CLI-toimintoja**: K√§ytt√§√§ Foundry Localin komentorivik√§ytt√∂liittym√§√§ mallien hallintaan ja k√§ytt√∂√∂nottoon
- **Suorittaa ensimm√§isen mallisi**: Ottaa k√§ytt√∂√∂n ja k√§ytt√§√§ paikallista teko√§lymallia
- **Rakentaa chat-sovelluksen**: Luoda yksinkertaisen chat-sovelluksen Foundry Local Python SDK:n avulla
- **Ymm√§rt√§√§ paikallista teko√§ly√§**: Sis√§ist√§√§ paikallisen inferenssin ja mallien hallinnan perusteet

## Esivaatimukset

### J√§rjestelm√§vaatimukset

- **Windows**: Windows 11 (22H2 tai uudempi) TAI **macOS**: macOS 11+ (rajoitettu tuki)
- **RAM**: V√§hint√§√§n 8GB, suositus 16GB+
- **Tallennustila**: V√§hint√§√§n 10GB vapaata tilaa malleille
- **Python**: Asennettuna versio 3.10 tai uudempi
- **Yll√§pit√§j√§n oikeudet**: Asennusta varten

### Kehitysymp√§rist√∂

- Visual Studio Code Python-laajennuksella (suositeltu)
- P√§√§sy komentoriville (PowerShell Windowsissa, Terminal macOS:ss√§)
- Git repositorioiden kloonaamiseen (valinnainen)

## Ty√∂pajan kulku (30 minuuttia)

### Vaihe 1: Asenna Foundry Local (5 minuuttia)

#### Windows-asennus

Asenna Foundry Local Windowsin pakettienhallinnan avulla:

```powershell
# Install via winget (recommended)
winget install Microsoft.FoundryLocal
```

Vaihtoehto: Lataa suoraan [Microsoft Learn](https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/install)

#### macOS-asennus (rajoitettu tuki)

> [!NOTE] 
> macOS-tuki on t√§ll√§ hetkell√§ esikatselussa. Tarkista virallinen dokumentaatio uusimmasta saatavuudesta.

Jos saatavilla, asenna Homebrewin avulla:

```bash
# If Homebrew formula is available
brew update
brew install foundry-local

# Or manual download (check official docs for latest)
curl -L -o foundry-local.tar.gz "https://download.microsoft.com/foundry-local/latest/macos/foundry-local.tar.gz"
tar -xzf foundry-local.tar.gz
sudo ./install.sh
```

**Vaihtoehto macOS-k√§ytt√§jille:**
- K√§yt√§ Windows 11 VM:√§√§ (Parallels/UTM) ja seuraa Windows-ohjeita
- Suorita kontissa, jos saatavilla, ja konfiguroi `FOUNDRY_LOCAL_ENDPOINT`

### Vaihe 2: Vahvista asennus (3 minuuttia)

Asennuksen j√§lkeen k√§ynnist√§ komentorivi uudelleen ja varmista, ett√§ Foundry Local toimii:

```powershell
# Check if Foundry Local is installed correctly
foundry --version

# View available commands
foundry --help
```

Odotettu tulos n√§ytt√§√§ version tiedot ja k√§ytett√§viss√§ olevat komennot.

### Vaihe 3: M√§√§rit√§ Python-ymp√§rist√∂ (5 minuuttia)

Luo omistettu Python-ymp√§rist√∂ t√§t√§ ty√∂pajaa varten:

**Windows:**
```powershell
# Create virtual environment
py -m venv .venv

# Activate environment
.\.venv\Scripts\Activate.ps1

# Upgrade pip and install dependencies
python -m pip install --upgrade pip
pip install foundry-local-sdk openai
```

**macOS/Linux:**
```bash
# Create virtual environment
python3 -m venv .venv

# Activate environment
source .venv/bin/activate

# Upgrade pip and install dependencies
python -m pip install --upgrade pip
pip install foundry-local-sdk openai
```

### Vaihe 4: Suorita ensimm√§inen mallisi (7 minuuttia)

Nyt suoritetaan ensimm√§inen teko√§lymalli paikallisesti!

#### Aloita Phi-4 Mini -mallilla (suositeltu aloitusmalli)

```powershell
# Download and start phi-4-mini (lightweight, fast)
foundry model run phi-4-mini

# Test the model with a simple prompt
foundry model run phi-4-mini --prompt "Hello, introduce yourself in one sentence"
```

> [!TIP]
> T√§m√§ komento lataa mallin (ensimm√§isell√§ kerralla) ja k√§ynnist√§√§ Foundry Local -palvelun automaattisesti.

#### Tarkista k√§ynniss√§ olevat palvelut

```powershell
# List available models (shows downloaded models)
foundry model list

# Check service status
foundry service status

# See what models are cached locally
foundry cache list
```

#### Kokeile muita malleja

Kun phi-4-mini toimii, kokeile muita malleja:

```powershell
# Larger model with better capabilities
foundry model run gpt-oss-20b --prompt "Explain edge AI in simple terms"

# Fast, efficient model
foundry model run qwen2.5-0.5b --prompt "What are the benefits of local AI inference?"
```

### Vaihe 5: Rakenna ensimm√§inen chat-sovelluksesi (10 minuuttia)

Nyt luodaan Python-sovellus, joka k√§ytt√§√§ juuri k√§ynnistettyj√§ malleja.

#### Luo chat-skripti

Luo uusi tiedosto nimelt√§ `my_first_chat.py` (tai k√§yt√§ annettua esimerkki√§):

```python
#!/usr/bin/env python3
"""
My First Foundry Local Chat Application
Using FoundryLocalManager for automatic service management
"""

import os
from foundry_local import FoundryLocalManager
from openai import OpenAI

def main():
    # Get model alias from environment or use default
    alias = os.getenv("FOUNDRY_LOCAL_ALIAS", "phi-4-mini")
    
    try:
        # Initialize Foundry Local Manager (auto-starts service, downloads model)
        manager = FoundryLocalManager(alias)
        
        # Create OpenAI client pointing to local endpoint
        client = OpenAI(
            base_url=manager.endpoint,
            api_key=manager.api_key or "not-needed"
        )
        
        # Get the actual model ID for this alias
        model_id = manager.get_model_info(alias).id
        
        print("ü§ñ Welcome to your first local AI chat!")
        print(f"ÔøΩ Using model: {alias} -> {model_id}")
        print(f"üåê Endpoint: {manager.endpoint}")
        print("ÔøΩüí° Type 'quit' to exit\n")
        
    except Exception as e:
        print(f"‚ùå Failed to initialize Foundry Local: {e}")
        print("üí° Make sure Foundry Local is installed: foundry --version")
        return
    
    while True:
        # Get user input
        user_message = input("You: ").strip()
        
        if user_message.lower() in ['quit', 'exit', 'bye']:
            print("üëã Goodbye!")
            break
            
        if not user_message:
            continue
            
        try:
            # Send message to local AI model
            response = client.chat.completions.create(
                model=model_id,
                messages=[
                    {"role": "system", "content": "You are a helpful AI assistant running locally."},
                    {"role": "user", "content": user_message}
                ],
                max_tokens=200,
                temperature=0.7
            )
            
            # Display the response
            ai_response = response.choices[0].message.content
            print(f"ü§ñ AI: {ai_response}\n")
            
        except Exception as e:
            print(f"‚ùå Error: {e}")
            print("üí° Check service status: foundry service status\n")

if __name__ == "__main__":
    main()
```

> [!TIP]
> **Liittyv√§t esimerkit**: Edistyneemp√§√§n k√§ytt√∂√∂n katso:
>
> - **Python-esimerkki**: `Workshop/samples/session01/chat_bootstrap.py` - Sis√§lt√§√§ suoratoistovastaukset ja virheenk√§sittelyn
> - **Jupyter Notebook**: `Workshop/notebooks/session01_chat_bootstrap.ipynb` - Interaktiivinen versio yksityiskohtaisilla selityksill√§

#### Testaa chat-sovelluksesi

```powershell
# No need to manually start models - FoundryLocalManager handles this!
# Just run your chat application
python my_first_chat.py
```

Vaihtoehto: K√§yt√§ suoraan annettuja esimerkkej√§

```powershell
# Try the complete sample with streaming support
cd Workshop/samples
python -m session01.chat_bootstrap "Your question here"
```

Tai tutki interaktiivista notebookia
Avaa Workshop/notebooks/session01_chat_bootstrap.ipynb VS Codessa

Kokeile n√§it√§ esimerkkikeskusteluja:

- "Mik√§ on Microsoft Foundry Local?"
- "Listaa 3 hy√∂ty√§ teko√§lymallien paikallisesta k√§yt√∂st√§"
- "Auttaako minua ymm√§rt√§m√§√§n edge AI:ta"

## Mit√§ olet saavuttanut

Onnittelut! Olet onnistuneesti:

1. ‚úÖ **Asentanut Foundry Localin** ja varmistanut sen toimivuuden
2. ‚úÖ **K√§ynnist√§nyt ensimm√§isen teko√§lymallisi** (phi-4-mini) paikallisesti
3. ‚úÖ **Testannut eri malleja** komentorivill√§
4. ‚úÖ **Rakentanut chat-sovelluksen**, joka yhdistyy paikalliseen teko√§lyyn
5. ‚úÖ **Kokenut paikallisen teko√§lyn inferenssin** ilman pilvipalveluriippuvuutta

## Ymm√§rr√§, mit√§ tapahtui

### Paikallinen teko√§lyn inferenssi

- Teko√§lymallisi toimii t√§ysin omalla tietokoneellasi
- Dataa ei l√§hetet√§ pilveen
- Vastaukset luodaan paikallisesti CPU/GPU:ta k√§ytt√§en
- Yksityisyys ja tietoturva s√§ilyv√§t

### Mallien hallinta

- `foundry model run` lataa ja k√§ynnist√§√§ malleja
- **FoundryLocalManager SDK** k√§ynnist√§√§ palvelun ja lataa mallin automaattisesti
- Mallit tallennetaan paikallisesti tulevaa k√§ytt√∂√§ varten
- Useita malleja voidaan ladata, mutta yleens√§ yksi toimii kerrallaan
- Palvelu hallitsee mallien elinkaaren automaattisesti

### SDK vs CLI -l√§hestymistavat

- **CLI-l√§hestymistapa**: Mallien manuaalinen hallinta komennolla `foundry model run <malli>`
- **SDK-l√§hestymistapa**: Automaattinen palvelu- ja mallinhallinta `FoundryLocalManager(alias)` avulla
- **Suositus**: K√§yt√§ SDK:ta sovelluksiin, CLI:t√§ testaukseen ja tutkimiseen

## Yleisimpien komentojen viite

### Keskeiset CLI-komennot

```powershell
# Installation & Setup
foundry --version              # Check installation
foundry --help                 # View all commands

# Model Management
foundry model list             # List available models
foundry model run <model>      # Download and start a model
foundry model run <model> --prompt "text"  # One-shot prompt
foundry cache list             # Show downloaded models

# Service Management
foundry service status         # Check if service is running
foundry service start          # Start the service manually
foundry service stop           # Stop the service
```

### Mallisuositukset

- **phi-4-mini**: Paras aloitusmalli - nopea, kevyt, hyv√§ laatu
- **qwen2.5-0.5b**: Nopein inferenssi, v√§h√§inen muistin k√§ytt√∂
- **gpt-oss-20b**: Korkealaatuiset vastaukset, vaatii enemm√§n resursseja
- **deepseek-coder-1.3b**: Optimoitu ohjelmointi- ja kooditeht√§viin

## Vianetsint√§

### "Foundry-komentoa ei l√∂ydy"

**Ratkaisu:**

```powershell
# Restart your terminal after installation
# Or manually add to PATH (Windows)
$env:PATH += ";C:\Program Files\Microsoft\FoundryLocal"
```

### "Mallin lataus ep√§onnistui"

**Ratkaisu:**

```powershell
# Check available system memory
foundry service status

# Try a smaller model first
foundry model run phi-4-mini

# Check disk space for model downloads
# Models are stored in: %USERPROFILE%\.foundry\models (Windows)
```

### "Yhteys localhostiin hyl√§tty"

**Ratkaisu:**

```powershell
# Check if service is running
foundry service status

# Start service if needed
foundry service start

# Verify the port (default is 5273)
# Check for port conflicts with: netstat -an | findstr 5273
```

## Seuraavat askeleet

### V√§litt√∂m√§t toimenpiteet

1. **Kokeile** eri malleja ja kysymyksi√§
2. **Muokkaa** chat-sovellustasi kokeillaksesi eri malleja
3. **Luo** omia kysymyksi√§ ja testaa vastauksia
4. **Tutki** Istunto 2: RAG-sovellusten rakentaminen

### Edistynyt oppimispolku

1. **Istunto 2**: Rakenna teko√§lyratkaisuja RAG:lla (Retrieval-Augmented Generation)
2. **Istunto 3**: Vertaa eri avoimen l√§hdekoodin malleja
3. **Istunto 4**: Ty√∂skentele huippumallien kanssa
4. **Istunto 5**: Rakenna monen agentin teko√§lyj√§rjestelmi√§

## Ymp√§rist√∂muuttujat (valinnainen)

Edistyneemp√§√§ k√§ytt√∂√§ varten voit asettaa n√§m√§ ymp√§rist√∂muuttujat:

| Muuttuja | Tarkoitus | Esimerkki |
|----------|---------|---------|
| `FOUNDRY_LOCAL_ALIAS` | Oletusmalli k√§ytett√§v√§ksi | `phi-4-mini` |
| `FOUNDRY_LOCAL_ENDPOINT` | Ylikirjoita p√§√§tepisteen URL | `http://localhost:5273/v1` |

Luo `.env`-tiedosto projektikansioosi:
```
FOUNDRY_LOCAL_ALIAS=phi-4-mini
FOUNDRY_LOCAL_ENDPOINT=auto
```

## Lis√§resurssit

### Dokumentaatio

- [Foundry Local Python SDK -viite](https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/reference/reference-sdk?pivots=programming-language-python)
- [Foundry Local -asennusopas](https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/install)
- [Mallikatalogi](https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/models)

### Esimerkkikoodi

- **Session01 Python-esimerkki**: `Workshop/samples/session01/chat_bootstrap.py` - T√§ydellinen chat-sovellus suoratoistolla
- **Session01 Notebook**: `Workshop/notebooks/session01_chat_bootstrap.ipynb` - Interaktiivinen opas  
- [Module08 Sample 01](../Module08/samples/01/README.md) - REST Chat Quickstart
- [Module08 Sample 02](../Module08/samples/02/README.md) - OpenAI SDK -integraatio
- [Module08 Sample 03](../Module08/samples/03/README.md) - Mallien l√∂yt√§minen ja vertailu

### Yhteis√∂

- [Foundry Local GitHub -keskustelut](https://github.com/microsoft/Foundry-Local/discussions)
- [Azure AI -yhteis√∂](https://techcommunity.microsoft.com/category/artificialintelligence)

---

**Istunnon kesto**: 30 minuuttia k√§yt√§nn√∂n harjoittelua + 15 minuuttia kysymyksi√§ ja vastauksia  
**Vaikeustaso**: Aloittelija  
**Esivaatimukset**: Windows 11/macOS 11+, Python 3.10+, yll√§pit√§j√§n oikeudet

## Ty√∂pajan esimerkkitilanne

### Todellinen konteksti

**Tilanne**: Yrityksen IT-tiimi haluaa arvioida laitteessa tapahtuvaa teko√§lyn inferenssi√§ k√§sitell√§kseen arkaluontoista ty√∂ntekij√§palautetta ilman datan l√§hett√§mist√§ ulkoisiin palveluihin.

**Tavoitteesi**: Todista, ett√§ paikalliset teko√§lymallit voivat tuottaa laadukkaita vastauksia alle sekunnin viiveell√§ samalla, kun tietosuoja s√§ilyy t√§ysin.

### Testikysymykset

K√§yt√§ n√§it√§ kysymyksi√§ varmistaaksesi asetuksesi:

```json
[
    "List two benefits of local inference.",
    "Summarize why keeping data on device improves privacy.",
    "Give one trade-off when choosing a small model over a large model."
]
```

### Onnistumisen kriteerit

- ‚úÖ Kaikki kysymykset saavat vastaukset alle 2 sekunnissa
- ‚úÖ Data ei poistu paikalliselta koneeltasi
- ‚úÖ Vastaukset ovat osuvia ja hy√∂dyllisi√§
- ‚úÖ Chat-sovelluksesi toimii sujuvasti

T√§m√§ validointi varmistaa, ett√§ Foundry Local -asennuksesi on valmis edistyneempiin ty√∂pajoihin istunnoissa 2-6.

---

<!-- CO-OP TRANSLATOR DISCLAIMER START -->
**Vastuuvapauslauseke**:  
T√§m√§ asiakirja on k√§√§nnetty k√§ytt√§m√§ll√§ teko√§lypohjaista k√§√§nn√∂spalvelua [Co-op Translator](https://github.com/Azure/co-op-translator). Vaikka pyrimme tarkkuuteen, huomioithan, ett√§ automaattiset k√§√§nn√∂kset voivat sis√§lt√§√§ virheit√§ tai ep√§tarkkuuksia. Alkuper√§inen asiakirja sen alkuper√§isell√§ kielell√§ tulisi katsoa ensisijaiseksi l√§hteeksi. Kriittisen tiedon osalta suositellaan ammattimaista ihmisk√§√§nn√∂st√§. Emme ole vastuussa v√§√§rink√§sityksist√§ tai virhetulkinnoista, jotka johtuvat t√§m√§n k√§√§nn√∂ksen k√§yt√∂st√§.
<!-- CO-OP TRANSLATOR DISCLAIMER END -->