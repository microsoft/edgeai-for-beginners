<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "6485323e2963241723d26eb0e0e9a492",
  "translation_date": "2025-12-15T19:42:31+00:00",
  "source_file": "Module05/03.SLMOps-Finetuing.md",
  "language_code": "te"
}
-->
# విభాగం 3: ఫైన్-ట్యూనింగ్ - నిర్దిష్ట పనుల కోసం మోడల్స్‌ను అనుకూలీకరించడం

## విషయ సూచిక
1. [ఫైన్-ట్యూనింగ్ పరిచయం](../../../Module05)
2. [ఫైన్-ట్యూనింగ్ ఎందుకు ముఖ్యం](../../../Module05)
3. [ఫైన్-ట్యూనింగ్ రకాలు](../../../Module05)
4. [Microsoft Olive తో ఫైన్-ట్యూనింగ్](../../../Module05)
5. [ప్రాక్టికల్ ఉదాహరణలు](../../../Module05)
6. [ఉత్తమ ఆచారాలు మరియు మార్గదర్శకాలు](../../../Module05)
7. [అధునాతన సాంకేతికతలు](../../../Module05)
8. [మూల్యాంకనం మరియు పర్యవేక్షణ](../../../Module05)
9. [సాధారణ సవాళ్లు మరియు పరిష్కారాలు](../../../Module05)
10. [సారాంశం](../../../Module05)

## ఫైన్-ట్యూనింగ్ పరిచయం

**ఫైన్-ట్యూనింగ్** అనేది ఒక శక్తివంతమైన మెషీన్ లెర్నింగ్ సాంకేతికత, ఇది ముందుగా శిక్షణ పొందిన మోడల్‌ను నిర్దిష్ట పనులు చేయడానికి లేదా ప్రత్యేక డేటాసెట్‌లతో పని చేయడానికి అనుకూలీకరించడం. మోడల్‌ను మొదలుండి శిక్షణ ఇవ్వడం కాకుండా, ఫైన్-ట్యూనింగ్ ఇప్పటికే నేర్చుకున్న జ్ఞానాన్ని ఉపయోగించి మీ ప్రత్యేక అవసరాలకు అనుగుణంగా సర్దుబాటు చేస్తుంది.

### ఫైన్-ట్యూనింగ్ అంటే ఏమిటి?

ఫైన్-ట్యూనింగ్ అనేది ఒక రకమైన **ట్రాన్స్‌ఫర్ లెర్నింగ్**:
- పెద్ద డేటాసెట్‌ల నుండి సాధారణ నమూనాలను నేర్చుకున్న ముందుగా శిక్షణ పొందిన మోడల్‌తో ప్రారంభిస్తారు
- మీ ప్రత్యేక డేటాసెట్ ఉపయోగించి మోడల్ అంతర్గత పారామితులను సర్దుబాటు చేస్తారు
- విలువైన జ్ఞానాన్ని నిలుపుకుని, మీ పనికి మోడల్‌ను ప్రత్యేకంగా తయారు చేస్తారు

ఇది ఒక నైపుణ్యవంతుడైన వంటకారుడికి కొత్త వంటకాన్ని నేర్పించడం లాంటిది - వారు వంటక శాస్త్రాన్ని ఇప్పటికే అర్థం చేసుకున్నారు, కానీ కొత్త శైలికి ప్రత్యేక సాంకేతికతలు మరియు రుచులను నేర్చుకోవాలి.

### ముఖ్య లాభాలు

- **సమయ సామర్థ్యం**: మొదలుండి శిక్షణ ఇవ్వడం కంటే గణనీయంగా వేగంగా ఉంటుంది
- **డేటా సామర్థ్యం**: మంచి పనితీరు కోసం తక్కువ డేటా అవసరం
- **ఖర్చు-సమర్థవంతం**: తక్కువ కంప్యూటింగ్ అవసరాలు
- **మంచి పనితీరు**: మొదలుండి శిక్షణ ఇచ్చినదానికంటే మెరుగైన ఫలితాలు సాధిస్తుంది
- **వనరుల ఆప్టిమైజేషన్**: శక్తివంతమైన AIని చిన్న బృందాలు మరియు సంస్థలకు అందుబాటులో ఉంచుతుంది

## ఫైన్-ట్యూనింగ్ ఎందుకు ముఖ్యం

### వాస్తవ ప్రపంచ అనువర్తనాలు

ఫైన్-ట్యూనింగ్ అనేక సందర్భాలలో అవసరం:

**1. డొమైన్ అనుకూలీకరణ**
- వైద్య AI: సాధారణ భాషా మోడల్స్‌ను వైద్య పదజాలం మరియు క్లినికల్ నోట్స్ కోసం అనుకూలీకరించడం
- చట్ట సాంకేతికత: చట్టపరమైన డాక్యుమెంట్ల విశ్లేషణ మరియు ఒప్పంద సమీక్ష కోసం మోడల్స్‌ను ప్రత్యేకీకరించడం
- ఆర్థిక సేవలు: ఆర్థిక నివేదికల విశ్లేషణ మరియు ప్రమాద అంచనాకు మోడల్స్‌ను అనుకూలీకరించడం

**2. పని ప్రత్యేకీకరణ**
- కంటెంట్ ఉత్పత్తి: నిర్దిష్ట రచనా శైలులు లేదా టోన్ల కోసం ఫైన్-ట్యూనింగ్
- కోడ్ ఉత్పత్తి: నిర్దిష్ట ప్రోగ్రామింగ్ భాషలు లేదా ఫ్రేమ్‌వర్క్‌ల కోసం మోడల్స్‌ను అనుకూలీకరించడం
- అనువాదం: నిర్దిష్ట భాష జంటలు లేదా సాంకేతిక డొమైన్‌ల కోసం పనితీరు మెరుగుపరచడం

**3. సంస్థ అనువర్తనాలు**
- కస్టమర్ సర్వీస్: సంస్థ-స్పెసిఫిక్ పదజాలాన్ని అర్థం చేసుకునే చాట్‌బాట్లను సృష్టించడం
- అంతర్గత డాక్యుమెంటేషన్: సంస్థ ప్రక్రియలకు పరిచయమైన AI సహాయకులను నిర్మించడం
- పరిశ్రమ-స్పెసిఫిక్ పరిష్కారాలు: రంగానికి సంబంధించిన పదజాలం మరియు వర్క్‌ఫ్లోలను అర్థం చేసుకునే మోడల్స్‌ను అభివృద్ధి చేయడం

## ఫైన్-ట్యూనింగ్ రకాలు

### 1. పూర్తి ఫైన్-ట్యూనింగ్ (ఇన్‌స్ట్రక్షన్ ఫైన్-ట్యూనింగ్)

పూర్తి ఫైన్-ట్యూనింగ్‌లో, శిక్షణ సమయంలో అన్ని మోడల్ పారామితులు నవీకరించబడతాయి. ఈ విధానం:
- గరిష్ట అనుకూలత మరియు పనితీరు సామర్థ్యాన్ని అందిస్తుంది
- గణనీయమైన కంప్యూటింగ్ వనరులు అవసరం
- మోడల్ యొక్క పూర్తిగా కొత్త వెర్షన్‌ను ఉత్పత్తి చేస్తుంది
- మీరు పెద్ద శిక్షణ డేటా మరియు కంప్యూటింగ్ వనరులు ఉన్న సందర్భాలలో ఉత్తమం

### 2. పారామితి-సమర్థవంతమైన ఫైన్-ట్యూనింగ్ (PEFT)

PEFT పద్ధతులు కేవలం చిన్న పారామితుల ఉపసమితిని నవీకరిస్తాయి, ఇది ప్రక్రియను మరింత సమర్థవంతంగా చేస్తుంది:

#### లో-రాంక్ అడాప్టేషన్ (LoRA)
- ఉన్న బరువులకు చిన్న శిక్షణీయ ర్యాంక్ డీకంపోజిషన్ మ్యాట్రిక్స్‌లను జోడిస్తుంది
- శిక్షణీయ పారామితుల సంఖ్యను గణనీయంగా తగ్గిస్తుంది
- పూర్తి ఫైన్-ట్యూనింగ్‌కు సమీప పనితీరు నిలుపుకుంటుంది
- వివిధ అనుకూలీకరణల మధ్య సులభంగా మార్పిడి చేయగలదు

#### QLoRA (క్వాంటైజ్డ్ LoRA)
- LoRAని క్వాంటైజేషన్ సాంకేతికతలతో కలిపి ఉపయోగిస్తుంది
- మెమరీ అవసరాలను మరింత తగ్గిస్తుంది
- వినియోగదారుల హార్డ్వేర్‌పై పెద్ద మోడల్స్‌ను ఫైన్-ట్యూన్ చేయగలదు
- సమర్థవంతత మరియు పనితీరు మధ్య సమతుల్యతను అందిస్తుంది

#### అడాప్టర్లు
- ఉన్న లేయర్ల మధ్య చిన్న న్యూరల్ నెట్‌వర్క్‌లను చొప్పిస్తుంది
- బేస్ మోడల్‌ను ఫ్రోజెన్‌గా ఉంచి లక్ష్యంగా ఫైన్-ట్యూనింగ్ చేయగలదు
- మోడల్ అనుకూలీకరణకు మాడ్యులర్ విధానాన్ని అనుమతిస్తుంది

### 3. పని-స్పెసిఫిక్ ఫైన్-ట్యూనింగ్

నిర్దిష్ట డౌన్‌స్ట్రీమ్ పనుల కోసం మోడల్స్‌ను అనుకూలీకరించడంపై దృష్టి:
- **వర్గీకరణ**: వర్గీకరణ పనుల కోసం మోడల్స్ సర్దుబాటు
- **ఉత్పత్తి**: కంటెంట్ సృష్టి మరియు టెక్స్ట్ ఉత్పత్తికి ఆప్టిమైజ్ చేయడం
- **ఎక్స్‌ట్రాక్షన్**: సమాచారం సేకరణ మరియు నేమ్డ్ ఎంటిటీ గుర్తింపు కోసం ఫైన్-ట్యూనింగ్
- **సారాంశం**: డాక్యుమెంట్ సారాంశానికి మోడల్స్‌ను ప్రత్యేకీకరించడం

## Microsoft Olive తో ఫైన్-ట్యూనింగ్

Microsoft Olive అనేది సమగ్ర మోడల్ ఆప్టిమైజేషన్ టూల్‌కిట్, ఇది ఫైన్-ట్యూనింగ్ ప్రక్రియను సులభతరం చేస్తూ ఎంటర్‌ప్రైజ్-గ్రేడ్ ఫీచర్లను అందిస్తుంది.

### Microsoft Olive అంటే ఏమిటి?

Microsoft Olive ఒక ఓపెన్-సోర్స్ మోడల్ ఆప్టిమైజేషన్ టూల్:
- వివిధ హార్డ్వేర్ లక్ష్యాల కోసం ఫైన్-ట్యూనింగ్ వర్క్‌ఫ్లోలను సరళతరం చేస్తుంది
- ప్రముఖ మోడల్ ఆర్కిటెక్చర్ల (Llama, Phi, Qwen, Gemma) కోసం బిల్ట్-ఇన్ సపోర్ట్ అందిస్తుంది
- క్లౌడ్ మరియు లోకల్ డిప్లాయ్‌మెంట్ ఎంపికలను అందిస్తుంది
- Azure ML మరియు ఇతర Microsoft AI సేవలతో సజావుగా ఇంటిగ్రేట్ అవుతుంది
- ఆటోమేటిక్ ఆప్టిమైజేషన్ మరియు క్వాంటైజేషన్‌ను మద్దతు ఇస్తుంది

### ముఖ్య ఫీచర్లు

- **హార్డ్వేర్-అవేర్ ఆప్టిమైజేషన్**: నిర్దిష్ట హార్డ్వేర్ (CPU, GPU, NPU) కోసం మోడల్స్‌ను ఆటోమేటిక్‌గా ఆప్టిమైజ్ చేస్తుంది
- **బహుళ ఫార్మాట్ సపోర్ట్**: PyTorch, Hugging Face, మరియు ONNX మోడల్స్‌తో పని చేస్తుంది
- **ఆటోమేటెడ్ వర్క్‌ఫ్లోలు**: మాన్యువల్ కాన్ఫిగరేషన్ మరియు ట్రయల్-అండ్-ఎర్రర్‌ను తగ్గిస్తుంది
- **ఎంటర్‌ప్రైజ్ ఇంటిగ్రేషన్**: Azure ML మరియు క్లౌడ్ డిప్లాయ్‌మెంట్‌లకు బిల్ట్-ఇన్ సపోర్ట్
- **విస్తరించదగిన ఆర్కిటెక్చర్**: కస్టమ్ ఆప్టిమైజేషన్ సాంకేతికతలను అనుమతిస్తుంది

### ఇన్‌స్టాలేషన్ మరియు సెటప్

#### ప్రాథమిక ఇన్‌స్టాలేషన్

```bash
# ఒక వర్చువల్ ఎన్విరాన్‌మెంట్ సృష్టించండి
python -m venv olive-env
source olive-env/bin/activate  # విండోస్‌లో: olive-env\Scripts\activate

# ఆటో-ఆప్టిమైజేషన్ ఫీచర్లతో Olive ను ఇన్‌స్టాల్ చేయండి
pip install olive-ai[auto-opt]

# అదనపు ఆధారాలను ఇన్‌స్టాల్ చేయండి
pip install transformers onnxruntime-genai
```

#### ఐచ్ఛిక ఆధారాలు

```bash
# CPU ఆప్టిమైజేషన్ కోసం
pip install olive-ai[cpu]

# GPU ఆప్టిమైజేషన్ కోసం
pip install olive-ai[gpu]

# DirectML (విండోస్) కోసం
pip install olive-ai[directml]

# Azure ML సమీకరణ కోసం
pip install olive-ai[azureml]
```

#### ఇన్‌స్టాలేషన్ నిర్ధారించుకోండి

```bash
# ఒలివ్ CLI అందుబాటులో ఉందో లేదో తనిఖీ చేయండి
olive --help

# ఇన్‌స్టాలేషన్‌ను ధృవీకరించండి
python -c "import olive; print('Olive installed successfully')"
```

## ప్రాక్టికల్ ఉదాహరణలు

### ఉదాహరణ 1: Olive CLI తో ప్రాథమిక ఫైన్-ట్యూనింగ్

ఈ ఉదాహరణ చిన్న భాషా మోడల్‌ను ఫ్రేజ్ వర్గీకరణ కోసం ఫైన్-ట్యూన్ చేయడం చూపిస్తుంది:

#### దశ 1: మీ వాతావరణాన్ని సిద్ధం చేయండి

```bash
# పరిసరాన్ని సెట్ చేయండి
mkdir fine-tuning-project
cd fine-tuning-project

# నమూనా డేటాను డౌన్లోడ్ చేయండి (ఐచ్ఛికం - ఒలివ్ డేటాను స్వయంచాలకంగా పొందవచ్చు)
huggingface-cli login  # ప్రైవేట్ డేటాసెట్‌లను ఉపయోగిస్తుంటే
```

#### దశ 2: మోడల్‌ను ఫైన్-ట్యూన్ చేయండి

```bash
# ప్రాథమిక ఫైన్-ట్యూనింగ్ కమాండ్
olive finetune \
  --model_name_or_path meta-llama/Llama-3.2-1B-Instruct \
  --trust_remote_code \
  --output_path models/llama/ft \
  --data_name xxyyzzz/phrase_classification \
  --text_template "<|start_header_id|>user<|end_header_id|>\n{phrase}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n{tone}" \
  --method lora \
  --max_steps 100 \
  --log_level 1
```

#### దశ 3: డిప్లాయ్‌మెంట్ కోసం ఆప్టిమైజ్ చేయండి

```bash
# ఆప్టిమైజ్డ్ ఇన్ఫరెన్స్ కోసం ONNX ఫార్మాట్‌కు మార్చండి
olive auto-opt \
  --model_name_or_path models/llama/ft/model \
  --adapter_path models/llama/ft/adapter \
  --device cpu \
  --provider CPUExecutionProvider \
  --use_ort_genai \
  --output_path models/llama/onnx \
  --log_level 1
```

### ఉదాహరణ 2: కస్టమ్ డేటాసెట్‌తో అధునాతన కాన్ఫిగరేషన్

#### దశ 1: కస్టమ్ డేటాసెట్ సిద్ధం చేయండి

మీ శిక్షణ డేటాతో JSON ఫైల్ సృష్టించండి:

```json
[
  {
    "input": "What is machine learning?",
    "output": "Machine learning is a subset of artificial intelligence that enables computers to learn and improve from experience without being explicitly programmed."
  },
  {
    "input": "Explain neural networks",
    "output": "Neural networks are computing systems inspired by biological neural networks that learn from data through interconnected nodes or neurons."
  }
]
```

#### దశ 2: కాన్ఫిగరేషన్ ఫైల్ సృష్టించండి

```yaml
# olive-config.yaml
model:
  type: PyTorchModel
  config:
    model_path: "microsoft/DialoGPT-medium"
    task: "text-generation"

data_configs:
  - name: "custom_dataset"
    type: "HuggingfaceContainer"
    load_dataset_config:
      data_files: "path/to/your/dataset.json"
      split: "train"
    pre_process_data_config:
      text_template: "User: {input}\nAssistant: {output}"

passes:
  lora:
    type: LoRA
    config:
      r: 16
      lora_alpha: 32
      target_modules: ["c_attn", "c_proj"]
      modules_to_save: ["ln_f", "lm_head"]
```

#### దశ 3: ఫైన్-ట్యూనింగ్ అమలు చేయండి

```bash
# కస్టమ్ కాన్ఫిగరేషన్‌తో నడపండి
olive run --config olive-config.yaml --setup
```

### ఉదాహరణ 3: మెమరీ సామర్థ్యం కోసం QLoRA ఫైన్-ట్యూనింగ్

```bash
# మెమరీ సామర్థ్యాన్ని మెరుగుపరచడానికి QLoRA తో ఫైన్-ట్యూన్ చేయండి
olive finetune \
  --method qlora \
  --model_name_or_path meta-llama/Meta-Llama-3-8B \
  --data_name nampdn-ai/tiny-codes \
  --train_split "train[:4096]" \
  --eval_split "train[4096:4224]" \
  --text_template "### Language: {programming_language} \n### Question: {prompt} \n### Answer: {response}" \
  --per_device_train_batch_size 16 \
  --per_device_eval_batch_size 16 \
  --max_steps 150 \
  --logging_steps 50 \
  --output_path adapters/tiny-codes
```

## ఉత్తమ ఆచారాలు మరియు మార్గదర్శకాలు

### డేటా సిద్ధత

**1. డేటా నాణ్యత పరిమాణం కంటే ముఖ్యం**
- తక్కువ నాణ్యత గల పెద్ద డేటా కంటే ఉన్నత నాణ్యత గల, విభిన్న ఉదాహరణలను ప్రాధాన్యం ఇవ్వండి
- డేటా మీ లక్ష్య వినియోగానికి ప్రతినిధిగా ఉండాలి
- డేటాను సక్రమంగా శుభ్రపరచి ప్రీప్రాసెస్ చేయండి

**2. డేటా ఫార్మాట్ మరియు టెంప్లేట్లు**
- అన్ని శిక్షణ ఉదాహరణలలో సुसంగతమైన ఫార్మాటింగ్ ఉపయోగించండి
- మీ వినియోగానికి సరిపోయే స్పష్టమైన ఇన్‌పుట్-అవుట్‌పుట్ టెంప్లేట్లు సృష్టించండి
- ఇన్‌స్ట్రక్షన్-ట్యూన్డ్ మోడల్స్ కోసం సరైన ఇన్‌స్ట్రక్షన్ ఫార్మాటింగ్ చేర్చండి

**3. డేటాసెట్ విభజన**
- 10-20% డేటాను వాలిడేషన్ కోసం వదిలివేయండి
- ట్రైన్/వాలిడేషన్ విభజనలలో సమాన పంపిణీని నిర్వహించండి
- వర్గీకరణ పనుల కోసం స్ట్రాటిఫైడ్ శాంప్లింగ్‌ను పరిగణించండి

### శిక్షణ కాన్ఫిగరేషన్

**1. లెర్నింగ్ రేట్ ఎంపిక**
- ఫైన్-ట్యూనింగ్ కోసం చిన్న లెర్నింగ్ రేట్లతో (1e-5 నుండి 1e-4) ప్రారంభించండి
- మెరుగైన కన్వర్జెన్స్ కోసం లెర్నింగ్ రేట్ షెడ్యూలింగ్ ఉపయోగించండి
- నష్ట వక్రాలను పర్యవేక్షించి రేట్లను సర్దుబాటు చేయండి

**2. బ్యాచ్ సైజ్ ఆప్టిమైజేషన్**
- అందుబాటులో ఉన్న మెమరీతో బ్యాచ్ సైజ్‌ను సమతుల్యం చేయండి
- పెద్ద సమర్థవంతమైన బ్యాచ్ సైజ్‌ల కోసం గ్రాడియంట్ అక్యుమ్యులేషన్ ఉపయోగించండి
- బ్యాచ్ సైజ్ మరియు లెర్నింగ్ రేట్ మధ్య సంబంధాన్ని పరిగణించండి

**3. శిక్షణ వ్యవధి**
- ఓవర్‌ఫిట్టింగ్ నివారించడానికి వాలిడేషన్ మెట్రిక్స్‌ను పర్యవేక్షించండి
- వాలిడేషన్ పనితీరు స్థిరపడినప్పుడు ఎర్లీ స్టాప్పింగ్ ఉపయోగించండి
- పునరుద్ధరణ మరియు విశ్లేషణ కోసం రెగ్యులర్‌గా చెక్పాయింట్‌లను సేవ్ చేయండి

### మోడల్ ఎంపిక

**1. బేస్ మోడల్ ఎంపిక**
- సాధ్యమైనంత వరకు సమాన డొమైన్‌లపై ముందుగా శిక్షణ పొందిన మోడల్స్‌ను ఎంచుకోండి
- మీ కంప్యూటింగ్ పరిమితులకు అనుగుణంగా మోడల్ పరిమాణాన్ని పరిగణించండి
- వాణిజ్య ఉపయోగం కోసం లైసెన్సింగ్ అవసరాలను పరిశీలించండి

**2. ఫైన్-ట్యూనింగ్ పద్ధతి ఎంపిక**
- వనరుల పరిమితుల ఉన్న వాతావరణాల్లో LoRA/QLoRA ఉపయోగించండి
- గరిష్ట పనితీరు అవసరమైతే పూర్తి ఫైన్-ట్యూనింగ్ ఎంచుకోండి
- బహుళ పనుల సందర్భాల్లో అడాప్టర్-ఆధారిత పద్ధతులను పరిగణించండి

### వనరు నిర్వహణ

**1. హార్డ్వేర్ ఆప్టిమైజేషన్**
- మీ మోడల్ పరిమాణం మరియు పద్ధతికి సరిపోయే హార్డ్వేర్‌ను ఎంచుకోండి
- గ్రాడియంట్ చెక్పాయింటింగ్‌తో GPU మెమరీని సమర్థవంతంగా ఉపయోగించండి
- పెద్ద మోడల్స్ కోసం క్లౌడ్ ఆధారిత పరిష్కారాలను పరిగణించండి

**2. మెమరీ నిర్వహణ**
- అందుబాటులో ఉన్నప్పుడు మిక్స్‌డ్ ప్రెసిషన్ శిక్షణను ఉపయోగించండి
- మెమరీ పరిమితుల కోసం గ్రాడియంట్ అక్యుమ్యులేషన్ అమలు చేయండి
- శిక్షణ సమయంలో GPU మెమరీ వినియోగాన్ని పర్యవేక్షించండి

## అధునాతన సాంకేతికతలు

### బహుళ అడాప్టర్ శిక్షణ

బేస్ మోడల్‌ను పంచుకుంటూ వివిధ పనుల కోసం బహుళ అడాప్టర్‌లను శిక్షణ ఇవ్వండి:

```bash
# బహుళ LoRA అడాప్టర్లను శిక్షణ ఇవ్వండి
olive finetune --method lora --task_name "classification" --output_path adapters/classifier
olive finetune --method lora --task_name "generation" --output_path adapters/generator

# బహుళ అడాప్టర్ ONNX మోడల్‌ను ఉత్పత్తి చేయండి
olive generate-adapter \
  --base_model_path models/base \
  --adapter_paths adapters/classifier,adapters/generator \
  --output_path models/multi-adapter
```

### హైపర్‌పారామితి ఆప్టిమైజేషన్

వ్యవస్థాపక హైపర్‌పారామితి ట్యూనింగ్‌ను అమలు చేయండి:

```yaml
# hyperparameter-search.yaml
search_strategy:
  type: "random"
  num_trials: 20

search_space:
  learning_rate:
    type: "float"
    low: 1e-6
    high: 1e-3
    log: true
  
  lora_r:
    type: "int"
    low: 8
    high: 64
  
  batch_size:
    type: "choice"
    values: [8, 16, 32]
```

### కస్టమ్ లాస్ ఫంక్షన్లు

డొమైన్-స్పెసిఫిక్ లాస్ ఫంక్షన్లను అమలు చేయండి:

```python
# కస్టమ్_లాస్.py
import torch
import torch.nn as nn

class CustomContrastiveLoss(nn.Module):
    def __init__(self, margin=1.0):
        super(CustomContrastiveLoss, self).__init__()
        self.margin = margin
        
    def forward(self, output1, output2, label):
        euclidean_distance = nn.functional.pairwise_distance(output1, output2)
        loss_contrastive = torch.mean((1-label) * torch.pow(euclidean_distance, 2) +
                                    (label) * torch.pow(torch.clamp(self.margin - euclidean_distance, min=0.0), 2))
        return loss_contrastive
```

## మూల్యాంకనం మరియు పర్యవేక్షణ

### మెట్రిక్స్ మరియు మూల్యాంకనం

**1. ప్రామాణిక మెట్రిక్స్**
- **ఖచ్చితత్వం**: వర్గీకరణ పనుల కోసం మొత్తం సరైనత
- **పర్ప్లెక్సిటీ**: భాషా మోడలింగ్ నాణ్యత కొలమానం
- **BLEU/ROUGE**: టెక్స్ట్ ఉత్పత్తి మరియు సారాంశ నాణ్యత
- **F1 స్కోరు**: వర్గీకరణ కోసం సమతుల్యమైన ప్రెసిషన్ మరియు రీకాల్

**2. డొమైన్-స్పెసిఫిక్ మెట్రిక్స్**
- **పని-స్పెసిఫిక్ బెంచ్‌మార్కులు**: మీ డొమైన్ కోసం స్థాపించబడిన బెంచ్‌మార్కులను ఉపయోగించండి
- **మానవ మూల్యాంకనం**: సబ్జెక్టివ్ పనుల కోసం మానవ అంచనాను చేర్చండి
- **వ్యాపార మెట్రిక్స్**: వాస్తవ వ్యాపార లక్ష్యాలతో సరిపోల్చండి

**3. మూల్యాంకన సెటప్**

```python
# evaluation_script.py
from transformers import AutoTokenizer, AutoModelForCausalLM
from datasets import load_dataset
import torch

def evaluate_model(model_path, test_dataset, metric_type="accuracy"):
    """
    Evaluate fine-tuned model performance
    """
    tokenizer = AutoTokenizer.from_pretrained(model_path)
    model = AutoModelForCausalLM.from_pretrained(model_path)
    
    # ఇక్కడ మూల్యాంకన తర్కం
    results = {}
    
    for example in test_dataset:
        # ఉదాహరణను ప్రాసెస్ చేసి మెట్రిక్స్ లెక్కించండి
        pass
    
    return results
```

### శిక్షణ పురోగతిని పర్యవేక్షణ

**1. నష్టం ట్రాకింగ్**
```bash
# విస్తృత లాగింగ్‌ను ప్రారంభించండి
olive finetune \
  --logging_steps 10 \
  --eval_steps 50 \
  --save_steps 100 \
  --logging_dir ./logs \
  --report_to tensorboard
```

**2. వాలిడేషన్ పర్యవేక్షణ**
- శిక్షణ నష్టంతో పాటు వాలిడేషన్ నష్టాన్ని ట్రాక్ చేయండి
- ఓవర్‌ఫిట్టింగ్ సంకేతాల కోసం పర్యవేక్షించండి (శిక్షణ నష్టం తగ్గుతుండగా వాలిడేషన్ నష్టం పెరుగుతుంటే)
- వాలిడేషన్ మెట్రిక్స్ ఆధారంగా ఎర్లీ స్టాప్పింగ్ ఉపయోగించండి

**3. వనరు పర్యవేక్షణ**
- GPU/CPU వినియోగాన్ని పర్యవేక్షించండి
- మెమరీ వినియోగ నమూనాలను ట్రాక్ చేయండి
- శిక్షణ వేగం మరియు థ్రూపుట్‌ను పర్యవేక్షించండి

## సాధారణ సవాళ్లు మరియు పరిష్కారాలు

### సవాలు 1: ఓవర్‌ఫిట్టింగ్

**లక్షణాలు:**
- శిక్షణ నష్టం తగ్గుతూనే వాలిడేషన్ నష్టం పెరుగుతుంది
- శిక్షణ మరియు వాలిడేషన్ పనితీరు మధ్య పెద్ద తేడా
- కొత్త డేటాపై తక్కువ సాధారణీకరణ

**పరిష్కారాలు:**
```yaml
# Regularization techniques
passes:
  lora:
    type: LoRA
    config:
      r: 16  # Reduce rank to prevent overfitting
      lora_alpha: 16  # Lower alpha value
      lora_dropout: 0.1  # Add dropout
      weight_decay: 0.01  # L2 regularization
```

### సవాలు 2: మెమరీ పరిమితులు

**పరిష్కారాలు:**
- గ్రాడియంట్ చెక్పాయింటింగ్ ఉపయోగించండి
- గ్రాడియంట్ అక్యుమ్యులేషన్ అమలు చేయండి
- పారామితి-సమర్థవంతమైన పద్ధతులు (LoRA, QLoRA) ఎంచుకోండి
- పెద్ద మోడల్స్ కోసం మోడల్ పారలలిజం ఉపయోగించండి

```bash
# మెమరీ-సమర్థవంతమైన శిక్షణ
olive finetune \
  --method qlora \
  --gradient_checkpointing true \
  --per_device_train_batch_size 1 \
  --gradient_accumulation_steps 16
```

### సవాలు 3: నెమ్మదిగా శిక్షణ

**పరిష్కారాలు:**
- డేటా లోడింగ్ పైప్‌లైన్లను ఆప్టిమైజ్ చేయండి
- మిక్స్‌డ్ ప్రెసిషన్ శిక్షణ ఉపయోగించండి
- సమర్థవంతమైన బ్యాచింగ్ వ్యూహాలను అమలు చేయండి
- పెద్ద డేటాసెట్‌ల కోసం పంపిణీ శిక్షణ పరిగణించండి

```yaml
# Performance optimization
training_config:
  fp16: true  # Mixed precision
  dataloader_num_workers: 4
  optim: "adamw_torch"
  lr_scheduler_type: "cosine"
```

### సవాలు 4: తక్కువ పనితీరు

**నిర్ధారణ దశలు:**
1. డేటా నాణ్యత మరియు ఫార్మాటింగ్‌ను నిర్ధారించండి
2. లెర్నింగ్ రేట్ మరియు శిక్షణ వ్యవధిని తనిఖీ చేయండి
3. బేస్ మోడల్ ఎంపికను మూల్యాంకనం చేయండి
4. ప్రీప్రాసెసింగ్ మరియు టోకనైజేషన్‌ను సమీక్షించండి

**పరిష్కారాలు:**
- శిక్షణ డేటా వైవిధ్యాన్ని పెంచండి
- లెర్నింగ్ రేట్ షెడ్యూల్‌ను సర్దుబాటు చేయండి
- వేరే బేస్ మోడల్స్ ప్రయత్నించండి
- డేటా ఆగ్మెంటేషన్ సాంకేతికతలను అమలు చేయండి

## సారాంశం

ఫైన్-ట్యూనింగ్ అనేది ఆధునిక AI సామర్థ్యాలకు ప్రజలందరికీ సులభంగా అందుబాటులో ఉండే శక్తివంతమైన సాంకేతికత. Microsoft Olive వంటి టూల్స్‌ను ఉపయోగించి, సంస్థలు తమ నిర్దిష్ట అవసరాలకు అనుగుణంగా ముందుగా శిక్షణ పొందిన మోడల్స్‌ను సమర్థవంతంగా అనుకూలీకరించవచ్చు, పనితీరు మరియు వనరు పరిమితుల కోసం ఆప్టిమైజ్ చేస్తూ.

### ముఖ్యమైన పాఠాలు

1. **సరైన పద్ధతిని ఎంచుకోండి**: మీ కంప్యూటింగ్ వనరులు మరియు పనితీరు అవసరాల ఆధారంగా ఫైన్-ట్యూనింగ్ పద్ధతులను ఎంచుకోండి
2. **డేటా నాణ్యత ముఖ్యం**: ఉన్నత నాణ్యత గల, ప్రతినిధి శిక్షణ డేటాలో పెట్టుబడి పెట్టండి
3. **పర్యవేక్షించండి మరియు పునరావృతం చేయండి**: మీ మోడల్స్‌ను నిరంతరం మూల్యాంకనం చేసి మెరుగుపరచండి
4. **టూల్స్‌ను ఉపయోగించండి**: Olive వంటి ఫ్రేమ్‌వర్క్‌లను ఉపయోగించి ప్రక్రియను సులభతరం చేసి ఆప్టిమైజ్ చేయండి
5. **డిప్లాయ్‌మెంట్‌ను పరిగణించండి**: ప్రారంభం నుండే మోడల్ ఆప్టిమైజేషన్ మరియు డిప్లాయ్‌మెంట్ కోసం ప్రణాళిక రూపొందించండి


## ➡️ తదుపరి ఏమిటి

- [04: డిప్లాయ్‌మెంట్ - ప్రొడక్షన్-రెడీ మోడల్ అమలు](./04.SLMOps.Deployment.md)

---

<!-- CO-OP TRANSLATOR DISCLAIMER START -->
**అస్పష్టత**:  
ఈ పత్రాన్ని AI అనువాద సేవ [Co-op Translator](https://github.com/Azure/co-op-translator) ఉపయోగించి అనువదించబడింది. మేము ఖచ్చితత్వానికి ప్రయత్నించినప్పటికీ, ఆటోమేటెడ్ అనువాదాల్లో పొరపాట్లు లేదా తప్పిదాలు ఉండవచ్చు. మూల పత్రం దాని స్వదేశీ భాషలో అధికారిక మూలంగా పరిగణించాలి. ముఖ్యమైన సమాచారానికి, ప్రొఫెషనల్ మానవ అనువాదం సిఫార్సు చేయబడుతుంది. ఈ అనువాదం వాడకంలో ఏర్పడిన ఏవైనా అపార్థాలు లేదా తప్పుదారుల కోసం మేము బాధ్యత వహించము.
<!-- CO-OP TRANSLATOR DISCLAIMER END -->