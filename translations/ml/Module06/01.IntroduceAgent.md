<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "44bc28c27b993c5fb988791b7a115705",
  "translation_date": "2025-12-15T21:42:25+00:00",
  "source_file": "Module06/01.IntroduceAgent.md",
  "language_code": "ml"
}
-->
# AI เดเดเดจเตเดฑเตเดเดณเตเด เดเตเดฑเดฟเดฏ เดญเดพเดทเดพ เดฎเตเดกเดฒเตเดเดณเตเด: เดธเดฎเดเตเดฐ เดเตเดกเต

## เดชเดฐเดฟเดเดฏเด

เด เดเตเดฏเตเดเตเดเตเดฑเดฟเดฏเดฒเดฟเตฝ, เดจเดพเด AI เดเดเดจเตเดฑเตเดเดณเตเด เดเตเดฑเดฟเดฏ เดญเดพเดทเดพ เดฎเตเดกเดฒเตเดเดณเตเด (SLMs) เดเดตเดฏเตเดเต เดเดกเตเดเต เดเดเดชเตเดฏเตเดเตเดเดฟเดเดเต เดชเดฐเดฟเดธเตเดฅเดฟเดคเดฟเดเดณเดฟเดฒเต เดเดงเตเดจเดฟเด เดจเดเดชเตเดชเดพเดเตเดเตฝ เดคเดจเตเดคเตเดฐเดเตเดเดณเตเด เดชเดฐเดฟเดถเตเดงเดฟเดเตเดเตเด. เดเดเดจเตเดฑเดฟเดเต AIเดฏเตเดเต เดเดเดฟเดธเตเดฅเดพเดจ เดเดถเดฏเดเตเดเตพ, SLM เดเดชเตเดฑเตเดฑเดฟเดฎเตเดธเตเดทเตป เดธเดพเดเตเดเตเดคเดฟเดเดตเดฟเดฆเตเดฏเดเตพ, เดธเตเดฐเตเดคเดธเตเดธเต-เดชเดฐเดฟเดฎเดฟเดค เดเดชเดเดฐเดฃเดเตเดเตพเดเตเดเต เดชเตเดฐเดพเดฏเตเดเดฟเด เดตเดฟเดจเตเดฏเดพเดธ เดคเดจเตเดคเตเดฐเดเตเดเตพ, เดชเตเดฐเตเดกเดเตเดทเตป-เดธเดเตเดเดฎเดพเดฏ เดเดเดจเตเดฑเต เดธเดฟเดธเตเดฑเตเดฑเดเตเดเตพ เดจเดฟเตผเดฎเตเดฎเดฟเดเตเดเดพเตป Microsoft Agent Framework เดเดจเตเดจเดฟเดต เดเตพเดชเตเดชเตเดเต เดจเดพเด เดชเดเดฟเดเตเดเตเด.

2025-เตฝ เดเตเดคเตเดฐเดฟเดฎ เดฌเตเดฆเตเดงเดฟเดฎเตเดเตเดเดฟเดจเตเดฑเต เดฐเดเดเด เดเดฐเต เดชเดพเดฐเดกเตเด เดฎเดพเดฑเตเดฑเด เดเดจเตเดญเดตเดฟเดเตเดเตเดจเตเดจเต. 2023 เดเดพเดฑเตเดฑเตเดฌเตเดเตเดเตเดเดณเตเดเต เดตเตผเดทเดฎเดพเดฏเดฟเดฐเตเดจเตเดจเดชเตเดชเตเตพ, 2024 เดเตเดชเตเดฒเดฑเตเดฑเตเดเดณเตเดเต เดตเดณเตผเดเตเด เดเดฃเตเดเต, 2025 AI เดเดเดจเตเดฑเตเดเตพเดเตเดเต เดธเดฎเตผเดชเตเดชเดฟเดเตเดเดฟเดฐเดฟเดเตเดเตเดจเตเดจเต โ เดเดฟเดจเตเดคเดฟเดเตเดเตเดจเตเดจ, เดคเตผเดเตเดเด เดเตเดฏเตเดฏเตเดจเตเดจ, เดชเดฆเตเดงเดคเดฟเดฏเดฟเดเตเดจเตเดจ, เดเดชเดเดฐเดฃเดเตเดเตพ เดเดชเดฏเตเดเดฟเดเตเดเตเดจเตเดจ, เดเตเดฑเดเตเด เดฎเดจเตเดทเตเดฏ เดเดเดชเตเดเดฒเตเดเต เดชเตเดฐเดตเตผเดคเตเดคเดจเดเตเดเตพ เดจเดฟเตผเดตเดนเดฟเดเตเดเตเดจเตเดจ เดฌเตเดฆเตเดงเดฟเดฎเตเดเตเดเตเดณเตเดณ เดธเดฟเดธเตเดฑเตเดฑเดเตเดเตพ, เดเดพเดฐเตเดฏเดเตเดทเดฎเดฎเดพเดฏ เดเตเดฑเดฟเดฏ เดญเดพเดทเดพ เดฎเตเดกเดฒเตเดเตพ เดเดชเดฏเตเดเดฟเดเตเดเต เดถเดเตเดคเดฟเดชเตเดชเตเดเตเดคเตเดคเดชเตเดชเตเดเตเดเดต. Microsoft Agent Framework เด เดฌเตเดฆเตเดงเดฟเดฎเตเดเตเดเตเดณเตเดณ เดธเดฟเดธเตเดฑเตเดฑเดเตเดเตพ เดเดซเตโเดฒเตเตป เดเดกเตเดเต เดเดเดฟเดธเตเดฅเดพเดจ เดถเตเดทเดฟเดเดณเตเดเต เดจเดฟเตผเดฎเตเดฎเดฟเดเตเดเดพเตป เดฎเตเตปเดจเดฟเดฐ เดชเดฐเดฟเดนเดพเดฐเดฎเดพเดฏเดฟ เดเดฏเดฐเตเดจเตเดจเต.

## เดชเดเดจ เดฒเดเตเดทเตเดฏเดเตเดเตพ

เด เดเตเดฏเตเดเตเดเตเดฑเดฟเดฏเดฒเดฟเดจเตเดฑเต เดเดตเดธเดพเดจเด, เดจเดฟเดเตเดเตพเดเตเดเต เดเดดเดฟเดฏเตเด:

- ๐ค AI เดเดเดจเตเดฑเตเดเดณเตเด เดเดเดจเตเดฑเดฟเดเต เดธเดฟเดธเตเดฑเตเดฑเดเตเดเดณเตเด เดเดเดฟเดธเตเดฅเดพเดจ เดเดถเดฏเดเตเดเตพ เดฎเดจเดธเดฟเดฒเดพเดเตเดเตเด
- ๐ฌ เดเดเดจเตเดฑเดฟเดเต เดชเตเดฐเดฏเตเดเดเตเดเดณเดฟเตฝ เดตเดฒเดฟเดฏ เดญเดพเดทเดพ เดฎเตเดกเดฒเตเดเดณเต เดเดชเตเดเตเดทเดฟเดเตเดเต เดเตเดฑเดฟเดฏ เดญเดพเดทเดพ เดฎเตเดกเดฒเตเดเดณเตเดเต เดเตเดฃเดเตเดเตพ เดคเดฟเดฐเดฟเดเตเดเดฑเดฟเดฏเตเด
- ๐ เดเดกเตเดเต เดเดเดชเตเดฏเตเดเตเดเดฟเดเดเต เดชเดฐเดฟเดธเตเดฅเดฟเดคเดฟเดเตพเดเตเดเดพเดฏเดฟ เดเดงเตเดจเดฟเด SLM เดตเดฟเดจเตเดฏเดพเดธ เดคเดจเตเดคเตเดฐเดเตเดเตพ เดชเดเดฟเดเตเดเตเด
- ๐ฑ เดฏเดพเดฅเดพเตผเดคเตเดฅเตเดฏ เดชเตเดฐเดฏเตเดเดเตเดเตพเดเตเดเต เดชเตเดฐเดพเดฏเตเดเดฟเดเดฎเดพเดฏ SLM-เดถเดเตเดคเดฟเดฏเตเดณเตเดณ เดเดเดจเตเดฑเตเดเตพ เดจเดเดชเตเดชเดฟเดฒเดพเดเตเดเตเด
- ๐๏ธ Microsoft Agent Framework เดเดชเดฏเตเดเดฟเดเตเดเต เดชเตเดฐเตเดกเดเตเดทเตป-เดธเดเตเดเดฎเดพเดฏ เดเดเดจเตเดฑเตเดเตพ เดจเดฟเตผเดฎเตเดฎเดฟเดเตเดเตเด
- ๐ เดชเตเดฐเดพเดฆเตเดถเดฟเด LLM, SLM เดธเดเดฏเตเดเดจเดคเตเดคเตเดเต เดเดซเตโเดฒเตเตป เดเดกเตเดเต-เดเดเดฟเดธเตเดฅเดพเดจ เดเดเดจเตเดฑเตเดเตพ เดตเดฟเดจเตเดฏเดธเดฟเดเตเดเตเด
- ๐ง เดเดกเตเดเต เดตเดฟเดจเตเดฏเดพเดธเดคเตเดคเดฟเดจเดพเดฏเดฟ Microsoft Agent Framework-เดจเต Foundry Local-เดจเตเดชเตเดชเด เดธเดเดฏเตเดเดฟเดชเตเดชเดฟเดเตเดเตเด

## AI เดเดเดจเตเดฑเตเดเตพ เดฎเดจเดธเดฟเดฒเดพเดเตเดเตฝ: เดเดเดฟเดธเตเดฅเดพเดจเดตเตเด เดตเตผเดเตเดเตเดเดฐเดฃเดตเตเด

### เดจเดฟเตผเดตเดเดจเดเดฏเตเด เดฎเตเดเตเดฏ เดเดถเดฏเดเตเดเดณเตเด

เดเตเดคเตเดฐเดฟเดฎ เดฌเตเดฆเตเดงเดฟเดฎเตเดเตเดเต (AI) เดเดเดจเตเดฑเต เดเดจเตเดจเดคเต เดเดฐเต เดเดชเดฏเตเดเตเดคเดพเดตเดฟเดจเต เดฎเดฑเตเดฑเตเดฐเต เดธเดฟเดธเตเดฑเตเดฑเดคเตเดคเดฟเดจเต เดตเตเดฃเตเดเดฟ เดธเตเดตเดฏเด เดชเตเดฐเดตเตผเดคเตเดคเดจเดเตเดเตพ เดจเดฟเตผเดตเดนเดฟเดเตเดเดพเตป เดเดดเดฟเดตเตเดณเตเดณ เดธเดฟเดธเตเดฑเตเดฑเด เดเดฒเตเดฒเตเดเตเดเดฟเตฝ เดชเตเดฐเตเดเตเดฐเดพเดฎเดพเดฃเต, เดเดคเดฟเดจเตเดฑเต เดชเตเดฐเดตเตเดคเตเดคเดฟ เดชเตเดฐเดตเดพเดนเด เดฐเตเดชเดเตฝเดชเตเดชเดจ เดเตเดฏเตเดคเต เดฒเดญเตเดฏเดฎเดพเดฏ เดเดชเดเดฐเดฃเดเตเดเตพ เดเดชเดฏเตเดเดฟเดเตเดเตเดจเตเดจเต. เดจเดฟเดเตเดเดณเตเดเต เดเตเดฆเตเดฏเดเตเดเตพเดเตเดเต เดฎเดฑเตเดชเดเดฟ เดจเตฝเดเตเดจเตเดจ เดชเดฐเดฎเตเดชเดฐเดพเดเดค AI-เดฏเต เดเดชเตเดเตเดทเดฟเดเตเดเต, เดเดเดจเตเดฑเต เดธเตเดตเดคเดจเตเดคเตเดฐเดฎเดพเดฏเดฟ เดชเตเดฐเดตเตผเดคเตเดคเดฟเดเตเดเต เดฒเดเตเดทเตเดฏเดเตเดเตพ เดจเตเดเดพเตป เดเดดเดฟเดฏเตเด.

### เดเดเดจเตเดฑเต เดตเตผเดเตเดเตเดเดฐเดฃ เดเดเดจ

เดตเดฟเดตเดฟเดง เดเดเดชเตเดฏเตเดเตเดเดฟเดเดเต เดธเดพเดนเดเดฐเตเดฏเดเตเดเตพเดเตเดเต เดเดจเตเดฏเตเดเตเดฏเดฎเดพเดฏ เดเดเดจเตเดฑเต เดคเดฐเด เดคเดฟเดฐเดเตเดเตเดเตเดเตเดเดพเตป เดเดเดจเตเดฑเต เดชเดฐเดฟเดงเดฟเดเตพ เดฎเดจเดธเดฟเดฒเดพเดเตเดเตเด:

- **๐ฌ เดฒเดณเดฟเดคเดฎเดพเดฏ เดฑเดฟเดซเตเดฒเดเตเดธเต เดเดเดจเตเดฑเตเดเตพ**: เดเดเตป เดเดจเตเดญเดตเดฟเดเตเดเตเดจเตเดจ เดเดพเดฐเตเดฏเดเตเดเตพเดเตเดเต เดชเตเดฐเดคเดฟเดเดฐเดฟเดเตเดเตเดจเตเดจ เดจเดฟเดฏเดฎเดพเดงเดฟเดทเตเดเดฟเดค เดธเดฟเดธเตเดฑเตเดฑเดเตเดเตพ (เดคเตเตผเดฎเตเดธเตเดฑเตเดฑเดพเดฑเตเดฑเตเดเตพ, เดเดเดฟเดธเตเดฅเดพเดจ เดเดเตเดเตเดฎเตเดทเตป)
- **๐ฑ เดฎเตเดกเตฝ-เดเดงเดฟเดทเตเดเดฟเดค เดเดเดจเตเดฑเตเดเตพ**: เดเดจเตเดคเดฐเดฟเด เดเดตเดธเตเดฅเดฏเตเด เดเตผเดฎเตเดฎเดฏเตเด เดจเดฟเดฒเดจเดฟเตผเดคเตเดคเตเดจเตเดจ เดธเดฟเดธเตเดฑเตเดฑเดเตเดเตพ (เดฑเตเดฌเตเดเตเดเต เดตเดพเดเตเดฏเตเดฎเตเดเตพ, เดจเดพเดตเดฟเดเตเดทเตป เดธเดฟเดธเตเดฑเตเดฑเดเตเดเตพ)
- **โ๏ธ เดฒเดเตเดทเตเดฏ-เดเดงเดฟเดทเตเดเดฟเดค เดเดเดจเตเดฑเตเดเตพ**: เดฒเดเตเดทเตเดฏเดเตเดเตพ เดจเตเดเดพเตป เดชเดฆเตเดงเดคเดฟเดฏเดฟเดเตเดเดฏเตเด เดชเตเดฐเดตเตผเดคเตเดคเดจเดเตเดเตพ เดจเดเดชเตเดชเดฟเดฒเดพเดเตเดเตเดเดฏเตเด เดเตเดฏเตเดฏเตเดจเตเดจ เดธเดฟเดธเตเดฑเตเดฑเดเตเดเตพ (เดฑเตเดเตเดเต เดชเตเดฒเดพเดจเดฑเตเดเตพ, เดเดพเดธเตโเดเต เดทเตเดกเตเดฏเตเดณเดฑเตเดเตพ)
- **๐ง เดชเดเดจ เดเดเดจเตเดฑเตเดเตพ**: เดธเดฎเดฏเด เดเตเดเตเดฎเตเดชเตเตพ เดชเตเดฐเดเดเดจเด เดฎเตเดเตเดเดชเตเดชเตเดเตเดคเตเดคเตเดจเตเดจ เดเดจเตเดฏเตเดเตเดฏเดฎเดพเดฏ เดธเดฟเดธเตเดฑเตเดฑเดเตเดเตพ (เดถเตเดชเดพเตผเดถเดพ เดธเดฟเดธเตเดฑเตเดฑเดเตเดเตพ, เดตเตเดฏเดเตเดคเดฟเดเดค เดธเดนเดพเดฏเดฟเดเตพ)

### AI เดเดเดจเตเดฑเตเดเดณเตเดเต เดชเตเดฐเดงเดพเดจ เดเตเดฃเดเตเดเตพ

เดเดกเตเดเต เดเดเดชเตเดฏเตเดเตเดเดฟเดเดเต เดชเตเดฐเดฏเตเดเดเตเดเตพเดเตเดเต เดเดจเตเดฏเตเดเตเดฏเดฎเดพเดฏ เดจเดฟเดฐเดตเดงเดฟ เดเดเดฟเดธเตเดฅเดพเดจ เดเตเดฃเดเตเดเตพ AI เดเดเดจเตเดฑเตเดเตพ เดจเตฝเดเตเดจเตเดจเต:

**เดชเตเดฐเดตเตผเดคเตเดคเดจ เดธเตเดตเดพเดคเดจเตเดคเตเดฐเตเดฏเด**: เดเดเดจเตเดฑเตเดเตพ เดธเตเดฅเดฟเดฐเดฎเดพเดฏ เดฎเดจเตเดทเตเดฏ เดฎเตเตฝเดจเตเดเตเดเด เดเดฒเตเดฒเดพเดคเต เดธเตเดตเดคเดจเตเดคเตเดฐเดฎเดพเดฏเดฟ เดชเตเดฐเดตเตผเดคเตเดคเดจเด เดจเดเดคเตเดคเตเดจเตเดจเต, เดฏเดฅเดพเตผเดคเตเดฅ เดธเดฎเดฏ เดชเตเดฐเดฏเตเดเดเตเดเตพเดเตเดเต เดเดจเตเดฏเตเดเตเดฏเดฎเดพเดฃเต. เดเตเดฑเดเตเด เดฎเตเตฝเดจเตเดเตเดเด เดเดตเดถเตเดฏเดชเตเดชเตเดเตเดเดฏเตเด เดเดจเตเดฏเตเดเตเดฏเดฎเดพเดฏ เดชเตเดฐเตเดฎเดพเดฑเตเดฑเด เดจเดฟเดฒเดจเดฟเตผเดคเตเดคเตเดเดฏเตเด เดเตเดฏเตเดฏเตเดจเตเดจเต, เดธเตเดฐเตเดคเดธเตเดธเต-เดชเดฐเดฟเดฎเดฟเดค เดเดชเดเดฐเดฃเดเตเดเดณเดฟเตฝ เดตเดฟเดจเตเดฏเดพเดธเด เดธเดพเดงเตเดฏเดฎเดพเดเตเดเตเดจเตเดจเต.

**เดตเดฟเดจเตเดฏเดพเดธ เดธเตเดเดฐเตเดฏเด**: เดเดจเตเดฑเตผเดจเตเดฑเตเดฑเต เดฌเดจเตเดงเด เดเดตเดถเตเดฏเดฎเดฟเดฒเตเดฒเดพเดคเต เดเดชเดเดฐเดฃเดคเตเดคเดฟเตฝ เดคเดจเตเดจเต AI เดเดดเดฟเดตเตเดเตพ เดจเตฝเดเตเดจเตเดจเต, เดชเตเดฐเดพเดฆเตเดถเดฟเด เดชเตเดฐเตเดธเดธเตเดธเดฟเดเดเดฟเดฒเตเดเต เดธเตเดตเดเดพเดฐเตเดฏเดคเดฏเตเด เดธเตเดฐเดเตเดทเดฏเตเด เดฎเตเดเตเดเดชเตเดชเตเดเตเดคเตเดคเตเดจเตเดจเต, เดกเตเดฎเตเดฏเตเตป-เดจเดฟเตผเดฆเตเดฆเดฟเดทเตเด เดชเตเดฐเดฏเตเดเดเตเดเตพเดเตเดเต เดเดทเตเดเดพเดจเตเดธเตเดคเดฎเดพเดเตเดเดพเดตเตเดจเตเดจเดคเตเด เดตเดฟเดตเดฟเดง เดเดกเตเดเต เดเดเดชเตเดฏเตเดเตเดเดฟเดเดเต เดชเดฐเดฟเดธเตเดฅเดฟเดคเดฟเดเตพเดเตเดเดพเดฏเดฟ เดเดจเตเดฏเตเดเตเดฏเดตเตเดฎเดพเดฃเต.

**เดเตเดฒเดตเต เดเดพเดฐเตเดฏเดเตเดทเดฎเดค**: เดเตเดฒเตเดกเต เดเดเดฟเดธเตเดฅเดพเดจ เดชเดฐเดฟเดนเดพเดฐเดเตเดเดณเต เดเดชเตเดเตเดทเดฟเดเตเดเต เดเตเดฒเดตเต เดเตเดฑเดเตเด เดตเดฟเดจเตเดฏเดพเดธเด, เดชเตเดฐเดตเตผเดคเตเดคเดจ เดเตเดฒเดตเตเดเตพ เดเตเดฑเดตเต, เดเดกเตเดเต เดชเตเดฐเดฏเตเดเดเตเดเตพเดเตเดเต เดเตเดฑเดเตเด เดฌเดพเตปเดกเตโเดตเดฟเดกเตเดคเตเดคเต เดเดตเดถเตเดฏเดเดค เดเดจเตเดจเดฟเดต เดเดเดจเตเดฑเต เดธเดฟเดธเตเดฑเตเดฑเดเตเดเตพ เดจเตฝเดเตเดจเตเดจเต.

## เดเดงเตเดจเดฟเด เดเตเดฑเดฟเดฏ เดญเดพเดทเดพ เดฎเตเดกเตฝ เดคเดจเตเดคเตเดฐเดเตเดเตพ

### SLM (เดเตเดฑเดฟเดฏ เดญเดพเดทเดพ เดฎเตเดกเตฝ) เดเดเดฟเดธเตเดฅเดพเดจเดเตเดเตพ

เดเตเดฑเดฟเดฏ เดญเดพเดทเดพ เดฎเตเดกเตฝ (SLM) เดเดจเตเดจเดคเต เดธเดพเดงเดพเดฐเดฃ เดเดชเดญเตเดเตเดคเต เดเดฒเดเตเดเตเดฐเตเดฃเดฟเดเต เดเดชเดเดฐเดฃเดคเตเดคเดฟเตฝ เดซเดฟเดฑเตเดฑเต เดเตเดฏเตเดคเต เดเดฐเต เดเดชเดฏเตเดเตเดคเดพเดตเดฟเดจเตเดฑเต เดเดเดจเตเดฑเดฟเดเต เดเดญเตเดฏเตผเดคเตเดฅเดจเดเตพ เดธเตเดตเดฟเดเตเดเตเดจเตเดจเดคเดฟเดจเต เดชเตเดฐเดพเดฏเตเดเดฟเดเดฎเดพเดฏ เดเตเดฑเดเตเด เดตเตเดเดฒเตเดฏเดคเตเดคเตเดเต เดเตปเดซเดฑเตปเดธเต เดจเดเดคเตเดคเดพเตป เดเดดเดฟเดฏเตเดจเตเดจ เดญเดพเดทเดพ เดฎเตเดกเดฒเดพเดฃเต. เดธเดพเดงเดพเดฐเดฃเดฏเดพเดฏเดฟ, 10 เดฌเดฟเดฒเตเดฏเตบ เดชเดพเดฐเดพเดฎเตเดฑเตเดฑเดฑเตเดเตพเดเตเดเต เดคเดพเดดเตเดฏเตเดณเตเดณ เดฎเตเดกเดฒเตเดเดณเดพเดฃเต SLMเดเตพ.

**เดซเตเตผเดฎเดพเดฑเตเดฑเต เดเดฃเตเดเตเดคเตเดคเตฝ เดธเดตเดฟเดถเตเดทเดคเดเตพ**: SLMเดเตพ เดตเดฟเดตเดฟเดง เดเตเดตเดพเดฃเตเดเตเดธเตเดทเตป เดจเดฟเดฒเดเตพเดเตเดเต เดเดงเตเดจเดฟเด เดชเดฟเดจเตเดคเตเดฃ, เดเตเดฐเตเดธเต-เดชเตเดฒเดพเดฑเตเดฑเตเดซเตเด เดเดจเตเดฏเตเดเตเดฏเดค, เดฏเดฅเดพเตผเดคเตเดฅ เดธเดฎเดฏ เดชเตเดฐเดเดเดจ เดเดชเตเดฑเตเดฑเดฟเดฎเตเดธเตเดทเตป, เดเดกเตเดเต เดตเดฟเดจเตเดฏเดพเดธ เดถเตเดทเดฟเดเตพ เดเดจเตเดจเดฟเดต เดจเตฝเดเตเดจเตเดจเต. เดชเตเดฐเดพเดฆเตเดถเดฟเด เดชเตเดฐเตเดธเดธเตเดธเดฟเดเดเดฟเดฒเตเดเต เดฎเตเดเตเดเดชเตเดชเตเดเตเด เดธเตเดตเดเดพเดฐเตเดฏเดคเดฏเตเด เดฌเตเดฐเตเดธเตผ เดเดเดฟเดธเตเดฅเดพเดจ เดตเดฟเดจเตเดฏเดพเดธเดคเตเดคเดฟเดจเดพเดฏเดฟ WebGPU เดชเดฟเดจเตเดคเตเดฃเดฏเตเด เดฒเดญเตเดฏเดฎเดพเดฃเต.

**เดเตเดตเดพเดฃเตเดเตเดธเตเดทเตป เดฒเตเดตเตฝ เดถเตเดเดฐเดเตเดเตพ**: เดเดจเดชเตเดฐเดฟเดฏ SLM เดซเตเตผเดฎเดพเดฑเตเดฑเตเดเดณเดฟเตฝ เดฎเตเดฌเตเตฝ เดชเตเดฐเดฏเตเดเดเตเดเตพเดเตเดเต เดคเตเดฒเตเดฏเดฎเดพเดฏ เดธเดเดฏเตเดเดจเด เดจเตฝเดเตเดจเตเดจ Q4_K_M, เดเตเดฃเดจเดฟเดฒเดตเดพเดฐ-เดเตเดตเดพเดฃเตเดเตเดธเตเดทเตป เดธเตเดฐเตเดธเต Q5_K_S, เดถเดเตเดคเดฎเดพเดฏ เดเดกเตเดเต เดเดชเดเดฐเดฃเดเตเดเดณเดฟเตฝ เดเดเดฆเตเดถเด เดฏเดฅเดพเตผเดคเตเดฅ เดเตเดคเตเดฏเดคเดฏเตเดณเตเดณ Q8_0, เดเดคเตเดฏเดจเตเดคเด เดเตเดฑเดเตเด เดธเตเดฐเตเดคเดธเตเดธเต เดธเดพเดนเดเดฐเตเดฏเดเตเดเตพเดเตเดเต เดชเดฐเตเดเตเดทเดฃ เดซเตเตผเดฎเดพเดฑเตเดฑเดพเดฏ Q2_K เดเดจเตเดจเดฟเดต เดเตพเดชเตเดชเตเดเตเดจเตเดจเต.

### GGUF (เดเดจเดฑเตฝ GGML เดฏเตเดฃเดฟเดตเตเดดเตเดธเตฝ เดซเตเตผเดฎเดพเดฑเตเดฑเต) SLM เดตเดฟเดจเตเดฏเดพเดธเดคเตเดคเดฟเดจเดพเดฏเดฟ

GGUF CPU, เดเดกเตเดเต เดเดชเดเดฐเดฃเดเตเดเดณเดฟเตฝ เดเตเดตเดพเดฃเตเดเตเดธเตเดกเต SLMเดเตพ เดตเดฟเดจเตเดฏเดธเดฟเดเตเดเดพเตป เดชเตเดฐเดพเดฅเดฎเดฟเด เดซเตเตผเดฎเดพเดฑเตเดฑเดพเดฏเดฟ เดชเตเดฐเดตเตผเดคเตเดคเดฟเดเตเดเตเดจเตเดจเต, เดชเตเดฐเดคเตเดฏเตเดเดฟเดเตเดเต เดเดเดจเตเดฑเดฟเดเต เดชเตเดฐเดฏเตเดเดเตเดเตพเดเตเดเต เดเดชเตเดฑเตเดฑเดฟเดฎเตเดธเต เดเตเดฏเตเดคเดฟเดฐเดฟเดเตเดเตเดจเตเดจเต:

**เดเดเดจเตเดฑเต-เดเดชเตเดฑเตเดฑเดฟเดฎเตเดธเตเดกเต เดธเดตเดฟเดถเตเดทเดคเดเตพ**: เดเตเตพ เดเตเดณเดฟเดเดเต, เดเดเดจเดพเดชเดฐเดฎเดพเดฏ เดเดเตเดเตเดชเตเดเตเดเต เดธเตเดทเตเดเดฟ, เดฎเตพเดเตเดเดฟ-เดเตเตบ เดธเดเดญเดพเดทเดฃเดเตเดเตพ เดเดจเตเดจเดฟเดตเดฏเตเดเตเดเต เดฎเตเดเตเดเดชเตเดชเตเดเตเด เดชเดฟเดจเตเดคเตเดฃเดฏเตเดเต SLM เดชเดฐเดฟเดตเตผเดคเตเดคเดจเดตเตเด เดตเดฟเดจเตเดฏเดพเดธเดตเตเด เดธเดฎเดเตเดฐเดฎเดพเดฏเดฟ เดจเตฝเดเตเดจเตเดจเต. เดเตเดฐเตเดธเต-เดชเตเดฒเดพเดฑเตเดฑเตเดซเตเด เดเดจเตเดฏเตเดเตเดฏเดค เดตเตเดฏเดคเตเดฏเดธเตเดค เดเดกเตเดเต เดเดชเดเดฐเดฃเดเตเดเดณเดฟเตฝ เดเดเตเดเตเดค เดเดเดจเตเดฑเต เดชเตเดฐเตเดฎเดพเดฑเตเดฑเด เดเดฑเดชเตเดชเดพเดเตเดเตเดจเตเดจเต.

**เดชเตเดฐเดเดเดจ เดเดชเตเดฑเตเดฑเดฟเดฎเตเดธเตเดทเตป**: เดเดเดจเตเดฑเต เดชเตเดฐเดตเตเดคเตเดคเดฟ เดชเตเดฐเดตเดพเดนเดเตเดเตพเดเตเดเต เดเดพเดฐเตเดฏเดเตเดทเดฎเดฎเดพเดฏ เดฎเตเดฎเตเดฎเดฑเดฟ เดเดชเดฏเตเดเด, เดฎเตพเดเตเดเดฟ-เดเดเดจเตเดฑเต เดธเดฟเดธเตเดฑเตเดฑเดเตเดเตพเดเตเดเดพเดฏเดฟ เดกเตเดจเดพเดฎเดฟเดเต เดฎเตเดกเตฝ เดฒเตเดกเดฟเดเดเต, เดฏเดฅเดพเตผเดคเตเดฅ เดธเดฎเดฏ เดเดเดจเตเดฑเต เดเดเดชเตเดเดฒเตเดเตพเดเตเดเดพเดฏเดฟ เดเดชเตเดฑเตเดฑเดฟเดฎเตเดธเตเดกเต เดเตปเดซเดฑเตปเดธเต เดเดจเตเดจเดฟเดต GGUF เดตเดดเดฟ เดธเดพเดงเตเดฏเดฎเดพเดฃเต.

### เดเดกเตเดเต-เดเดชเตเดฑเตเดฑเดฟเดฎเตเดธเตเดกเต SLM เดซเตเดฐเตเดฏเดฟเดเดตเตผเดเตเดเตโเดธเต

#### Llama.cpp เดเดเดจเตเดฑเตเดเตพเดเตเดเตเดณเตเดณ เดเดชเตเดฑเตเดฑเดฟเดฎเตเดธเตเดทเตป

Llama.cpp เดเดเดจเตเดฑเดฟเดเต SLM เดตเดฟเดจเตเดฏเดพเดธเดคเตเดคเดฟเดจเดพเดฏเดฟ เดชเตเดฐเดคเตเดฏเตเดเดฎเดพเดฏเดฟ เดเดชเตเดฑเตเดฑเดฟเดฎเตเดธเต เดเตเดฏเตเดค เดเดงเตเดจเดฟเด เดเตเดตเดพเดฃเตเดเตเดธเตเดทเตป เดธเดพเดเตเดเตเดคเดฟเดเดตเดฟเดฆเตเดฏเดเตพ เดจเตฝเดเตเดจเตเดจเต:

**เดเดเดจเตเดฑเต-เดจเดฟเตผเดฆเตเดฆเดฟเดทเตเด เดเตเดตเดพเดฃเตเดเตเดธเตเดทเตป**: เดฎเตเดฌเตเตฝ เดเดเดจเตเดฑเต เดตเดฟเดจเตเดฏเดพเดธเดคเตเดคเดฟเดจเต 75% เดตเดฒเตเดชเตเดช เดเตเดฑเดตเตเดณเตเดณ Q4_0, เดเดกเตเดเต เดเตปเดซเดฑเตปเดธเต เดเดเดจเตเดฑเตเดเตพเดเตเดเดพเดฏเดฟ เดเตเดฃเดจเดฟเดฒเดตเดพเดฐ-เดเตเดตเดพเดฃเตเดเตเดธเตเดทเตป เดคเตเดฒเตเดฏเดฎเดพเดฏ Q5_1, เดชเตเดฐเตเดกเดเตเดทเตป เดเดเดจเตเดฑเต เดธเดฟเดธเตเดฑเตเดฑเดเตเดเตพเดเตเดเดพเดฏเดฟ เดเดเดฆเตเดถเด เดฏเดฅเดพเตผเดคเตเดฅ เดเตเดฃเดจเดฟเดฒเดตเดพเดฐเดฎเตเดณเตเดณ Q8_0 เดเดจเตเดจเดฟเดต เดชเดฟเดจเตเดคเตเดฃเดฏเตเดเตเดเตเดจเตเดจเต. เดเดงเตเดจเดฟเด เดซเตเตผเดฎเดพเดฑเตเดฑเตเดเตพ เดเดคเตเดฏเดจเตเดคเด เดเดกเตเดเต เดธเดพเดนเดเดฐเตเดฏเดเตเดเตพเดเตเดเต เดเตพเดเตเดฐเดพ-เดเดฎเตเดชเตเดฐเดธเตเดธเต เดเตเดฏเตเดค เดเดเดจเตเดฑเตเดเตพ เดเดจเตเดตเดฆเดฟเดเตเดเตเดจเตเดจเต.

**เดจเดเดชเตเดชเดพเดเตเดเตฝ เดเตเดฃเดเตเดเตพ**: SIMD เดตเตเดเดค เดตเตผเดฆเตเดงเดจเดตเตเดเต CPU-เดเดชเตเดฑเตเดฑเดฟเดฎเตเดธเตเดกเต เดเตปเดซเดฑเตปเดธเต เดฎเตเดฎเตเดฎเดฑเดฟ เดเดพเดฐเตเดฏเดเตเดทเดฎเดฎเดพเดฏ เดเดเดจเตเดฑเต เดชเตเดฐเดตเตผเดคเตเดคเดจเด เดจเตฝเดเตเดจเตเดจเต. x86, ARM, Apple Silicon เดเตผเดเตเดเดฟเดเตเดเตเดเดฑเตเดเดณเดฟเตฝ เดเตเดฐเตเดธเต-เดชเตเดฒเดพเดฑเตเดฑเตเดซเตเด เดเดจเตเดฏเตเดเตเดฏเดค เดธเตผเดตเดคเตเดฐ เดเดเดจเตเดฑเต เดตเดฟเดจเตเดฏเดพเดธ เดถเตเดทเดฟเดเตพ เดเดฑเดชเตเดชเดพเดเตเดเตเดจเตเดจเต.

#### Apple MLX SLM เดเดเดจเตเดฑเตเดเตพเดเตเดเดพเดฏเดฟ

Apple MLX Apple Silicon เดเดชเดเดฐเดฃเดเตเดเดณเดฟเตฝ SLM-เดถเดเตเดคเดฟเดฏเตเดณเตเดณ เดเดเดจเตเดฑเตเดเตพเดเตเดเดพเดฏเดฟ เดธเตเดตเดฆเตเดถเตเดฏ เดเดชเตเดฑเตเดฑเดฟเดฎเตเดธเตเดทเตป เดจเตฝเดเตเดจเตเดจเต:

**Apple Silicon เดเดเดจเตเดฑเต เดเดชเตเดฑเตเดฑเดฟเดฎเตเดธเตเดทเตป**: Metal Performance Shaders เดธเดเดฏเตเดเดจเด เดเดชเดฏเตเดเดฟเดเตเดเต เดเดเตเดเตเดค เดฎเตเดฎเตเดฎเดฑเดฟ เดเตผเดเตเดเดฟเดเตเดเตเดเตผ, เดเดเดจเตเดฑเต เดเตปเดซเดฑเตปเดธเดฟเดจเดพเดฏเดฟ เดธเตเดตเดฏเด เดฎเดฟเดถเตเดฐเดฟเดค เดเตเดคเตเดฏเดค, เดฎเตพเดเตเดเดฟ-เดเดเดจเตเดฑเต เดธเดฟเดธเตเดฑเตเดฑเดเตเดเตพเดเตเดเดพเดฏเดฟ เดฎเตเดฎเตเดฎเดฑเดฟ เดฌเดพเตปเดกเตโเดตเดฟเดกเตเดคเตเดคเต เดเดชเตเดฑเตเดฑเดฟเดฎเตเดธเตเดทเตป เดเดจเตเดจเดฟเดต เดเตพเดชเตเดชเตเดเตเดจเตเดจเต. M-เดธเตเดฐเตเดธเต เดเดฟเดชเตเดชเตเดเดณเดฟเตฝ SLM เดเดเดจเตเดฑเตเดเตพ เดเดคเตเดฒเตเดฏ เดชเตเดฐเดเดเดจเด เดเดพเดฃเดฟเดเตเดเตเดจเตเดจเต.

**เดตเดฟเดเดธเดจ เดธเดตเดฟเดถเตเดทเดคเดเตพ**: Python, Swift API เดชเดฟเดจเตเดคเตเดฃ, เดเดเดจเตเดฑเต-เดจเดฟเตผเดฆเตเดฆเดฟเดทเตเด เดเดชเตเดฑเตเดฑเดฟเดฎเตเดธเตเดทเดจเตเดเตพ, เดเดเดจเตเดฑเต เดชเดเดจเดคเตเดคเดฟเดจเดพเดฏเดฟ เดธเตเดตเดฏเด เดตเตเดฏเดคเตเดฏเดพเดธเด, Apple เดตเดฟเดเดธเดจ เดเดชเดเดฐเดฃเดเตเดเดณเตเดฎเดพเดฏเดฟ เดธเตเดคเดพเดฐเตเดฏ เดธเดเดฏเตเดเดจเด เดเดจเตเดจเดฟเดต เดธเดฎเดเตเดฐเดฎเดพเดฏ เดเดเดจเตเดฑเต เดตเดฟเดเดธเดจ เดชเดฐเดฟเดธเตเดฅเดฟเดคเดฟเดเตพ เดจเตฝเดเตเดจเตเดจเต.

#### ONNX เดฑเตบเดเตเด เดเตเดฐเตเดธเต-เดชเตเดฒเดพเดฑเตเดฑเตเดซเตเด SLM เดเดเดจเตเดฑเตเดเตพเดเตเดเดพเดฏเดฟ

ONNX เดฑเตบเดเตเด เดตเตเดฏเดคเตเดฏเดธเตเดค เดนเดพเตผเดกเตโเดตเตเดฏเตผ เดชเตเดฒเดพเดฑเตเดฑเตเดซเตเดฎเตเดเดณเดฟเดฒเตเด เดเดชเตเดชเดฑเตเดฑเตเดฑเดฟเดเดเต เดธเดฟเดธเตเดฑเตเดฑเดเตเดเดณเดฟเดฒเตเดฎเดพเดฏเดฟ SLM เดเดเดจเตเดฑเตเดเตพ เดธเตเดฅเดฟเดฐเดคเดฏเตเดเต เดชเตเดฐเดตเตผเดคเตเดคเดฟเดเตเดเดพเตป เดธเดพเดงเดฟเดเตเดเตเดจเตเดจ เดธเตผเดตเดคเตเดฐ เดเตปเดซเดฑเตปเดธเต เดเดเตเดเดฟเตป เดจเตฝเดเตเดจเตเดจเต:

**เดธเตผเดตเดคเตเดฐ เดตเดฟเดจเตเดฏเดพเดธเด**: Windows, Linux, macOS, iOS, Android เดชเตเดฒเดพเดฑเตเดฑเตเดซเตเดฎเตเดเดณเดฟเตฝ เดธเตเดฅเดฟเดฐเดคเดฏเตเดณเตเดณ SLM เดเดเดจเตเดฑเต เดชเตเดฐเตเดฎเดพเดฑเตเดฑเด เดเดฑเดชเตเดชเดพเดเตเดเตเดจเตเดจเต. เด เดเตเดฐเตเดธเต-เดชเตเดฒเดพเดฑเตเดฑเตเดซเตเด เดเดจเตเดฏเตเดเตเดฏเดค เดกเตเดตเดฒเดชเตเดชเตผเดฎเดพเตผเดเตเดเต เดเดฐเดฟเดเตเดเตฝ เดเดดเตเดคเดฟเดฏเตเด เดเดฒเตเดฒเดพเดฏเดฟเดเดคเตเดคเตเด เดตเดฟเดจเตเดฏเดธเดฟเดเตเดเดพเดจเตเด เดธเดพเดงเตเดฏเดฎเดพเดเตเดเตเดจเตเดจเต, เดฎเตพเดเตเดเดฟ-เดชเตเดฒเดพเดฑเตเดฑเตเดซเตเด เดชเตเดฐเดฏเตเดเดเตเดเดณเตเดเต เดตเดฟเดเดธเดจเดตเตเด เดชเดฐเดฟเดชเดพเดฒเดจเดตเตเด เดตเดณเดฐเต เดเตเดฑเดฏเตเดเตเดเตเดจเตเดจเต.

**เดนเดพเตผเดกเตโเดตเตเดฏเตผ เดตเตเดเดค เดตเตผเดฆเตเดงเดจเดตเต เดเดชเตเดทเดจเตเดเตพ**: CPU (Intel, AMD, ARM), GPU (NVIDIA CUDA, AMD ROCm), เดชเตเดฐเดคเตเดฏเตเด เดเดเตเดธเดฟเดฒเดฑเตเดฑเตเดฑเดฑเตเดเตพ (Intel VPU, Qualcomm NPU) เดเดจเตเดจเดฟเดตเดฏเตเดเตเดเดพเดฏเดฟ เดเดชเตเดฑเตเดฑเดฟเดฎเตเดธเตเดกเต เดเดเตเดธเดฟเดเตเดฏเตเดทเตป เดชเตเดฐเตเดตเตเดกเดฑเตเดเตพ เดจเตฝเดเตเดจเตเดจเต. เดเตเดกเต เดฎเดพเดฑเตเดฑเดฎเดฟเดฒเตเดฒเดพเดคเต เดฎเดฟเดเดเตเด เดนเดพเตผเดกเตโเดตเตเดฏเตผ เดธเตเดตเดฏเด เดเดชเดฏเตเดเดฟเดเตเดเดพเด.

**เดชเตเดฐเตเดกเดเตเดทเตป-เดธเดเตเด เดธเดตเดฟเดถเตเดทเดคเดเตพ**: เดตเตเดเดคเดฏเตเดณเตเดณ เดเตปเดซเดฑเตปเดธเดฟเดจเดพเดฏเดฟ เดเตเดฐเดพเดซเต เดเดชเตเดฑเตเดฑเดฟเดฎเตเดธเตเดทเตป, เดธเตเดฐเตเดคเดธเตเดธเต-เดชเดฐเดฟเดฎเดฟเดค เดชเดฐเดฟเดธเตเดฅเดฟเดคเดฟเดเตพเดเตเดเดพเดฏเดฟ เดฎเตเดฎเตเดฎเดฑเดฟ เดฎเดพเดจเตเดเตเดฎเตเดจเตเดฑเต, เดชเตเดฐเดเดเดจ เดตเดฟเดถเดเดฒเดจเดคเตเดคเดฟเดจเตเดณเตเดณ เดธเดฎเดเตเดฐ เดชเตเดฐเตเดซเตเดฒเดฟเดเดเต เดเตเดณเตเดเตพ เดเดจเตเดจเดฟเดต เดเตพเดชเตเดชเตเดเตเดจเตเดจ เดเดจเตเดฑเตผเดชเตเดฐเตเดธเต-เดเตเดฐเตเดกเต เดธเดตเดฟเดถเตเดทเดคเดเตพ. Python, C++ APIเดเตพ เดซเตเดฒเตเดเตเดธเดฟเดฌเดฟเตพ เดธเดเดฏเตเดเดจเดคเตเดคเดฟเดจเดพเดฏเดฟ เดชเดฟเดจเตเดคเตเดฃเดฏเตเดเตเดเตเดจเตเดจเต.

## เดเดเดจเตเดฑเดฟเดเต เดธเดฟเดธเตเดฑเตเดฑเดเตเดเดณเดฟเตฝ SLM vs LLM: เดเดงเตเดจเดฟเด เดคเดพเดฐเดคเดฎเตเดฏเด

### เดเดเดจเตเดฑเต เดชเตเดฐเดฏเตเดเดเตเดเดณเดฟเตฝ SLM เดเตเดฃเดเตเดเตพ

**เดชเตเดฐเดตเตผเดคเตเดคเดจ เดเดพเดฐเตเดฏเดเตเดทเดฎเดค**: เดเดเดจเตเดฑเต เดชเตเดฐเดตเตผเดคเตเดคเดจเดเตเดเตพเดเตเดเต LLM-เดเดณเต เดเดชเตเดเตเดทเดฟเดเตเดเต 10-30ร เดเตเดฒเดตเต เดเตเดฑเดตเต เดจเตฝเดเตเดจเตเดจเต, เดธเตเดเตเดฏเดฟเดฒเดฟเตฝ เดฏเดฅเดพเตผเดคเตเดฅ เดธเดฎเดฏ เดเดเดจเตเดฑเดฟเดเต เดชเตเดฐเดคเดฟเดเดฐเดฃเดเตเดเตพ เดธเดพเดงเตเดฏเดฎเดพเดเตเดเตเดจเตเดจเต. เดเตเดฑเดตเดพเดฏ เดเดเดชเตเดฏเตเดเตเดเตเดทเดฃเตฝ เดธเดเตเดเตเตผเดฃเตเดฃเดค เดฎเตเดฒเด เดตเตเดเดคเดฏเตเดณเตเดณ เดเตปเดซเดฑเตปเดธเต เดธเดฎเดฏเดเตเดเตพ เดจเตฝเดเตเดจเตเดจเต, เดเดจเตเดฑเดฑเดพเดเตเดเตเดตเต เดเดเดจเตเดฑเต เดชเตเดฐเดฏเตเดเดเตเดเตพเดเตเดเต เดเดจเตเดฏเตเดเตเดฏเดฎเดพเดฃเต.

**เดเดกเตเดเต เดตเดฟเดจเตเดฏเดพเดธ เดถเตเดทเดฟเดเตพ**: เดเดจเตเดฑเตผเดจเตเดฑเตเดฑเต เดเดถเตเดฐเดฟเดคเดคเตเดตเดฎเดฟเดฒเตเดฒเดพเดคเต เดเดชเดเดฐเดฃเดคเตเดคเดฟเตฝ เดคเดจเตเดจเต เดเดเดจเตเดฑเต เดชเตเดฐเดตเตผเดคเตเดคเดจเด, เดชเตเดฐเดพเดฆเตเดถเดฟเด เดเดเดจเตเดฑเต เดชเตเดฐเตเดธเดธเตเดธเดฟเดเดเดฟเดฒเตเดเต เดฎเตเดเตเดเดชเตเดชเตเดเตเด เดธเตเดตเดเดพเดฐเตเดฏเดค, เดกเตเดฎเตเดฏเตเตป-เดจเดฟเตผเดฆเตเดฆเดฟเดทเตเด เดเดเดจเตเดฑเต เดชเตเดฐเดฏเตเดเดเตเดเตพเดเตเดเต เดเดทเตเดเดพเดจเตเดธเตเดคเดฎเดพเดเตเดเตฝ, เดตเดฟเดตเดฟเดง เดเดกเตเดเต เดเดเดชเตเดฏเตเดเตเดเดฟเดเดเต เดชเดฐเดฟเดธเตเดฅเดฟเดคเดฟเดเตพเดเตเดเดพเดฏเดฟ เดเดจเตเดฏเตเดเตเดฏเดฎเดพเดฏเดต.

**เดเดเดจเตเดฑเต-เดจเดฟเตผเดฆเตเดฆเดฟเดทเตเด เดเดชเตเดฑเตเดฑเดฟเดฎเตเดธเตเดทเตป**: เดเตเตพ เดเตเดณเดฟเดเดเต, เดเดเดจเดพเดชเดฐเดฎเดพเดฏ เดเดเตเดเตเดชเตเดเตเดเต เดธเตเดทเตเดเดฟ, เดธเดพเดงเดพเดฐเดฃ เดคเตเดฐเตเดฎเดพเดจเดฎเตเดเตเดเตเดเตฝ เดชเตเดฐเดตเตเดคเตเดคเดฟ เดชเตเดฐเดตเดพเดนเดเตเดเตพ เดเดจเตเดจเดฟเดตเดฏเดฟเตฝ SLMเดเตพ 70-80% เดธเดพเดงเดพเดฐเดฃ เดเดเดจเตเดฑเต เดชเตเดฐเดตเตผเดคเตเดคเดจเดเตเดเตพเดเตเดเดพเดฏเดฟ เดฎเดฟเดเดเตเด เดชเตเดฐเดเดเดจเด เดเดพเดฃเดฟเดเตเดเตเดจเตเดจเต.

### เดเดเดจเตเดฑเต เดธเดฟเดธเตเดฑเตเดฑเดเตเดเดณเดฟเตฝ SLMเดเตพ LLMเดเดณเต เดเดชเตเดเตเดทเดฟเดเตเดเต เดเดชเตเดชเตเตพ เดเดชเดฏเตเดเดฟเดเตเดเดฃเด

**SLMเดเตพเดเตเดเต เดเดจเตเดฏเตเดเตเดฏเด**:
- **เดชเตเดจเดฐเดพเดตเตเดค เดเดเดจเตเดฑเต เดชเตเดฐเดตเตผเดคเตเดคเดจเดเตเดเตพ**: เดกเดพเดฑเตเดฑ เดเตปเดเตเดฐเดฟ, เดซเตเด เดชเตเดฐเดฟเดชเตเดชเดฟเดเตเดเตฝ, เดธเดพเดงเดพเดฐเดฃ API เดเตเตพเดธเต
- **เดเตเตพ เดธเดเดฏเตเดเดจเด**: เดกเดพเดฑเตเดฑเดพเดฌเตเดธเต เดเตเดตเตเดฑเดฟเดเตพ, เดซเดฏเตฝ เดชเตเดฐเดตเตผเดคเตเดคเดจเดเตเดเตพ, เดธเดฟเดธเตเดฑเตเดฑเด เดเดเดชเตเดเดฒเตเดเตพ
- **เดเดเดจเดพเดชเดฐเดฎเดพเดฏ เดชเตเดฐเดตเตเดคเตเดคเดฟ เดชเตเดฐเดตเดพเดนเดเตเดเตพ**: เดฎเตเตปเดเตเดเตเดเดฟ เดจเดฟเตผเดตเตเดตเดเดฟเดเตเด เดเดเดจเตเดฑเต เดชเตเดฐเดเตเดฐเดฟเดฏเดเตพ เดชเดพเดฒเดฟเดเตเดเตฝ
- **เดกเตเดฎเตเดฏเตเตป-เดจเดฟเตผเดฆเตเดฆเดฟเดทเตเด เดเดเดจเตเดฑเตเดเตพ**: เดเดชเดญเตเดเตเดคเต เดธเตเดตเดจเด, เดทเตเดกเตเดฏเตเดณเดฟเดเดเต, เดเดเดฟเดธเตเดฅเดพเดจ เดตเดฟเดถเดเดฒเดจเด
- **เดชเตเดฐเดพเดฆเตเดถเดฟเด เดชเตเดฐเตเดธเดธเตเดธเดฟเดเดเต**: เดธเตเดตเดเดพเดฐเตเดฏเดค-เดธเดเดฌเดจเตเดงเดฎเดพเดฏ เดเดเดจเตเดฑเต เดชเตเดฐเดตเตผเดคเตเดคเดจเดเตเดเตพ

**LLMเดเตพเดเตเดเต เดเดจเตเดฏเตเดเตเดฏเด**:
- **เดธเดเตเดเตเตผเดฃเตเดฃ เดคเตผเดเตเดเด**: เดชเตเดคเดฟเดฏ เดชเตเดฐเดถเตเดจ เดชเดฐเดฟเดนเดพเดฐเด, เดคเดจเตเดคเตเดฐเดชเดฐเดฎเดพเดฏ เดชเดฆเตเดงเดคเดฟเดฏเดฟเดเตฝ
- **เดคเตเดฑเดจเตเดจ เดธเดเดญเดพเดทเดฃเดเตเดเตพ**: เดชเตเดคเตเดตเดพเดฏ เดเดพเดฑเตเดฑเต, เดธเตเดทเตเดเดฟเดชเดฐเดฎเดพเดฏ เดเตผเดเตเดเดเตพ
- **เดตเตเดฏเดพเดชเดเดฎเดพเดฏ เดเดฑเดฟเดตเต เดเดตเดถเตเดฏเดฎเดพเดฏ เดชเตเดฐเดตเตผเดคเตเดคเดจเดเตเดเตพ**: เดตเดฟเดถเดพเดฒเดฎเดพเดฏ เดชเตเดคเตเดตเดพเดฏ เดเดฑเดฟเดตเต เดเดตเดถเตเดฏเดฎเดพเดฏ เดเดตเตเดทเดฃเด
- **เดชเตเดคเดฟเดฏ เดธเดพเดนเดเดฐเตเดฏเดเตเดเตพ**: เดชเตเตผเดฃเตเดฃเดฎเดพเดฏเตเด เดชเตเดคเดฟเดฏ เดเดเดจเตเดฑเต เดธเดพเดนเดเดฐเตเดฏเดเตเดเตพ เดเตเดเดพเดฐเตเดฏเด เดเตเดฏเตเดฏเตฝ

### เดนเตเดฌเตเดฐเดฟเดกเต เดเดเดจเตเดฑเต เดเตผเดเตเดเดฟเดเตเดเตเดเตผ

SLMเดเดณเตเด LLMเดเดณเตเด เดธเดเดฏเตเดเดฟเดชเตเดชเดฟเดเตเด เดนเตเดฑเตเดฑเดฑเตเดเตเดจเดฟเดฏเดธเต เดเดเดจเตเดฑเดฟเดเต เดธเดฟเดธเตเดฑเตเดฑเดเตเดเตพ เดเดฑเตเดฑเดตเตเด เดฎเดฟเดเดเตเด เดธเดฎเตเดชเดจเดฎเดพเดฃเต:

**เดธเตเดฎเดพเตผเดเตเดเต เดเดเดจเตเดฑเต เดเตผเดเตเดเดธเตเดเตเดฐเตเดทเตป**:
1. **เดชเตเดฐเดพเดฅเดฎเดฟเดเดฎเดพเดฏเดฟ SLM**: 70-80% เดธเดพเดงเดพเดฐเดฃ เดเดเดจเตเดฑเต เดชเตเดฐเดตเตผเดคเตเดคเดจเดเตเดเตพ เดชเตเดฐเดพเดฆเตเดถเดฟเดเดฎเดพเดฏเดฟ เดเตเดเดพเดฐเตเดฏเด เดเตเดฏเตเดฏเตเด
2. **เดเดตเดถเตเดฏเดฎเดพเดฏเดชเตเดชเตเตพ LLM**: เดธเดเตเดเตเตผเดฃเตเดฃ เดเตเดฆเตเดฏเดเตเดเตพ เดเตเดฒเตเดกเต-เดเดเดฟเดธเตเดฅเดพเดจ เดตเดฒเดฟเดฏ เดฎเตเดกเดฒเตเดเดณเดฟเดฒเตเดเตเดเต เดฑเตเดเตเดเตเดเตเดฏเตเดฏเตเด
3. **เดชเตเดฐเดคเตเดฏเตเด SLMเดเตพ**: เดตเตเดฏเดคเตเดฏเดธเตเดค เดเดเดจเตเดฑเต เดกเตเดฎเตเดฏเตเตปเดธเดฟเดจเดพเดฏเดฟ เดตเตเดฏเดคเตเดฏเดธเตเดค เดเตเดฑเดฟเดฏ เดฎเตเดกเดฒเตเดเตพ
4. **เดเตเดฒเดตเต เดเดชเตเดฑเตเดฑเดฟเดฎเตเดธเตเดทเตป**: เดฌเตเดฆเตเดงเดฟเดฎเตเดเตเดเตเดณเตเดณ LLM เดเตเตพเดธเต เดเตเดฑเดฏเตเดเตเดเดพเตป เดฌเตเดฆเตเดงเดฟเดฎเตเดเตเดเตเดณเตเดณ เดฑเตเดเตเดเดฟเดเดเต

## เดชเตเดฐเตเดกเดเตเดทเตป SLM เดเดเดจเตเดฑเต เดตเดฟเดจเตเดฏเดพเดธ เดคเดจเตเดคเตเดฐเดเตเดเตพ

### Foundry Local: เดเดจเตเดฑเตผเดชเตเดฐเตเดธเต-เดเตเดฐเตเดกเต เดเดกเตเดเต AI เดฑเตบเดเตเด

Foundry Local (https://github.com/microsoft/foundry-local) Microsoft-เดจเตเดฑเต เดชเตเดฐเดงเดพเดจ เดชเดฐเดฟเดนเดพเดฐเดฎเดพเดฏเดฟ เดชเตเดฐเตเดกเดเตเดทเตป เดเดกเตเดเต เดชเดฐเดฟเดธเตเดฅเดฟเดคเดฟเดเดณเดฟเตฝ เดเตเดฑเดฟเดฏ เดญเดพเดทเดพ เดฎเตเดกเดฒเตเดเตพ เดตเดฟเดจเตเดฏเดธเดฟเดเตเดเดพเตป เดธเตเดตเดจเด เดจเตฝเดเตเดจเตเดจเต. SLM-เดถเดเตเดคเดฟเดฏเตเดณเตเดณ เดเดเดจเตเดฑเตเดเตพเดเตเดเดพเดฏเดฟ เดชเตเดฐเดคเตเดฏเตเดเดฎเดพเดฏเดฟ เดฐเตเดชเดเตฝเดชเตเดชเดจ เดเตเดฏเตเดค เดธเดฎเดเตเดฐ เดฑเตบเดเตเด เดชเดฐเดฟเดธเตเดฅเดฟเดคเดฟ, เดเดจเตเดฑเตผเดชเตเดฐเตเดธเต-เดเตเดฐเตเดกเต เดธเดตเดฟเดถเตเดทเดคเดเตพ, เดธเตเดคเดพเดฐเตเดฏ เดธเดเดฏเตเดเดจเด เดเดจเตเดจเดฟเดต เดจเตฝเดเตเดจเตเดจเต.

**เดชเตเดฐเดงเดพเดจ เดเตผเดเตเดเดฟเดเตเดเตเดเตผ, เดธเดตเดฟเดถเตเดทเดคเดเตพ**:
- **OpenAI-เดธเดฎเดพเดจเดฎเดพเดฏ API**: OpenAI SDK, Agent Framework เดธเดเดฏเตเดเดจเดเตเดเดณเตเดฎเดพเดฏเดฟ เดชเตเตผเดฃเตเดฃ เดเดจเตเดฏเตเดเตเดฏเดค
- **เดธเตเดตเดฏเด เดนเดพเตผเดกเตโเดตเตเดฏเตผ เดเดชเตเดฑเตเดฑเดฟเดฎเตเดธเตเดทเตป**: เดฒเดญเตเดฏเดฎเดพเดฏ เดนเดพเตผเดกเตโเดตเตเดฏเตผ (CUDA GPU, Qualcomm NPU, CPU) เดเดเดฟเดธเตเดฅเดพเดจเดฎเดพเดเตเดเดฟ เดฎเตเดกเตฝ เดตเดเดญเตเดฆเดเตเดเตพ เดฌเตเดฆเตเดงเดฟเดฎเตเดเตเดเตเดเต เดคเดฟเดฐเดเตเดเตเดเตเดเตเดเตฝ
- **เดฎเตเดกเตฝ เดฎเดพเดจเตเดเตเดฎเตเดจเตเดฑเต**: SLM เดฎเตเดกเดฒเตเดเดณเตเดเต เดธเตเดตเดฏเด เดกเตเตบเดฒเตเดกเต, เดเดพเดทเดฟเดเดเต, เดฒเตเดซเตโเดธเตเดเตเดเดฟเตพ เดฎเดพเดจเตเดเตเดฎเตเดจเตเดฑเต
- **เดธเตเดตเดจ เดเดฃเตเดเตเดคเตเดคเตฝ**: เดเดเดจเตเดฑเต เดซเตเดฐเตเดฏเดฟเดเดตเตผเดเตเดเตโเดธเดฟเดจเดพเดฏเดฟ เดธเตเดฑเต-เดเตเตบเดซเดฟเดเดฑเตเดทเตป เดธเตเดตเดจ เดเดฃเตเดเตเดคเตเดคเตฝ
- **เดธเตเดฐเตเดคเดธเตเดธเต เดเดชเตเดฑเตเดฑเดฟเดฎเตเดธเตเดทเตป**: เดเดกเตเดเต เดตเดฟเดจเตเดฏเดพเดธเดคเตเดคเดฟเดจเดพเดฏเดฟ เดฌเตเดฆเตเดงเดฟเดฎเตเดเตเดเตเดณเตเดณ เดฎเตเดฎเตเดฎเดฑเดฟ เดฎเดพเดจเตเดเตเดฎเตเดจเตเดฑเต, เดชเดตเตผ เดเดพเดฐเตเดฏเดเตเดทเดฎเดค

#### เดเตปเดธเตเดฑเตเดฑเดฒเตเดทเตป, เดธเตเดฑเตเดฑเดชเตเดชเต

**เดเตเดฐเตเดธเต-เดชเตเดฒเดพเดฑเตเดฑเตเดซเตเด เดเตปเดธเตเดฑเตเดฑเดฒเตเดทเตป**:
```bash
# เดตเดฟเตปเดกเตเดธเต (เดถเตเดชเดพเตผเดถ เดเตเดฏเตเดฏเตเดจเตเดจเต)
winget install Microsoft.FoundryLocal

# เดฎเดพเดเตโเดเดเดธเต
brew tap microsoft/foundrylocal
brew install foundrylocal

# เดฒเดฟเดจเดเตเดธเต (เดฎเดพเดจเตเดตเตฝ เดเตปเดธเตเดฑเตเดฑเดฒเตเดทเตป)
wget https://github.com/microsoft/foundry-local/releases/latest/download/foundry-local-linux.tar.gz
tar -xzf foundry-local-linux.tar.gz
sudo mv foundry-local /usr/local/bin/
```

**เดเดเดจเตเดฑเต เดตเดฟเดเดธเดจเดคเตเดคเดฟเดจเต เดเตเดตเดฟเดเตเดเต เดธเตเดฑเตเดฑเดพเตผเดเตเดเต**:
```bash
# เดเดเตเดเตเดฎเดพเดฑเตเดฑเดฟเดเต เดฎเตเดกเตฝ เดฒเตเดกเดฟเดเดเตเดเต เดธเตผเดตเตเดธเต เดเดฐเดเดญเดฟเดเตเดเตเด
foundry model run phi-4-mini

# เดธเตผเดตเตเดธเต เดจเดฟเดฒเดฏเตเด เดเดจเตเดฑเตเดชเตเดฏเดฟเดจเตเดฑเตเด เดชเดฐเดฟเดถเตเดงเดฟเดเตเดเตเด
foundry service status

# เดฒเดญเตเดฏเดฎเดพเดฏ เดฎเตเดกเดฒเตเดเตพ เดชเดเตเดเดฟเดเดชเตเดชเตเดเตเดคเตเดคเตเด
foundry model ls

# API เดเดจเตเดฑเตเดชเตเดฏเดฟเดจเตเดฑเต เดชเดฐเตเดเตเดทเดฟเดเตเดเตเด
curl http://localhost:<port>/v1/models
```

#### เดเดเดจเตเดฑเต เดซเตเดฐเตเดฏเดฟเดเดตเตผเดเตเดเต เดธเดเดฏเตเดเดจเด

**Foundry Local SDK เดธเดเดฏเตเดเดจเด**:
```python
from foundry_local import FoundryLocalManager
from microsoft_agent_framework import Agent, Config
import openai

# Foundry Local เดธเตเดตเดฏเด เดธเตเดตเดจ เดฎเดพเดจเตเดเตเดฎเตเดจเตเดฑเตเดเต เดเดฐเดเดญเดฟเดเตเดเตเด
manager = FoundryLocalManager("phi-4-mini")

# เดชเตเดฐเดพเดฆเตเดถเดฟเด เดเตปเดซเดฑเตปเดธเดฟเดจเดพเดฏเดฟ OpenAI เดเตเดฒเดฏเดจเตเดฑเต เดเตเดฐเดฎเตเดเดฐเดฟเดเตเดเตเด
client = openai.OpenAI(
    base_url=manager.endpoint,
    api_key=manager.api_key  # เดชเตเดฐเดพเดฆเตเดถเดฟเด เดเดชเดฏเตเดเดคเตเดคเดฟเดจเดพเดฏเดฟ เดธเตเดตเดฏเด เดธเตเดทเตเดเดฟเดเตเดเดคเต
)

# Foundry Local เดฌเดพเดเตเดเตโเดเตปเดกเตเดเต เดเดเดจเตเดฑเต เดธเตเดทเตเดเดฟเดเตเดเตเด
agent_config = Config(
    name="production-agent",
    model_provider="foundry-local",
    model_id=manager.get_model_info("phi-4-mini").id,
    endpoint=manager.endpoint,
    api_key=manager.api_key
)

agent = Agent(config=agent_config)
```

**เดธเตเดตเดฏเด เดฎเตเดกเตฝ เดคเดฟเดฐเดเตเดเตเดเตเดเตเดเตฝ, เดนเดพเตผเดกเตโเดตเตเดฏเตผ เดเดชเตเดฑเตเดฑเดฟเดฎเตเดธเตเดทเตป**:
```python
# เดซเตเดฃเตเดเตเดฐเดฟ เดฒเตเดเตเดเตฝ เดธเตเดตเดฏเด เดเดฑเตเดฑเดตเตเด เดเดจเตเดฏเตเดเตเดฏเดฎเดพเดฏ เดฎเตเดกเตฝ เดตเตเดฐเดฟเดฏเดจเตเดฑเต เดคเดฟเดฐเดเตเดเตเดเตเดเตเดเตเดจเตเดจเต
models_by_use_case = {
    "lightweight_routing": "qwen2.5-0.5b",      # 500MB, เดเตพเดเตเดฐเดพ-เดซเดพเดธเตเดฑเตเดฑเต
    "general_conversation": "phi-4-mini",       # 2.4GB, เดฌเดพเดฒเตปเดธเตเดกเต
    "complex_reasoning": "phi-4",               # 7GB, เดเดฏเตผเดจเตเดจ เดถเตเดทเดฟเดฏเตเดณเตเดณ
    "code_assistance": "qwen2.5-coder-0.5b"    # 500MB, เดเตเดกเต-เดเดชเตเดฑเตเดฑเดฟเดฎเตเดธเตเดกเต
}

# เดซเตเดฃเตเดเตเดฐเดฟ เดฒเตเดเตเดเตฝ เดนเดพเตผเดกเตโเดตเตเดฏเตผ เดเดฃเตเดเตเดคเตเดคเดฒเตเด เดเตเดตเดพเดฃเตเดเตเดธเตเดทเดจเตเด เดเตเดเดพเดฐเตเดฏเด เดเตเดฏเตเดฏเตเดจเตเดจเต
for use_case, model_alias in models_by_use_case.items():
    manager = FoundryLocalManager(model_alias)
    print(f"{use_case}: {manager.get_model_info(model_alias).variant_selected}")
    # เดเดเตเดเตเดชเตเดเตเดเต เดเดฆเดพเดนเดฐเดฃเดเตเดเตพ:
    # lightweight_routing: qwen2.5-0.5b-instruct-q4_k_m.gguf (CPU เดเดชเตเดฑเตเดฑเดฟเดฎเตเดธเตเดกเต)
    # general_conversation: phi-4-mini-instruct-cuda-q5_k_m.gguf (GPU เดเดเตเดธเดฟเดฒเดฑเตเดฑเตเดฑเดกเต)
```

#### เดชเตเดฐเตเดกเดเตเดทเตป เดตเดฟเดจเตเดฏเดพเดธ เดฎเดพเดคเตเดเดเตพ

**เดเดฑเตเดฑ เดเดเดจเตเดฑเต เดชเตเดฐเตเดกเดเตเดทเตป เดธเตเดฑเตเดฑเดชเตเดชเต**:
```python
import asyncio
from foundry_local import FoundryLocalManager
from microsoft_agent_framework import Agent, Config, Tool

class ProductionAgentService:
    def __init__(self, model_alias="phi-4-mini"):
        self.foundry = FoundryLocalManager(model_alias)
        self.agent = self._create_agent()
        
    def _create_agent(self):
        config = Config(
            name="production-customer-service",
            model_provider="foundry-local",
            model_id=self.foundry.get_model_info().id,
            endpoint=self.foundry.endpoint,
            api_key=self.foundry.api_key,
            max_tokens=512,
            temperature=0.1,
            timeout=30.0
        )
        
        agent = Agent(config=config)
        
        # เดเดคเตเดชเดพเดฆเดจ เดเดชเดเดฐเดฃเดเตเดเตพ เดเตเตผเดเตเดเตเด
        @agent.tool
        def lookup_customer(customer_id: str) -> dict:
            """Look up customer information from local database."""
            return self.local_db.get_customer(customer_id)
            
        @agent.tool
        def create_ticket(issue: str, priority: str = "medium") -> str:
            """Create a support ticket."""
            ticket_id = self.ticketing_system.create(issue, priority)
            return f"Created ticket {ticket_id}"
            
        return agent
    
    async def process_request(self, user_input: str) -> str:
        """Process user request with error handling and monitoring."""
        try:
            response = await self.agent.chat_async(user_input)
            self.log_interaction(user_input, response, "success")
            return response
        except Exception as e:
            self.log_interaction(user_input, str(e), "error")
            return "I'm experiencing technical difficulties. Please try again."
    
    def health_check(self) -> dict:
        """Check service health for monitoring."""
        return {
            "foundry_status": self.foundry.health_check(),
            "model_loaded": self.foundry.is_model_loaded(),
            "endpoint": self.foundry.endpoint,
            "memory_usage": self.foundry.get_memory_usage()
        }

# เดเดคเตเดชเดพเดฆเดจ เดเดชเดฏเตเดเด
service = ProductionAgentService("phi-4-mini")
response = await service.process_request("I need help with my order #12345")
```

**เดฎเตพเดเตเดเดฟ-เดเดเดจเตเดฑเต เดชเตเดฐเตเดกเดเตเดทเตป เดเตผเดเตเดเดธเตเดเตเดฐเตเดทเตป**:
```python
from foundry_local import FoundryLocalManager
from microsoft_agent_framework import AgentOrchestrator, Agent, Config

class MultiAgentProductionSystem:
    def __init__(self):
        self.agents = self._initialize_agents()
        self.orchestrator = AgentOrchestrator(list(self.agents.values()))
        
    def _initialize_agents(self):
        agents = {}
        
        # เดฒเดเตเดตเดพเดฏ เดฑเตเดเตเดเดฟเดเดเต เดเดเดจเตเดฑเต
        routing_foundry = FoundryLocalManager("qwen2.5-0.5b")
        agents["router"] = Agent(Config(
            name="request-router",
            model_provider="foundry-local",
            endpoint=routing_foundry.endpoint,
            api_key=routing_foundry.api_key,
            role="Route user requests to appropriate specialized agents"
        ))
        
        # เดเดชเดญเตเดเตเดคเต เดธเตเดตเดจ เดเดเดจเตเดฑเต
        service_foundry = FoundryLocalManager("phi-4-mini")
        agents["customer_service"] = Agent(Config(
            name="customer-service",
            model_provider="foundry-local",
            endpoint=service_foundry.endpoint,
            api_key=service_foundry.api_key,
            role="Handle customer service inquiries and support requests"
        ))
        
        # เดธเดพเดเตเดเตเดคเดฟเด เดชเดฟเดจเตเดคเตเดฃ เดเดเดจเตเดฑเต
        tech_foundry = FoundryLocalManager("qwen2.5-coder-0.5b")
        agents["technical"] = Agent(Config(
            name="technical-support",
            model_provider="foundry-local",
            endpoint=tech_foundry.endpoint,
            api_key=tech_foundry.api_key,
            role="Provide technical assistance and troubleshooting"
        ))
        
        return agents
    
    async def process_request(self, user_input: str) -> str:
        """Route and process user requests through appropriate agents."""
        # เดเดตเดถเตเดฏเดฎเดพเดฏ เดเดเดจเตเดฑเดฟเดฒเตเดเตเดเต เดฑเตเดเตเดเตเดเตเดฏเตเดฏเตเด
        routing_result = await self.agents["router"].chat_async(
            f"Classify this request and route to customer_service or technical: {user_input}"
        )
        
        # เดฑเตเดเตเดเดฟเดเดเดฟเดจเตเดฑเต เดเดเดฟเดธเตเดฅเดพเดจเดคเตเดคเดฟเตฝ เดฒเดเตเดทเตเดฏ เดเดเดจเตเดฑเต เดจเดฟเตผเดฃเดฏเดฟเดเตเดเตเด
        target_agent = "customer_service" if "customer" in routing_result.lower() else "technical"
        
        # เดชเตเดฐเดคเตเดฏเตเดเดคเดฏเตเดณเตเดณ เดเดเดจเตเดฑเตเดฎเดพเดฏเดฟ เดชเตเดฐเตเดธเดธเตเดธเต เดเตเดฏเตเดฏเตเด
        response = await self.agents[target_agent].chat_async(user_input)
        
        return response

# เดเดคเตเดชเดพเดฆเดจ เดตเดฟเดจเตเดฏเดพเดธเด
system = MultiAgentProductionSystem()
response = await system.process_request("My application keeps crashing")
```

#### เดเดจเตเดฑเตผเดชเตเดฐเตเดธเต เดธเดตเดฟเดถเตเดทเดคเดเดณเตเด เดจเดฟเดฐเตเดเตเดทเดฃเดตเตเด

**เดเดฐเตเดเตเดฏ เดจเดฟเดฐเตเดเตเดทเดฃเดตเตเด เดฆเตเดถเตเดฏเดตเตฝเดเตเดเดฐเดฃเดตเตเด**:
```python
from foundry_local import FoundryLocalManager
import asyncio
import logging

class FoundryMonitoringService:
    def __init__(self):
        self.managers = {}
        self.metrics = []
        
    def add_model(self, alias: str) -> FoundryLocalManager:
        """Add a model to monitoring."""
        manager = FoundryLocalManager(alias)
        self.managers[alias] = manager
        return manager
    
    async def collect_metrics(self):
        """Collect performance metrics from all Foundry Local instances."""
        metrics = {
            "timestamp": time.time(),
            "models": {}
        }
        
        for alias, manager in self.managers.items():
            try:
                model_metrics = {
                    "status": "healthy" if manager.health_check() else "unhealthy",
                    "memory_usage": manager.get_memory_usage(),
                    "inference_count": manager.get_inference_count(),
                    "average_latency": manager.get_average_latency(),
                    "error_rate": manager.get_error_rate()
                }
                metrics["models"][alias] = model_metrics
            except Exception as e:
                logging.error(f"Failed to collect metrics for {alias}: {e}")
                metrics["models"][alias] = {"status": "error", "error": str(e)}
        
        self.metrics.append(metrics)
        return metrics
    
    def get_health_status(self) -> dict:
        """Get overall system health status."""
        healthy_models = 0
        total_models = len(self.managers)
        
        for alias, manager in self.managers.items():
            if manager.health_check():
                healthy_models += 1
        
        return {
            "overall_status": "healthy" if healthy_models == total_models else "degraded",
            "healthy_models": healthy_models,
            "total_models": total_models,
            "health_percentage": (healthy_models / total_models) * 100 if total_models > 0 else 0
        }

# เดเดคเตเดชเดพเดฆเดจ เดจเดฟเดฐเตเดเตเดทเดฃ เดเตเดฐเดฎเตเดเดฐเดฃเด
monitor = FoundryMonitoringService()
monitor.add_model("phi-4-mini")
monitor.add_model("qwen2.5-0.5b")

# เดคเตเดเตผเดเตเดเดฏเดพเดฏ เดจเดฟเดฐเตเดเตเดทเดฃเด
async def monitoring_loop():
    while True:
        metrics = await monitor.collect_metrics()
        health = monitor.get_health_status()
        
        if health["health_percentage"] < 100:
            logging.warning(f"System health degraded: {health}")
        
        await asyncio.sleep(30)  # เดเดฐเต 30 เดธเตเดเตเดเตปเดกเดฟเดฒเตเด เดฎเตเดเตเดฐเดฟเดเตโเดธเต เดถเตเดเดฐเดฟเดเตเดเตเด
```

**เดธเตเดฐเตเดคเดธเตเดธเต เดฎเดพเดจเตเดเตเดฎเตเดจเตเดฑเต, เดเดเตเดเต-เดธเตเดเตเดฏเดฟเดฒเดฟเดเดเต**:
```python
class FoundryResourceManager:
    def __init__(self):
        self.model_instances = {}
        self.resource_limits = {
            "max_memory_gb": 8,
            "max_concurrent_models": 3,
            "cpu_threshold": 80
        }
    
    def auto_scale_models(self, demand_metrics: dict):
        """Automatically scale models based on demand."""
        current_memory = self.get_total_memory_usage()
        
        # เดฎเตเดฎเตเดฎเดฑเดฟ เดเดชเดฏเตเดเด เดเตเดเตเดคเดฒเดพเดฏเดพเตฝ เดธเตเดเตเดฏเดฟเตฝ เดกเตเตบ เดเตเดฏเตเดฏเตเด
        if current_memory > self.resource_limits["max_memory_gb"] * 0.8:
            self.scale_down_idle_models()
        
        # เดเดตเดถเตเดฏเดเดค เดเตเดเตเดคเดฒเดพเดฏเตเด เดตเดฟเดญเดตเดเตเดเตพ เดเดจเตเดตเดฆเดฟเดเตเดเตเดจเตเดจเดคเตเด เดเดฃเตเดเตเดเดฟเตฝ เดธเตเดเตเดฏเดฟเตฝ เดเดชเตเดชเต เดเตเดฏเตเดฏเตเด
        for model_alias, demand in demand_metrics.items():
            if demand > 0.8 and len(self.model_instances) < self.resource_limits["max_concurrent_models"]:
                self.load_model_instance(model_alias)
    
    def load_model_instance(self, alias: str) -> FoundryLocalManager:
        """Load a new model instance if resources allow."""
        if alias not in self.model_instances:
            try:
                manager = FoundryLocalManager(alias)
                self.model_instances[alias] = manager
                logging.info(f"Loaded model instance: {alias}")
                return manager
            except Exception as e:
                logging.error(f"Failed to load model {alias}: {e}")
                return None
        return self.model_instances[alias]
    
    def scale_down_idle_models(self):
        """Remove idle model instances to free resources."""
        idle_models = []
        
        for alias, manager in self.model_instances.items():
            if manager.get_idle_time() > 300:  # 5 เดฎเดฟเดจเดฟเดฑเตเดฑเต เดเดเดตเตเดณ
                idle_models.append(alias)
        
        for alias in idle_models:
            self.model_instances[alias].shutdown()
            del self.model_instances[alias]
            logging.info(f"Scaled down idle model: {alias}")
```

#### เดเดงเตเดจเดฟเด เดเตเตบเดซเดฟเดเดฑเตเดทเตป, เดเดชเตเดฑเตเดฑเดฟเดฎเตเดธเตเดทเตป

**เดเดทเตเดเดพเดจเตเดธเตเดค เดฎเตเดกเตฝ เดเตเตบเดซเดฟเดเดฑเตเดทเตป**:
```python
# เดเดคเตเดชเดพเดฆเดจเดคเตเดคเดฟเดจเตเดณเตเดณ เดเดกเตเดตเดพเตปเดธเตเดกเต เดซเตเดฃเตเดเตเดฐเดฟ เดฒเตเดเตเดเตฝ เดเตเตบเดซเดฟเดเดฑเตเดทเตป
from foundry_local import FoundryLocalManager, ModelConfig

# เดชเตเดฐเดคเตเดฏเตเด เดเดชเดฏเตเด เดเตเดธเตเดเตพเดเตเดเตเดณเตเดณ เดเดธเตเดฑเตเดฑเด เดเตเตบเดซเดฟเดเดฑเตเดทเตป
config = ModelConfig(
    alias="phi-4-mini",
    quantization="Q5_K_M",  # เดชเตเดฐเดคเตเดฏเตเด เดเตเดตเดพเดฃเตเดเตเดธเตเดทเตป เดจเดฟเดฒ
    context_length=4096,    # เดธเดเตเดเตเตผเดฃเตเดฃ เดเดเดจเตเดฑเตเดเตพเดเตเดเตเดณเตเดณ เดตเดฟเดชเตเดฒเตเดเดฐเดฟเดเตเด เดเตเตบเดเตเดเตเดธเตเดฑเตเดฑเต
    batch_size=1,          # เดเด เดเดชเดฏเตเดเตเดคเต เดเดเดจเตเดฑเตเดเตพเดเตเดเดพเดฏเดฟ เดเดชเตเดฑเตเดฑเดฟเดฎเตเดธเต เดเตเดฏเตเดคเดฟเดฐเดฟเดเตเดเตเดจเตเดจเต
    threads=4,             # CPU เดคเตเดฐเตเดกเต เดเดชเตเดฑเตเดฑเดฟเดฎเตเดธเตเดทเตป
    gpu_layers=32,         # GPU เดเดเตเดธเดฟเดฒเดฑเตเดทเตป เดฒเตเดฏเดฑเตเดเตพ
    memory_lock=True,      # เดธเตเดฅเดฟเดฐเดฎเดพเดฏ เดชเตเดฐเดเดเดจเดคเตเดคเดฟเดจเดพเดฏเดฟ เดฎเตเดกเตฝ เดฎเตเดฎเตเดฎเดฑเดฟเดฏเดฟเตฝ เดฒเตเดเตเดเต เดเตเดฏเตเดฏเตเด
    numa=True              # เดฎเตพเดเตเดเดฟ-เดธเตเดเตเดเดฑเตเดฑเต เดธเดฟเดธเตเดฑเตเดฑเดเตเดเตพเดเตเดเตเดณเตเดณ NUMA เดเดชเตเดฑเตเดฑเดฟเดฎเตเดธเตเดทเตป
)

manager = FoundryLocalManager(config=config)
```

**เดชเตเดฐเตเดกเดเตเดทเตป เดตเดฟเดจเตเดฏเดพเดธ เดเตเดเตเดเตเดฒเดฟเดธเตเดฑเตเดฑเต**:

โ **เดธเตเดตเดจ เดเตเตบเดซเดฟเดเดฑเตเดทเตป**:
- เดเดชเดฏเตเด เดเตเดธเตเดเตพเดเตเดเดพเดฏเดฟ เดเดจเตเดฏเตเดเตเดฏเดฎเดพเดฏ เดฎเตเดกเตฝ เดเดฒเดฟเดฏเดพเดธเตเดเตพ เดเตเดฐเดฎเตเดเดฐเดฟเดเตเดเตเด
- เดธเตเดฐเตเดคเดธเตเดธเต เดชเดฐเดฟเดงเดฟเดเดณเตเด เดจเดฟเดฐเตเดเตเดทเดฃ เดชเดฐเดฟเดงเดฟเดเดณเตเด เดธเดเตเดเดฎเดพเดเตเดเตเด
- เดเดฐเตเดเตเดฏ เดชเดฐเดฟเดถเตเดงเดจเดเดณเตเด เดฎเตเดเตเดฐเดฟเดเต เดถเตเดเดฐเดฃเดตเตเด เดธเดเตเดเดฎเดพเดเตเดเตเด
- เดธเตเดตเดฏเด เดชเตเดจเดฐเดพเดฐเดเดญเดตเตเด เดซเตเดฏเดฟเดฒเตเดตเดฑเตเด เดเตเดฐเดฎเตเดเดฐเดฟเดเตเดเตเด

โ **เดธเตเดฐเดเตเดทเดพ เดเตเดฐเดฎเตเดเดฐเดฃเด**:
- เดชเตเดฐเดพเดฆเตเดถเดฟเด เดฎเดพเดคเตเดฐเด API เดเดเตโเดธเดธเต (เดฌเดพเดนเตเดฏ เดชเตเดฐเดฆเตผเดถเดจเด เดเดฒเตเดฒเดพเดคเต) เดธเดเตเดเดฎเดพเดเตเดเตเด
- เดเดจเตเดฏเตเดเตเดฏเดฎเดพเดฏ API เดเต เดฎเดพเดจเตเดเตเดฎเตเดจเตเดฑเต เดเตเดฐเดฎเตเดเดฐเดฟเดเตเดเตเด
- เดเดเดจเตเดฑเต เดเดเดชเตเดเดฒเตเดเตพเดเตเดเดพเดฏเดฟ เดเดกเดฟเดฑเตเดฑเต เดฒเตเดเดฟเดเดเต เดจเดเดชเตเดชเดฟเดฒเดพเดเตเดเตเด
- เดชเตเดฐเตเดกเดเตเดทเตป เดเดชเดฏเตเดเดคเตเดคเดฟเดจเดพเดฏเดฟ เดจเดฟเดฐเดเตเดเต เดจเดฟเดฏเดจเตเดคเตเดฐเดฃเด เดจเดเดชเตเดชเดฟเดฒเดพเดเตเดเตเด

โ **เดชเตเดฐเดเดเดจ เดเดชเตเดฑเตเดฑเดฟเดฎเตเดธเตเดทเตป**:
- เดชเตเดฐเดคเตเดเตเดทเดฟเดเตเด เดฒเตเดกเดฟเตฝ เดฎเตเดกเตฝ เดชเตเดฐเดเดเดจเด เดชเดฐเตเดเตเดทเดฟเดเตเดเตเด
- เดเดจเตเดฏเตเดเตเดฏเดฎเดพเดฏ เดเตเดตเดพเดฃเตเดเตเดธเตเดทเตป เดจเดฟเดฒเดเตพ เดเตเดฐเดฎเตเดเดฐเดฟเดเตเดเตเด
- เดฎเตเดกเตฝ เดเดพเดทเดฟเดเดเต, เดตเดพเดฐเตเดฎเดฟเดเดเต เดคเดจเตเดคเตเดฐเดเตเดเตพ เดธเดเตเดเดฎเดพเดเตเดเตเด
- เดฎเตเดฎเตเดฎเดฑเดฟ, CPU เดเดชเดฏเตเด เดชเดพเดฑเตเดฑเตเดฃเตเดเตพ เดจเดฟเดฐเตเดเตเดทเดฟเดเตเดเตเด

โ **เดธเดเดฏเตเดเดฟเดค เดชเดฐเดฟเดถเตเดงเดจ**:
- เดเดเดจเตเดฑเต เดซเตเดฐเตเดฏเดฟเดเดตเตผเดเตเดเต เดธเดเดฏเตเดเดจเด เดชเดฐเตเดเตเดทเดฟเดเตเดเตเด
- เดเดซเตโเดฒเตเตป เดชเตเดฐเดตเตผเดคเตเดคเดจ เดถเตเดทเดฟเดเตพ เดธเตเดฅเดฟเดฐเตเดเดฐเดฟเดเตเดเตเด
- เดซเตเดฏเดฟเดฒเตเดตเตผ, เดชเตเดจเดฐเตเดฆเตเดงเดพเดฐเดฃ เดธเดพเดนเดเดฐเตเดฏเดเตเดเตพ เดชเดฐเตเดเตเดทเดฟเดเตเดเตเด
- เดเดจเตเดฑเต-เดเตปเดกเต เดเดเดจเตเดฑเต เดชเตเดฐเดตเตเดคเตเดคเดฟ เดชเตเดฐเดตเดพเดนเดเตเดเตพ เดธเดพเดงเตเดเดฐเดฟเดเตเดเตเด

### Ollama: เดฒเดณเดฟเดคเดฎเดพเดฏ SLM เดเดเดจเตเดฑเต เดตเดฟเดจเตเดฏเดพเดธเด

### Ollama: เดธเดฎเตเดน-เดเตเดจเตเดฆเตเดฐเดฟเดค SLM เดเดเดจเตเดฑเต เดตเดฟเดจเตเดฏเดพเดธเด

Ollama เดฒเดณเดฟเดคเดคเตเดตเด, เดตเตเดฏเดพเดชเด เดฎเตเดกเตฝ เดเดเตเดเตเดธเดฟเดธเตเดฑเตเดฑเด, เดกเตเดตเดฒเดชเตเดชเตผ-เดธเตเดนเตเดฆ เดชเตเดฐเดตเตเดคเตเดคเดฟ เดชเตเดฐเดตเดพเดนเดเตเดเตพ เดเดจเตเดจเดฟเดตเดฏเดฟเตฝ เดเดจเตเดจเตฝ เดจเตฝเดเดฟ SLM เดเดเดจเตเดฑเต เดตเดฟเดจเตเดฏเดพเดธเดคเตเดคเดฟเดจเต เดธเดฎเตเดนเด เดจเดฏเดฟเดเตเดเตเดจเตเดจ เดธเดฎเตเดชเดจเด เดจเตฝเดเตเดจเตเดจเต. Foundry Local เดเดจเตเดฑเตผเดชเตเดฐเตเดธเต-เดเตเดฐเตเดกเต เดธเดตเดฟเดถเตเดทเดคเดเดณเดฟเตฝ เดถเตเดฐเดฆเตเดง เดเตเดจเตเดฆเตเดฐเตเดเดฐเดฟเดเตเดเตเดจเตเดจเดชเตเดชเตเตพ, Ollama เดตเตเดเดคเตเดคเดฟเดฒเตเดณเตเดณ เดชเตเดฐเตเดเตเดเตเดเตเดชเตเดชเดฟเดเดเต, เดธเดฎเตเดน เดฎเตเดกเตฝ เดเดเตโเดธเดธเต, เดฒเดณเดฟเดคเดฎเดพเดฏ เดตเดฟเดจเตเดฏเดพเดธ เดธเดพเดนเดเดฐเตเดฏเดเตเดเดณเดฟเตฝ เดฎเดฟเดเดเตเดเดคเดพเดฃเต.

**เดชเตเดฐเดงเดพเดจ เดเตผเดเตเดเดฟเดเตเดเตเดเตผ, เดธเดตเดฟเดถเตเดทเดคเดเตพ**:
- **OpenAI-เดธเดฎเดพเดจเดฎเดพเดฏ API**: เดธเตเดคเดพเดฐเตเดฏเดฎเดพเดฏ เดเดเดจเตเดฑเต เดซเตเดฐเตเดฏเดฟเดเดตเตผเดเตเดเต เดธเดเดฏเตเดเดจเดคเตเดคเดฟเดจเดพเดฏเดฟ เดชเตเตผเดฃเตเดฃ REST API เดเดจเตเดฏเตเดเตเดฏเดค
- **เดตเตเดฏเดพเดชเด เดฎเตเดกเตฝ เดฒเตเดฌเตเดฐเดฑเดฟ**: เดจเตเดฑเตเดเดฃเดเตเดเดฟเดจเต เดธเดฎเตเดน เดธเดเดญเดพเดตเดจเดฏเตเด เดเดฆเตเดฏเตเดเดฟเด เดฎเตเดกเดฒเตเดเดณเตเด เดฒเดญเตเดฏเดฎเดพเดเตเดเตเดจเตเดจเต
- **เดธเดฟเดฎเตเดชเดฟเตพ เดฎเตเดกเตฝ เดฎเดพเดจเตเดเตเดฎเตเดจเตเดฑเต**: เดเดฐเต เดเดฎเดพเตปเดกเดฟเตฝ เดฎเตเดกเตฝ เดเตปเดธเตเดฑเตเดฑเดพเตพ เดเตเดฏเตเดฏเดพเดจเตเด เดฎเดพเดฑเตเดฑเดพเดจเตเด เดธเดพเดงเดฟเดเตเดเตเดจเตเดจเต
- **เดเตเดฐเตเดธเต-เดชเตเดฒเดพเดฑเตเดฑเตเดซเตเด เดชเดฟเดจเตเดคเตเดฃ**: Windows, macOS, Linux เดเดจเตเดจเดฟเดตเดฏเดฟเตฝ เดธเตเดตเดฆเตเดถเตเดฏ เดชเดฟเดจเตเดคเตเดฃ
- **เดธเตเดฐเตเดคเดธเตเดธเต เดเดชเตเดฑเตเดฑเดฟเดฎเตเดธเตเดทเตป**: เดธเตเดตเดฏเด เดเตเดตเดพเดฃเตเดเตเดธเตเดทเตป, เดนเดพเตผเดกเตโเดตเตเดฏเตผ เดเดฃเตเดเตเดคเตเดคเตฝ

#### เดเตปเดธเตเดฑเตเดฑเดฒเตเดทเตป, เดธเตเดฑเตเดฑเดชเตเดชเต

**เดเตเดฐเตเดธเต-เดชเตเดฒเดพเดฑเตเดฑเตเดซเตเด เดเตปเดธเตเดฑเตเดฑเดฒเตเดทเตป**:
```bash
# เดตเดฟเตปเดกเตเดธเต
winget install Ollama.Ollama

# เดฎเดพเดเตโเดเดเดธเต
brew install ollama

# เดฒเดฟเดจเดเตเดธเต
curl -fsSL https://ollama.com/install.sh | sh

# เดกเตเดเตเดเตผ เดตเดฟเดจเตเดฏเดพเดธเด
docker run -d -v ollama:/root/.ollama -p 11434:11434 --name ollama ollama/ollama
```

**เดเดเดจเตเดฑเต เดตเดฟเดเดธเดจเดคเตเดคเดฟเดจเต เดเตเดตเดฟเดเตเดเต เดธเตเดฑเตเดฑเดพเตผเดเตเดเต**:
```bash
# เดเดฒเตเดฒเดพเดฎ เดธเตผเดตเตเดธเต เดเดฐเดเดญเดฟเดเตเดเตเด
ollama serve

# เดเดเดจเตเดฑเต เดตเดฟเดเดธเดจเดคเตเดคเดฟเดจเดพเดฏเดฟ เดฎเตเดกเดฒเตเดเตพ เดชเตเตพ เดเตเดฏเตเดคเต เดชเตเดฐเดตเตผเดคเตเดคเดฟเดชเตเดชเดฟเดเตเดเตเด
ollama pull phi3.5:3.8b-mini-instruct-q4_K_M    # เดฎเตเดเตเดฐเตเดธเตเดซเตเดฑเตเดฑเต เดซเต-3.5 เดฎเดฟเดจเดฟ
ollama pull qwen2.5:0.5b-instruct-q4_K_M        # เดเตเดตเตเตป2.5 0.5เดฌเดฟ
ollama pull llama3.2:1b-instruct-q4_K_M         # เดฒเตเดฒเดพเดฎ 3.2 1เดฌเดฟ

# เดฎเตเดกเตฝ เดฒเดญเตเดฏเดค เดชเดฐเดฟเดถเตเดงเดฟเดเตเดเตเด
ollama list

# API เดเตปเดกเตโเดชเตเดฏเดฟเดจเตเดฑเต เดชเดฐเดฟเดถเตเดงเดฟเดเตเดเตเด
curl http://localhost:11434/api/generate -d '{
  "model": "phi3.5:3.8b-mini-instruct-q4_K_M",
  "prompt": "Hello, how can I help you today?"
}'
```

#### เดเดเดจเตเดฑเต เดซเตเดฐเตเดฏเดฟเดเดตเตผเดเตเดเต เดธเดเดฏเตเดเดจเด

**Microsoft Agent Framework-เดจเตเดชเตเดชเด Ollama**:
```python
from microsoft_agent_framework import Agent, Config
import openai
import requests
import json

class OllamaManager:
    def __init__(self, model_name: str, base_url: str = "http://localhost:11434"):
        self.model_name = model_name
        self.base_url = base_url
        self.api_url = f"{base_url}/api"
        self.openai_url = f"{base_url}/v1"
        
    def ensure_model_available(self) -> bool:
        """Ensure the model is pulled and available."""
        try:
            response = requests.post(f"{self.api_url}/pull", 
                json={"name": self.model_name})
            return response.status_code == 200
        except Exception as e:
            print(f"Failed to pull model {self.model_name}: {e}")
            return False
    
    def get_openai_client(self) -> openai.OpenAI:
        """Get OpenAI-compatible client for Ollama."""
        return openai.OpenAI(
            base_url=self.openai_url,
            api_key="ollama",  # เดเดฒเตเดฒเดพเดฎเดฏเตเดเตเดเต เดฏเดฅเดพเตผเดคเตเดฅ API เดเต เดเดตเดถเตเดฏเดฎเดฟเดฒเตเดฒ
        )
    
    def health_check(self) -> bool:
        """Check if Ollama service is running."""
        try:
            response = requests.get(f"{self.base_url}/api/tags")
            return response.status_code == 200
        except:
            return False

# เดเดเดจเตเดฑเต เดตเดฟเดเดธเดจเดคเตเดคเดฟเดจเดพเดฏเดฟ เดเดฒเตเดฒเดพเดฎ เดเดฐเดเดญเดฟเดเตเดเตเด
ollama_manager = OllamaManager("phi3.5:3.8b-mini-instruct-q4_K_M")
ollama_manager.ensure_model_available()

# เดเดฒเตเดฒเดพเดฎ เดฌเดพเดเตเดเตโเดเตปเดกเตเดฎเดพเดฏเดฟ เดเดเดจเตเดฑเต เดเตเดฐเดฎเตเดเดฐเดฟเดเตเดเตเด
agent_config = Config(
    name="ollama-agent",
    model_provider="ollama",
    model_id="phi3.5:3.8b-mini-instruct-q4_K_M",
    endpoint=ollama_manager.openai_url,
    api_key="ollama"
)

agent = Agent(config=agent_config)
```

**Ollama เดเดชเดฏเตเดเดฟเดเตเดเต เดฎเตพเดเตเดเดฟ-เดฎเตเดกเตฝ เดเดเดจเตเดฑเต เดธเตเดฑเตเดฑเดชเตเดชเต**:
```python
class OllamaMultiModelManager:
    def __init__(self):
        self.models = {
            "lightweight": "qwen2.5:0.5b-instruct-q4_K_M",      # 350MB
            "balanced": "phi3.5:3.8b-mini-instruct-q4_K_M",     # 2.3GB
            "capable": "llama3.2:3b-instruct-q4_K_M",           # 1.9GB
            "coding": "codellama:7b-code-q4_K_M"                # 4.1GB
        }
        self.base_url = "http://localhost:11434"
        self.clients = {}
        self._initialize_models()
    
    def _initialize_models(self):
        """Pull all required models and create clients."""
        for category, model_name in self.models.items():
            # เดฒเดญเตเดฏเดฎเดฒเตเดฒเตเดเตเดเดฟเตฝ เดชเตเตพ เดฎเตเดกเตฝ
            self._pull_model(model_name)
            
            # เดเดฐเต เดฎเตเดกเดฒเดฟเดจเตเด OpenAI เดเตเดฒเดฏเดจเตเดฑเต เดธเตเดทเตเดเดฟเดเตเดเตเด
            self.clients[category] = openai.OpenAI(
                base_url=f"{self.base_url}/v1",
                api_key="ollama"
            )
    
    def _pull_model(self, model_name: str):
        """Pull model if not already available."""
        try:
            response = requests.post(f"{self.base_url}/api/pull", 
                json={"name": model_name})
            if response.status_code == 200:
                print(f"Model {model_name} ready")
        except Exception as e:
            print(f"Failed to pull {model_name}: {e}")
    
    def get_agent_for_task(self, task_type: str) -> Agent:
        """Get appropriate agent based on task complexity."""
        model_category = self._classify_task(task_type)
        model_name = self.models[model_category]
        
        config = Config(
            name=f"ollama-{model_category}-agent",
            model_provider="ollama",
            model_id=model_name,
            endpoint=f"{self.base_url}/v1",
            api_key="ollama"
        )
        
        return Agent(config=config)
    
    def _classify_task(self, task_type: str) -> str:
        """Classify task to appropriate model category."""
        if any(keyword in task_type.lower() for keyword in ["simple", "route", "classify"]):
            return "lightweight"
        elif any(keyword in task_type.lower() for keyword in ["code", "programming", "debug"]):
            return "coding"
        elif any(keyword in task_type.lower() for keyword in ["complex", "analysis", "research"]):
            return "capable"
        else:
            return "balanced"

# เดเดชเดฏเตเด เดเดฆเดพเดนเดฐเดฃเด
manager = OllamaMultiModelManager()

# เดตเตเดฏเดคเตเดฏเดธเตเดค เดเตเดฒเดฟเดเตพเดเตเดเดพเดฏเดฟ เดเดจเตเดฏเตเดเตเดฏเดฎเดพเดฏ เดเดเดจเตเดฑเตเดเตพ เดจเตเดเตเด
routing_agent = manager.get_agent_for_task("simple routing")
coding_agent = manager.get_agent_for_task("code debugging")
analysis_agent = manager.get_agent_for_task("complex analysis")
```

#### เดชเตเดฐเตเดกเดเตเดทเตป เดตเดฟเดจเตเดฏเดพเดธ เดฎเดพเดคเตเดเดเตพ

**Ollama เดเดชเดฏเตเดเดฟเดเตเดเต เดชเตเดฐเตเดกเดเตเดทเตป เดธเตเดตเดจเด**:
```python
import asyncio
import logging
from typing import Dict, Optional
from microsoft_agent_framework import Agent, Config
import requests
import openai

class OllamaProductionService:
    def __init__(self, models_config: Dict[str, str]):
        self.models_config = models_config
        self.base_url = "http://localhost:11434"
        self.agents = {}
        self.metrics = {
            "requests_processed": 0,
            "errors": 0,
            "model_usage": {model: 0 for model in models_config.keys()}
        }
        self._initialize_production_agents()
    
    def _initialize_production_agents(self):
        """Initialize production agents with health checks."""
        for agent_type, model_name in self.models_config.items():
            try:
                # เดฎเตเดกเตฝ เดฒเดญเตเดฏเดฎเดพเดฏเดฟเดฐเดฟเดเตเดเดฃเดฎเตเดจเตเดจเต เดเดฑเดชเตเดชเดพเดเตเดเตเด
                self._ensure_model_ready(model_name)
                
                # เดชเตเดฐเตเดกเดเตเดทเตป เดเดเดจเตเดฑเต เดธเตเดทเตเดเดฟเดเตเดเตเด
                config = Config(
                    name=f"production-{agent_type}",
                    model_provider="ollama",
                    model_id=model_name,
                    endpoint=f"{self.base_url}/v1",
                    api_key="ollama",
                    max_tokens=512,
                    temperature=0.1,
                    timeout=30.0
                )
                
                agent = Agent(config=config)
                
                # เดเดเดจเตเดฑเต เดคเดฐเด เดเดเดฟเดธเตเดฅเดพเดจเดฎเดพเดเตเดเดฟ เดชเตเดฐเตเดกเดเตเดทเตป เดเดชเดเดฐเดฃเดเตเดเตพ เดเตเตผเดเตเดเตเด
                self._add_production_tools(agent, agent_type)
                
                self.agents[agent_type] = agent
                logging.info(f"Initialized {agent_type} agent with model {model_name}")
                
            except Exception as e:
                logging.error(f"Failed to initialize {agent_type} agent: {e}")
    
    def _ensure_model_ready(self, model_name: str):
        """Ensure model is pulled and ready for use."""
        try:
            # เดฎเตเดกเตฝ เดจเดฟเดฒเดตเดฟเดฒเตเดฃเตเดเต เดเดจเตเดจเต เดชเดฐเดฟเดถเตเดงเดฟเดเตเดเตเด
            response = requests.get(f"{self.base_url}/api/tags")
            models = response.json().get('models', [])
            
            model_exists = any(model['name'] == model_name for model in models)
            
            if not model_exists:
                logging.info(f"Pulling model {model_name}...")
                pull_response = requests.post(f"{self.base_url}/api/pull", 
                    json={"name": model_name})
                
                if pull_response.status_code != 200:
                    raise Exception(f"Failed to pull model {model_name}")
                    
        except Exception as e:
            raise Exception(f"Model setup failed for {model_name}: {e}")
    
    def _add_production_tools(self, agent: Agent, agent_type: str):
        """Add tools based on agent type."""
        if agent_type == "customer_service":
            @agent.tool
            def lookup_customer(customer_id: str) -> dict:
                """Look up customer information."""
                # เดกเดพเดฑเตเดฑเดพเดฌเตเดธเต เดฒเตเดเตเดเดชเตเดชเต เดเดจเตเดเดฐเดฟเดเตเดเตเด
                return {"customer_id": customer_id, "status": "active", "tier": "premium"}
            
            @agent.tool
            def create_support_ticket(issue: str, priority: str = "medium") -> str:
                """Create a support ticket."""
                ticket_id = f"TICK-{hash(issue) % 10000:04d}"
                return f"Created ticket {ticket_id} with priority {priority}"
        
        elif agent_type == "technical_support":
            @agent.tool
            def run_diagnostics(system_info: str) -> dict:
                """Run system diagnostics."""
                return {"status": "healthy", "issues": [], "recommendations": []}
            
            @agent.tool
            def access_knowledge_base(query: str) -> str:
                """Search technical knowledge base."""
                return f"Knowledge base results for: {query}"
    
    async def process_request(self, request: str, agent_type: str = "customer_service") -> dict:
        """Process user request with monitoring and error handling."""
        start_time = time.time()
        
        try:
            if agent_type not in self.agents:
                raise ValueError(f"Agent type {agent_type} not available")
            
            agent = self.agents[agent_type]
            response = await agent.chat_async(request)
            
            # เดฎเตเดเตเดฐเดฟเดเตโเดธเต เดเดชเตเดกเตเดฑเตเดฑเต เดเตเดฏเตเดฏเตเด
            self.metrics["requests_processed"] += 1
            self.metrics["model_usage"][agent_type] += 1
            
            processing_time = time.time() - start_time
            
            self._log_interaction(request, response, "success", processing_time, agent_type)
            
            return {
                "response": response,
                "status": "success",
                "processing_time": processing_time,
                "agent_type": agent_type
            }
            
        except Exception as e:
            self.metrics["errors"] += 1
            processing_time = time.time() - start_time
            
            self._log_interaction(request, str(e), "error", processing_time, agent_type)
            
            return {
                "response": "I'm experiencing technical difficulties. Please try again.",
                "status": "error",
                "error": str(e),
                "processing_time": processing_time
            }
    
    def _log_interaction(self, request: str, response: str, status: str, 
                        processing_time: float, agent_type: str):
        """Log interaction for monitoring and analysis."""
        logging.info(f"Agent: {agent_type}, Status: {status}, Time: {processing_time:.2f}s")
        
        # เดชเตเดฐเตเดกเดเตเดทเดจเดฟเตฝ, เดเดคเต เดถเดฐเดฟเดฏเดพเดฏ เดฒเตเดเดฟเดเดเต เดธเดฟเดธเตเดฑเตเดฑเดคเตเดคเดฟเดฒเตเดเตเดเต เดเดดเตเดคเตเด
        log_entry = {
            "timestamp": time.time(),
            "agent_type": agent_type,
            "request_length": len(request),
            "response_length": len(response),
            "status": status,
            "processing_time": processing_time
        }
    
    def get_health_status(self) -> dict:
        """Get service health status."""
        try:
            # เดเดฒเตเดฒเดพเดฎ เดธเตผเดตเตเดธเต เดเดฐเตเดเตเดฏ เดธเตเดฅเดฟเดคเดฟ เดชเดฐเดฟเดถเตเดงเดฟเดเตเดเตเด
            response = requests.get(f"{self.base_url}/api/tags", timeout=5)
            ollama_healthy = response.status_code == 200
            
            # เดฎเตเดกเตฝ เดฒเดญเตเดฏเดค เดชเดฐเดฟเดถเตเดงเดฟเดเตเดเตเด
            available_models = []
            if ollama_healthy:
                models = response.json().get('models', [])
                available_models = [model['name'] for model in models]
            
            return {
                "service_status": "healthy" if ollama_healthy else "unhealthy",
                "ollama_endpoint": self.base_url,
                "available_models": available_models,
                "active_agents": list(self.agents.keys()),
                "metrics": self.metrics,
                "timestamp": time.time()
            }
            
        except Exception as e:
            return {
                "service_status": "error",
                "error": str(e),
                "timestamp": time.time()
            }

# เดชเตเดฐเตเดกเดเตเดทเตป เดตเดฟเดจเตเดฏเดพเดธ เดเดฆเดพเดนเดฐเดฃเด
production_models = {
    "customer_service": "phi3.5:3.8b-mini-instruct-q4_K_M",
    "technical_support": "llama3.2:3b-instruct-q4_K_M",
    "routing": "qwen2.5:0.5b-instruct-q4_K_M"
}

service = OllamaProductionService(production_models)

# เดเดญเตเดฏเตผเดคเตเดฅเดจเดเตพ เดชเตเดฐเตเดธเดธเตเดธเต เดเตเดฏเตเดฏเตเด
result = await service.process_request(
    "I need help with my account settings", 
    "customer_service"
)
print(result)
```

#### เดเดจเตเดฑเตผเดชเตเดฐเตเดธเต เดธเดตเดฟเดถเตเดทเดคเดเดณเตเด เดจเดฟเดฐเตเดเตเดทเดฃเดตเตเด

**Ollama เดจเดฟเดฐเตเดเตเดทเดฃเดตเตเด เดฆเตเดถเตเดฏเดตเตฝเดเตเดเดฐเดฃเดตเตเด**:
```python
import time
import asyncio
import requests
from typing import Dict, List

class OllamaMonitoringService:
    def __init__(self, base_url: str = "http://localhost:11434"):
        self.base_url = base_url
        self.metrics_history = []
        self.alert_thresholds = {
            "response_time_ms": 2000,
            "error_rate_percent": 5,
            "memory_usage_percent": 85
        }
    
    async def collect_metrics(self) -> dict:
        """Collect comprehensive metrics from Ollama service."""
        metrics = {
            "timestamp": time.time(),
            "service_status": "unknown",
            "models": {},
            "performance": {},
            "resources": {}
        }
        
        try:
            # เดธเตเดตเดจเดพเดฐเตเดเตเดฏเด เดชเดฐเดฟเดถเตเดงเดฟเดเตเดเตเด
            health_response = requests.get(f"{self.base_url}/api/tags", timeout=5)
            metrics["service_status"] = "healthy" if health_response.status_code == 200 else "unhealthy"
            
            if metrics["service_status"] == "healthy":
                # เดฎเตเดกเตฝ เดตเดฟเดตเดฐเดเตเดเตพ เดจเตเดเตเด
                models_data = health_response.json().get('models', [])
                for model in models_data:
                    model_name = model['name']
                    metrics["models"][model_name] = {
                        "size_gb": model.get('size', 0) / (1024**3),
                        "modified": model.get('modified_at', ''),
                        "digest": model.get('digest', '')[:12]  # เดเตเดฐเตเดเตเดเด
                    }
                
                # เดเตปเดซเดฑเตปเดธเต เดชเตเดฐเดเดเดจเด เดชเดฐเดฟเดถเตเดงเดฟเดเตเดเตเด
                start_time = time.time()
                test_response = requests.post(f"{self.base_url}/api/generate", 
                    json={
                        "model": list(metrics["models"].keys())[0] if metrics["models"] else "",
                        "prompt": "Hello",
                        "stream": False
                    }, timeout=10)
                
                if test_response.status_code == 200:
                    inference_time = (time.time() - start_time) * 1000
                    metrics["performance"] = {
                        "inference_time_ms": inference_time,
                        "tokens_per_second": self._calculate_tokens_per_second(test_response.json()),
                        "last_successful_inference": time.time()
                    }
            
        except Exception as e:
            metrics["service_status"] = "error"
            metrics["error"] = str(e)
        
        self.metrics_history.append(metrics)
        
        # เดเดตเดธเดพเดจ 100 เดฎเตเดเตเดฐเดฟเดเต เดเตปเดเตเดฐเดฟเดเตพ เดฎเดพเดคเตเดฐเด เดธเตเดเตเดทเดฟเดเตเดเตเด
        if len(self.metrics_history) > 100:
            self.metrics_history = self.metrics_history[-100:]
        
        return metrics
    
    def _calculate_tokens_per_second(self, response_data: dict) -> float:
        """Calculate approximate tokens per second from response."""
        try:
            # เดเตเดเตเดเดฃเตเดเตพ เดเดณเดเตเดเตเด (เดเดเดฆเตเดถเด)
            response_text = response_data.get('response', '')
            estimated_tokens = len(response_text.split())
            
            # เดฒเดญเตเดฏเดฎเดพเดฏเตเดเตเดเดฟเตฝ เดธเดฎเดฏ เดตเดฟเดตเดฐเดเตเดเตพ เดจเตเดเตเด
            eval_duration = response_data.get('eval_duration', 0)
            if eval_duration > 0:
                # เดจเดพเดจเตเดธเตเดเตเดเตปเดกเตเดเตพ เดธเตเดเตเดเตปเดกเตเดเดณเดพเดเตเดเดฟ เดฎเดพเดฑเตเดฑเตเด
                duration_seconds = eval_duration / 1e9
                return estimated_tokens / duration_seconds if duration_seconds > 0 else 0
        except:
            pass
        return 0
    
    def check_alerts(self, current_metrics: dict) -> List[dict]:
        """Check current metrics against alert thresholds."""
        alerts = []
        
        # เดชเตเดฐเดคเดฟเดเดฐเดฃ เดธเดฎเดฏเด เดชเดฐเดฟเดถเตเดงเดฟเดเตเดเตเด
        if current_metrics.get('performance', {}).get('inference_time_ms', 0) > self.alert_thresholds['response_time_ms']:
            alerts.append({
                "type": "performance",
                "message": f"High response time: {current_metrics['performance']['inference_time_ms']:.0f}ms",
                "severity": "warning"
            })
        
        # เดธเตเดตเดจ เดจเดฟเดฒ เดชเดฐเดฟเดถเตเดงเดฟเดเตเดเตเด
        if current_metrics.get('service_status') != 'healthy':
            alerts.append({
                "type": "availability",
                "message": f"Service unhealthy: {current_metrics.get('error', 'Unknown error')}",
                "severity": "critical"
            })
        
        return alerts
    
    def get_performance_summary(self, minutes: int = 60) -> dict:
        """Get performance summary for the last N minutes."""
        cutoff_time = time.time() - (minutes * 60)
        recent_metrics = [m for m in self.metrics_history if m['timestamp'] > cutoff_time]
        
        if not recent_metrics:
            return {"error": "No recent metrics available"}
        
        # เดถเดฐเดพเดถเดฐเดฟเดเตพ เดเดฃเดเตเดเดพเดเตเดเตเด
        response_times = [m.get('performance', {}).get('inference_time_ms', 0) 
                         for m in recent_metrics if m.get('performance')]
        
        healthy_checks = sum(1 for m in recent_metrics if m.get('service_status') == 'healthy')
        uptime_percent = (healthy_checks / len(recent_metrics)) * 100 if recent_metrics else 0
        
        return {
            "period_minutes": minutes,
            "total_checks": len(recent_metrics),
            "uptime_percent": uptime_percent,
            "avg_response_time_ms": sum(response_times) / len(response_times) if response_times else 0,
            "max_response_time_ms": max(response_times) if response_times else 0,
            "min_response_time_ms": min(response_times) if response_times else 0
        }

# เดเดคเตเดชเดพเดฆเดจ เดจเดฟเดฐเตเดเตเดทเดฃ เดเตเดฐเดฎเตเดเดฐเดฃเด
monitor = OllamaMonitoringService()

async def monitoring_loop():
    """Continuous monitoring loop."""
    while True:
        try:
            metrics = await monitor.collect_metrics()
            alerts = monitor.check_alerts(metrics)
            
            if alerts:
                for alert in alerts:
                    logging.warning(f"ALERT: {alert['message']} (Severity: {alert['severity']})")
            
            # เดเดฐเต 10 เดฎเดฟเดจเดฟเดฑเตเดฑเดฟเดฒเตเด เดชเตเดฐเดเดเดจ เดธเดเดเตเดฐเดนเด เดฒเตเดเต เดเตเดฏเตเดฏเตเด
            if int(time.time()) % 600 == 0:  # เดเดฐเต 10 เดฎเดฟเดจเดฟเดฑเตเดฑเดฟเดฒเตเด
                summary = monitor.get_performance_summary(10)
                logging.info(f"Performance Summary: {summary}")
            
        except Exception as e:
            logging.error(f"Monitoring error: {e}")
        
        await asyncio.sleep(30)  # เดเดฐเต 30 เดธเตเดเตเดเตปเดกเดฟเดฒเตเด เดชเดฐเดฟเดถเตเดงเดฟเดเตเดเตเด

# เดจเดฟเดฐเตเดเตเดทเดฃเด เดเดฐเดเดญเดฟเดเตเดเตเด
# asyncio.create_task(monitoring_loop())
```

#### เดเดงเตเดจเดฟเด เดเตเตบเดซเดฟเดเดฑเตเดทเตป, เดเดชเตเดฑเตเดฑเดฟเดฎเตเดธเตเดทเตป

**Ollama-เดฏเตเดฎเดพเดฏเดฟ เดเดทเตเดเดพเดจเตเดธเตเดค เดฎเตเดกเตฝ เดฎเดพเดจเตเดเตเดฎเตเดจเตเดฑเต**:
```python
class OllamaModelManager:
    def __init__(self, base_url: str = "http://localhost:11434"):
        self.base_url = base_url
        self.model_catalog = {
            # เดตเตเดเดคเตเดคเดฟเดฒเตเดณเตเดณ เดชเตเดฐเดคเดฟเดเดฐเดฃเดเตเดเตพเดเตเดเต เดฒเดเตเดตเดพเดฏ เดฎเตเดกเดฒเตเดเตพ
            "ultra_light": [
                "qwen2.5:0.5b-instruct-q4_K_M",
                "tinyllama:1.1b-chat-q4_K_M"
            ],
            # เดชเตเดคเตเดตเดพเดฏ เดเดชเดฏเตเดเดคเตเดคเดฟเดจเตเดณเตเดณ เดธเดฎเดคเตเดฒเดฟเดค เดฎเตเดกเดฒเตเดเตพ
            "balanced": [
                "phi3.5:3.8b-mini-instruct-q4_K_M",
                "llama3.2:3b-instruct-q4_K_M"
            ],
            # เดชเตเดฐเดคเตเดฏเตเด เดเตเดฒเดฟเดเตพเดเตเดเตเดณเตเดณ เดชเตเดฐเดคเตเดฏเตเด เดฎเตเดกเดฒเตเดเตพ
            "code_specialist": [
                "codellama:7b-code-q4_K_M",
                "codegemma:7b-code-q4_K_M"
            ],
            # เดเดฏเตผเดจเตเดจ เดถเตเดทเดฟเดฏเตเดณเตเดณ เดฎเตเดกเดฒเตเดเตพ
            "high_capability": [
                "llama3.1:8b-instruct-q4_K_M",
                "qwen2.5:7b-instruct-q4_K_M"
            ]
        }
    
    def setup_production_models(self, categories: List[str]) -> dict:
        """Set up models for production use."""
        setup_results = {}
        
        for category in categories:
            if category not in self.model_catalog:
                setup_results[category] = {"status": "error", "message": "Unknown category"}
                continue
            
            models = self.model_catalog[category]
            category_results = []
            
            for model in models:
                try:
                    # เดชเตเตพ เดฎเตเดกเตฝ
                    response = requests.post(f"{self.base_url}/api/pull", 
                        json={"name": model})
                    
                    if response.status_code == 200:
                        category_results.append({"model": model, "status": "ready"})
                    else:
                        category_results.append({"model": model, "status": "failed"})
                        
                except Exception as e:
                    category_results.append({"model": model, "status": "error", "error": str(e)})
            
            setup_results[category] = category_results
        
        return setup_results
    
    def optimize_for_hardware(self) -> dict:
        """Recommend optimal models based on available hardware."""
        # เดธเดพเดงเดพเดฐเดฃเดฏเดพเดฏเดฟ เดเดคเต เดฏเดฅเดพเตผเดคเตเดฅ เดนเดพเตผเดกเตโเดตเตเดฏเตผ เดธเตเดชเตเดเตโเดธเต เดชเดฐเดฟเดถเตเดงเดฟเดเตเดเตเด
        # เดกเตเดฎเต เดเดตเดถเตเดฏเดเตเดเตพเดเตเดเต, เดจเดพเด เดนเดพเตผเดกเตโเดตเตเดฏเตผ เดเดฃเตเดเตเดคเตเดคเตฝ เดเดจเตเดเดฐเดฟเดเตเดเตเด
        
        recommendations = {
            "low_resource": {
                "models": ["qwen2.5:0.5b-instruct-q4_K_M"],
                "max_concurrent": 1,
                "memory_usage": "< 1GB"
            },
            "medium_resource": {
                "models": ["phi3.5:3.8b-mini-instruct-q4_K_M", "llama3.2:3b-instruct-q4_K_M"],
                "max_concurrent": 2,
                "memory_usage": "2-4GB"
            },
            "high_resource": {
                "models": ["llama3.1:8b-instruct-q4_K_M", "codellama:7b-code-q4_K_M"],
                "max_concurrent": 3,
                "memory_usage": "6-12GB"
            }
        }
        
        return recommendations

# เดชเตเดฐเตเดกเดเตเดทเตป เดฎเตเดกเตฝ เดเตเดฐเดฎเตเดเดฐเดฃเด
model_manager = OllamaModelManager()
setup_results = model_manager.setup_production_models(["balanced", "ultra_light"])
print(f"Model setup results: {setup_results}")
```

**Ollama เดชเตเดฐเตเดกเดเตเดทเตป เดตเดฟเดจเตเดฏเดพเดธ เดเตเดเตเดเตเดฒเดฟเดธเตเดฑเตเดฑเต**:

โ **เดธเตเดตเดจ เดเตเตบเดซเดฟเดเดฑเตเดทเตป**:
- Ollama เดธเตเดตเดจเด เดถเดฐเดฟเดฏเดพเดฏ เดธเดฟเดธเตเดฑเตเดฑเด เดธเดเดฏเตเดเดจเดคเตเดคเตเดเต เดเตปเดธเตเดฑเตเดฑเดพเตพ เดเตเดฏเตเดฏเตเด
- เดชเตเดฐเดคเตเดฏเตเด เดเดเดจเตเดฑเต เดเดชเดฏเตเด เดเตเดธเตเดเตพเดเตเดเดพเดฏเดฟ เดฎเตเดกเดฒเตเดเตพ เดเตเดฐเดฎเตเดเดฐเดฟเดเตเดเตเด
- เดถเดฐเดฟเดฏเดพเดฏ เดธเตเดฑเตเดฑเดพเตผเดเตเดเดชเตเดชเต เดธเตเดเตเดฐเดฟเดชเตเดฑเตเดฑเตเดเดณเตเด เดธเตเดตเดจ เดฎเดพเดจเตเดเตเดฎเตเดจเตเดฑเตเด เดธเดเตเดเดฎเดพเดเตเดเตเด
- เดฎเตเดกเตฝ เดฒเตเดกเดฟเดเดเต, API เดฒเดญเตเดฏเดค เดชเดฐเตเดเตเดทเดฟเดเตเดเตเด

โ **เดฎเตเดกเตฝ เดฎเดพเดจเตเดเตเดฎเตเดจเตเดฑเต**:
- เดเดตเดถเตเดฏเดฎเดพเดฏ เดฎเตเดกเดฒเตเดเตพ เดชเตเตพ เดเตเดฏเตเดคเต เดธเดฎเดเตเดฐเดค เดชเดฐเดฟเดถเตเดงเดฟเดเตเดเตเด
- เดฎเตเดกเตฝ เดเดชเตเดกเตเดฑเตเดฑเต, เดฑเตเดเตเดเตเดทเตป เดจเดเดชเดเดฟเดเตเดฐเดฎเดเตเดเตพ เดธเดเตเดเดฎเดพเดเตเดเตเด
- เดฎเตเดกเตฝ เดเดพเดทเดฟเดเดเต, เดธเดเดญเดฐเดฃ เดเดชเตเดฑเตเดฑเดฟเดฎเตเดธเตเดทเตป เดเตเดฐเดฎเตเดเดฐเดฟเดเตเดเตเด
- เดชเตเดฐเดคเตเดเตเดทเดฟเดเตเด เดฒเตเดกเดฟเตฝ เดฎเตเดกเตฝ เดชเตเดฐเดเดเดจเด เดชเดฐเตเดเตเดทเดฟเดเตเดเตเด

โ **เดธเตเดฐเดเตเดทเดพ เดเตเดฐเดฎเตเดเดฐเดฃเด**:
- เดชเตเดฐเดพเดฆเตเดถเดฟเด เดฎเดพเดคเตเดฐเด เดเดเตโเดธเดธเดฟเดจเดพเดฏเดฟ เดซเดฏเตผเดตเดพเตพ เดจเดฟเดฏเดฎเดเตเดเตพ เดเตเดฐเดฎเตเดเดฐเดฟเดเตเดเตเด
- API เดเดเตโเดธเดธเต เดจเดฟเดฏเดจเตเดคเตเดฐเดฃเดเตเดเดณเตเด เดจเดฟเดฐเดเตเดเต เดจเดฟเดฏเดจเตเดคเตเดฐเดฃเดตเตเด เดธเดเตเดเดฎเดพเดเตเดเตเด
- เดเดเดจเตเดฑเต เดเดเดชเตเดเดฒเตเดเตพเดเตเดเดพเดฏเดฟ เดเดกเดฟเดฑเตเดฑเต เดฒเตเดเดฟเดเดเต เดจเดเดชเตเดชเดฟเดฒเดพเดเตเดเตเด
- เดธเตเดฐเดเตเดทเดฟเดค เดฎเตเดกเตฝ เดธเดเดญเดฐเดฃเด, เดเดเตโเดธเดธเต เดเตเดฐเดฎเตเดเดฐเดฟเดเตเดเตเด

โ **เดชเตเดฐเดเดเดจ เดเดชเตเดฑเตเดฑเดฟเดฎเตเดธเตเดทเตป**:
- เดชเตเดฐเดคเตเดเตเดทเดฟเดเตเด เดเดชเดฏเตเด เดเตเดธเตเดเตพเดเตเดเดพเดฏเดฟ เดฎเตเดกเดฒเตเดเตพ เดฌเดเตเดเตเดฎเดพเตผเดเตเดเต เดเตเดฏเตเดฏเตเด
- เดเดจเตเดฏเตเดเตเดฏเดฎเดพเดฏ เดนเดพเตผเดกเตโเดตเตเดฏเตผ เดตเตเดเดค เดตเตผเดฆเตเดงเดจเดตเต เดเตเดฐเดฎเตเดเดฐเดฟเดเตเดเตเด
- เดฎเตเดกเตฝ เดตเดพเดฐเตเดฎเดฟเดเดเต, เดเดพเดทเดฟเดเดเต เดคเดจเตเดคเตเดฐเดเตเดเตพ เดธเดเตเดเดฎเดพเดเตเดเตเด
- เดธเตเดฐเตเดคเดธเตเดธเต เดเดชเดฏเตเดเดตเตเด เดชเตเดฐเดเดเดจ เดฎเตเดเตเดฐเดฟเดเตโเดธเตเด เดจเดฟเดฐเตเดเตเดทเดฟเดเตเดเตเด

โ **เดธเดเดฏเตเดเดฟเดค เดชเดฐเดฟเดถเตเดงเดจ**:
- Microsoft เดเดเดจเตเดฑเต เดซเตเดฐเตเดฏเดฟเดเดตเตผเดเตเดเต เดเดจเตเดฑเดเตเดฐเตเดทเตป เดเตเดธเตเดฑเตเดฑเต เดเตเดฏเตเดฏเตเด  
- เดเดซเตโเดฒเตเตป เดชเตเดฐเดตเตผเดคเตเดคเดจ เดถเตเดทเดฟเดเตพ เดธเตเดฅเดฟเดฐเตเดเดฐเดฟเดเตเดเตเด  
- เดซเตเดฏเดฟเตฝเดเดตเตผ เดธเตเดจเดพเดฐเดฟเดฏเตเดเดณเตเด เดชเดฟเดถเดเต เดเตเดเดพเดฐเตเดฏเด เดเตเดฏเตเดฏเดฒเตเด เดเตเดธเตเดฑเตเดฑเต เดเตเดฏเตเดฏเตเด  
- เดเดจเตเดฑเต-เดเตปเดกเต เดเดเดจเตเดฑเต เดตเตผเดเตเดเตโเดซเตเดฒเตเดเตพ เดธเดพเดงเตเดเดฐเดฟเดเตเดเตเด  

**Foundry Local-เดจเตเดเตเดณเตเดณ เดคเดพเดฐเดคเดฎเตเดฏเด**:

| เดซเตเดเตเดเตผ | Foundry Local | Ollama |
|---------|---------------|--------|
| **เดฒเดเตเดทเตเดฏ เดเดชเดฏเตเด เดเตเดธเต** | เดเดจเตเดฑเตผเดชเตเดฐเตเดธเต เดชเตเดฐเตเดกเดเตเดทเตป | เดกเตเดตเดฒเดชเตเดชเตเดฎเตเดจเตเดฑเต & เดเดฎเตเดฎเตเดฏเตเดฃเดฟเดฑเตเดฑเดฟ |
| **เดฎเตเดกเตฝ เดเดเตเดเตเดธเดฟเดธเตเดฑเตเดฑเด** | Microsoft-เดเตเดฏเตเดฑเตเดฑเตเดฑเดกเต | เดตเตเดฏเดพเดชเดเดฎเดพเดฏ เดเดฎเตเดฎเตเดฏเตเดฃเดฟเดฑเตเดฑเดฟ |
| **เดนเดพเตผเดกเตโเดตเตเดฏเตผ เดเดชเตเดฑเตเดฑเดฟเดฎเตเดธเตเดทเตป** | เดเดเตเดเตเดฎเดพเดฑเตเดฑเดฟเดเต (CUDA/NPU/CPU) | เดฎเดพเดจเตเดตเตฝ เดเตเตบเดซเดฟเดเดฑเตเดทเตป |
| **เดเดจเตเดฑเตผเดชเตเดฐเตเดธเต เดซเตเดเตเดเดฑเตเดเตพ** | เดเตปเดฌเดฟเตฝเดฑเตเดฑเต เดฎเตเดฃเดฟเดฑเตเดฑเดฑเดฟเดเดเต, เดธเตเดเตเดฏเตเดฐเดฟเดฑเตเดฑเดฟ | เดเดฎเตเดฎเตเดฏเตเดฃเดฟเดฑเตเดฑเดฟ เดเตเดณเตเดเตพ |
| **เดกเดฟเดชเตเดฒเตเดฏเตเดฎเตเดจเตเดฑเต เดธเดเตเดเตเตผเดฃเตเดฃเดค** | เดฒเดณเดฟเดคเด (winget install) | เดฒเดณเดฟเดคเด (curl install) |
| **API เดชเตเดฐเตเดคเตเดคเด** | OpenAI + เดเดเตเดธเตเดฑเตเดฑเตปเดทเดจเตเดเตพ | OpenAI เดธเตเดฑเตเดฑเดพเตปเดกเตเตผเดกเต |
| **เดธเดชเตเดชเตเตผเดเตเดเต** | Microsoft เดเดฆเตเดฏเตเดเดฟเดเด | เดเดฎเตเดฎเตเดฏเตเดฃเดฟเดฑเตเดฑเดฟ-เดกเตเดฐเดฟเดตเตป |
| **เดเดคเตเดคเดฎเด** | เดชเตเดฐเตเดกเดเตเดทเตป เดเดเดจเตเดฑเตเดเตพ | เดชเตเดฐเตเดเตเดเตเดเตเดชเตเดชเดฟเดเดเต, เดเดตเตเดทเดฃเด |

**Ollama เดคเดฟเดฐเดเตเดเตเดเตเดเตเดเตเดฃเตเดเดชเตเดชเตเตพ**:  
- **เดกเตเดตเดฒเดชเตเดชเตเดฎเตเดจเตเดฑเต & เดชเตเดฐเตเดเตเดเตเดเตเดชเตเดชเดฟเดเดเต**: เดตเตเดฏเดคเตเดฏเดธเตเดค เดฎเตเดกเดฒเตเดเดณเตเดฎเดพเดฏเดฟ เดตเตเดเดคเตเดคเดฟเดฒเตเดณเตเดณ เดชเดฐเตเดเตเดทเดฃเดเตเดเตพ  
- **เดเดฎเตเดฎเตเดฏเตเดฃเดฟเดฑเตเดฑเดฟ เดฎเตเดกเดฒเตเดเตพ**: เดเดฑเตเดฑเดตเตเด เดชเตเดคเดฟเดฏ เดเดฎเตเดฎเตเดฏเตเดฃเดฟเดฑเตเดฑเดฟ-เดธเดเดญเดพเดตเดจ เดฎเตเดกเดฒเตเดเตพเดเตเดเต เดเดเตโเดธเดธเต  
- **เดตเดฟเดฆเตเดฏเดพเดญเตเดฏเดพเดธ เดเดชเดฏเตเดเด**: AI เดเดเดจเตเดฑเต เดตเดฟเดเดธเดจเด เดชเดเดฟเดเตเดเตเดเดฏเตเด เดชเดเดฟเดชเตเดชเดฟเดเตเดเตเดเดฏเตเด เดเตเดฏเตเดฏเตเด  
- **เดเดตเตเดทเดฃ เดชเตเดฐเตเดเดเตเดเตเดเตพ**: เดตเตเดตเดฟเดงเตเดฏเดฎเดพเตผเดจเตเดจ เดฎเตเดกเตฝ เดเดเตโเดธเดธเต เดเดตเดถเตเดฏเดฎเดพเดฏ เดเดเตเดเดพเดฆเดฎเดฟเดเต เดเดตเตเดทเดฃเด  
- **เดเดธเตเดฑเตเดฑเด เดฎเตเดกเดฒเตเดเตพ**: เดเดธเตเดฑเตเดฑเด เดซเตเตป-เดเตเดฏเตเตบ เดเตเดฏเตเดค เดฎเตเดกเดฒเตเดเตพ เดจเดฟเตผเดฎเตเดฎเดฟเดเตเดเตเดเดฏเตเด เดเตเดธเตเดฑเตเดฑเต เดเตเดฏเตเดฏเตเดเดฏเตเด เดเตเดฏเตเดฏเตเด  

### VLLM: เดเดฏเตผเดจเตเดจ เดชเตเดฐเดเดเดจเดฎเตเดณเตเดณ SLM เดเดเดจเตเดฑเต เดเตปเดซเดฑเตปเดธเต

VLLM (เดตเตเดฑเดฟ เดฒเดพเตผเดเต เดฒเดพเดเดเตเดตเตเดเต เดฎเตเดกเตฝ เดเตปเดซเดฑเตปเดธเต) เดเตฝเดชเตเดชเดพเดฆเดจ SLM เดกเดฟเดชเตเดฒเตเดฏเตเดฎเตเดจเตเดฑเตเดเตพเดเตเดเต เดธเตเดเตเดฏเดฟเดฒเดฟเตฝ เดชเดฐเดฎเดพเดตเดงเดฟ เดคเตเดฐเตเดชเตเดเตเดเตเด เดฎเตเดฎเตเดฎเดฑเดฟ เดเดพเดฐเตเดฏเดเตเดทเดฎเดคเดฏเตเด เดจเตฝเดเตเดจเตเดจ เดเดฏเตผเดจเตเดจ เดคเตเดฐเตเดชเตเดเตเดเต, เดฎเตเดฎเตเดฎเดฑเดฟ-เดเดซเดฟเดทเตเดฏเดจเตเดฑเต เดเตปเดซเดฑเตปเดธเต เดเดเตเดเดฟเตป เดเดฃเต. Foundry Local เดเดชเดฏเตเดเดธเตเดเดฐเตเดฏเดคเตเดคเดฟเตฝ เดถเตเดฐเดฆเตเดง เดเตเดจเตเดฆเตเดฐเตเดเดฐเดฟเดเตเดเตเดจเตเดจเดชเตเดชเตเตพ, Ollama เดเดฎเตเดฎเตเดฏเตเดฃเดฟเดฑเตเดฑเดฟ เดฎเตเดกเดฒเตเดเตพเดเตเดเต เดชเตเดฐเดพเดงเดพเดจเตเดฏเด เดจเตฝเดเตเดฎเตเดชเตเตพ, VLLM เดชเดฐเดฎเดพเดตเดงเดฟ เดคเตเดฐเตเดชเตเดเตเดเตเด เดเดพเดฐเตเดฏเดเตเดทเดฎเดฎเดพเดฏ เดฑเดฟเดธเตเดดเตโเดธเต เดเดชเดฏเตเดเดตเตเด เดเดตเดถเตเดฏเดฎเดพเดฏ เดเดฏเตผเดจเตเดจ เดชเตเดฐเดเดเดจ เดธเตเดจเดพเดฐเดฟเดฏเตเดเดณเดฟเตฝ เดฎเดฟเดเดเตเดเดคเดพเดฃเต.  

**เดเตเตผ เดเตผเดเตเดเดฟเดเตเดเตเดเตผ & เดซเตเดเตเดเดฑเตเดเตพ**:  
- **PagedAttention**: เดเดพเดฐเตเดฏเดเตเดทเดฎเดฎเดพเดฏ เดเดฑเตเดฑเตปเดทเตป เดเดเดชเตเดฏเตเดเตเดเตเดทเดจเดฟเดจเตเดณเตเดณ เดตเดฟเดชเตเดฒเดตเดเดฐเดฎเดพเดฏ เดฎเตเดฎเตเดฎเดฑเดฟ เดฎเดพเดจเตเดเตเดฎเตเดจเตเดฑเต  
- **Dynamic Batching**: เดชเดฐเดฎเดพเดตเดงเดฟ เดคเตเดฐเตเดชเตเดเตเดเดฟเดจเดพเดฏเดฟ เดฌเตเดฆเตเดงเดฟเดฎเตเดเตเดเตเดณเตเดณ เดเดญเตเดฏเตผเดคเตเดฅเดจ เดฌเดพเดเตเดเดฟเดเดเต  
- **GPU เดเดชเตเดฑเตเดฑเดฟเดฎเตเดธเตเดทเตป**: เดเดงเตเดจเดฟเด CUDA เดเตผเดฃเดฒเตเดเดณเตเด เดเตเตปเดธเตผ เดชเดพเดฐเดฒเดฒเดฟเดธเดตเตเด เดชเดฟเดจเตเดคเตเดฃเดฏเตเดเตเดเตเดจเตเดจเต  
- **OpenAI เดชเตเดฐเตเดคเตเดคเด**: เดธเตเดคเดพเดฐเตเดฏเดฎเดพเดฏ เดเดจเตเดฑเดเตเดฐเตเดทเดจเดฟเดจเดพเดฏเดฟ เดชเตเตผเดฃเตเดฃ API เดชเตเดฐเตเดคเตเดคเด  
- **Speculative Decoding**: เดเดงเตเดจเดฟเด เดเตปเดซเดฑเตปเดธเต เดตเตเดเดค เดตเตผเดฆเตเดงเดจเดตเดฟเดจเตเดณเตเดณ เดธเดพเดเตเดเตเดคเดฟเด เดตเดฟเดฆเตเดฏเดเตพ  
- **Quantization Support**: เดฎเตเดฎเตเดฎเดฑเดฟ เดเดพเดฐเตเดฏเดเตเดทเดฎเดคเดฏเตเดเตเดเดพเดฏเดฟ INT4, INT8, FP16 เดเตเดตเดพเดฃเตเดเตเดธเตเดทเตป  

#### เดเตปเดธเตเดฑเตเดฑเดฒเตเดทเตป & เดธเตเดฑเตเดฑเดชเตเดชเต

**เดเตปเดธเตเดฑเตเดฑเดฒเตเดทเตป เดเดชเตเดทเดจเตเดเตพ**:  
```bash
# เดธเตเดฑเตเดฑเดพเตปเดกเตเตผเดกเต เดเตปเดธเตเดฑเตเดฑเดฒเตเดทเตป
pip install vllm

# เดเดเดจเตเดฑเต เดซเตเดฐเตเดฏเดฟเดเดตเตผเดเตเดเตเดเตพเดเตเดเตเดณเตเดณ เดเดงเดฟเด เดเดถเตเดฐเดฟเดคเดเตเดเดณเตเดเตเดเตเดเดฟ
pip install vllm[agent] openai

# เดชเตเดฐเตเดกเดเตเดทเดจเดพเดฏเดฟ เดกเตเดเตเดเตผ เดตเดฟเดจเตเดฏเดพเดธเด
docker pull vllm/vllm-openai:latest

# เดเดฑเตเดฑเดตเตเด เดชเตเดคเดฟเดฏ เดซเตเดเตเดเดฑเตเดเตพเดเตเดเดพเดฏเดฟ เดธเตเดดเตโเดธเดฟเตฝ เดจเดฟเดจเตเดจเต
git clone https://github.com/vllm-project/vllm.git
cd vllm
pip install -e .
```
  
**เดเดเดจเตเดฑเต เดกเตเดตเดฒเดชเตเดชเตเดฎเตเดจเตเดฑเดฟเดจเตเดณเตเดณ เดเตเดตเดฟเดเตเดเต เดธเตเดฑเตเดฑเดพเตผเดเตเดเต**:  
```bash
# SLM เดฎเตเดกเดฒเตเดฎเดพเดฏเดฟ VLLM เดธเตเตผเดตเตผ เดเดฐเดเดญเดฟเดเตเดเตเด
python -m vllm.entrypoints.openai.api_server \
    --model microsoft/Phi-3.5-mini-instruct \
    --trust-remote-code \
    --max-model-len 4096 \
    --gpu-memory-utilization 0.8

# เดฌเดฆเตฝ: เดฒเดเตเดตเดพเดฏ เดเดเดจเตเดฑเตเดเตพเดเตเดเดพเดฏเดฟ Qwen2.5 เดเดชเดฏเตเดเดฟเดเตเดเต เดเดฐเดเดญเดฟเดเตเดเตเด
python -m vllm.entrypoints.openai.api_server \
    --model Qwen/Qwen2.5-0.5B-Instruct \
    --trust-remote-code \
    --max-model-len 2048 \
    --tensor-parallel-size 1

# API เดเตปเดกเตโเดชเตเดฏเดฟเดจเตเดฑเต เดชเดฐเดฟเดถเตเดงเดจ
curl http://localhost:8000/v1/models

# เดเดพเดฑเตเดฑเต เดชเตเตผเดคเตเดคเตเดเดฐเดฃเด เดชเดฐเดฟเดถเตเดงเดจ
curl http://localhost:8000/v1/chat/completions \
    -H "Content-Type: application/json" \
    -d '{
        "model": "microsoft/Phi-3.5-mini-instruct",
        "messages": [{"role": "user", "content": "Hello!"}]
    }'
```
  
#### เดเดเดจเตเดฑเต เดซเตเดฐเตเดฏเดฟเดเดตเตผเดเตเดเต เดเดจเตเดฑเดเตเดฐเตเดทเตป

**Microsoft Agent Framework-เดเด VLLM-เดเด**:  
```python
from microsoft_agent_framework import Agent, Config
import openai
import subprocess
import time
import requests
from typing import Optional, Dict, Any

class VLLMManager:
    def __init__(self, model_name: str, 
                 host: str = "localhost", 
                 port: int = 8000,
                 gpu_memory_utilization: float = 0.8,
                 max_model_len: int = 4096):
        self.model_name = model_name
        self.host = host
        self.port = port
        self.base_url = f"http://{host}:{port}"
        self.gpu_memory_utilization = gpu_memory_utilization
        self.max_model_len = max_model_len
        self.process = None
        self.client = None
        
    def start_server(self) -> bool:
        """Start VLLM server with optimized settings for agents."""
        try:
            cmd = [
                "python", "-m", "vllm.entrypoints.openai.api_server",
                "--model", self.model_name,
                "--host", self.host,
                "--port", str(self.port),
                "--gpu-memory-utilization", str(self.gpu_memory_utilization),
                "--max-model-len", str(self.max_model_len),
                "--trust-remote-code",
                "--disable-log-requests",  # เดเดเดจเตเดฑเตเดเตพเดเตเดเตเดณเตเดณ เดฒเตเดเดฟเดเดเต เดเตเดฑเดฏเตเดเตเดเตเด
                "--served-model-name", self.get_served_model_name()
            ]
            
            self.process = subprocess.Popen(cmd, 
                stdout=subprocess.PIPE, 
                stderr=subprocess.PIPE)
            
            # เดธเตเตผเดตเตผ เดเดฐเดเดญเดฟเดเตเดเดพเตป เดเดพเดคเตเดคเดฟเดฐเดฟเดเตเดเตเด
            max_retries = 30
            for _ in range(max_retries):
                if self.health_check():
                    self.client = openai.OpenAI(base_url=f"{self.base_url}/v1")
                    return True
                time.sleep(2)
                
            return False
            
        except Exception as e:
            print(f"Failed to start VLLM server: {e}")
            return False
    
    def get_served_model_name(self) -> str:
        """Get a clean model name for serving."""
        return self.model_name.replace("/", "--")
    
    def health_check(self) -> bool:
        """Check if VLLM server is healthy."""
        try:
            response = requests.get(f"{self.base_url}/health", timeout=5)
            return response.status_code == 200
        except:
            return False
    
    def get_openai_client(self) -> openai.OpenAI:
        """Get OpenAI-compatible client for VLLM."""
        if not self.client:
            self.client = openai.OpenAI(base_url=f"{self.base_url}/v1")
        return self.client
    
    def get_model_info(self) -> Dict[str, Any]:
        """Get model information and statistics."""
        try:
            response = requests.get(f"{self.base_url}/v1/models")
            if response.status_code == 200:
                return response.json()
        except:
            pass
        return {}
    
    def shutdown(self):
        """Shutdown VLLM server."""
        if self.process:
            self.process.terminate()
            self.process.wait()

# เดเดฏเตผเดจเตเดจ เดชเตเดฐเดเดเดจ เดเดเดจเตเดฑเตเดเตพเดเตเดเดพเดฏเดฟ VLLM เดเดฐเดเดญเดฟเดเตเดเตเด
vllm_manager = VLLMManager("microsoft/Phi-3.5-mini-instruct")
if vllm_manager.start_server():
    print("VLLM server started successfully")
    
    # VLLM เดฌเดพเดเตเดเตเดเตปเดกเตเดเต เดเดเดจเตเดฑเต เดเตเตบเดซเดฟเดเตผ เดเตเดฏเตเดฏเตเด
    agent_config = Config(
        name="vllm-performance-agent",
        model_provider="vllm",
        model_id=vllm_manager.get_served_model_name(),
        endpoint=f"{vllm_manager.base_url}/v1",
        api_key="none"  # VLLM-เดจเต API เดเต เดเดตเดถเตเดฏเดฎเดฟเดฒเตเดฒ
    )
    
    agent = Agent(config=agent_config)
else:
    print("Failed to start VLLM server")
```
  
**เดเดฏเตผเดจเตเดจ เดคเตเดฐเตเดชเตเดเตเดเต เดฎเตพเดเตเดเดฟ-เดเดเดจเตเดฑเต เดธเตเดฑเตเดฑเดชเตเดชเต**:  
```python
import asyncio
from concurrent.futures import ThreadPoolExecutor
from microsoft_agent_framework import Agent, Config
import openai

class VLLMHighThroughputManager:
    def __init__(self):
        self.model_configs = {
            "lightweight": {
                "model": "Qwen/Qwen2.5-0.5B-Instruct",
                "port": 8000,
                "max_model_len": 2048,
                "gpu_memory_utilization": 0.3
            },
            "balanced": {
                "model": "microsoft/Phi-3.5-mini-instruct",
                "port": 8001,
                "max_model_len": 4096,
                "gpu_memory_utilization": 0.5
            },
            "capable": {
                "model": "meta-llama/Llama-3.2-3B-Instruct",
                "port": 8002,
                "max_model_len": 8192,
                "gpu_memory_utilization": 0.7
            }
        }
        self.managers = {}
        self.agents = {}
        self.client_pool = {}
        
    async def initialize_all_models(self):
        """Initialize all VLLM models in parallel."""
        initialization_tasks = []
        
        for category, config in self.model_configs.items():
            task = self._initialize_model(category, config)
            initialization_tasks.append(task)
        
        results = await asyncio.gather(*initialization_tasks, return_exceptions=True)
        
        successful_inits = 0
        for i, result in enumerate(results):
            category = list(self.model_configs.keys())[i]
            if isinstance(result, Exception):
                print(f"Failed to initialize {category}: {result}")
            else:
                successful_inits += 1
                print(f"Successfully initialized {category} model")
        
        return successful_inits
    
    async def _initialize_model(self, category: str, config: Dict[str, Any]):
        """Initialize a single VLLM model instance."""
        manager = VLLMManager(
            model_name=config["model"],
            port=config["port"],
            max_model_len=config["max_model_len"],
            gpu_memory_utilization=config["gpu_memory_utilization"]
        )
        
        # เดคเดเดธเตเดธเด เดเดดเดฟเดตเดพเดเตเดเดพเตป เดคเตเดฐเตเดกเดฟเตฝ เดธเตเตผเดตเตผ เดเดฐเดเดญเดฟเดเตเดเตเด
        loop = asyncio.get_event_loop()
        with ThreadPoolExecutor() as executor:
            success = await loop.run_in_executor(executor, manager.start_server)
        
        if success:
            self.managers[category] = manager
            
            # เดเดเดจเตเดฑเต เดธเตเดทเตเดเดฟเดเตเดเตเด
            agent_config = Config(
                name=f"vllm-{category}-agent",
                model_provider="vllm",
                model_id=manager.get_served_model_name(),
                endpoint=f"{manager.base_url}/v1",
                api_key="none"
            )
            
            self.agents[category] = Agent(config=agent_config)
            
            # เดเดฏเตผเดจเตเดจ เดคเตเดฐเตเดชเตเดเตเดเดฟเดจเดพเดฏเดฟ เดเตเดฒเดฏเดจเตเดฑเต เดชเตเตพ เดธเตเดทเตเดเดฟเดเตเดเตเด
            self.client_pool[category] = [
                openai.OpenAI(base_url=f"{manager.base_url}/v1")
                for _ in range(5)  # เดธเดฎเดพเดจเตเดคเดฐเดคเดฏเตเดเตเดเดพเดฏเดฟ เดเดฐเต เดฎเตเดกเดฒเดฟเดจเตเด 5 เดเตเดฒเดฏเดจเตเดฑเตเดเตพ
            ]
            
            return True
        else:
            raise Exception(f"Failed to start VLLM server for {category}")
    
    def get_optimal_agent(self, request_complexity: str, current_load: Dict[str, int]) -> str:
        """Select optimal agent based on request complexity and current load."""
        complexity_mapping = {
            "simple": "lightweight",
            "moderate": "balanced", 
            "complex": "capable"
        }
        
        preferred_category = complexity_mapping.get(request_complexity, "balanced")
        
        # เดเดทเตเดเดชเตเดชเตเดเตเด เดเดเดจเตเดฑเต เดฒเดญเตเดฏเดฎเดพเดฏเตเด เดเดงเดฟเดเดญเดพเดฐเดฎเดฟเดฒเตเดฒเดพเดคเตเดฏเตเด เดเดณเตเดณเดคเดพเดฏเดฟ เดชเดฐเดฟเดถเตเดงเดฟเดเตเดเตเด
        if (preferred_category in self.agents and 
            current_load.get(preferred_category, 0) < 10):  # เดเดฐเต เดเดเดจเตเดฑเดฟเดจเตเด เดชเดฐเดฎเดพเดตเดงเดฟ 10 เดธเดฎเดเดพเดฒเดฟเดเด
            return preferred_category
        
        # เดเตเดฑเดเตเด เดญเดพเดฐเดฎเตเดณเตเดณ เดฒเดญเตเดฏเดฎเดพเดฏ เดเดเดจเตเดฑเดฟเดฒเตเดเตเดเตFallback
        available_agents = [(cat, load) for cat, load in current_load.items() 
                          if cat in self.agents and load < 10]
        
        if available_agents:
            return min(available_agents, key=lambda x: x[1])[0]
        
        return "balanced"  # เดกเดฟเดซเตเตพเดเตเดเตFallback
    
    async def process_batch_requests(self, requests: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """Process multiple requests in parallel for maximum throughput."""
        current_load = {cat: 0 for cat in self.agents.keys()}
        tasks = []
        
        for request in requests:
            # เดเดฑเตเดฑเดตเตเด เดเดจเตเดฏเตเดเตเดฏเดฎเดพเดฏ เดเดเดจเตเดฑเต เดจเดฟเตผเดฃเตเดฃเดฏเดฟเดเตเดเตเด
            complexity = request.get("complexity", "moderate")
            agent_category = self.get_optimal_agent(complexity, current_load)
            current_load[agent_category] += 1
            
            # เดชเตเดฐเตเดธเดธเตเดธเดฟเดเดเต เดเดพเดธเตโเดเต เดธเตเดทเตเดเดฟเดเตเดเตเด
            task = self._process_single_request(request, agent_category)
            tasks.append(task)
        
        # เดเดฒเตเดฒเดพ เดเดญเตเดฏเตผเดคเตเดฅเดจเดเดณเตเด เดธเดฎเดพเดจเตเดคเดฐเดฎเดพเดฏเดฟ เดชเตเดฐเตเดธเดธเตเดธเต เดเตเดฏเตเดฏเตเด
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # เดซเดฒเดเตเดเตพ เดซเตเตผเดฎเดพเดฑเตเดฑเต เดเตเดฏเตเดฏเตเด
        formatted_results = []
        for i, result in enumerate(results):
            if isinstance(result, Exception):
                formatted_results.append({
                    "request_id": requests[i].get("id", i),
                    "status": "error",
                    "error": str(result)
                })
            else:
                formatted_results.append(result)
        
        return formatted_results
    
    async def _process_single_request(self, request: Dict[str, Any], agent_category: str) -> Dict[str, Any]:
        """Process a single request with the specified agent."""
        start_time = time.time()
        
        try:
            agent = self.agents[agent_category]
            response = await agent.chat_async(request["message"])
            
            processing_time = time.time() - start_time
            
            return {
                "request_id": request.get("id"),
                "status": "success",
                "response": response,
                "agent_used": agent_category,
                "processing_time": processing_time
            }
            
        except Exception as e:
            return {
                "request_id": request.get("id"),
                "status": "error",
                "error": str(e),
                "agent_used": agent_category,
                "processing_time": time.time() - start_time
            }

# เดเดฏเตผเดจเตเดจ เดคเตเดฐเตเดชเตเดเตเดเต เดเดชเดฏเตเด เดเดฆเดพเดนเดฐเดฃเด
throughput_manager = VLLMHighThroughputManager()

# เดเดฒเตเดฒเดพ เดฎเตเดกเดฒเตเดเดณเตเด เดเดฐเดเดญเดฟเดเตเดเตเด
initialized_count = await throughput_manager.initialize_all_models()
print(f"Initialized {initialized_count} models")

# เดฌเดพเดเตเดเต เดเดญเตเดฏเตผเดคเตเดฅเดจเดเตพ เดชเตเดฐเตเดธเดธเตเดธเต เดเตเดฏเตเดฏเตเด
batch_requests = [
    {"id": 1, "message": "Simple question", "complexity": "simple"},
    {"id": 2, "message": "Complex analysis needed", "complexity": "complex"},
    {"id": 3, "message": "Moderate difficulty task", "complexity": "moderate"}
]

results = await throughput_manager.process_batch_requests(batch_requests)
for result in results:
    print(f"Request {result['request_id']}: {result['status']} in {result.get('processing_time', 0):.2f}s")
```
  
#### เดชเตเดฐเตเดกเดเตเดทเตป เดกเดฟเดชเตเดฒเตเดฏเตเดฎเตเดจเตเดฑเต เดชเดพเดฑเตเดฑเตเดฃเตเดเตพ

**เดเดจเตเดฑเตผเดชเตเดฐเตเดธเต VLLM เดชเตเดฐเตเดกเดเตเดทเตป เดธเตผเดตเตเดธเต**:  
```python
import asyncio
import logging
import time
from typing import Dict, List, Optional
from dataclasses import dataclass
from microsoft_agent_framework import Agent, Config
import uvicorn
from fastapi import FastAPI, HTTPException, BackgroundTasks
from pydantic import BaseModel

@dataclass
class VLLMServerConfig:
    model_name: str
    port: int
    gpu_memory_utilization: float
    max_model_len: int
    tensor_parallel_size: int = 1
    quantization: Optional[str] = None

class AgentRequest(BaseModel):
    message: str
    agent_type: str = "general"
    priority: str = "normal"
    timeout: int = 30

class VLLMProductionService:
    def __init__(self, server_configs: Dict[str, VLLMServerConfig]):
        self.server_configs = server_configs
        self.managers = {}
        self.agents = {}
        self.metrics = {
            "requests_processed": 0,
            "requests_failed": 0,
            "total_processing_time": 0,
            "agent_usage": {name: 0 for name in server_configs.keys()},
            "throughput_per_minute": 0
        }
        self.request_queue = asyncio.Queue(maxsize=1000)
        self.processing_workers = []
        self.app = FastAPI(title="VLLM Agent Service")
        self._setup_routes()
        
    async def initialize_production_environment(self):
        """Initialize all VLLM servers for production."""
        logging.info("Initializing VLLM production environment...")
        
        initialization_tasks = []
        for name, config in self.server_configs.items():
            task = self._initialize_server(name, config)
            initialization_tasks.append(task)
        
        results = await asyncio.gather(*initialization_tasks, return_exceptions=True)
        
        successful_servers = 0
        for i, result in enumerate(results):
            server_name = list(self.server_configs.keys())[i]
            if isinstance(result, Exception):
                logging.error(f"Failed to initialize {server_name}: {result}")
            else:
                successful_servers += 1
                logging.info(f"Successfully initialized {server_name}")
        
        if successful_servers == 0:
            raise Exception("No VLLM servers could be initialized")
        
        # เดคเตเดดเดฟเดฒเดพเดณเดฟเดเดณเต เดชเตเดฐเตเดธเดธเตเดธเต เดเตเดฏเตเดฏเดพเตป เดเดฐเดเดญเดฟเดเตเดเตเด
        self.processing_workers = [
            asyncio.create_task(self._processing_worker(i))
            for i in range(min(4, successful_servers))  # เดชเดฐเดฎเดพเดตเดงเดฟ 4 เดคเตเดดเดฟเดฒเดพเดณเดฟเดเตพ
        ]
        
        logging.info(f"Production environment ready with {successful_servers} servers")
        return successful_servers
    
    async def _initialize_server(self, name: str, config: VLLMServerConfig):
        """Initialize a single VLLM server."""
        manager = VLLMManager(
            model_name=config.model_name,
            port=config.port,
            gpu_memory_utilization=config.gpu_memory_utilization,
            max_model_len=config.max_model_len
        )
        
        # เดจเดฟเตผเดฆเตเดฆเตเดถเดฟเดเตเดเดพเตฝ เดเตเดตเดพเดฃเตเดเตเดธเตเดทเตป เดเตเตผเดเตเดเตเด
        if config.quantization:
            # เดเดคเต เดฎเดพเดจเตเดเดฑเตเดเต เดธเตเดฑเตเดฑเดพเตผเดเตเดเต เดเดฎเดพเตปเดกเดฟเตฝ เดเตเตผเดเตเดเตเด
            pass
        
        success = manager.start_server()
        if success:
            self.managers[name] = manager
            
            # เดชเตเดฐเตเดกเดเตเดทเตป เดเดเดจเตเดฑเต เดธเตเดทเตเดเดฟเดเตเดเตเด
            agent_config = Config(
                name=f"vllm-production-{name}",
                model_provider="vllm",
                model_id=manager.get_served_model_name(),
                endpoint=f"{manager.base_url}/v1",
                api_key="none",
                timeout=30.0
            )
            
            agent = Agent(config=agent_config)
            
            # เดชเตเดฐเตเดกเดเตเดทเตป เดเตเดณเตเดเตพ เดเตเตผเดเตเดเตเด
            self._add_production_tools(agent, name)
            
            self.agents[name] = agent
            return True
        else:
            raise Exception(f"Failed to start VLLM server for {name}")
    
    def _add_production_tools(self, agent: Agent, server_type: str):
        """Add production tools based on server type."""
        if server_type == "customer_service":
            @agent.tool
            def escalate_to_human(issue: str, customer_id: str) -> str:
                """Escalate complex issues to human agents."""
                return f"Escalated issue for customer {customer_id}: {issue}"
            
            @agent.tool
            def lookup_order_status(order_id: str) -> dict:
                """Look up order status from production database."""
                # เดชเตเดฐเตเดกเดเตเดทเตป เดกเดพเดฑเตเดฑเดพเดฌเตเดธเต เดฒเตเดเตเดเดชเตเดชเต
                return {"order_id": order_id, "status": "shipped", "eta": "2 days"}
        
        elif server_type == "technical_support":
            @agent.tool
            def run_system_diagnostics(system_id: str) -> dict:
                """Run comprehensive system diagnostics."""
                return {"system_id": system_id, "status": "healthy", "issues": []}
            
            @agent.tool
            def create_incident_report(description: str, severity: str) -> str:
                """Create incident report in production system."""
                incident_id = f"INC-{hash(description) % 100000:05d}"
                return f"Created incident {incident_id} with severity {severity}"
    
    def _setup_routes(self):
        """Set up FastAPI routes for production service."""
        @self.app.post("/chat")
        async def chat_endpoint(request: AgentRequest, background_tasks: BackgroundTasks):
            try:
                # เดเดญเตเดฏเตผเดคเตเดฅเดจ เดเตเดฏเตเดตเดฟเดฒเตเดเตเดเต เดเตเตผเดเตเดเตเด
                await self.request_queue.put({
                    "request": request,
                    "timestamp": time.time(),
                    "future": asyncio.Future()
                })
                
                # เดชเตเดฐเตเดธเดธเตเดธเต เดเตเดฏเตเดฏเตเดจเตเดจเดคเดฟเดจเต เดเดพเดคเตเดคเดฟเดฐเดฟเดเตเดเตเด (เดเตเดเดเดเตเดเตเดเต)
                result = await asyncio.wait_for(
                    self._wait_for_result(request),
                    timeout=request.timeout
                )
                
                return result
                
            except asyncio.TimeoutError:
                raise HTTPException(status_code=408, detail="Request timeout")
            except Exception as e:
                raise HTTPException(status_code=500, detail=str(e))
        
        @self.app.get("/health")
        async def health_endpoint():
            return await self.get_health_status()
        
        @self.app.get("/metrics")
        async def metrics_endpoint():
            return self.get_production_metrics()
    
    async def _processing_worker(self, worker_id: int):
        """Background worker for processing agent requests."""
        logging.info(f"Starting processing worker {worker_id}")
        
        while True:
            try:
                # เดเตเดฏเตเดตเดฟเตฝ เดจเดฟเดจเตเดจเต เดเดญเตเดฏเตผเดคเตเดฅเดจ เดจเตเดเตเด
                queue_item = await self.request_queue.get()
                request_data = queue_item["request"]
                request_future = queue_item["future"]
                
                # เดเดจเตเดฏเตเดเตเดฏเดฎเดพเดฏ เดเดเดจเตเดฑเต เดคเดฟเดฐเดเตเดเตเดเตเดเตเดเตเด
                agent_name = self._select_agent(request_data.agent_type)
                
                if agent_name not in self.agents:
                    request_future.set_exception(Exception(f"Agent {agent_name} not available"))
                    continue
                
                # เดเดญเตเดฏเตผเดคเตเดฅเดจ เดชเตเดฐเตเดธเดธเตเดธเต เดเตเดฏเตเดฏเตเด
                start_time = time.time()
                try:
                    agent = self.agents[agent_name]
                    response = await agent.chat_async(request_data.message)
                    
                    processing_time = time.time() - start_time
                    
                    # เดฎเตเดเตเดฐเดฟเดเตโเดธเต เดเดชเตเดกเตเดฑเตเดฑเต เดเตเดฏเตเดฏเตเด
                    self.metrics["requests_processed"] += 1
                    self.metrics["total_processing_time"] += processing_time
                    self.metrics["agent_usage"][agent_name] += 1
                    
                    result = {
                        "response": response,
                        "agent_used": agent_name,
                        "processing_time": processing_time,
                        "worker_id": worker_id
                    }
                    
                    request_future.set_result(result)
                    
                except Exception as e:
                    self.metrics["requests_failed"] += 1
                    request_future.set_exception(e)
                
                finally:
                    self.request_queue.task_done()
                    
            except Exception as e:
                logging.error(f"Worker {worker_id} error: {e}")
                await asyncio.sleep(1)
    
    def _select_agent(self, agent_type: str) -> str:
        """Select appropriate agent based on request type."""
        agent_mapping = {
            "customer_service": "customer_service",
            "technical": "technical_support",
            "general": "general_purpose"
        }
        
        return agent_mapping.get(agent_type, "general_purpose")
    
    async def _wait_for_result(self, request: AgentRequest):
        """Wait for request processing to complete."""
        # เดเดคเต เดฒเดณเดฟเดคเดฎเดพเดเตเดเดฟเดฏเดคเดพเดฃเต - เดชเตเดฐเตเดกเดเตเดทเดจเดฟเตฝ เดจเดฟเดเตเดเตพ เดซเตเดฏเตเดเตเดเดฑเตเดเตพ เดถเดฐเดฟเดฏเดพเดฏเดฟ เดเตเดฐเดพเดเตเดเต เดเตเดฏเตเดฏเตเด
        await asyncio.sleep(0.1)  # เดชเตเดฒเตเดธเตเดนเตเตพเดกเตผ
        return {"response": "Processed", "status": "success"}
    
    async def get_health_status(self) -> dict:
        """Get comprehensive health status of all services."""
        health_status = {
            "overall_status": "healthy",
            "servers": {},
            "queue_size": self.request_queue.qsize(),
            "active_workers": len([w for w in self.processing_workers if not w.done()]),
            "timestamp": time.time()
        }
        
        unhealthy_servers = 0
        for name, manager in self.managers.items():
            try:
                is_healthy = manager.health_check()
                health_status["servers"][name] = {
                    "status": "healthy" if is_healthy else "unhealthy",
                    "endpoint": manager.base_url,
                    "model": manager.model_name
                }
                if not is_healthy:
                    unhealthy_servers += 1
            except Exception as e:
                health_status["servers"][name] = {
                    "status": "error",
                    "error": str(e)
                }
                unhealthy_servers += 1
        
        if unhealthy_servers > 0:
            health_status["overall_status"] = "degraded" if unhealthy_servers < len(self.managers) else "unhealthy"
        
        return health_status
    
    def get_production_metrics(self) -> dict:
        """Get production performance metrics."""
        total_requests = self.metrics["requests_processed"] + self.metrics["requests_failed"]
        avg_processing_time = (
            self.metrics["total_processing_time"] / self.metrics["requests_processed"]
            if self.metrics["requests_processed"] > 0 else 0
        )
        
        success_rate = (
            self.metrics["requests_processed"] / total_requests * 100
            if total_requests > 0 else 0
        )
        
        return {
            "total_requests": total_requests,
            "successful_requests": self.metrics["requests_processed"],
            "failed_requests": self.metrics["requests_failed"],
            "success_rate_percent": success_rate,
            "average_processing_time_seconds": avg_processing_time,
            "agent_usage_distribution": self.metrics["agent_usage"],
            "queue_size": self.request_queue.qsize()
        }
    
    async def start_production_server(self, host: str = "0.0.0.0", port: int = 8080):
        """Start the production FastAPI server."""
        config = uvicorn.Config(
            self.app,
            host=host,
            port=port,
            log_level="info",
            workers=1  # เดฒเดณเดฟเดคเดคเตเดตเดคเตเดคเดฟเดจเดพเดฏเดฟ เดเดฑเตเดฑ เดคเตเดดเดฟเดฒเดพเดณเดฟ
        )
        server = uvicorn.Server(config)
        await server.serve()

# เดชเตเดฐเตเดกเดเตเดทเตป เดกเดฟเดชเตเดฒเตเดฏเตเดฎเตเดจเตเดฑเต เดเดฆเดพเดนเดฐเดฃเด
production_configs = {
    "customer_service": VLLMServerConfig(
        model_name="microsoft/Phi-3.5-mini-instruct",
        port=8000,
        gpu_memory_utilization=0.4,
        max_model_len=4096
    ),
    "technical_support": VLLMServerConfig(
        model_name="meta-llama/Llama-3.2-3B-Instruct",
        port=8001,
        gpu_memory_utilization=0.6,
        max_model_len=8192
    ),
    "general_purpose": VLLMServerConfig(
        model_name="Qwen/Qwen2.5-1.5B-Instruct",
        port=8002,
        gpu_memory_utilization=0.3,
        max_model_len=2048
    )
}

production_service = VLLMProductionService(production_configs)

# เดชเตเดฐเตเดกเดเตเดทเตป เดธเตผเดตเตเดธเต เดเตปเดทเดฟเดฏเดฒเตเดธเต เดเตเดฏเตเดคเต เดเดฐเดเดญเดฟเดเตเดเตเด
# await production_service.initialize_production_environment()
# await production_service.start_production_server()
```
  
#### เดเดจเตเดฑเตผเดชเตเดฐเตเดธเต เดซเตเดเตเดเดฑเตเดเดณเตเด เดฎเตเดฃเดฟเดฑเตเดฑเดฑเดฟเดเดเตเด

**เดเดงเตเดจเดฟเด VLLM เดชเตเดฐเดเดเดจ เดฎเตเดฃเดฟเดฑเตเดฑเดฑเดฟเดเดเต**:  
```python
import psutil
import nvidia_ml_py3 as nvml
from dataclasses import dataclass
from typing import List, Dict, Optional
import json
import asyncio

@dataclass
class PerformanceMetrics:
    timestamp: float
    requests_per_second: float
    average_latency_ms: float
    gpu_utilization_percent: float
    gpu_memory_used_gb: float
    cpu_utilization_percent: float
    memory_used_gb: float
    queue_length: int
    active_requests: int

class VLLMAdvancedMonitoring:
    def __init__(self, vllm_managers: Dict[str, VLLMManager]):
        self.managers = vllm_managers
        self.metrics_history = []
        self.alert_thresholds = {
            "gpu_utilization_max": 95,
            "gpu_memory_max_gb": 10,
            "latency_max_ms": 3000,
            "queue_length_max": 50,
            "error_rate_max_percent": 10
        }
        
        # GPU เดจเดฟเดฐเตเดเตเดทเดฃเดคเตเดคเดฟเดจเดพเดฏเดฟ NVIDIA ML เดเดฐเดเดญเดฟเดเตเดเตเด
        try:
            nvml.nvmlInit()
            self.gpu_monitoring_available = True
            self.gpu_count = nvml.nvmlDeviceGetCount()
        except:
            self.gpu_monitoring_available = False
            self.gpu_count = 0
    
    async def collect_comprehensive_metrics(self) -> Dict[str, PerformanceMetrics]:
        """Collect detailed performance metrics for all VLLM instances."""
        all_metrics = {}
        
        for name, manager in self.managers.items():
            try:
                metrics = await self._collect_single_instance_metrics(name, manager)
                all_metrics[name] = metrics
            except Exception as e:
                logging.error(f"Failed to collect metrics for {name}: {e}")
                # เดชเดฟเดถเดเต เดฎเตเดเตเดฐเดฟเดเตโเดธเต เดธเตเดทเตเดเดฟเดเตเดเตเด
                all_metrics[name] = PerformanceMetrics(
                    timestamp=time.time(),
                    requests_per_second=0,
                    average_latency_ms=0,
                    gpu_utilization_percent=0,
                    gpu_memory_used_gb=0,
                    cpu_utilization_percent=0,
                    memory_used_gb=0,
                    queue_length=0,
                    active_requests=0
                )
        
        return all_metrics
    
    async def _collect_single_instance_metrics(self, name: str, manager: VLLMManager) -> PerformanceMetrics:
        """Collect metrics for a single VLLM instance."""
        timestamp = time.time()
        
        # API เดตเดดเดฟ VLLM-เดจเดฟเตผเดฆเตเดฆเดฟเดทเตเด เดฎเตเดเตเดฐเดฟเดเตโเดธเต เดจเตเดเตเด
        vllm_stats = await self._get_vllm_stats(manager)
        
        # เดธเดฟเดธเตเดฑเตเดฑเด เดฎเตเดเตเดฐเดฟเดเตโเดธเต เดจเตเดเตเด
        cpu_percent = psutil.cpu_percent(interval=0.1)
        memory_info = psutil.virtual_memory()
        memory_used_gb = memory_info.used / (1024**3)
        
        # เดฒเดญเตเดฏเดฎเดพเดฏเตเดเตเดเดฟเตฝ GPU เดฎเตเดเตเดฐเดฟเดเตโเดธเต เดจเตเดเตเด
        gpu_utilization = 0
        gpu_memory_used = 0
        
        if self.gpu_monitoring_available and self.gpu_count > 0:
            try:
                # เดฒเดณเดฟเดคเดคเตเดตเดคเตเดคเดฟเดจเดพเดฏเดฟ เดเดฆเตเดฏ GPU เดเดฐเตเดคเตเดจเตเดจเต
                handle = nvml.nvmlDeviceGetHandleByIndex(0)
                gpu_util = nvml.nvmlDeviceGetUtilizationRates(handle)
                gpu_utilization = gpu_util.gpu
                
                gpu_mem = nvml.nvmlDeviceGetMemoryInfo(handle)
                gpu_memory_used = gpu_mem.used / (1024**3)
                
            except Exception as e:
                logging.warning(f"GPU monitoring failed: {e}")
        
        return PerformanceMetrics(
            timestamp=timestamp,
            requests_per_second=vllm_stats.get("requests_per_second", 0),
            average_latency_ms=vllm_stats.get("average_latency_ms", 0),
            gpu_utilization_percent=gpu_utilization,
            gpu_memory_used_gb=gpu_memory_used,
            cpu_utilization_percent=cpu_percent,
            memory_used_gb=memory_used_gb,
            queue_length=vllm_stats.get("queue_length", 0),
            active_requests=vllm_stats.get("active_requests", 0)
        )
    
    async def _get_vllm_stats(self, manager: VLLMManager) -> dict:
        """Get VLLM-specific statistics via API calls."""
        try:
            # เดฒเดพเดฑเตเดฑเตปเดธเดฟ เดเดณเดเตเดเดพเตป เดเตเดธเตเดฑเตเดฑเต เดเตปเดซเดฑเตปเดธเต
            start_time = time.time()
            client = manager.get_openai_client()
            
            response = await asyncio.wait_for(
                asyncio.to_thread(
                    client.chat.completions.create,
                    model=manager.get_served_model_name(),
                    messages=[{"role": "user", "content": "ping"}],
                    max_tokens=1
                ),
                timeout=5.0
            )
            
            latency_ms = (time.time() - start_time) * 1000
            
            return {
                "average_latency_ms": latency_ms,
                "requests_per_second": 1000 / latency_ms if latency_ms > 0 else 0,
                "queue_length": 0,  # VLLM เดตเดดเดฟ เดชเตเดฐเดฆเตผเดถเดฟเดชเตเดชเดฟเดเตเดเตเดฃเตเดเดคเตเดฃเตเดเต
                "active_requests": 1  # เดเดเดฆเตเดถเด
            }
            
        except Exception as e:
            logging.warning(f"Failed to get VLLM stats: {e}")
            return {
                "average_latency_ms": 0,
                "requests_per_second": 0,
                "queue_length": 0,
                "active_requests": 0
            }
    
    def generate_performance_report(self, time_window_minutes: int = 60) -> dict:
        """Generate comprehensive performance report."""
        cutoff_time = time.time() - (time_window_minutes * 60)
        recent_metrics = [
            metrics for metrics in self.metrics_history
            if any(m.timestamp > cutoff_time for m in metrics.values())
        ]
        
        if not recent_metrics:
            return {"error": "No recent metrics available"}
        
        report = {
            "time_window_minutes": time_window_minutes,
            "total_samples": len(recent_metrics),
            "instances": {}
        }
        
        # เดเดฐเต เดเตปเดธเตเดฑเตเดฑเตปเดธเตเด เดตเดฟเดถเดเดฒเดจเด เดเตเดฏเตเดฏเตเด
        for instance_name in self.managers.keys():
            instance_metrics = [
                metrics[instance_name] for metrics in recent_metrics
                if instance_name in metrics
            ]
            
            if instance_metrics:
                report["instances"][instance_name] = {
                    "avg_latency_ms": sum(m.average_latency_ms for m in instance_metrics) / len(instance_metrics),
                    "max_latency_ms": max(m.average_latency_ms for m in instance_metrics),
                    "avg_gpu_utilization": sum(m.gpu_utilization_percent for m in instance_metrics) / len(instance_metrics),
                    "avg_requests_per_second": sum(m.requests_per_second for m in instance_metrics) / len(instance_metrics),
                    "max_queue_length": max(m.queue_length for m in instance_metrics),
                    "availability_percent": (len(instance_metrics) / len(recent_metrics)) * 100
                }
        
        return report
    
    async def auto_scaling_recommendations(self) -> List[dict]:
        """Generate auto-scaling recommendations based on performance metrics."""
        recommendations = []
        
        if not self.metrics_history:
            return recommendations
        
        latest_metrics = self.metrics_history[-1]
        
        for instance_name, metrics in latest_metrics.items():
            # เดเดฏเตผเดจเตเดจ เดฒเดพเดฑเตเดฑเตปเดธเดฟ เดถเตเดชเดพเตผเดถ
            if metrics.average_latency_ms > self.alert_thresholds["latency_max_ms"]:
                recommendations.append({
                    "instance": instance_name,
                    "type": "scale_up",
                    "reason": f"High latency: {metrics.average_latency_ms:.0f}ms",
                    "suggestion": "Consider adding tensor parallelism or increasing GPU memory"
                })
            
            # เดเดฏเตผเดจเตเดจ GPU เดเดชเดฏเตเดเด เดถเตเดชเดพเตผเดถ
            if metrics.gpu_utilization_percent > self.alert_thresholds["gpu_utilization_max"]:
                recommendations.append({
                    "instance": instance_name,
                    "type": "scale_out",
                    "reason": f"High GPU utilization: {metrics.gpu_utilization_percent:.1f}%",
                    "suggestion": "Consider adding additional GPU instances"
                })
            
            # เดเตเดฑเดเตเด เดเดชเดฏเตเดเด เดถเตเดชเดพเตผเดถ
            if (metrics.gpu_utilization_percent < 20 and 
                metrics.requests_per_second < 1):
                recommendations.append({
                    "instance": instance_name,
                    "type": "scale_down",
                    "reason": f"Low utilization: {metrics.gpu_utilization_percent:.1f}% GPU, {metrics.requests_per_second:.1f} RPS",
                    "suggestion": "Consider consolidating workloads or reducing resources"
                })
        
        return recommendations

# เดชเตเดฐเตเดเดฎเดฟเดเตเด เดจเดฟเดฐเตเดเตเดทเดฃ เดเตเดฐเดฎเตเดเดฐเดฃเด
monitoring = VLLMAdvancedMonitoring({
    "customer_service": vllm_manager,
    # เดเดตเดถเตเดฏเดคเตเดคเดฟเดจเต เดฎเดฑเตเดฑเต เดฎเดพเดจเตเดเตผเดฎเดพเตผ เดเตเตผเดเตเดเตเด
})

async def advanced_monitoring_loop():
    """Advanced monitoring with auto-scaling recommendations."""
    while True:
        try:
            # เดฎเตเดเตเดฐเดฟเดเตโเดธเต เดถเตเดเดฐเดฟเดเตเดเตเด
            metrics = await monitoring.collect_comprehensive_metrics()
            monitoring.metrics_history.append(metrics)
            
            # เดเดตเดธเดพเดจ 1000 เดเตปเดเตเดฐเดฟเดเตพ เดฎเดพเดคเตเดฐเด เดธเตเดเตเดทเดฟเดเตเดเตเด
            if len(monitoring.metrics_history) > 1000:
                monitoring.metrics_history = monitoring.metrics_history[-1000:]
            
            # เดเดฐเต 5 เดฎเดฟเดจเดฟเดฑเตเดฑเดฟเดฒเตเด เดถเตเดชเดพเตผเดถเดเตพ เดธเตเดทเตเดเดฟเดเตเดเตเด
            if len(monitoring.metrics_history) % 10 == 0:  # เดเดฐเต 10-เดเด เดถเตเดเดฐเดฃเดตเตเด (30 เดธเตเดเตเดเตปเดกเต๋ง๋ค เดถเตเดเดฐเดฟเดเตเดเตเดจเตเดจเตเดตเตเดเตเดเดฟเตฝ 5 เดฎเดฟเดจเดฟเดฑเตเดฑเต)
                recommendations = await monitoring.auto_scaling_recommendations()
                
                if recommendations:
                    logging.info(f"Auto-scaling recommendations: {recommendations}")
            
            # เดเดฐเต เดฎเดฃเดฟเดเตเดเตเดฑเดฟเดฒเตเด เดชเตเดฐเดเดเดจ เดฑเดฟเดชเตเดชเตเตผเดเตเดเต เดธเตเดทเตเดเดฟเดเตเดเตเด
            if len(monitoring.metrics_history) % 120 == 0:  # เดเดฐเต 120-เดเด เดถเตเดเดฐเดฃเดตเตเด (1 เดฎเดฃเดฟเดเตเดเตเตผ)
                report = monitoring.generate_performance_report(60)
                logging.info(f"Performance report: {json.dumps(report, indent=2)}")
            
        except Exception as e:
            logging.error(f"Advanced monitoring error: {e}")
        
        await asyncio.sleep(30)  # เดเดฐเต 30 เดธเตเดเตเดเตปเดกเดฟเดฒเตเด เดฎเตเดเตเดฐเดฟเดเตโเดธเต เดถเตเดเดฐเดฟเดเตเดเตเด

# เดชเตเดฐเตเดเดฎเดฟเดเตเด เดจเดฟเดฐเตเดเตเดทเดฃเด เดเดฐเดเดญเดฟเดเตเดเตเด
# asyncio.create_task(advanced_monitoring_loop())
```
  
#### เดเดงเตเดจเดฟเด เดเตเตบเดซเดฟเดเดฑเตเดทเตป & เดเดชเตเดฑเตเดฑเดฟเดฎเตเดธเตเดทเตป

**เดชเตเดฐเตเดกเดเตเดทเตป VLLM เดเตเตบเดซเดฟเดเดฑเตเดทเตป เดเตเดเดชเตเดฒเตเดฑเตเดฑเตเดเตพ**:  
```python
from enum import Enum
from typing import Dict, Any

class DeploymentScenario(Enum):
    DEVELOPMENT = "development"
    STAGING = "staging"
    PRODUCTION_LOW = "production_low"
    PRODUCTION_HIGH = "production_high"
    ENTERPRISE = "enterprise"

class VLLMConfigTemplates:
    """Production-ready VLLM configuration templates."""
    
    @staticmethod
    def get_config_template(scenario: DeploymentScenario) -> Dict[str, Any]:
        """Get optimized configuration for deployment scenario."""
        
        templates = {
            DeploymentScenario.DEVELOPMENT: {
                "gpu_memory_utilization": 0.6,
                "max_model_len": 2048,
                "tensor_parallel_size": 1,
                "pipeline_parallel_size": 1,
                "quantization": None,
                "enable_prefix_caching": False,
                "max_num_seqs": 32,
                "max_num_batched_tokens": 2048
            },
            
            DeploymentScenario.STAGING: {
                "gpu_memory_utilization": 0.8,
                "max_model_len": 4096,
                "tensor_parallel_size": 1,
                "pipeline_parallel_size": 1,
                "quantization": "awq",
                "enable_prefix_caching": True,
                "max_num_seqs": 64,
                "max_num_batched_tokens": 4096
            },
            
            DeploymentScenario.PRODUCTION_LOW: {
                "gpu_memory_utilization": 0.85,
                "max_model_len": 4096,
                "tensor_parallel_size": 1,
                "pipeline_parallel_size": 1,
                "quantization": "awq",
                "enable_prefix_caching": True,
                "max_num_seqs": 128,
                "max_num_batched_tokens": 8192,
                "enable_chunked_prefill": True
            },
            
            DeploymentScenario.PRODUCTION_HIGH: {
                "gpu_memory_utilization": 0.9,
                "max_model_len": 8192,
                "tensor_parallel_size": 2,
                "pipeline_parallel_size": 1,
                "quantization": "awq",
                "enable_prefix_caching": True,
                "max_num_seqs": 256,
                "max_num_batched_tokens": 16384,
                "enable_chunked_prefill": True,
                "speculative_model": "small_draft_model"
            },
            
            DeploymentScenario.ENTERPRISE: {
                "gpu_memory_utilization": 0.95,
                "max_model_len": 16384,
                "tensor_parallel_size": 4,
                "pipeline_parallel_size": 2,
                "quantization": "awq",
                "enable_prefix_caching": True,
                "max_num_seqs": 512,
                "max_num_batched_tokens": 32768,
                "enable_chunked_prefill": True,
                "speculative_model": "optimized_draft_model",
                "guided_decoding_backend": "outlines"
            }
        }
        
        return templates[scenario]
    
    @staticmethod
    def generate_vllm_command(model_name: str, 
                             scenario: DeploymentScenario,
                             port: int = 8000,
                             host: str = "0.0.0.0") -> List[str]:
        """Generate optimized VLLM command for deployment scenario."""
        
        config = VLLMConfigTemplates.get_config_template(scenario)
        
        cmd = [
            "python", "-m", "vllm.entrypoints.openai.api_server",
            "--model", model_name,
            "--host", host,
            "--port", str(port),
            "--gpu-memory-utilization", str(config["gpu_memory_utilization"]),
            "--max-model-len", str(config["max_model_len"]),
            "--tensor-parallel-size", str(config["tensor_parallel_size"]),
            "--max-num-seqs", str(config["max_num_seqs"]),
            "--max-num-batched-tokens", str(config["max_num_batched_tokens"]),
            "--trust-remote-code",
            "--disable-log-requests"
        ]
        
        # เดเดเตเดเดฟเด เดชเดพเดฐเดพเดฎเตเดฑเตเดฑเดฑเตเดเตพ เดเตเตผเดเตเดเตเด
        if config.get("quantization"):
            cmd.extend(["--quantization", config["quantization"]])
        
        if config.get("enable_prefix_caching"):
            cmd.append("--enable-prefix-caching")
        
        if config.get("enable_chunked_prefill"):
            cmd.append("--enable-chunked-prefill")
        
        if config.get("pipeline_parallel_size", 1) > 1:
            cmd.extend(["--pipeline-parallel-size", str(config["pipeline_parallel_size"])])
        
        if config.get("speculative_model"):
            cmd.extend(["--speculative-model", config["speculative_model"]])
        
        return cmd

# เดเดชเดฏเตเด เดเดฆเดพเดนเดฐเดฃเดเตเดเตพ
dev_cmd = VLLMConfigTemplates.generate_vllm_command(
    "microsoft/Phi-3.5-mini-instruct",
    DeploymentScenario.DEVELOPMENT,
    port=8000
)

prod_cmd = VLLMConfigTemplates.generate_vllm_command(
    "microsoft/Phi-3.5-mini-instruct",
    DeploymentScenario.PRODUCTION_HIGH,
    port=8001
)

print(f"Development command: {' '.join(dev_cmd)}")
print(f"Production command: {' '.join(prod_cmd)}")
```
  
**VLLM เดชเตเดฐเตเดกเดเตเดทเตป เดกเดฟเดชเตเดฒเตเดฏเตเดฎเตเดจเตเดฑเต เดเตเดเตเดเตเดฒเดฟเดธเตเดฑเตเดฑเต**:  

โ **เดนเดพเตผเดกเตโเดตเตเดฏเตผ เดเดชเตเดฑเตเดฑเดฟเดฎเตเดธเตเดทเตป**:  
- เดฎเตพเดเตเดเดฟ-GPU เดธเตเดฑเตเดฑเดชเตเดชเตเดเตพเดเตเดเดพเดฏเดฟ เดเตเตปเดธเตผ เดชเดพเดฐเดฒเดฒเดฟเดธเด เดเตเตบเดซเดฟเดเตผ เดเตเดฏเตเดฏเตเด  
- เดฎเตเดฎเตเดฎเดฑเดฟ เดเดพเดฐเตเดฏเดเตเดทเดฎเดคเดฏเตเดเตเดเดพเดฏเดฟ เดเตเดตเดพเดฃเตเดเตเดธเตเดทเตป (AWQ/GPTQ) เดธเดเตเดเดฎเดพเดเตเดเตเด  
- เดชเดฐเดฎเดพเดตเดงเดฟ GPU เดฎเตเดฎเตเดฎเดฑเดฟ เดเดชเดฏเตเดเด (85-95%) เดธเดเตเดเดฎเดพเดเตเดเตเด  
- เดคเตเดฐเตเดชเตเดเตเดเดฟเดจเดพเดฏเดฟ เดเดจเตเดฏเตเดเตเดฏเดฎเดพเดฏ เดฌเดพเดเตเดเต เดธเตเดธเตเดเตพ เดเตเตบเดซเดฟเดเตผ เดเตเดฏเตเดฏเตเด  

โ **เดชเตเดฐเดเดเดจ เดเตเดฏเตเดฃเดฟเดเดเต**:  
- เดเดตเตผเดคเตเดคเดฟเดเตเดเตเดจเตเดจ เดเตเดตเตเดฑเดฟเดฏเตเดเตพเดเตเดเดพเดฏเดฟ เดชเตเดฐเดฟเดซเดฟเดเตเดธเต เดเดพเดทเดฟเดเดเต เดธเดเตเดเดฎเดพเดเตเดเตเด  
- เดฆเตเตผเดเดฎเดพเดฏ เดธเตเดเตเดตเตปเดธเตเดเตพเดเตเดเดพเดฏเดฟ เดเดเตเดเต เดเตเดฏเตเดค เดชเตเดฐเดฟเดซเดฟเตฝ เดเตเตบเดซเดฟเดเตผ เดเตเดฏเตเดฏเตเด  
- เดตเตเดเดคเตเดคเดฟเดฒเตเดณเตเดณ เดเตปเดซเดฑเตปเดธเดฟเดจเดพเดฏเดฟ เดธเตเดชเตเดเตเดฒเตเดฑเตเดฑเตเดตเต เดกเดฟเดเตเดกเดฟเดเดเต เดธเดเตเดเดฎเดพเดเตเดเตเด  
- เดนเดพเตผเดกเตโเดตเตเดฏเตผ เดเดเดฟเดธเตเดฅเดพเดจเดฎเดพเดเตเดเดฟ max_num_seqs เดเดชเตเดฑเตเดฑเดฟเดฎเตเดธเต เดเตเดฏเตเดฏเตเด  

โ **เดชเตเดฐเตเดกเดเตเดทเตป เดซเตเดเตเดเดฑเตเดเตพ**:  
- เดนเตเตฝเดคเตเดคเต เดฎเตเดฃเดฟเดฑเตเดฑเดฑเดฟเดเดเต, เดฎเตเดเตเดฐเดฟเดเตโเดธเต เดถเตเดเดฐเดฃเด เดธเดเตเดเดฎเดพเดเตเดเตเด  
- เดเดเตเดเตเดฎเดพเดฑเตเดฑเดฟเดเต เดฑเตเดธเตเดฑเตเดฑเดพเตผเดเตเดเต, เดซเตเดฏเดฟเตฝเดเดตเตผ เดเตเตบเดซเดฟเดเตผ เดเตเดฏเตเดฏเตเด  
- เดเดญเตเดฏเตผเดคเตเดฅเดจ เดเตเดฏเตเดฏเดฟเดเดเต, เดฒเตเดกเต เดฌเดพเดฒเตปเดธเดฟเดเดเต เดจเดเดชเตเดชเดฟเดฒเดพเดเตเดเตเด  
- เดธเดฎเดเตเดฐเดฎเดพเดฏ เดฒเตเดเดฟเดเดเต, เดเดฒเตผเดเตเดเดฟเดเดเต เดธเดเตเดเดฎเดพเดเตเดเตเด  

โ **เดธเตเดฐเดเตเดทเดฏเตเด เดตเดฟเดถเตเดตเดพเดธเตเดฏเดคเดฏเตเด**:  
- เดซเดฏเตผเดตเดพเตพ เดจเดฟเดฏเดฎเดเตเดเดณเตเด เดเดเตโเดธเดธเต เดจเดฟเดฏเดจเตเดคเตเดฐเดฃเดเตเดเดณเตเด เดเตเตบเดซเดฟเดเตผ เดเตเดฏเตเดฏเตเด  
- API เดฑเตเดฑเตเดฑเต เดฒเดฟเดฎเดฟเดฑเตเดฑเดฟเดเดเต, เดเดคเดจเตเดฑเดฟเดเตเดเตเดทเตป เดธเดเตเดเดฎเดพเดเตเดเตเด  
- เดเตเดฐเตเดธเตเดซเตเตพ เดทเดเตเดเตเดกเตเตบ, เดเตเดฒเตเดจเดชเตเดชเต เดจเดเดชเตเดชเดฟเดฒเดพเดเตเดเตเด  
- เดฌเดพเดเตเดเดชเตเดชเต, เดฆเตเดฐเดจเตเดค เดชเตเดจเดฐเตเดฆเตเดงเดพเดฐเดฃเด เดเตเตบเดซเดฟเดเตผ เดเตเดฏเตเดฏเตเด  

โ **เดเดจเตเดฑเดเตเดฐเตเดทเตป เดเตเดธเตเดฑเตเดฑเดฟเดเดเต**:  
- Microsoft Agent Framework เดเดจเตเดฑเดเตเดฐเตเดทเตป เดเตเดธเตเดฑเตเดฑเต เดเตเดฏเตเดฏเตเด  
- เดเดฏเตผเดจเตเดจ เดคเตเดฐเตเดชเตเดเตเดเต เดธเตเดจเดพเดฐเดฟเดฏเตเดเตพ เดธเดพเดงเตเดเดฐเดฟเดเตเดเตเด  
- เดซเตเดฏเดฟเตฝเดเดตเตผ, เดฑเดฟเดเตเดเดตเดฑเดฟ เดชเตเดฐเตเดธเตเดเดฑเตเดเตพ เดเตเดธเตเดฑเตเดฑเต เดเตเดฏเตเดฏเตเด  
- เดฒเตเดกเดฟเตฝ เดชเตเดฐเดเดเดจเด เดฌเตเดเตเดเตเดฎเดพเตผเดเตเดเต เดเตเดฏเตเดฏเตเด  

**เดฎเดฑเตเดฑเต เดธเตเดฒเตเดฏเตเดทเดจเตเดเดณเตเดฎเดพเดฏเตเดณเตเดณ เดคเดพเดฐเดคเดฎเตเดฏเด**:  

| เดซเตเดเตเดเตผ | VLLM | Foundry Local | Ollama |
|---------|------|---------------|--------|
| **เดฒเดเตเดทเตเดฏ เดเดชเดฏเตเด เดเตเดธเต** | เดเดฏเตผเดจเตเดจ เดคเตเดฐเตเดชเตเดเตเดเต เดชเตเดฐเตเดกเดเตเดทเตป | เดเดจเตเดฑเตผเดชเตเดฐเตเดธเต เดธเตเดเดฐเตเดฏเด | เดกเตเดตเดฒเดชเตเดชเตเดฎเตเดจเตเดฑเต & เดเดฎเตเดฎเตเดฏเตเดฃเดฟเดฑเตเดฑเดฟ |
| **เดชเตเดฐเดเดเดจเด** | เดชเดฐเดฎเดพเดตเดงเดฟ เดคเตเดฐเตเดชเตเดเตเดเต | เดฌเดพเดฒเตปเดธเตเดกเต | เดจเดฒเตเดฒเดคเต |
| **เดฎเตเดฎเตเดฎเดฑเดฟ เดเดพเดฐเตเดฏเดเตเดทเดฎเดค** | PagedAttention เดเดชเตเดฑเตเดฑเดฟเดฎเตเดธเตเดทเตป | เดเดเตเดเตเดฎเดพเดฑเตเดฑเดฟเดเต เดเดชเตเดฑเตเดฑเดฟเดฎเตเดธเตเดทเตป | เดธเตเดฑเตเดฑเดพเตปเดกเตเตผเดกเต |
| **เดธเตเดฑเตเดฑเดชเตเดชเต เดธเดเตเดเตเตผเดฃเตเดฃเดค** | เดเดฏเตผเดจเตเดจ (เดชเดฒ เดชเดพเดฐเดพเดฎเตเดฑเตเดฑเดฑเตเดเตพ) | เดเตเดฑเดเตเดเดคเต (เดเดเตเดเตเดฎเดพเดฑเตเดฑเดฟเดเต) | เดเตเดฑเดเตเดเดคเต (เดฒเดณเดฟเดคเด) |
| **เดธเตเดเตเดฏเดฟเดฒเดฌเดฟเดฒเดฟเดฑเตเดฑเดฟ** | เดฎเดฟเดเดเตเดเดคเต (เดเตเตปเดธเตผ/เดชเตเดชเตเดชเตโเดฒเตเตป เดชเดพเดฐเดฒเตฝ) | เดจเดฒเตเดฒเดคเต | เดชเดฐเดฟเดฎเดฟเดคเด |
| **เดเตเดตเดพเดฃเตเดเตเดธเตเดทเตป** | เดเดงเตเดจเดฟเดเด (AWQ, GPTQ, FP8) | เดเดเตเดเตเดฎเดพเดฑเตเดฑเดฟเดเต | เดธเตเดฑเตเดฑเดพเตปเดกเตเตผเดกเต GGUF |
| **เดเดจเตเดฑเตผเดชเตเดฐเตเดธเต เดซเตเดเตเดเดฑเตเดเตพ** | เดเดธเตเดฑเตเดฑเด เดเดเดชเตเดฒเดฟเดฎเตเดจเตเดฑเตเดทเตป เดเดตเดถเตเดฏเดฎเดพเดฃเต | เดเตปเดฌเดฟเตฝเดฑเตเดฑเต | เดเดฎเตเดฎเตเดฏเตเดฃเดฟเดฑเตเดฑเดฟ เดเตเดณเตเดเตพ |
| **เดเดคเตเดคเดฎเด** | เดเดฏเตผเดจเตเดจ เดธเตเดเตเดฏเดฟเตฝ เดชเตเดฐเตเดกเดเตเดทเตป เดเดเดจเตเดฑเตเดเตพ | เดเดจเตเดฑเตผเดชเตเดฐเตเดธเต เดชเตเดฐเตเดกเดเตเดทเตป | เดกเตเดตเดฒเดชเตเดชเตเดฎเตเดจเตเดฑเต |

**VLLM เดคเดฟเดฐเดเตเดเตเดเตเดเตเดเตเดฃเตเดเดชเตเดชเตเตพ**:  
- **เดเดฏเตผเดจเตเดจ เดคเตเดฐเตเดชเตเดเตเดเต เดเดตเดถเตเดฏเดเดคเดเตพ**: เดธเตเดเตเดเตปเดกเดฟเตฝ เดจเตเดฑเตเดเดฃเดเตเดเดฟเดจเต เดเดญเตเดฏเตผเดคเตเดฅเดจเดเตพ เดชเตเดฐเตเดธเดธเตเดธเต เดเตเดฏเตเดฏเตเด  
- **เดตเดฒเดฟเดฏ เดธเตเดเตเดฏเดฟเตฝ เดกเดฟเดชเตเดฒเตเดฏเตเดฎเตเดจเตเดฑเตเดเตพ**: เดฎเตพเดเตเดเดฟ-GPU, เดฎเตพเดเตเดเดฟ-เดจเตเดกเต เดกเดฟเดชเตเดฒเตเดฏเตเดฎเตเดจเตเดฑเตเดเตพ  
- **เดชเตเดฐเดเดเดจ เดจเดฟเตผเดฃเดพเดฏเดเดฎเดพเดฏ เดธเดพเดนเดเดฐเตเดฏเดเตเดเตพ**: เดธเตเดเตเดฏเดฟเดฒเดฟเตฝ เดธเตเดเตเดเตปเดกเดฟเดจเตเดฑเต เดญเดพเดเด เดชเตเดฐเดคเดฟเดเดฐเดฃ เดธเดฎเดฏเด  
- **เดเดงเตเดจเดฟเด เดเดชเตเดฑเตเดฑเดฟเดฎเตเดธเตเดทเตป**: เดเดธเตเดฑเตเดฑเด เดเตเดตเดพเดฃเตเดเตเดธเตเดทเตป, เดฌเดพเดเตเดเดฟเดเดเต เดเดตเดถเตเดฏเดเตเดเตพ  
- **เดฑเดฟเดธเตเดดเตโเดธเต เดเดพเดฐเตเดฏเดเตเดทเดฎเดค**: เดตเดฟเดฒเดฏเตเดฑเดฟเดฏ GPU เดนเดพเตผเดกเตโเดตเตเดฏเตผ เดชเดฐเดฎเดพเดตเดงเดฟ เดเดชเดฏเตเดเด  

## เดฏเดฅเดพเตผเดคเตเดฅ เดฒเตเด SLM เดเดเดจเตเดฑเต เดเดชเตเดฒเดฟเดเตเดเตเดทเดจเตเดเตพ

### เดเดธเตเดฑเตเดฑเดฎเตผ เดธเตผเดตเตเดธเต SLM เดเดเดจเตเดฑเตเดเตพ  
- **SLM เดถเตเดทเดฟเดเตพ**: เดเดเตเดเตเดฃเตเดเต เดฒเตเดเตเดเดชเตเดชเตเดเตพ, เดชเดพเดธเตโเดตเตเดกเต เดฑเตเดธเตเดฑเตเดฑเตเดเตพ, เดเตผเดกเตผ เดธเตเดฑเตเดฑเดพเดฑเตเดฑเดธเต เดชเดฐเดฟเดถเตเดงเดฟเดเตเดเตฝ  
- **เดเตเดฒเดตเต เดฒเดพเดญเดเตเดเตพ**: LLM เดเดเดจเตเดฑเตเดเดณเต เดเดชเตเดเตเดทเดฟเดเตเดเต 10 เดฎเดเดเตเดเต เดเตปเดซเดฑเตปเดธเต เดเตเดฒเดตเต เดเตเดฑเดตเต  
- **เดชเตเดฐเดเดเดจเด**: เดธเตเดฅเดฟเดฐเดคเดฏเตเดณเตเดณ เดเตเดฃเดฎเตเดจเตเดฎเดฏเตเดเต เดตเตเดเดคเตเดคเดฟเดฒเตเดณเตเดณ เดชเตเดฐเดคเดฟเดเดฐเดฃ เดธเดฎเดฏเด  

### เดฌเดฟเดธเดฟเดจเดธเต เดชเตเดฐเตเดธเดธเต SLM เดเดเดจเตเดฑเตเดเตพ  
- **เดเตปเดตเตเดฏเตเดธเต เดชเตเดฐเตเดธเดธเตเดธเดฟเดเดเต เดเดเดจเตเดฑเตเดเตพ**: เดกเดพเดฑเตเดฑ เดเดเตเดธเตเดเตเดฐเดพเดเตเดทเตป, เดตเดฟเดตเดฐเดเตเดเตพ เดธเดพเดงเตเดเดฐเดฟเดเตเดเตฝ, เดเดเดเตเดเดพเดฐเดคเตเดคเดฟเดจเดพเดฏเดฟ เดฑเตเดเตเดเดฟเดเดเต  
- **เดเดฎเตเดฏเดฟเตฝ เดฎเดพเดจเตเดเตเดฎเตเดจเตเดฑเต เดเดเดจเตเดฑเตเดเตพ**: เดตเตผเดเตเดเตเดเดฐเดฃเด, เดฎเตเตปเดเดฃเดจ, เดธเตเดตเดฏเด เดฎเดฑเตเดชเดเดฟ เดฐเตเดชเดฐเตเด  
- **เดทเตเดกเตเดฏเตเดณเดฟเดเดเต เดเดเดจเตเดฑเตเดเตพ**: เดฎเตเดฑเตเดฑเดฟเดเดเตเดเตพ เดเตเตผเดกเดฟเดจเตเดฑเตเดฑเต เดเตเดฏเตเดฏเตเด, เดเดฒเดฃเตเดเดฑเตเดเตพ เดฎเดพเดจเตเดเต เดเตเดฏเตเดฏเตเด, เดฑเดฟเดฎเตเตปเดกเดฑเตเดเตพ เดเดฏเดฏเตเดเตเดเตเด  

### เดตเตเดฏเดเตเดคเดฟเดเดค SLM เดกเดฟเดเดฟเดฑเตเดฑเตฝ เดเดธเดฟเดธเตเดฑเตเดฑเดจเตเดฑเตเดเตพ  
- **เดเดพเดธเตโเดเต เดฎเดพเดจเตเดเตเดฎเตเดจเตเดฑเต เดเดเดจเตเดฑเตเดเตพ**: เดเต-เดกเต เดฒเดฟเดธเตเดฑเตเดฑเตเดเตพ เดธเตเดทเตเดเดฟเดเตเดเตเด, เดเดชเตเดกเตเดฑเตเดฑเต เดเตเดฏเตเดฏเตเด, เดเตเดฐเดฎเตเดเดฐเดฟเดเตเดเตเด  
- **เดตเดฟเดตเดฐ เดถเตเดเดฐเดฃ เดเดเดจเตเดฑเตเดเตพ**: เดตเดฟเดทเดฏเดเตเดเตพ เดเดตเตเดทเดฃเด เดเตเดฏเตเดฏเตเด, เดเดฃเตเดเตเดคเตเดคเดฒเตเดเตพ เดชเตเดฐเดพเดฆเตเดถเดฟเดเดฎเดพเดฏเดฟ เดธเดเดเตเดฐเดนเดฟเดเตเดเตเด  
- **เดเดฎเตเดฎเตเดฏเตเดฃเดฟเดเตเดเตเดทเตป เดเดเดจเตเดฑเตเดเตพ**: เดเดฎเตเดฏเดฟเดฒเตเดเตพ, เดธเดจเตเดฆเตเดถเดเตเดเตพ, เดธเตเดทเตเดฏเตฝ เดฎเตเดกเดฟเดฏ เดชเตเดธเตเดฑเตเดฑเตเดเตพ เดธเตเดตเดเดพเดฐเตเดฏเดฎเดพเดฏเดฟ เดฐเตเดชเดฐเตเดเดชเตเดชเตเดเตเดคเตเดคเตเด  

### เดเตเดฐเตเดกเดฟเดเดเต & เดซเดฟเดจเดพเตปเดทเตเดฏเตฝ SLM เดเดเดจเตเดฑเตเดเตพ  
- **เดฎเดพเตผเดเตเดเดฑเตเดฑเต เดฎเตเดฃเดฟเดฑเตเดฑเดฑเดฟเดเดเต เดเดเดจเตเดฑเตเดเตพ**: เดตเดฟเดฒเดเตพ เดเตเดฐเดพเดเตเดเต เดเตเดฏเตเดฏเตเด, เดฑเดฟเดฏเตฝ-เดเตเด เดเตเดฐเตเตปเดกเตเดเตพ เดคเดฟเดฐเดฟเดเตเดเดฑเดฟเดฏเตเด  
- **เดฑเดฟเดชเตเดชเตเตผเดเตเดเต เดเดจเดฑเตเดทเตป เดเดเดจเตเดฑเตเดเตพ**: เดฆเดฟเดตเดธเดตเตเด/เดเดดเตเดเดตเดพเดฐ เดธเดเดเตเดฐเดนเดเตเดเตพ เดธเตเดตเดฏเด เดธเตเดทเตเดเดฟเดเตเดเตเด  
- **เดฑเดฟเดธเตเดเต เดเดธเดธเตเดฎเตเดจเตเดฑเต เดเดเดจเตเดฑเตเดเตพ**: เดชเตเดฐเดพเดฆเตเดถเดฟเด เดกเดพเดฑเตเดฑ เดเดชเดฏเตเดเดฟเดเตเดเต เดชเตเตผเดเตเดเตเดซเตเดณเดฟเดฏเต เดธเตเดฅเดฟเดคเดฟเดเตพ เดตเดฟเดฒเดฏเดฟเดฐเตเดคเตเดคเตเด  

### เดนเตเตฝเดคเตเดคเตโเดเตเดฏเตผ เดธเดชเตเดชเตเตผเดเตเดเต SLM เดเดเดจเตเดฑเตเดเตพ  
- **เดชเตเดทเดจเตเดฑเต เดทเตเดกเตเดฏเตเดณเดฟเดเดเต เดเดเดจเตเดฑเตเดเตพ**: เดเดชเตเดชเตเดฏเดฟเดจเตเดฑเตเดฎเตเดจเตเดฑเตเดเตพ เดเตเตผเดกเดฟเดจเตเดฑเตเดฑเต เดเตเดฏเตเดฏเตเด, เดเดเตเดเตเดฎเดพเดฑเตเดฑเดฟเดเต เดฑเดฟเดฎเตเตปเดกเดฑเตเดเตพ เดเดฏเดฏเตเดเตเดเตเด  
- **เดกเตเดเตเดฏเตเดฎเตเดจเตเดฑเตเดทเตป เดเดเดจเตเดฑเตเดเตพ**: เดฎเตเดกเดฟเดเตเดเตฝ เดธเดเดเตเดฐเดนเดเตเดเตพ, เดฑเดฟเดชเตเดชเตเตผเดเตเดเตเดเตพ เดชเตเดฐเดพเดฆเตเดถเดฟเดเดฎเดพเดฏเดฟ เดธเตเดทเตเดเดฟเดเตเดเตเด  
- **เดชเตเดฐเดฟเดธเตเดเตเดฐเดฟเดชเตเดทเตป เดฎเดพเดจเตเดเตเดฎเตเดจเตเดฑเต เดเดเดจเตเดฑเตเดเตพ**: เดฑเดฟเดซเดฟเตฝ เดเตเดฐเดพเดเตเดเต เดเตเดฏเตเดฏเตเด, เดเดเดชเตเดเดฒเตเดเตพ เดธเตเดตเดเดพเดฐเตเดฏเดฎเดพเดฏเดฟ เดชเดฐเดฟเดถเตเดงเดฟเดเตเดเตเด  

## Microsoft Agent Framework: เดชเตเดฐเตเดกเดเตเดทเตป-เดฑเตเดกเดฟ เดเดเดจเตเดฑเต เดกเตเดตเดฒเดชเตเดชเตเดฎเตเดจเตเดฑเต

### เดเดตเดฒเตเดเดจเดตเตเด เดเตผเดเตเดเดฟเดเตเดเตเดเดฑเตเด

Microsoft Agent Framework เดเตเดฒเตเดกเต, เดเดซเตโเดฒเตเตป เดเดกเตเดเต เดชเดฐเดฟเดธเตเดฅเดฟเดคเดฟเดเดณเดฟเตฝ เดชเตเดฐเดตเตผเดคเตเดคเดฟเดเตเดเดพเตป เดเดดเดฟเดฏเตเดจเตเดจ AI เดเดเดจเตเดฑเตเดเตพ เดจเดฟเตผเดฎเตเดฎเดฟเดเตเดเดพเตป, เดกเดฟเดชเตเดฒเตเดฏเต เดเตเดฏเตเดฏเดพเตป, เดฎเดพเดจเตเดเต เดเตเดฏเตเดฏเดพเตป เดธเดฎเดเตเดฐเดฎเดพเดฏ เดเดจเตเดฑเตผเดชเตเดฐเตเดธเต-เดเตเดฐเตเดกเต เดชเตเดฒเดพเดฑเตเดฑเตเดซเตเด เดจเตฝเดเตเดจเตเดจเต. SLM-เดเตพเดเตเดเตเด เดเดกเตเดเต เดเดเดชเตเดฏเตเดเตเดเดฟเดเดเต เดธเตเดจเดพเดฐเดฟเดฏเตเดเตพเดเตเดเตเด เดเดจเตเดฏเตเดเตเดฏเดฎเดพเดฏเดฟ เดฐเตเดชเดเตฝเดชเตเดชเดจ เดเตเดฏเตเดค เด เดซเตเดฐเตเดฏเดฟเดเดตเตผเดเตเดเต เดชเตเดฐเตเดตเดธเดฟ-เดธเตเตปเดธเดฟเดฑเตเดฑเตเดตเต, เดฑเดฟเดธเตเดดเตโเดธเต-เดชเดฐเดฟเดฎเดฟเดค เดกเดฟเดชเตเดฒเตเดฏเตเดฎเตเดจเตเดฑเตเดเตพเดเตเดเดพเดฏเดฟ เดเดจเตเดฏเตเดเตเดฏเดฎเดพเดฃเต.  

**เดเตเตผ เดซเตเดฐเตเดฏเดฟเดเดตเตผเดเตเดเต เดเดเดเดเตเดเตพ**:  
- **เดเดเดจเตเดฑเต เดฑเตบเดเตเด**: เดเดกเตเดเต เดกเดฟเดตเตเดธเตเดเตพเดเตเดเดพเดฏเดฟ เดเดณเดฟเดเตเด, เดฒเดเตเดตเดพเดฏ เดเดเตเดธเดฟเดเตเดฏเตเดทเตป เดเตปเดตเดฏเตเตบเดฎเตเดจเตเดฑเต  
- **เดเตเตพ เดเดจเตเดฑเดเตเดฐเตเดทเตป เดธเดฟเดธเตเดฑเตเดฑเด**: เดฌเดพเดนเตเดฏ เดธเตผเดตเตเดธเตเดเดณเตเด API-เดเดณเตเด เดฌเดจเตเดงเดฟเดชเตเดชเดฟเดเตเดเดพเตป เดตเดฟเดชเตเดฒเตเดเดฐเดฟเดเตเดเดพเดตเตเดจเตเดจ เดชเตเดฒเดเดฟเตป เดเตผเดเตเดเดฟเดเตเดเตเดเตผ  
- **เดธเตเดฑเตเดฑเตเดฑเตเดฑเต เดฎเดพเดจเตเดเตเดฎเตเดจเตเดฑเต**: เดธเตเดทเดจเตเดเตพเดเตเดเดฟเดเดฏเดฟเตฝ เดธเตเดฅเดฟเดฐเดคเดฏเตเดณเตเดณ เดเดเดจเตเดฑเต เดฎเตเดฎเตเดฎเดฑเดฟ, เดเตเตบเดเตเดเตเดธเตเดฑเตเดฑเต เดเตเดเดพเดฐเตเดฏเด เดเตเดฏเตเดฏเตฝ  
- **เดธเตเดเตเดฏเตเดฐเดฟเดฑเตเดฑเดฟ เดฒเตเดฏเตผ**: เดเดจเตเดฑเตผเดชเตเดฐเตเดธเต เดกเดฟเดชเตเดฒเตเดฏเตเดฎเตเดจเตเดฑเดฟเดจเตเดณเตเดณ เดเตปเดฌเดฟเตฝเดฑเตเดฑเต เดธเตเดเตเดฏเตเดฐเดฟเดฑเตเดฑเดฟ เดจเดฟเดฏเดจเตเดคเตเดฐเดฃเดเตเดเตพ  
- **เดเตผเดเตเดเดธเตเดเตเดฐเตเดทเตป เดเดเตเดเดฟเตป**: เดฎเตพเดเตเดเดฟ-เดเดเดจเตเดฑเต เดเตเตผเดกเดฟเดจเตเดทเตป, เดตเตผเดเตเดเตโเดซเตเดฒเต เดฎเดพเดจเตเดเตเดฎเตเดจเตเดฑเต  

### เดเดกเตเดเต เดกเดฟเดชเตเดฒเตเดฏเตเดฎเตเดจเตเดฑเดฟเดจเตเดณเตเดณ เดชเตเดฐเดงเดพเดจ เดซเตเดเตเดเดฑเตเดเตพ

**เดเดซเตโเดฒเตเตป-เดซเดธเตเดฑเตเดฑเต เดเตผเดเตเดเดฟเดเตเดเตเดเตผ**: Microsoft Agent Framework เดเดซเตโเดฒเตเตป-เดซเดธเตเดฑเตเดฑเต เดธเดฟเดฆเตเดงเดพเดจเตเดคเดเตเดเตพ เดชเดพเดฒเดฟเดเตเดเต เดฐเตเดชเดเตฝเดชเตเดชเดจ เดเตเดฏเตเดคเดคเดพเดฃเต, เดเดเดจเตเดฑเตเดเตพ เดธเตเดฅเดฟเดฐเดฎเดพเดฏ เดเดจเตเดฑเตผเดจเตเดฑเตเดฑเต เดเดฃเดเตเดทเตป เดเดฒเตเดฒเดพเดคเต เดเดพเดฐเตเดฏเดเตเดทเดฎเดฎเดพเดฏเดฟ เดชเตเดฐเดตเตผเดคเตเดคเดฟเดเตเดเดพเตป เดธเดพเดงเดฟเดเตเดเตเด. เดเดคเดฟเตฝ เดชเตเดฐเดพเดฆเตเดถเดฟเด เดฎเตเดกเตฝ เดเตปเดซเดฑเตปเดธเต, เดเดพเดทเต เดเตเดฏเตเดค เดจเตเดณเดเต เดฌเตเดธเตเดเตพ, เดเดซเตโเดฒเตเตป เดเตเตพ เดเดเตเดธเดฟเดเตเดฏเตเดทเตป, เดเตเดฒเตเดกเต เดธเตผเดตเตเดธเตเดเตพ เดฒเดญเตเดฏเดฎเดฒเตเดฒเดพเดคเตเดคเดชเตเดชเตเตพ เดเตเดฐเตเดธเตเดซเตเตพ เดกเดฟเดเตเดฐเตเดกเตเดทเตป เดเดจเตเดจเดฟเดต เดเตพเดชเตเดชเตเดเตเดจเตเดจเต.  

**เดฑเดฟเดธเตเดดเตโเดธเต เดเดชเตเดฑเตเดฑเดฟเดฎเตเดธเตเดทเตป**: SLM-เดเตพเดเตเดเดพเดฏเดฟ เดเดเตเดเตเดฎเดพเดฑเตเดฑเดฟเดเต เดฎเตเดฎเตเดฎเดฑเดฟ เดเดชเตเดฑเตเดฑเดฟเดฎเตเดธเตเดทเตป, เดเดกเตเดเต เดกเดฟเดตเตเดธเตเดเตพเดเตเดเดพเดฏเดฟ CPU/GPU เดฒเตเดกเต เดฌเดพเดฒเตปเดธเดฟเดเดเต, เดฒเดญเตเดฏเดฎเดพเดฏ เดฑเดฟเดธเตเดดเตโเดธเตเดเตพ เดเดเดฟเดธเตเดฅเดพเดจเดฎเดพเดเตเดเดฟ เดเดกเดพเดชเตเดฑเตเดฑเตเดตเต เดฎเตเดกเตฝ เดธเตเดฒเดเตเดทเตป, เดฎเตเดฌเตเตฝ เดกเดฟเดชเตเดฒเตเดฏเตเดฎเตเดจเตเดฑเดฟเดจเดพเดฏเดฟ เดชเดตเตผ-เดเดซเดฟเดทเตเดฏเดจเตเดฑเต เดเตปเดซเดฑเตปเดธเต เดชเดพเดฑเตเดฑเตเดฃเตเดเตพ เดเดจเตเดจเดฟเดต เดจเตฝเดเตเดจเตเดจเต.  

**เดธเตเดเตเดฏเตเดฐเดฟเดฑเตเดฑเดฟ & เดชเตเดฐเตเดตเดธเดฟ**: เดชเตเดฐเดพเดฆเตเดถเดฟเด เดกเดพเดฑเตเดฑ เดชเตเดฐเตเดธเดธเตเดธเดฟเดเดเต เดตเดดเดฟ เดชเตเดฐเตเดตเดธเดฟ เดจเดฟเดฒเดจเดฟเตผเดคเตเดคเตฝ, เดเตปเดเตเดฐเดฟเดชเตเดฑเตเดฑเดกเต เดเดเดจเตเดฑเต เดเดฎเตเดฎเตเดฏเตเดฃเดฟเดเตเดเตเดทเตป เดเดพเดจเดฒเตเดเตพ, เดเดเดจเตเดฑเต เดถเตเดทเดฟเดเตพเดเตเดเตเดณเตเดณ เดฑเตเดณเตเดฌเตเดธเต เดเดเตโเดธเดธเต เดจเดฟเดฏเดจเตเดคเตเดฐเดฃเดเตเดเตพ, เดเดเดชเตเดฒเดฏเตปเดธเต เดเดตเดถเตเดฏเดเดคเดเตพเดเตเดเดพเดฏเดฟ เดเดกเดฟเดฑเตเดฑเต เดฒเตเดเดฟเดเดเต เดเดจเตเดจเดฟเดต เดเตพเดชเตเดชเตเดเตเดจเตเดจ เดเดจเตเดฑเตผเดชเตเดฐเตเดธเต-เดเตเดฐเตเดกเต เดธเตเดเตเดฏเตเดฐเดฟเดฑเตเดฑเดฟ เดซเตเดเตเดเดฑเตเดเตพ.  

### Foundry Local-เดจเตเดเตเดณเตเดณ เดเดจเตเดฑเดเตเดฐเตเดทเตป

Microsoft Agent Framework Foundry Local-เดจเตเดเตเดชเตเดชเด เดธเตเดคเดพเดฐเตเดฏเดฎเดพเดฏเดฟ เดเดจเตเดฑเดเตเดฐเตเดฑเตเดฑเต เดเตเดฏเตเดคเต เดธเดฎเดเตเดฐ เดเดกเตเดเต AI เดธเตเดฒเตเดฏเตเดทเตป เดจเตฝเดเตเดจเตเดจเต:  

**เดเดเตเดเตเดฎเดพเดฑเตเดฑเดฟเดเต เดฎเตเดกเตฝ เดกเดฟเดธเตเดเดตเดฑเดฟ**: เดซเตเดฐเตเดฏเดฟเดเดตเตผเดเตเดเต Foundry Local เดเตปเดธเตเดฑเตเดฑเตปเดธเตเดเตพ เดธเตเดตเดฏเด เดเดฃเตเดเตเดคเตเดคเตเดเดฏเตเด, เดฒเดญเตเดฏเดฎเดพเดฏ SLM เดฎเตเดกเดฒเตเดเตพ เดเดฃเตเดเตเดคเตเดคเตเดเดฏเตเด, เดเดเดจเตเดฑเต เดเดตเดถเตเดฏเดเดคเดเดณเตเด เดนเดพเตผเดกเตโเดตเตเดฏเตผ เดถเตเดทเดฟเดเดณเตเด เดเดเดฟเดธเตเดฅเดพเดจเดฎเดพเดเตเดเดฟ เดฎเดฟเดเดเตเด เดฎเตเดกเดฒเตเดเตพ เดคเดฟเดฐเดเตเดเตเดเตเดเตเดเตเดเดฏเตเด เดเตเดฏเตเดฏเตเดจเตเดจเต.  

**เดกเตเดจเดพเดฎเดฟเดเต เดฎเตเดกเตฝ เดฒเตเดกเดฟเดเดเต**: เดเดเดจเตเดฑเตเดเตพ เดชเตเดฐเดคเตเดฏเตเด เดเดพเดธเตเดเตเดเตพเดเตเดเดพเดฏเดฟ เดตเตเดฏเดคเตเดฏเดธเตเดค SLMเดเตพ เดกเตเดจเดพเดฎเดฟเดเตเดเดพเดฏเดฟ เดฒเตเดกเต เดเตเดฏเตเดฏเดพเตป เดเดดเดฟเดฏเตเด, เดฎเตพเดเตเดเดฟ-เดฎเตเดกเตฝ เดเดเดจเตเดฑเต เดธเดฟเดธเตเดฑเตเดฑเดเตเดเตพ เดธเตเดทเตเดเดฟเดเตเดเดพเตป เดธเดพเดงเดฟเดเตเดเตเด, เดตเดฟเดตเดฟเดง เดฎเตเดกเดฒเตเดเตพ เดตเตเดฏเดคเตเดฏเดธเตเดค เดเดญเตเดฏเตผเดคเตเดฅเดจเดเตพ เดเตเดเดพเดฐเตเดฏเด เดเตเดฏเตเดฏเตเดเดฏเตเด, เดฒเดญเตเดฏเดคเดฏเตเด เดชเตเดฐเดเดเดจเดตเตเด เดเดเดฟเดธเตเดฅเดพเดจเดฎเดพเดเตเดเดฟ เดฎเตเดกเดฒเตเดเตพเดเตเดเดฟเดเดฏเดฟเตฝ เดเดเตเดเตเดฎเดพเดฑเตเดฑเดฟเดเต เดซเตเดฏเดฟเตฝเดเดตเตผ เดจเดเดชเตเดชเดฟเดฒเดพเดเตเดเตเดเดฏเตเด เดเตเดฏเตเดฏเตเดจเตเดจเต.  

**เดชเตเดฐเดเดเดจ เดเดชเตเดฑเตเดฑเดฟเดฎเตเดธเตเดทเตป**: เดเดจเตเดฑเดเตเดฐเตเดฑเตเดฑเดกเต เดเดพเดทเดฟเดเดเต เดฎเตเดเตเดเดพเดจเดฟเดธเดเตเดเตพ เดฎเตเดกเตฝ เดฒเตเดกเดฟเดเดเต เดธเดฎเดฏเด เดเตเดฑเดฏเตเดเตเดเตเดจเตเดจเต, เดเดฃเดเตเดทเตป เดชเตเดณเดฟเดเดเต Foundry Local-เดฒเตเดเตเดเต API เดเตเตพเดธเต เดฎเตเดเตเดเดชเตเดชเตเดเตเดคเตเดคเตเดจเตเดจเต, เดฌเตเดฆเตเดงเดฟเดฎเตเดเตเดเตเดณเตเดณ เดฌเดพเดเตเดเดฟเดเดเต เดฎเตพเดเตเดเดฟ-เดเดเดจเตเดฑเต เดเดญเตเดฏเตผเดคเตเดฅเดจเดเดณเตเดเต เดคเตเดฐเตเดชเตเดเตเดเต เดฎเตเดเตเดเดชเตเดชเตเดเตเดคเตเดคเตเดจเตเดจเต.  

### Microsoft Agent Framework เดเดชเดฏเตเดเดฟเดเตเดเต เดเดเดจเตเดฑเตเดเตพ เดจเดฟเตผเดฎเตเดฎเดฟเดเตเดเตฝ

#### เดเดเดจเตเดฑเต เดจเดฟเตผเดตเดเดจเดตเตเด เดเตเตบเดซเดฟเดเดฑเตเดทเดจเตเด

```python
from microsoft_agent_framework import Agent, Tool, Config
from foundry_local import FoundryLocalManager

# เดซเตเดฃเตเดเตเดฐเดฟ เดฒเตเดเตเดเตฝ เดเดจเตเดฑเดเตเดฐเตเดทเดจเตเดฎเดพเดฏเดฟ เดเดเดจเตเดฑเต เดเตเตบเดซเดฟเดเตผ เดเตเดฏเตเดฏเตเด
config = Config(
    name="customer-service-agent",
    model_provider="foundry-local",
    model_alias="phi-4-mini",
    max_tokens=512,
    temperature=0.1,
    offline_mode=True
)

# เดซเตเดฃเตเดเตเดฐเดฟ เดฒเตเดเตเดเตฝ เดเดฃเดเตเดทเตป เดเดฐเดเดญเดฟเดเตเดเตเด
foundry = FoundryLocalManager("phi-4-mini")

# เดเดเดจเตเดฑเต เดเตปเดธเตเดฑเตเดฑเตปเดธเต เดธเตเดทเตเดเดฟเดเตเดเตเด
agent = Agent(
    config=config,
    model_endpoint=foundry.endpoint,
    api_key=foundry.api_key
)
```
  
#### เดเดกเตเดเต เดธเตเดจเดพเดฐเดฟเดฏเตเดเตพเดเตเดเตเดณเตเดณ เดเตเตพ เดเดจเตเดฑเดเตเดฐเตเดทเตป

```python
# เดเดซเตโเดฒเตเตป เดชเตเดฐเดตเตผเดคเตเดคเดจเดคเตเดคเดฟเดจเตเดณเตเดณ เดเดชเดเดฐเดฃเดเตเดเตพ เดจเดฟเตผเดตเดเดฟเดเตเดเตเด
@agent.tool
def lookup_customer_info(customer_id: str) -> dict:
    """Look up customer information from local database."""
    # เดฒเตเดเตเดเตฝ เดกเดพเดฑเตเดฑเดพเดฌเตเดธเต เดเตเดตเดฑเดฟ - เดเดซเตโเดฒเตเตป เดชเตเดฐเดตเตผเดคเตเดคเดฟเดเตเดเตเดจเตเดจเต
    return local_db.get_customer(customer_id)

@agent.tool
def create_support_ticket(issue: str, priority: str) -> str:
    """Create a support ticket in local system."""
    # เดเตบเดฒเตเดจเดฟเตฝ เดธเดฟเดเตเดเต เดเตเดฏเตเดฏเตเดฎเตเดชเตเตพ เดฒเตเดเตเดเตฝ เดเดฟเดเตเดเดฑเตเดฑเต เดธเตเดทเตเดเดฟเดเตเดเตฝ
    ticket_id = local_system.create_ticket(issue, priority)
    return f"Ticket {ticket_id} created successfully"

@agent.tool
def schedule_callback(customer_id: str, preferred_time: str) -> str:
    """Schedule a callback for the customer."""
    # เดเดฒเดฃเตเดเตผ เดเดจเตเดฑเดเตเดฐเตเดทเดจเตเดเตเดเตเดเดฟเดฏ เดฒเตเดเตเดเตฝ เดทเตเดกเตเดฏเตเดณเดฟเดเดเต
    return local_calendar.schedule(customer_id, preferred_time)
```
  
#### เดฎเตพเดเตเดเดฟ-เดเดเดจเตเดฑเต เดเตผเดเตเดเดธเตเดเตเดฐเตเดทเตป

```python
from microsoft_agent_framework import AgentOrchestrator

# เดตเตเดฏเดคเตเดฏเดธเตเดค เดกเตเดฎเตเดฏเตโเดจเตเดเตพเดเตเดเดพเดฏเดฟ เดชเตเดฐเดคเตเดฏเตเด เดเดเดจเตเดฑเตเดเตพ เดธเตเดทเตเดเดฟเดเตเดเตเด
scheduling_agent = Agent(
    config=Config(
        name="scheduling-agent",
        model_alias="qwen2.5-0.5b",  # เดฒเดณเดฟเดคเดฎเดพเดฏ เดเตเดฒเดฟเดเตพเดเตเดเดพเดฏเดฟ เดฒเดเตเดตเดพเดฏเดคเต
        specialized_for="scheduling"
    )
)

technical_support_agent = Agent(
    config=Config(
        name="technical-agent",
        model_alias="phi-4-mini",  # เดธเดเตเดเตเตผเดฃเตเดฃ เดชเตเดฐเดถเตเดจเดเตเดเตพเดเตเดเต เดเตเดเตเดคเตฝ เดเดดเดฟเดตเตเดณเตเดณเดคเต
        specialized_for="technical_support"
    )
)

# เดชเดฒ เดเดเดจเตเดฑเตเดเดณเตเดฏเตเด เดเดเตเดชเดฟเดชเตเดชเดฟเดเตเดเตเด
orchestrator = AgentOrchestrator([
    scheduling_agent,
    technical_support_agent
])

# เดเดฆเตเดฆเตเดถเตเดฏเดคเตเดคเดฟเดจเตเดฑเต เดเดเดฟเดธเตเดฅเดพเดจเดคเตเดคเดฟเตฝ เดเดญเตเดฏเตผเดคเตเดฅเดจเดเตพ เดฑเตเดเตเดเตเดเตเดฏเตเดฏเตเด
result = orchestrator.process_request(
    "I need to schedule a callback for a technical issue",
    routing_strategy="intent-based"
)
```
  
### เดเดงเตเดจเดฟเด เดเดกเตเดเต เดกเดฟเดชเตเดฒเตเดฏเตเดฎเตเดจเตเดฑเต เดชเดพเดฑเตเดฑเตเดฃเตเดเตพ

#### เดนเดฏเตผเดเตผเดเตเดเดฟเดเตเดเตฝ เดเดเดจเตเดฑเต เดเตผเดเตเดเดฟเดเตเดเตเดเตผ

**เดชเตเดฐเดพเดฆเตเดถเดฟเด เดเดเดจเตเดฑเต เดเตเดฒเดธเตเดฑเตเดฑเดฑเตเดเตพ**: เดเดกเตเดเต เดกเดฟเดตเตเดธเตเดเดณเดฟเตฝ เดจเดฟเดฐเดตเดงเดฟ เดชเตเดฐเดคเตเดฏเตเด SLM เดเดเดจเตเดฑเตเดเตพ เดกเดฟเดชเตเดฒเตเดฏเต เดเตเดฏเตเดฏเตเด, เดเดฐเตเดจเตเดจเตเด เดชเตเดฐเดคเตเดฏเตเด เดเดพเดธเตเดเตเดเตพเดเตเดเดพเดฏเดฟ เดเดชเตเดฑเตเดฑเดฟเดฎเตเดธเต เดเตเดฏเตเดคเดคเดพเดฏเดฟเดฐเดฟเดเตเดเตเด. เดฒเดณเดฟเดคเดฎเดพเดฏ เดฑเตเดเตเดเดฟเดเดเต, เดทเตเดกเตเดฏเตเดณเดฟเดเดเดฟเดจเดพเดฏเดฟ Qwen2.5-0.5B เดชเตเดฒเตเดณเตเดณ เดฒเดเต เดฎเตเดกเดฒเตเดเตพ, เดเดธเตเดฑเตเดฑเดฎเตผ เดธเตผเดตเตเดธเต, เดกเตเดเตเดฏเตเดฎเตเดจเตเดฑเตเดทเดจเดพเดฏเดฟ Phi-4-Mini เดชเตเดฒเตเดณเตเดณ เดฎเดงเตเดฏเดธเตเดฅ เดฎเตเดกเดฒเตเดเตพ, เดธเดเตเดเตเตผเดฃเตเดฃเดฎเดพเดฏ เดฑเตเดธเดฃเดฟเดเตเดเดฟเดจเดพเดฏเดฟ เดตเดฒเดฟเดฏ เดฎเตเดกเดฒเตเดเตพ เดเดชเดฏเตเดเดฟเดเตเดเตเด.  

**เดเดกเตเดเต-เดเต-เดเตเดฒเตเดกเต เดเตเตผเดกเดฟเดจเตเดทเตป**: เดชเตเดฐเดพเดฆเตเดถเดฟเด เดเดเดจเตเดฑเตเดเตพ เดธเดพเดงเดพเดฐเดฃ เดเดพเดธเตเดเตเดเตพ เดเตเดเดพเดฐเตเดฏเด เดเตเดฏเตเดฏเตเดฎเตเดชเตเตพ, เดเดฃเดเตเดเดฟเดตเดฟเดฑเตเดฑเดฟ เดฒเดญเตเดฏเดฎเดพเดเตเดฎเตเดชเตเตพ เดเตเดฒเตเดกเต เดเดเดจเตเดฑเตเดเตพ เดธเดเตเดเตเตผเดฃเตเดฃเดฎเดพเดฏ เดฑเตเดธเดฃเดฟเดเดเต เดจเตฝเดเตเดเดฏเตเด, เดเดกเตเดเต-เดเตเดฒเตเดกเต เดชเตเดฐเตเดธเดธเตเดธเดฟเดเตเดเดฟเดจเดฟเดเดฏเดฟเตฝ เดธเตเดคเดพเดฐเตเดฏเดฎเดพเดฏ เดเตเดฎเดพเดฑเตเดฑเด เดคเตเดเตผเดเตเด เดเดฑเดชเตเดชเดพเดเตเดเตเดเดฏเตเด เดเตเดฏเตเดฏเตเดจเตเดจ เดฌเตเดฆเตเดงเดฟเดฎเตเดเตเดเตเดณเตเดณ เดเดธเตเดเดฒเตเดทเตป เดชเดพเดฑเตเดฑเตเดฃเตเดเตพ เดจเดเดชเตเดชเดฟเดฒเดพเดเตเดเตเด.  

#### เดกเดฟเดชเตเดฒเตเดฏเตเดฎเตเดจเตเดฑเต เดเตเตบเดซเดฟเดเดฑเตเดทเดจเตเดเตพ

**เดธเดฟเดเดเดฟเตพ เดกเดฟเดตเตเดธเต เดกเดฟเดชเตเดฒเตเดฏเตเดฎเตเดจเตเดฑเต**:  
```yaml
deployment:
  type: single-device
  hardware: edge-device
  models:
    - alias: "phi-4-mini"
      primary: true
      tasks: ["conversation", "reasoning"]
    - alias: "qwen2.5-0.5b"
      secondary: true
      tasks: ["routing", "classification"]
  agents:
    - name: "primary-agent"
      model: "phi-4-mini"
      tools: ["database", "calendar", "email"]
```
  
**เดกเดฟเดธเตเดเตเดฐเดฟเดฌเตเดฏเตเดเตเดเดกเต เดเดกเตเดเต เดกเดฟเดชเตเดฒเตเดฏเตเดฎเตเดจเตเดฑเต**:  
```yaml
deployment:
  type: distributed-edge
  nodes:
    - id: "edge-1"
      agents: ["customer-service", "scheduling"]
      models: ["phi-4-mini"]
    - id: "edge-2"
      agents: ["technical-support", "documentation"]
      models: ["qwen2.5-coder-0.5b"]
  coordination:
    load_balancing: true
    failover: automatic
```
  
### เดเดกเตเดเต เดเดเดจเตเดฑเตเดเตพเดเตเดเตเดณเตเดณ เดชเตเดฐเดเดเดจ เดเดชเตเดฑเตเดฑเดฟเดฎเตเดธเตเดทเตป

#### เดฎเตเดกเตฝ เดธเตเดฒเดเตเดทเตป เดคเดจเตเดคเตเดฐเดเตเดเตพ

**เดเดพเดธเตโเดเต เดเดเดฟเดธเตเดฅเดพเดจเดฎเดพเดเตเดเดฟเดฏ เดฎเตเดกเตฝ เดเดธเตเตปเดฎเตเดจเตเดฑเต**: Microsoft Agent Framework เดเดพเดธเตโเดเต เดธเดเตเดเตเตผเดฃเตเดฃเดคเดฏเตเด เดเดตเดถเตเดฏเดเดคเดเดณเตเด เดเดเดฟเดธเตเดฅเดพเดจเดฎเดพเดเตเดเดฟ เดฌเตเดฆเตเดงเดฟเดฎเตเดเตเดเตเดณเตเดณ เดฎเตเดกเตฝ เดธเตเดฒเดเตเดทเตป เดเดจเตเดตเดฆเดฟเดเตเดเตเดจเตเดจเต:  

- **เดฒเดณเดฟเดคเดฎเดพเดฏ เดเดพเดธเตเดเตเดเตพ** (Q&A, เดฑเตเดเตเดเดฟเดเดเต): Qwen2.5-0.5B (500MB, <100ms เดชเตเดฐเดคเดฟเดเดฐเดฃเด)  
- **เดฎเดงเตเดฏเดธเตเดฅ เดเดพเดธเตเดเตเดเตพ** (เดเดธเตเดฑเตเดฑเดฎเตผ เดธเตผเดตเตเดธเต, เดทเตเดกเตเดฏเตเดณเดฟเดเดเต): Phi-4-Mini (2.4GB, 200-500ms เดชเตเดฐเดคเดฟเดเดฐเดฃเด)  
- **เดธเดเตเดเตเตผเดฃเตเดฃ เดเดพเดธเตเดเตเดเตพ** (เดเตเดเตเดจเดฟเดเตเดเตฝ เดเดจเดพเดฒเดฟเดธเดฟเดธเต, เดชเตเดฒเดพเดจเดฟเดเดเต): Phi-4 (7GB, 1-3s เดชเตเดฐเดคเดฟเดเดฐเดฃเด, เดฑเดฟเดธเตเดดเตโเดธเตเดเตพ เดฒเดญเตเดฏเดฎเตเดเตเดเดฟเตฝ)  

**เดกเตเดจเดพเดฎเดฟเดเต เดฎเตเดกเตฝ เดธเตเดตเดฟเดเตเดเต เดเตเดฏเตเดฏเตฝ**: เดเดเดจเตเดฑเตเดเตพ เดจเดฟเดฒเดตเดฟเดฒเต เดธเดฟเดธเตเดฑเตเดฑเด เดฒเตเดกเต, เดเดพเดธเตโเดเต เดธเดเตเดเตเตผเดฃเตเดฃเดค เดตเดฟเดฒเดฏเดฟเดฐเตเดคเตเดคเตฝ, เดเดชเดฏเตเดเตเดคเต เดฎเตเตปเดเดฃเดจ เดจเดฟเดฒเดเตพ, เดฒเดญเตเดฏเดฎเดพเดฏ เดนเดพเตผเดกเตโเดตเตเดฏเตผ เดฑเดฟเดธเตเดดเตโเดธเตเดเตพ เดเดจเตเดจเดฟเดตเดฏเตเดเต เดเดเดฟเดธเตเดฅเดพเดจเดคเตเดคเดฟเตฝ เดฎเตเดกเดฒเตเดเตพ เดคเดฎเตเดฎเดฟเตฝ เดฎเดพเดฑเดพเด.  

#### เดฎเตเดฎเตเดฎเดฑเดฟ & เดฑเดฟเดธเตเดดเตโเดธเต เดฎเดพเดจเตเดเตเดฎเตเดจเตเดฑเต

```python
# เดเดกเตเดเต เดกเดฟเดชเตเดฒเตเดฏเตเดฎเตเดจเตเดฑเดฟเดจเตเดณเตเดณ เดฑเดฟเดธเตเดดเตโเดธเต เดจเดฟเดฏเดจเตเดคเตเดฐเดฃเดเตเดเตพ เดเตเดฐเดฎเตเดเดฐเดฟเดเตเดเตเด
resource_config = ResourceConfig(
    max_memory_usage="4GB",
    max_concurrent_agents=3,
    model_cache_size="2GB",
    auto_unload_idle_models=True,
    power_management=True
)

agent = Agent(
    config=config,
    resource_limits=resource_config
)
```
  
### เดเดจเตเดฑเตผเดชเตเดฐเตเดธเต เดเดจเตเดฑเดเตเดฐเตเดทเตป เดชเดพเดฑเตเดฑเตเดฃเตเดเตพ

#### เดธเตเดเตเดฏเตเดฐเดฟเดฑเตเดฑเดฟ & เดเดเดชเตเดฒเดฏเตปเดธเต

**เดชเตเดฐเดพเดฆเตเดถเดฟเด เดกเดพเดฑเตเดฑ เดชเตเดฐเตเดธเดธเตเดธเดฟเดเดเต**: เดเดฒเตเดฒเดพ เดเดเดจเตเดฑเต เดชเตเดฐเตเดธเดธเตเดธเดฟเดเดเตเด เดชเตเดฐเดพเดฆเตเดถเดฟเดเดฎเดพเดฏเดฟ เดจเดเดเตเดเตเดจเตเดจเต, เดเดคเดฟเดจเดพเตฝ เดธเตเตปเดธเดฟเดฑเตเดฑเตเดตเต เดกเดพเดฑเตเดฑ เดเดกเตเดเต เดกเดฟเดตเตเดธเตเดเตพ เดตเดฟเดเตเดเต เดชเตเดเดพเดฑเดฟเดฒเตเดฒ. เดเดคเดฟเตฝ เดเดธเตเดฑเตเดฑเดฎเตผ เดตเดฟเดตเดฐ เดธเดเดฐเดเตเดทเดฃเด, เดนเตเตฝเดคเตเดคเตโเดเตเดฏเตผ เดเดเดจเตเดฑเตเดเตพเดเตเดเตเดณเตเดณ HIPAA เดเดเดชเตเดฒเดฏเตปเดธเต, เดฌเดพเดเตเดเดฟเดเดเต เดเดเดจเตเดฑเตเดเตพเดเตเดเตเดณเตเดณ เดซเดฟเดจเดพเตปเดทเตเดฏเตฝ เดกเดพเดฑเตเดฑ เดธเตเดฐเดเตเดท, เดฏเตเดฑเตเดชเตเดฏเตป เดกเดฟเดชเตเดฒเตเดฏเตเดฎเตเดจเตเดฑเตเดเตพเดเตเดเตเดณเตเดณ GDPR เดเดเดชเตเดฒเดฏเตปเดธเต เดเดจเตเดจเดฟเดต เดเตพเดชเตเดชเตเดเตเดจเตเดจเต.  

**เดเดเตโเดธเดธเต เดเตบเดเตเดฐเตเตพ**: เดเดเดจเตเดฑเตเดเตพเดเตเดเต เดเดเตโเดธเดธเต เดเตเดฏเตเดฏเดพเดตเตเดจเตเดจ เดเตเดณเตเดเตพ เดจเดฟเดฏเดจเตเดคเตเดฐเดฟเดเตเดเตเดจเตเดจ เดฑเตเดณเตเดฌเตเดธเต เดเดจเตเดฎเดคเดฟเดเตพ, เดเดเดจเตเดฑเต เดเดเดชเตเดเดฒเตเดเตพเดเตเดเตเดณเตเดณ เดเดชเดฏเตเดเตเดคเต เดเดคเดจเตเดฑเดฟเดเตเดเตเดทเตป, เดเดฒเตเดฒเดพ เดเดเดจเตเดฑเต เดชเตเดฐเดตเตผเดคเตเดคเดจเดเตเดเดณเตเด เดคเตเดฐเตเดฎเดพเดจเดเตเดเดณเตเด เดเดกเดฟเดฑเตเดฑเต เดเตเดฐเตเดฏเดฟเดฒเตเดเตพ.  

#### เดฎเตเดฃเดฟเดฑเตเดฑเดฑเดฟเดเดเต & เดเดฌเตเดธเตผเดตเดฌเดฟเดฒเดฟเดฑเตเดฑเดฟ

```python
from microsoft_agent_framework import AgentMonitor

# เดเดกเตเดเต เดเดเดจเตเดฑเตเดเตพเดเตเดเดพเดฏเดฟ เดจเดฟเดฐเตเดเตเดทเดฃเด เดธเดเตเดเดฎเดพเดเตเดเตเด
monitor = AgentMonitor(
    metrics=["response_time", "success_rate", "resource_usage"],
    alerts=[
        {"metric": "response_time", "threshold": "2s", "action": "scale_down_model"},
        {"metric": "memory_usage", "threshold": "80%", "action": "unload_idle_agents"}
    ],
    local_storage=True  # เดเดซเตโเดฒเตเตป เดชเตเดฐเดตเตผเดคเตเดคเดจเดคเตเดคเดฟเดจเดพเดฏเดฟ เดฎเตเดเตเดฐเดฟเดเตโเดธเต เดชเตเดฐเดพเดฆเตเดถเดฟเดเดฎเดพเดฏเดฟ เดธเดเดญเดฐเดฟเดเตเดเตเด
)

agent.add_monitor(monitor)
```
  
### เดฏเดฅเดพเตผเดคเตเดฅ เดฒเตเด เดจเดเดชเตเดชเดพเดเตเดเตฝ เดเดฆเดพเดนเดฐเดฃเดเตเดเตพ

#### เดฑเตเดเตเดเตเดฏเดฟเตฝ เดเดกเตเดเต เดเดเดจเตเดฑเต เดธเดฟเดธเตเดฑเตเดฑเด

```python
# เดธเตเดฑเตเดฑเตเตผเดเตเดณเตเดณ เดเดชเดญเตเดเตเดคเต เดธเดนเดพเดฏเดคเตเดคเดฟเดจเตเดณเตเดณ เดฑเตเดเตเดเตเดฏเดฟเตฝ เดเดฟเดฏเตเดธเตเดเต เดเดเดจเตเดฑเต
retail_agent = Agent(
    config=Config(
        name="retail-assistant",
        model_alias="phi-4-mini",
        context="You are a helpful retail assistant in an electronics store."
    )
)

@retail_agent.tool
def check_inventory(product_sku: str) -> dict:
    """Check local inventory for a product."""
    return local_inventory.lookup(product_sku)

@retail_agent.tool
def find_alternatives(product_category: str) -> list:
    """Find alternative products in the same category."""
    return local_catalog.find_similar(product_category)

@retail_agent.tool
def create_price_quote(items: list) -> dict:
    """Generate a price quote for multiple items."""
    return pricing_engine.calculate_quote(items)
```
  
#### เดนเตเตฝเดคเตเดคเตโเดเตเดฏเตผ เดธเดชเตเดชเตเตผเดเตเดเต เดเดเดจเตเดฑเต

```python
# HIPAA-เดเดจเตเดธเตเดค เดฐเตเดเดฟ เดชเดฟเดจเตเดคเตเดฃ เดเดเดจเตเดฑเต
healthcare_agent = Agent(
    config=Config(
        name="patient-support",
        model_alias="phi-4-mini",
        privacy_mode=True,  # เดเดฐเตเดเตเดฏเดชเดฐเดฟเดเดฐเดฃเดคเตเดคเดฟเดจเตเดณเตเดณ เดฎเตเดเตเดเดชเตเดชเตเดเตเด เดธเตเดตเดเดพเดฐเตเดฏเดค
        compliance=["HIPAA"]
    )
)

@healthcare_agent.tool
def check_appointment_availability(provider_id: str, date_range: str) -> list:
    """Check appointment slots with healthcare provider."""
    return local_scheduling.get_availability(provider_id, date_range)

@healthcare_agent.tool
def access_patient_portal(patient_id: str, auth_token: str) -> dict:
    """Secure access to patient information."""
    if security.validate_token(auth_token):
        return patient_portal.get_summary(patient_id)
    return {"error": "Authentication failed"}
```
  
### Microsoft Agent Framework-เดจเตเดณเตเดณ เดฎเดฟเดเดเตเด เดชเตเดฐเดพเดเตเดเตเดธเตเดเตพ

#### เดกเตเดตเดฒเดชเตเดชเตเดฎเตเดจเตเดฑเต เดฎเดพเตผเดเตเดเดจเดฟเตผเดฆเตเดฆเตเดถเดเตเดเตพ

1. **เดฒเดณเดฟเดคเดฎเดพเดฏเดฟ เดเดฐเดเดญเดฟเดเตเดเตเด**: เดธเดฟเดเดเดฟเตพ-เดเดเดจเตเดฑเต เดธเตเดจเดพเดฐเดฟเดฏเตเดเดณเดฟเตฝ เดจเดฟเดจเตเดจเต เดเดฐเดเดญเดฟเดเตเดเต เดธเดเตเดเตเตผเดฃเตเดฃ เดฎเตพเดเตเดเดฟ-เดเดเดจเตเดฑเต เดธเดฟเดธเตเดฑเตเดฑเดเตเดเตพ เดจเดฟเตผเดฎเตเดฎเดฟเดเตเดเตเด  
2. **เดฎเตเดกเตฝ เดถเดฐเดฟเดฏเดพเดฏ เดตเดฒเตเดชเตเดชเด เดคเดฟเดฐเดเตเดเตเดเตเดเตเดเตเด**: เดจเดฟเดเตเดเดณเตเดเต เดเตเดคเตเดฏเดค เดเดตเดถเตเดฏเดเดคเดเตพ เดจเดฟเดฑเดตเตเดฑเตเดฑเตเดจเตเดจ เดเดฑเตเดฑเดตเตเด เดเตเดฑเดฟเดฏ เดฎเตเดกเตฝ เดคเดฟเดฐเดเตเดเตเดเตเดเตเดเตเด  
3. **เดเตเตพ เดกเดฟเดธเตเตป**: เดธเดเตเดเตเตผเดฃเตเดฃ เดฎเตพเดเตเดเดฟ-เดซเดเดเตเดทเตป เดเตเดณเตเดเตพเดเตเดเตเดชเดเดฐเด เดเตเดจเตเดฆเตเดฐเตเดเตเดค, เดเดฑเตเดฑ-เดเดฆเตเดฆเตเดถเตเดฏ เดเตเดณเตเดเตพ เดธเตเดทเตเดเดฟเดเตเดเตเด  
4. **เดชเดฟเดถเดเต เดเตเดเดพเดฐเตเดฏเด เดเตเดฏเตเดฏเตฝ**: เดเดซเตโเดฒเตเตป เดธเตเดจเดพเดฐเดฟเดฏเตเดเดณเดฟเดฒเตเด เดฎเตเดกเตฝ เดชเดฐเดพเดเดฏเดเตเดเดณเดฟเดฒเตเด เดเตเดฐเตเดธเตเดซเตเตพ เดกเดฟเดเตเดฐเตเดกเตเดทเตป เดจเดเดชเตเดชเดฟเดฒเดพเดเตเดเตเด  
5. **เดเตเดธเตเดฑเตเดฑเดฟเดเดเต**: เดเดซเตโเดฒเตเตป เดธเดพเดนเดเดฐเตเดฏเดเตเดเดณเดฟเดฒเตเด เดฑเดฟเดธเตเดดเตโเดธเต เดชเดฐเดฟเดฎเดฟเดค เดธเดพเดนเดเดฐเตเดฏเดเตเดเดณเดฟเดฒเตเด เดเดเดจเตเดฑเตเดเตพ เดตเตเดฏเดพเดชเดเดฎเดพเดฏเดฟ เดเตเดธเตเดฑเตเดฑเต เดเตเดฏเตเดฏเตเด  

#### เดกเดฟเดชเตเดฒเตเดฏเตเดฎเตเดจเตเดฑเต เดฎเดฟเดเดเตเด เดชเตเดฐเดพเดเตเดเตเดธเตเดเตพ

1. **ๅพๅพ เดชเตเดฐเดเดฐเดฟเดชเตเดชเดฟเดเตเดเตฝ**: เดเดฆเตเดฏเด เดเตเดฑเดฟเดฏ เดเดชเดฏเตเดเตเดคเต เดเตเดฐเตเดชเตเดชเตเดเดณเดฟเตฝ เดกเดฟเดชเตเดฒเตเดฏเต เดเตเดฏเตเดคเต เดชเตเดฐเดเดเดจ เดฎเตเดเตเดฐเดฟเดเตโเดธเต เดถเตเดฐเดฆเตเดงเดพเดชเตเตผเดตเตเดตเด เดจเดฟเดฐเตเดเตเดทเดฟเดเตเดเตเด  
2. **เดฑเดฟเดธเตเดดเตโเดธเต เดฎเตเดฃเดฟเดฑเตเดฑเดฑเดฟเดเดเต**: เดฎเตเดฎเตเดฎเดฑเดฟ, CPU, เดชเตเดฐเดคเดฟเดเดฐเดฃ เดธเดฎเดฏเด เดชเดฐเดฟเดงเดฟเดเตพเดเตเดเดพเดฏเดฟ เดเดฒเตผเดเตเดเตเดเตพ เดธเดเตเดเดฎเดพเดเตเดเตเด  
3. **เดซเดพเตพเดฌเดพเดเตเดเต เดคเดจเตเดคเตเดฐเดเตเดเตพ**: เดฎเตเดกเตฝ เดชเดฐเดพเดเดฏเดเตเดเตพเดเตเดเตเด เดฑเดฟเดธเตเดดเตโเดธเต เดเตเดทเดพเดฎเดคเตเดคเดฟเดจเตเด เดฌเดพเดเตเดเดชเตเดชเต เดชเดฆเตเดงเดคเดฟเดเตพ เดเดฒเตเดฒเดพเดฏเตเดชเตเดชเตเดดเตเด เดเดฃเตเดเดพเดเตเดเตเด  
4. **เดธเตเดเตเดฏเตเดฐเดฟเดฑเตเดฑเดฟ เดเดฆเตเดฏเด**: เดคเตเดเดเตเดเดคเตเดคเดฟเตฝ เดคเดจเตเดจเต เดธเตเดเตเดฏเตเดฐเดฟเดฑเตเดฑเดฟ เดจเดฟเดฏเดจเตเดคเตเดฐเดฃเดเตเดเตพ เดจเดเดชเตเดชเดฟเดฒเดพเดเตเดเตเด, เดชเดฟเดจเตเดจเตเดเต เดชเดฐเดฟเดเดฃเดฟเดเตเดเดพเดคเต  
5. **เดกเตเดเตเดฏเตเดฎเตเดจเตเดฑเตเดทเตป**: เดเดเดจเตเดฑเต เดถเตเดทเดฟเดเดณเตเด เดชเดฐเดฟเดฎเดฟเดคเดฟเดเดณเตเด เดตเตเดฏเดเตเดคเดฎเดพเดฏเดฟ เดฐเตเดเดชเตเดชเตเดเตเดคเตเดคเตเด  

### เดญเดพเดตเดฟ เดฑเตเดกเตโเดฎเดพเดชเตเดชเตเด เดเดจเตเดฑเดเตเดฐเตเดทเดจเตเด

Microsoft Agent Framework เดฎเตเดเตเดเดชเตเดชเตเดเตเด SLM เดเดชเตเดฑเตเดฑเดฟเดฎเตเดธเตเดทเตป, เดฎเตเดเตเดเดชเตเดชเตเดเตเด เดเดกเตเดเต เดกเดฟเดชเตเดฒเตเดฏเตเดฎเตเดจเตเดฑเต เดเตเดณเตเดเตพ, เดชเดฐเดฟเดฎเดฟเดค เดชเดฐเดฟเดธเตเดฅเดฟเดคเดฟเดเตพเดเตเดเตเดณเตเดณ เดฎเตเดเตเดเดชเตเดชเตเดเตเด เดฑเดฟเดธเตเดดเตโเดธเต เดฎเดพเดจเตเดเตเดฎเตเดจเตเดฑเต, เดธเดพเดงเดพเดฐเดฃ เดเดจเตเดฑเตผเดชเตเดฐเตเดธเต เดธเตเดจเดพเดฐเดฟเดฏเตเดเตพเดเตเดเตเดณเตเดณ เดตเดฟเดชเตเดฒเดฎเดพเดฏ เดเตเตพ เดเดเตเดเตเดธเดฟเดธเตเดฑเตเดฑเด เดเดจเตเดจเดฟเดตเดฏเตเดฎเดพเดฏเดฟ เดคเตเดเตผเดเตเดเดฏเดพเดฏเดฟ เดตเดฟเดเดธเดฟเดเตเดเตเดจเตเดจเต.  

**เดตเดฐเดพเดจเดฟเดฐเดฟเดเตเดเตเดจเตเดจ เดซเตเดเตเดเดฑเตเดเตพ**:  
- **เดเดเดจเตเดฑเต เดเดชเตเดฑเตเดฑเดฟเดฎเตเดธเตเดทเดจเดฟเดจเตเดณเตเดณ AutoML**: เดชเตเดฐเดคเตเดฏเตเด เดเดเดจเตเดฑเต เดเดพเดธเตเดเตเดเตพเดเตเดเดพเดฏเดฟ SLM-เดเดณเตเดเต เดเดเตเดเตเดฎเดพเดฑเตเดฑเดฟเดเต เดซเตเตป-เดเตเดฏเตเดฃเดฟเดเดเต  
- **เดเดกเตเดเต เดฎเตเดทเต เดจเตเดฑเตเดฑเตเดตเตผเดเตเดเดฟเดเดเต**: เดฎเตพเดเตเดเดฟ เดเดกเตเดเต เดเดเดจเตเดฑเต เดกเดฟเดชเตเดฒเตเดฏเตเดฎเตเดจเตเดฑเตเดเตพเดเตเดเดฟเดเดฏเดฟเดฒเต เดเตเตผเดกเดฟเดจเตเดทเตป  
- **เดเดงเตเดจเดฟเด เดเตเดฒเดฟเดฎเตเดเตเดฐเดฟ**: เดเดเดจเตเดฑเต เดชเตเดฐเดเดเดจเดคเตเดคเดฟเดจเตเดณเตเดณ เดฎเตเดเตเดเดชเตเดชเตเดเตเด เดฎเตเดฃเดฟเดฑเตเดฑเดฑเดฟเดเดเต, เดเดจเดฒเดฟเดฑเตเดฑเดฟเดเตเดธเต  
- **เดตเดฟเดทเตเดตเตฝ เดเดเดจเตเดฑเต เดฌเดฟเตฝเดกเตผ**: เดฒเต-เดเตเดกเต/เดจเต-เดเตเดกเต เดเดเดจเตเดฑเต เดกเตเดตเดฒเดชเตเดชเตเดฎเตเดจเตเดฑเต เดเตเดณเตเดเตพ  

## SLM เดเดเดจเตเดฑเต เดจเดเดชเตเดชเดพเดเตเดเดฒเดฟเดจเตเดณเตเดณ เดฎเดฟเดเดเตเด เดชเตเดฐเดพเดเตเดเตเดธเตเดเตพ

### เดเดเดจเตเดฑเตเดเตพเดเตเดเตเดณเตเดณ SLM เดคเดฟเดฐเดเตเดเตเดเตเดชเตเดชเต เดฎเดพเตผเดเตเดเดจเดฟเตผเดฆเตเดฆเตเดถเดเตเดเตพ

เดเดเดจเตเดฑเต เดกเดฟเดชเตเดฒเตเดฏเตเดฎเตเดจเตเดฑเดฟเดจเดพเดฏเดฟ SLMเดเตพ เดคเดฟเดฐเดเตเดเตเดเตเดเตเดเตเดฎเตเดชเตเตพ เดคเดพเดดเตเดชเตเดชเดฑเดฏเตเดจเตเดจ เดเดเดเดเตเดเตพ เดชเดฐเดฟเดเดฃเดฟเดเตเดเตเด:  

**เดฎเตเดกเตฝ เดตเดฒเตเดชเตเดช เดชเดฐเดฟเดเดฃเดจเดเตพ**: เดเดคเตเดฏเดจเตเดคเด เดฎเตเดฌเตเตฝ เดเดเดจเตเดฑเต เดเดชเตเดฒเดฟเดเตเดเตเดทเดจเตเดเตพเดเตเดเดพเดฏเดฟ Q2_K เดชเตเดฒเตเดณเตเดณ เดเตพเดเตเดฐเดพ-เดเดฎเตเดชเตเดฐเดธเตเดธเต เดเตเดฏเตเดค เดฎเตเดกเดฒเตเดเตพ, เดชเตเดคเตเดตเดพเดฏ เดเดเดจเตเดฑเต เดธเตเดจเดพเดฐเดฟเดฏเตเดเตพเดเตเดเดพเดฏเดฟ Q4_K_M เดชเตเดฒเตเดณเตเดณ เดฌเดพเดฒเตปเดธเตเดกเต เดฎเตเดกเดฒเตเดเตพ, เดเตเดฃเดฎเตเดจเตเดฎ เดจเดฟเตผเดฃเดพเดฏเดเดฎเดพเดฏ เดเดเดจเตเดฑเต เดเดชเตเดฒเดฟเดเตเดเตเดทเดจเตเดเตพเดเตเดเดพเดฏเดฟ Q8_0 เดชเตเดฒเตเดณเตเดณ เดเดฏเตผเดจเตเดจ เดเตเดคเตเดฏเดค เดฎเตเดกเดฒเตเดเตพ เดคเดฟเดฐเดเตเดเตเดเตเดเตเดเตเด.  

**เดเดเดจเตเดฑเต เดเดชเดฏเตเด เดเตเดธเต เดชเตเดฐเตเดคเตเดคเด**: เดเดเดจเตเดฑเต เดคเตเดฐเตเดฎเดพเดจเดเตเดเตพเดเตเดเต เดเตเดคเตเดฏเดค เดจเดฟเดฒเดจเดฟเตผเดคเตเดคเตฝ, เดฑเดฟเดฏเตฝ-เดเตเด เดเดเดจเตเดฑเต เดเดเดชเตเดเดฒเตเดเตพเดเตเดเตเดณเตเดณ เดเตปเดซเดฑเตปเดธเต เดตเตเดเด, เดเดกเตเดเต เดเดเดจเตเดฑเต เดกเดฟเดชเตเดฒเตเดฏเตเดฎเตเดจเตเดฑเดฟเดจเตเดณเตเดณ เดฎเตเดฎเตเดฎเดฑเดฟ เดชเดฐเดฟเดฎเดฟเดคเดฟเดเตพ, เดชเตเดฐเตเดตเดธเดฟ-เดซเตเดเดธเตเดกเต เดเดเดจเตเดฑเตเดเตพเดเตเดเตเดณเตเดณ เดเดซเตโเดฒเตเตป เดชเตเดฐเดตเตผเดคเตเดคเดจ เดเดตเดถเตเดฏเดเดคเดเตพ เดเดจเตเดจเดฟเดต เดชเดฐเดฟเดเดฃเดฟเดเตเดเต SLM เดถเตเดทเดฟเดเตพ เดชเตเดฐเตเดคเตเดคเดชเตเดชเตเดเตเดคเตเดคเตเด.  

### SLM เดเดเดจเตเดฑเตเดเตพเดเตเดเตเดณเตเดณ เดเดชเตเดฑเตเดฑเดฟเดฎเตเดธเตเดทเตป เดคเดจเตเดคเตเดฐเด เดคเดฟเดฐเดเตเดเตเดเตเดชเตเดชเต

**เดเดเดจเตเดฑเตเดเตพเดเตเดเตเดณเตเดณ เดเตเดตเดพเดฃเตเดเตเดธเตเดทเตป เดธเดฎเตเดชเดจเด**: เดเดเดจเตเดฑเต เดเตเดฃเดฎเตเดจเตเดฎ เดเดตเดถเตเดฏเดเดคเดเดณเตเด เดนเดพเตผเดกเตโเดตเตเดฏเตผ เดชเดฐเดฟเดฎเดฟเดคเดฟเดเดณเตเด เดเดเดฟเดธเตเดฅเดพเดจเดฎเดพเดเตเดเดฟ เดเดจเตเดฏเตเดเตเดฏเดฎเดพเดฏ เดเตเดตเดพเดฃเตเดเตเดธเตเดทเตป เดจเดฟเดฒเดเตพ เดคเดฟเดฐเดเตเดเตเดเตเดเตเดเตเด. เดฎเตเดฌเตเตฝ เดเดเดจเตเดฑเตเดเตพเดเตเดเดพเดฏเดฟ เดชเดฐเดฎเดพเดตเดงเดฟ เดเดฎเตเดชเตเดฐเดทเตป เดฒเดญเดฟเดเตเดเตเดจเตเดจ Q4_0, เดชเตเดคเตเดตเดพเดฏ เดเดเดจเตเดฑเตเดเตพเดเตเดเดพเดฏเดฟ เดเตเดฃเดฎเตเดจเตเดฎ-เดเดฎเตเดชเตเดฐเดทเตป เดฌเดพเดฒเตปเดธเต เดจเตฝเดเตเดจเตเดจ Q5_1, เดจเดฟเตผเดฃเดพเดฏเด เดเดเดจเตเดฑเต เดเดชเตเดฒเดฟเดเตเดเตเดทเดจเตเดเตพเดเตเดเดพเดฏเดฟ เดเดเดฆเตเดถเด เดฏเดฅเดพเตผเดคเตเดฅ เดเตเดฃเดฎเตเดจเตเดฎเดฏเตเดณเตเดณ Q8_0 เดชเดฐเดฟเดเดฃเดฟเดเตเดเตเด.
Translation for chunk 3 of '01.IntroduceAgent.md' skipped due to timeout.

---

<!-- CO-OP TRANSLATOR DISCLAIMER START -->
**เดเดธเตเดฏเดพเดชเดคเตเดฐเด**:  
เด เดฐเตเด AI เดตเดฟเดตเตผเดคเตเดคเดจ เดธเตเดตเดจเด [Co-op Translator](https://github.com/Azure/co-op-translator) เดเดชเดฏเตเดเดฟเดเตเดเต เดตเดฟเดตเตผเดคเตเดคเดจเด เดเตเดฏเตเดคเดคเดพเดฃเต. เดจเดพเด เดเตเดคเตเดฏเดคเดฏเตเดเตเดเต เดถเตเดฐเดฎเดฟเดเตเดเดฟเดเตเดเตเดฃเตเดเตเดเตเดเดฟเดฒเตเด, เดฏเดจเตเดคเตเดฐเด เดเตเดฏเตเดค เดตเดฟเดตเตผเดคเตเดคเดจเดเตเดเดณเดฟเตฝ เดชเดฟเดถเดเตเดเตพ เดเดฒเตเดฒเตเดเตเดเดฟเตฝ เดคเตเดฑเตเดฑเตเดเตพ เดเดฃเตเดเดพเดเดพเดฎเตเดจเตเดจเต เดฆเดฏเดตเดพเดฏเดฟ เดถเตเดฐเดฆเตเดงเดฟเดเตเดเตเด. เดเดคเดฟเดจเตเดฑเต เดฎเดพเดคเตเดญเดพเดทเดฏเดฟเดฒเตเดณเตเดณ เดฏเดฅเดพเตผเดคเตเดฅ เดฐเตเด เดเดงเดฟเดเดพเดฐเดชเดฐเดฎเดพเดฏ เดเดฑเดตเดฟเดเดฎเดพเดฏเดฟ เดเดฃเดเตเดเดพเดเตเดเดฃเด. เดจเดฟเตผเดฃเดพเดฏเด เดตเดฟเดตเดฐเดเตเดเตพเดเตเดเต, เดชเตเดฐเตเดซเดทเดฃเตฝ เดฎเดจเตเดทเตเดฏ เดตเดฟเดตเตผเดคเตเดคเดจเด เดถเตเดชเดพเตผเดถ เดเตเดฏเตเดฏเดชเตเดชเตเดเตเดจเตเดจเต. เด เดตเดฟเดตเตผเดคเตเดคเดจเด เดเดชเดฏเตเดเดฟเดเตเดเตเดจเตเดจเดคเดฟเตฝ เดจเดฟเดจเตเดจเตเดฃเตเดเดพเดเตเดจเตเดจ เดเดคเตเดเตเดเดฟเดฒเตเด เดคเตเดฑเตเดฑเดฟเดฆเตเดงเดพเดฐเดฃเดเตพเดเตเดเต เดคเตเดฑเตเดฑเดพเดฏ เดตเตเดฏเดพเดเตเดฏเดพเดจเดเตเดเตพเดเตเดเต เดเดเตเดเตพ เดเดคเตเดคเดฐเดตเดพเดฆเดฟเดเดณเดฒเตเดฒ.
<!-- CO-OP TRANSLATOR DISCLAIMER END -->