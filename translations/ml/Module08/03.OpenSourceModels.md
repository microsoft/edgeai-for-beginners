<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "e3d7e45c04a9946ff6f9a3358db9ba74",
  "translation_date": "2025-12-15T22:33:38+00:00",
  "source_file": "Module08/03.OpenSourceModels.md",
  "language_code": "ml"
}
-->
# സെഷൻ 3: ഓപ്പൺ-സോഴ്‌സ് മോഡൽ കണ്ടെത്തലും മാനേജ്മെന്റും

## അവലോകനം

ഈ സെഷൻ ഫൗണ്ട്രി ലോക്കലുമായി പ്രായോഗിക മോഡൽ കണ്ടെത്തലും മാനേജ്മെന്റും കേന്ദ്രീകരിക്കുന്നു. ലഭ്യമായ മോഡലുകൾ എങ്ങനെ ലിസ്റ്റ് ചെയ്യാമെന്ന്, വ്യത്യസ്ത ഓപ്ഷനുകൾ പരീക്ഷിക്കാമെന്ന്, അടിസ്ഥാന പ്രകടന സവിശേഷതകൾ മനസ്സിലാക്കാമെന്ന് നിങ്ങൾ പഠിക്കും. ഫൗണ്ട്രി CLI ഉപയോഗിച്ച് കൈകൊണ്ട് പരീക്ഷണത്തിലൂടെ ശരിയായ മോഡലുകൾ തിരഞ്ഞെടുക്കാൻ സഹായിക്കുന്ന സമീപനമാണ് ഇത്.

## പഠന ലക്ഷ്യങ്ങൾ

- മോഡൽ കണ്ടെത്തലിനും മാനേജ്മെന്റിനും ഫൗണ്ട്രി CLI കമാൻഡുകൾ നിപുണത നേടുക  
- മോഡൽ കാഷെയും ലോക്കൽ സ്റ്റോറേജ് പാറ്റേണുകളും മനസ്സിലാക്കുക  
- വ്യത്യസ്ത മോഡലുകൾ വേഗത്തിൽ പരീക്ഷിച്ച് താരതമ്യം ചെയ്യാൻ പഠിക്കുക  
- മോഡൽ തിരഞ്ഞെടുപ്പിനും ബെഞ്ച്മാർക്കിംഗിനും പ്രായോഗിക പ്രവൃത്തിപദ്ധതികൾ സ്ഥാപിക്കുക  
- ഫൗണ്ട്രി ലോക്കലിലൂടെ ലഭ്യമായ വളരുന്ന മോഡൽ പരിസ്ഥിതിയെ അന്വേഷിക്കുക  

## മുൻകൂട്ടി ആവശ്യങ്ങൾ

- സെഷൻ 1: ഫൗണ്ട്രി ലോക്കലുമായി ആരംഭിക്കൽ പൂർത്തിയാക്കിയിരിക്കണം  
- ഫൗണ്ട്രി ലോക്കൽ CLI ഇൻസ്റ്റാൾ ചെയ്ത് ആക്സസ് ചെയ്യാവുന്നതായിരിക്കണം  
- മോഡൽ ഡൗൺലോഡുകൾക്കായി മതിയായ സ്റ്റോറേജ് സ്ഥലം (1GB മുതൽ 20GB+ വരെ മോഡലുകൾ)  
- മോഡൽ തരംകളും ഉപയോഗ കേസുകളും അടിസ്ഥാനമായി മനസ്സിലാക്കൽ  

## ഭാഗം 6: കൈകൊണ്ട് അഭ്യാസം

### അഭ്യാസം: മോഡൽ കണ്ടെത്തലും താരതമ്യവും

Sample 03 അടിസ്ഥാനമാക്കി നിങ്ങളുടെ സ്വന്തം മോഡൽ മൂല്യനിർണയ സ്ക്രിപ്റ്റ് സൃഷ്ടിക്കുക:

```cmd
REM create_model_test.cmd
@echo off
echo Model Discovery and Testing Script
echo =====================================

echo.
echo Step 1: List available models
foundry model list

echo.
echo Step 2: Check what's cached
foundry cache list

echo.
echo Step 3: Start phi-4-mini for testing
foundry model run phi-4-mini --verbose

echo.
echo Step 4: Test with a simple prompt
curl -X POST http://localhost:8000/v1/chat/completions ^
  -H "Content-Type: application/json" ^
  -d "{\"model\":\"phi-4-mini\",\"messages\":[{\"role\":\"user\",\"content\":\"Hello, please introduce yourself.\"}],\"max_tokens\":100}"

echo.
echo Model test complete!
```

### നിങ്ങളുടെ ജോലി

1. **Sample 03 സ്ക്രിപ്റ്റ് റൺ ചെയ്യുക**: `samples\03\list_and_bench.cmd`  
2. **വ്യത്യസ്ത മോഡലുകൾ പരീക്ഷിക്കുക**: കുറഞ്ഞത് 3 വ്യത്യസ്ത മോഡലുകൾ പരീക്ഷിക്കുക  
3. **പ്രകടനം താരതമ്യം ചെയ്യുക**: വേഗതയും പ്രതികരണ ഗുണനിലവാരവും വ്യത്യാസങ്ങൾ ശ്രദ്ധിക്കുക  
4. **ഫലങ്ങൾ രേഖപ്പെടുത്തുക**: ഒരു ലളിതമായ താരതമ്യ ചാർട്ട് സൃഷ്ടിക്കുക  

### ഉദാഹരണ താരതമ്യ ഫോർമാറ്റ്

```
Model Comparison Results:
========================
phi-4-mini:        Fast (~2s), good for general chat
qwen2.5-7b:       Slower (~5s), better reasoning  
deepseek-r1:      Medium (~3s), excellent for code

Recommendation: Start with phi-4-mini for development, 
switch to qwen2.5-7b for production reasoning tasks.
```

## ഭാഗം 7: പ്രശ്നപരിഹാരവും മികച്ച പ്രാക്ടീസുകളും

### സാധാരണ പ്രശ്നങ്ങളും പരിഹാരങ്ങളും

**മോഡൽ ആരംഭിക്കില്ല:**
```cmd
REM Check service status
foundry service status

REM Restart service if needed
foundry service stop
foundry service start

REM Try with verbose output
foundry model run phi-4-mini --verbose
```

**സ്മൃതി കുറവ്:**
- ചെറിയ മോഡലുകൾ (`phi-4-mini`) ഉപയോഗിച്ച് ആരംഭിക്കുക  
- മറ്റ് ആപ്ലിക്കേഷനുകൾ അടയ്ക്കുക  
- പരിധി തൊട്ടുപോകുമ്പോൾ RAM അപ്ഗ്രേഡ് ചെയ്യുക  

**മന്ദഗതിയിലുള്ള പ്രകടനം:**
- മോഡൽ പൂർണ്ണമായി ലോഡ് ചെയ്തിട്ടുണ്ടെന്ന് ഉറപ്പാക്കുക (വെർബോസ് ഔട്ട്പുട്ട് പരിശോധിക്കുക)  
- അനാവശ്യ ബാക്ക്ഗ്രൗണ്ട് ആപ്ലിക്കേഷനുകൾ അടയ്ക്കുക  
- വേഗതയുള്ള സ്റ്റോറേജ് (SSD) പരിഗണിക്കുക  

### മികച്ച പ്രാക്ടീസുകൾ

1. **ചെറിയതിൽ നിന്ന് ആരംഭിക്കുക**: സജ്ജീകരണം സ്ഥിരീകരിക്കാൻ `phi-4-mini` ഉപയോഗിക്കുക  
2. **ഒരേസമയം ഒരു മോഡൽ മാത്രം**: പുതിയ മോഡൽ തുടങ്ങുന്നതിന് മുമ്പ് പഴയ മോഡലുകൾ നിർത്തുക  
3. **സ്രോതസ്സ് നിരീക്ഷണം**: സ്മൃതി ഉപയോഗം ശ്രദ്ധിക്കുക  
4. **സ്ഥിരമായി പരീക്ഷിക്കുക**: നീതിപൂർവ്വം താരതമ്യത്തിന് ഒരേ പ്രോംപ്റ്റുകൾ ഉപയോഗിക്കുക  
5. **ഫലങ്ങൾ രേഖപ്പെടുത്തുക**: നിങ്ങളുടെ ഉപയോഗകേസുകൾക്കായി മോഡൽ പ്രകടനം കുറിപ്പിടുക  

## ഭാഗം 8: അടുത്ത ഘട്ടങ്ങളും റഫറൻസുകളും

### സെഷൻ 4-ന് തയ്യാറെടുക്കൽ

- **സെഷൻ 4 ഫോകസ്**: ഒപ്റ്റിമൈസേഷൻ ടൂളുകളും സാങ്കേതിക വിദ്യകളും  
- **മുൻകൂട്ടി ആവശ്യങ്ങൾ**: മോഡൽ സ്വിച്ച് ചെയ്യലിലും അടിസ്ഥാന പ്രകടന പരിശോധനയിലും പരിചയം  
- **ശുപാർശ**: ഈ സെഷനിൽ നിന്നുള്ള 2-3 പ്രിയപ്പെട്ട മോഡലുകൾ തിരിച്ചറിയുക  

### അധിക സ്രോതസ്സ്

- **[Foundry Local ഡോക്യുമെന്റേഷൻ](https://learn.microsoft.com/azure/ai-foundry/foundry-local/)**: ഔദ്യോഗിക ഡോക്യുമെന്റേഷൻ  
- **[CLI റഫറൻസ്](https://learn.microsoft.com/azure/ai-foundry/foundry-local/reference/reference-cli)**: സമ്പൂർണ്ണ കമാൻഡ് റഫറൻസ്  
- **[Model Mondays](https://aka.ms/model-mondays)**: ആഴ്ചവാര മോഡൽ സ്പോട്ട്ലൈറ്റുകൾ  
- **[Foundry Local GitHub](https://github.com/microsoft/Foundry-Local)**: കമ്മ്യൂണിറ്റി, പ്രശ്നങ്ങൾ  
- **[Sample 03: Model Discovery](samples/03/README.md)**: കൈകൊണ്ട് ഉദാഹരണ സ്ക്രിപ്റ്റ്  

### പ്രധാനപ്പെട്ട കാര്യങ്ങൾ

✅ **മോഡൽ കണ്ടെത്തൽ**: ലഭ്യമായ മോഡലുകൾ പരിശോധിക്കാൻ `foundry model list` ഉപയോഗിക്കുക  
✅ **വേഗത്തിലുള്ള പരിശോധന**: വേഗത്തിലുള്ള മൂല്യനിർണയത്തിന് `list_and_bench.cmd` പാറ്റേൺ  
✅ **പ്രകടനം നിരീക്ഷണം**: അടിസ്ഥാന സ്രോതസ്സ് ഉപയോഗവും പ്രതികരണ സമയവും  
✅ **മോഡൽ തിരഞ്ഞെടുപ്പ്**: ഉപയോഗകേസുകൾ അനുസരിച്ച് മോഡലുകൾ തിരഞ്ഞെടുക്കാനുള്ള പ്രായോഗിക മാർഗ്ഗനിർദ്ദേശങ്ങൾ  
✅ **കാഷെ മാനേജ്മെന്റ്**: സ്റ്റോറേജ്, ക്ലീൻഅപ്പ് നടപടിക്രമങ്ങൾ മനസ്സിലാക്കുക  

ഇപ്പോൾ നിങ്ങൾക്ക് ഫൗണ്ട്രി ലോക്കലിന്റെ ലളിതമായ CLI സമീപനം ഉപയോഗിച്ച് നിങ്ങളുടെ AI ആപ്ലിക്കേഷനുകൾക്കായി അനുയോജ്യമായ മോഡലുകൾ കണ്ടെത്താനും പരീക്ഷിക്കാനും തിരഞ്ഞെടുക്കാനും പ്രായോഗിക കഴിവുകൾ ലഭിച്ചിട്ടുണ്ട്.  
: കമ്മ്യൂണിറ്റി മോഡലുകൾ തിരഞ്ഞെടുക്കൽ, Hugging Face ഉള്ളടക്കം സംയോജിപ്പിക്കൽ, “നിങ്ങളുടെ സ്വന്തം മോഡൽ കൊണ്ടുവരുക” (BYOM) തന്ത്രങ്ങൾ സ്വീകരിക്കൽ എന്നിവയും ഉൾപ്പെടുന്നു. തുടർച്ചയായ പഠനത്തിനും മോഡൽ കണ്ടെത്തലിനും Model Mondays സീരീസ് നിങ്ങൾക്ക് കണ്ടെത്താം.

റഫറൻസുകൾ:  
- Foundry Local ഡോക്സ്: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/  
- Hugging Face മോഡലുകൾ സംയോജിപ്പിക്കൽ: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/how-to/how-to-compile-hugging-face-models  
- Model Mondays: https://aka.ms/model-mondays  
- Foundry Local GitHub: https://github.com/microsoft/Foundry-Local  

## പഠന ലക്ഷ്യങ്ങൾ  
- ലോക്കൽ ഇൻഫറൻസിനായി ഓപ്പൺ-സോഴ്‌സ് മോഡലുകൾ കണ്ടെത്തുകയും മൂല്യനിർണയവും ചെയ്യുക  
- ഫൗണ്ട്രി ലോക്കലിൽ Hugging Face മോഡലുകൾ സംയോജിപ്പിച്ച് പ്രവർത്തിപ്പിക്കുക  
- കൃത്യത, ലാറ്റൻസി, സ്രോതസ്സ് ആവശ്യകതകൾക്കായി മോഡൽ തിരഞ്ഞെടുപ്പ് തന്ത്രങ്ങൾ പ്രയോഗിക്കുക  
- കാഷെയും വേർഷനിങ്ങും ഉപയോഗിച്ച് മോഡലുകൾ ലോക്കലായി മാനേജുചെയ്യുക  

## ഭാഗം 1: ഫൗണ്ട്രി CLI ഉപയോഗിച്ച് മോഡൽ കണ്ടെത്തൽ

### അടിസ്ഥാന മോഡൽ മാനേജ്മെന്റ് കമാൻഡുകൾ

ഫൗണ്ട്രി CLI മോഡൽ കണ്ടെത്തലിനും മാനേജ്മെന്റിനും ലളിതമായ കമാൻഡുകൾ നൽകുന്നു:

```cmd
REM List all available models in the catalog
foundry model list

REM List cached (downloaded) models
foundry cache list

REM Check cache directory location
foundry cache ls
```

### നിങ്ങളുടെ ആദ്യ മോഡലുകൾ പ്രവർത്തിപ്പിക്കൽ

പ്രകടന സവിശേഷതകൾ മനസ്സിലാക്കാൻ ജനപ്രിയവും നന്നായി പരീക്ഷിച്ച മോഡലുകൾ ഉപയോഗിച്ച് ആരംഭിക്കുക:

```cmd
REM Run Phi-4-Mini (lightweight, fast)
foundry model run phi-4-mini --verbose

REM Run Qwen 2.5 7B (larger, more capable)
foundry model run qwen2.5-7b --verbose

REM Run DeepSeek (specialized for coding)
foundry model run deepseek-r1-7b --verbose
```

**കുറിപ്പ്:** `--verbose` ഫ്ലാഗ് വിശദമായ സ്റ്റാർട്ടപ്പ് വിവരങ്ങൾ നൽകുന്നു, അതിൽ ഉൾപ്പെടുന്നു:  
- മോഡൽ ഡൗൺലോഡ് പുരോഗതി (ആദ്യ റൺ-ൽ)  
- സ്മൃതി വിനിയോഗ വിശദാംശങ്ങൾ  
- സർവീസ് ബൈൻഡിംഗ് വിവരങ്ങൾ  
- പ്രകടന ആരംഭം മെട്രിക്‌സ്  

### മോഡൽ വിഭാഗങ്ങൾ മനസ്സിലാക്കൽ

**ചെറിയ ഭാഷാ മോഡലുകൾ (SLMs):**  
- `phi-4-mini`: വേഗതയുള്ള, കാര്യക്ഷമം, പൊതുവായ ചാറ്റിനായി മികച്ചത്  
- `phi-4`: മെച്ചപ്പെട്ട കാരണവത്കരണ ശേഷിയുള്ള കൂടുതൽ ശേഷിയുള്ള പതിപ്പ്  

**മധ്യസ്ഥ മോഡലുകൾ:**  
- `qwen2.5-7b`: മികച്ച കാരണവത്കരണം, നീണ്ട കോൺടെക്സ്റ്റ്  
- `deepseek-r1-7b`: കോഡ് ജനറേഷനായി ഒപ്റ്റിമൈസ്ഡ്  

**വലിയ മോഡലുകൾ:**  
- `llama-3.2`: മെറ്റയുടെ ഏറ്റവും പുതിയ ഓപ്പൺ-സോഴ്‌സ് മോഡൽ  
- `qwen2.5-14b`: എന്റർപ്രൈസ്-ഗ്രേഡ് കാരണവത്കരണം  

## ഭാഗം 2: വേഗത്തിലുള്ള മോഡൽ പരിശോധനയും താരതമ്യവും

### Sample 03 സമീപനം: ലളിതമായ ലിസ്റ്റും ബെഞ്ചും

Sample 03 പാറ്റേൺ അടിസ്ഥാനമാക്കി, ഇതാ കുറഞ്ഞപക്ഷം പ്രവൃത്തിപദ്ധതി:

```cmd
@echo off
REM Sample 03 - List and bench pattern
echo Listing available models...
foundry model list

echo.
echo Checking cached models...
foundry cache list

echo.
echo Starting phi-4-mini with verbose output...
foundry model run phi-4-mini --verbose
```

### മോഡൽ പ്രകടനം പരീക്ഷിക്കൽ

ഒരു മോഡൽ പ്രവർത്തനക്ഷമമായാൽ, സ്ഥിരതയുള്ള പ്രോംപ്റ്റുകൾ ഉപയോഗിച്ച് പരീക്ഷിക്കുക:

```cmd
REM Test via curl (Windows Command Prompt)
curl -X POST http://localhost:8000/v1/chat/completions ^
  -H "Content-Type: application/json" ^
  -d "{\"model\":\"phi-4-mini\",\"messages\":[{\"role\":\"user\",\"content\":\"Explain edge AI in one sentence.\"}],\"max_tokens\":50}"
```

### പവർഷെൽ പരീക്ഷണ ഓപ്ഷൻ

```powershell
# ടെസ്റ്റിംഗിനുള്ള പവർഷെൽ സമീപനം
$body = @{
    model = "phi-4-mini"
    messages = @(
        @{
            role = "user"
            content = "Explain edge AI in one sentence."
        }
    )
    max_tokens = 50
} | ConvertTo-Json -Depth 3

Invoke-RestMethod -Uri "http://localhost:8000/v1/chat/completions" -Method Post -Body $body -ContentType "application/json"
```

## ഭാഗം 3: മോഡൽ കാഷെയും സ്റ്റോറേജ് മാനേജ്മെന്റും

### മോഡൽ കാഷെ മനസ്സിലാക്കൽ

ഫൗണ്ട്രി ലോക്കൽ മോഡൽ ഡൗൺലോഡുകളും കാഷെ മാനേജ്മെന്റും സ്വയം കൈകാര്യം ചെയ്യുന്നു:

```cmd
REM Check cache directory and contents
foundry cache ls

REM View cache location
foundry cache cd

REM Clean up unused models (if needed)
foundry cache clean
```

### മോഡൽ സ്റ്റോറേജ് പരിഗണനകൾ

**സാധാരണ മോഡൽ വലിപ്പങ്ങൾ:**  
- `phi-4-mini`: ~2.5 GB  
- `qwen2.5-7b`: ~4.1 GB  
- `deepseek-r1-7b`: ~4.3 GB  
- `llama-3.2`: ~4.9 GB  
- `qwen2.5-14b`: ~8.2 GB  

**സ്റ്റോറേജ് മികച്ച പ്രാക്ടീസുകൾ:**  
- വേഗത്തിലുള്ള സ്വിച്ച് ചെയ്യലിനായി 2-3 മോഡലുകൾ കാഷെയിൽ സൂക്ഷിക്കുക  
- ഉപയോഗിക്കാത്ത മോഡലുകൾ നീക്കംചെയ്യാൻ: `foundry cache clean`  
- ചെറിയ SSD-കളിൽ ഡിസ്ക് ഉപയോഗം നിരീക്ഷിക്കുക  
- മോഡൽ വലിപ്പവും ശേഷിയും തമ്മിലുള്ള തുല്യവിലയിരുത്തൽ പരിഗണിക്കുക  

### മോഡൽ പ്രകടനം നിരീക്ഷണം

മോഡലുകൾ പ്രവർത്തിക്കുന്നപ്പോൾ സിസ്റ്റം സ്രോതസ്സ് നിരീക്ഷിക്കുക:

**Windows ടാസ്‌ക് മാനേജർ:**  
- സ്മൃതി ഉപയോഗം ശ്രദ്ധിക്കുക (മോഡലുകൾ RAM-ൽ ലോഡ് ചെയ്തിരിക്കും)  
- ഇൻഫറൻസിനിടെ CPU ഉപയോഗം നിരീക്ഷിക്കുക  
- ആദ്യ മോഡൽ ലോഡിംഗിനിടെ ഡിസ്ക് I/O പരിശോധിക്കുക  

**കമാൻഡ് ലൈൻ നിരീക്ഷണം:**  
```cmd
REM Check memory usage (PowerShell)
Get-Process | Where-Object {$_.ProcessName -like "*foundry*"} | Select-Object ProcessName, WorkingSet64

REM Monitor running models
foundry service ps
```

## ഭാഗം 4: പ്രായോഗിക മോഡൽ തിരഞ്ഞെടുപ്പ് മാർഗ്ഗനിർദ്ദേശങ്ങൾ

### ഉപയോഗകേസുകൾ അനുസരിച്ച് മോഡലുകൾ തിരഞ്ഞെടുക്കൽ

**പൊതുവായ ചാറ്റിനും Q&A-ക്കും:**  
- ആരംഭിക്കുക: `phi-4-mini` (വേഗം, കാര്യക്ഷമം)  
- അപ്ഗ്രേഡ് ചെയ്യുക: `phi-4` (മികച്ച കാരണവത്കരണം)  
- പുരോഗമനം: `qwen2.5-7b` (നീണ്ട കോൺടെക്സ്റ്റ്)  

**കോഡ് ജനറേഷനായി:**  
- ശുപാർശ: `deepseek-r1-7b`  
- ബദൽ: `qwen2.5-7b` (കോഡിനും നല്ലത്)  

**സങ്കീർണ്ണ കാരണവത്കരണത്തിന്:**  
- മികച്ചത്: `qwen2.5-7b` അല്ലെങ്കിൽ `qwen2.5-14b`  
- ബജറ്റ് ഓപ്ഷൻ: `phi-4`  

### ഹാർഡ്‌വെയർ ആവശ്യകതകൾ ഗൈഡ്

**കുറഞ്ഞ സിസ്റ്റം ആവശ്യകതകൾ:**  
```
phi-4-mini:     8GB RAM,  entry-level CPU
phi-4:         12GB RAM,  mid-range CPU
qwen2.5-7b:    16GB RAM,  mid-range CPU
deepseek-r1:   16GB RAM,  mid-range CPU
qwen2.5-14b:   24GB RAM,  high-end CPU
```

**മികച്ച പ്രകടനത്തിനായി ശുപാർശ:**  
- 32GB+ RAM, മൾട്ടി-മോഡൽ സ്വിച്ച് ചെയ്യാൻ സൗകര്യം  
- വേഗതയുള്ള മോഡൽ ലോഡിംഗിനായി SSD സ്റ്റോറേജ്  
- നല്ല സിംഗിൾ-ത്രീഡ് പ്രകടനമുള്ള ആധുനിക CPU  
- വേഗതക്കായി NPU പിന്തുണ (Windows 11 Copilot+ PCs)  

### മോഡൽ സ്വിച്ച് ചെയ്യൽ പ്രവൃത്തിപദ്ധതി

```cmd
REM Stop current model (if needed)
foundry service stop

REM Start different model
foundry model run qwen2.5-7b

REM Verify model is running
foundry service status
```

## ഭാഗം 5: ലളിതമായ മോഡൽ ബെഞ്ച്മാർക്കിംഗ്

### അടിസ്ഥാന പ്രകടന പരിശോധന

മോഡൽ പ്രകടനം താരതമ്യം ചെയ്യാൻ ലളിതമായ സമീപനം:

```python
# simple_bench.py - സാമ്പിൾ 03 പാറ്റേണുകൾ അടിസ്ഥാനമാക്കി
import time
import requests
import json

def test_model_response(model_name, prompt="Explain edge AI in one sentence."):
    """Test a single model with a prompt and measure response time."""
    start_time = time.time()
    
    try:
        response = requests.post(
            "http://localhost:8000/v1/chat/completions",
            headers={"Content-Type": "application/json"},
            json={
                "model": model_name,
                "messages": [{"role": "user", "content": prompt}],
                "max_tokens": 64
            },
            timeout=30
        )
        
        elapsed = time.time() - start_time
        
        if response.status_code == 200:
            result = response.json()
            return {
                "model": model_name,
                "latency_sec": round(elapsed, 3),
                "response": result["choices"][0]["message"]["content"],
                "status": "success"
            }
        else:
            return {
                "model": model_name,
                "status": "error",
                "error": f"HTTP {response.status_code}"
            }
            
    except Exception as e:
        return {
            "model": model_name,
            "status": "error", 
            "error": str(e)
        }

# നിലവിൽ പ്രവർത്തിക്കുന്ന മോഡൽ പരിശോധിക്കുക
if __name__ == "__main__":
    # വ്യത്യസ്ത മോഡലുകളുമായി പരീക്ഷിക്കുക (ഓരോ മോഡലും ആദ്യം ആരംഭിക്കുക)
    test_models = ["phi-4-mini", "qwen2.5-7b", "deepseek-r1-7b"]
    
    print("Model Performance Test")
    print("=" * 50)
    
    for model in test_models:
        print(f"\nTesting {model}...")
        print("Note: Make sure this model is running first with 'foundry model run {model}'")
        
        result = test_model_response(model)
        
        if result["status"] == "success":
            print(f"✅ {model}: {result['latency_sec']}s")
            print(f"   Response: {result['response'][:100]}...")
        else:
            print(f"❌ {model}: {result['error']}")
```

### മാനുവൽ ഗുണനിലവാര വിലയിരുത്തൽ

ഓരോ മോഡലിനും സ്ഥിരതയുള്ള പ്രോംപ്റ്റുകൾ ഉപയോഗിച്ച് പരീക്ഷിച്ച് മാനുവലായി വിലയിരുത്തുക:

**പരീക്ഷണ പ്രോംപ്റ്റുകൾ:**  
1. "ക്വാണ്ടം കമ്പ്യൂട്ടിംഗ് ലളിതമായി വിശദീകരിക്കുക."  
2. "ഒരു ലിസ്റ്റ് സോർട്ട് ചെയ്യാൻ പൈതൺ ഫംഗ്ഷൻ എഴുതുക."  
3. "റിമോട്ട് ജോലിയുടെ ഗുണങ്ങളും ദോഷങ്ങളും എന്തെല്ലാം?"  
4. "എഡ്ജ് AI-യുടെ പ്രയോജനങ്ങൾ സംഗ്രഹിക്കുക."  

**വിലയിരുത്തൽ മാനദണ്ഡങ്ങൾ:**  
- **കൃത്യത**: വിവരങ്ങൾ ശരിയാണോ?  
- **വ്യക്തത**: വിശദീകരണം എളുപ്പത്തിൽ മനസ്സിലാകുന്നുണ്ടോ?  
- **പൂർണ്ണത**: മുഴുവൻ ചോദ്യവും മറുപടി നൽകുന്നുണ്ടോ?  
- **വേഗം**: എത്ര വേഗം പ്രതികരിക്കുന്നു?  

### സ്രോതസ്സ് ഉപയോഗ നിരീക്ഷണം

```cmd
REM Monitor while testing different models
REM Start model
foundry model run phi-4-mini

REM In another terminal, monitor resources
foundry service status
foundry service ps

REM Check system resources (PowerShell)
Get-Process | Where-Object ProcessName -Like "*foundry*" | Format-Table ProcessName, WorkingSet64, CPU
```

## ഭാഗം 6: അടുത്ത ഘട്ടങ്ങൾ  
- പുതിയ മോഡലുകൾക്കും ടിപ്പുകൾക്കും Model Mondays സബ്സ്ക്രൈബ് ചെയ്യുക: https://aka.ms/model-mondays  
- നിങ്ങളുടെ ടീമിന്റെ `models.json`-ലേക്ക് കണ്ടെത്തലുകൾ സംഭാവന ചെയ്യുക  
- സെഷൻ 4-ന് തയ്യാറെടുക്കുക: LLMs vs SLMs, ലോക്കൽ vs ക്ലൗഡ് ഇൻഫറൻസ്, കൈകൊണ്ട് ഡെമോകൾ താരതമ്യം ചെയ്യൽ

---

<!-- CO-OP TRANSLATOR DISCLAIMER START -->
**അസൂയാ**:  
ഈ രേഖ AI വിവർത്തന സേവനം [Co-op Translator](https://github.com/Azure/co-op-translator) ഉപയോഗിച്ച് വിവർത്തനം ചെയ്തതാണ്. നാം കൃത്യതയ്ക്ക് ശ്രമിച്ചിട്ടുണ്ടെങ്കിലും, സ്വയം പ്രവർത്തിക്കുന്ന വിവർത്തനങ്ങളിൽ പിശകുകൾ അല്ലെങ്കിൽ തെറ്റുകൾ ഉണ്ടാകാമെന്ന് ദയവായി ശ്രദ്ധിക്കുക. അതിന്റെ മാതൃഭാഷയിലുള്ള യഥാർത്ഥ രേഖ അധികാരപരമായ ഉറവിടമായി കണക്കാക്കപ്പെടണം. നിർണായക വിവരങ്ങൾക്ക്, പ്രൊഫഷണൽ മനുഷ്യ വിവർത്തനം ശുപാർശ ചെയ്യപ്പെടുന്നു. ഈ വിവർത്തനത്തിന്റെ ഉപയോഗത്തിൽ നിന്നുണ്ടാകുന്ന ഏതെങ്കിലും തെറ്റിദ്ധാരണകൾക്കോ തെറ്റായ വ്യാഖ്യാനങ്ങൾക്കോ ഞങ്ങൾ ഉത്തരവാദികളല്ല.
<!-- CO-OP TRANSLATOR DISCLAIMER END -->