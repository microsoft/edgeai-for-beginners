<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "44bc28c27b993c5fb988791b7a115705",
  "translation_date": "2025-10-30T10:57:27+00:00",
  "source_file": "Module06/01.IntroduceAgent.md",
  "language_code": "fa"
}
-->
# Ø¹ÙˆØ§Ù…Ù„ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ Ùˆ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ø²Ø¨Ø§Ù† Ú©ÙˆÚ†Ú©: Ø±Ø§Ù‡Ù†Ù…Ø§ÛŒ Ø¬Ø§Ù…Ø¹

## Ù…Ù‚Ø¯Ù…Ù‡

Ø¯Ø± Ø§ÛŒÙ† Ø¢Ù…ÙˆØ²Ø´ØŒ Ø¹ÙˆØ§Ù…Ù„ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ Ùˆ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ø²Ø¨Ø§Ù† Ú©ÙˆÚ†Ú© (SLMs) Ùˆ Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒâ€ŒÙ‡Ø§ÛŒ Ù¾ÛŒØ´Ø±ÙØªÙ‡ Ù¾ÛŒØ§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø¢Ù†â€ŒÙ‡Ø§ Ø¨Ø±Ø§ÛŒ Ù…Ø­ÛŒØ·â€ŒÙ‡Ø§ÛŒ Ù…Ø­Ø§Ø³Ø¨Ø§ØªÛŒ Ù„Ø¨Ù‡ Ø±Ø§ Ø¨Ø±Ø±Ø³ÛŒ Ø®ÙˆØ§Ù‡ÛŒÙ… Ú©Ø±Ø¯. Ù…ÙØ§Ù‡ÛŒÙ… Ø¨Ù†ÛŒØ§Ø¯ÛŒ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ Ø¹Ø§Ù…Ù„â€ŒÙ…Ø­ÙˆØ±ØŒ ØªÚ©Ù†ÛŒÚ©â€ŒÙ‡Ø§ÛŒ Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ SLMØŒ Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒâ€ŒÙ‡Ø§ÛŒ Ø¹Ù…Ù„ÛŒ Ø¨Ø±Ø§ÛŒ Ø§Ø³ØªÙ‚Ø±Ø§Ø± Ø¯Ø± Ø¯Ø³ØªÚ¯Ø§Ù‡â€ŒÙ‡Ø§ÛŒ Ù…Ø­Ø¯ÙˆØ¯ Ù…Ù†Ø§Ø¨Ø¹ Ùˆ Ú†Ø§Ø±Ú†ÙˆØ¨ Ø¹Ø§Ù…Ù„ Ù…Ø§ÛŒÚ©Ø±ÙˆØ³Ø§ÙØª Ø¨Ø±Ø§ÛŒ Ø³Ø§Ø®Øª Ø³ÛŒØ³ØªÙ…â€ŒÙ‡Ø§ÛŒ Ø¹Ø§Ù…Ù„ Ø¢Ù…Ø§Ø¯Ù‡ ØªÙˆÙ„ÛŒØ¯ Ø±Ø§ Ù¾ÙˆØ´Ø´ Ø®ÙˆØ§Ù‡ÛŒÙ… Ø¯Ø§Ø¯.

Ú†Ø´Ù…â€ŒØ§Ù†Ø¯Ø§Ø² Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ Ø¯Ø± Ø³Ø§Ù„ Û²Û°Û²Ûµ Ø¯Ú†Ø§Ø± ÛŒÚ© ØªØºÛŒÛŒØ± Ù¾Ø§Ø±Ø§Ø¯Ø§ÛŒÙ… Ø´Ø¯Ù‡ Ø§Ø³Øª. Ø¯Ø± Ø­Ø§Ù„ÛŒ Ú©Ù‡ Ø³Ø§Ù„ Û²Û°Û²Û³ Ø³Ø§Ù„ Ú†Øªâ€ŒØ¨Ø§Øªâ€ŒÙ‡Ø§ Ùˆ Ø³Ø§Ù„ Û²Û°Û²Û´ Ø´Ø§Ù‡Ø¯ Ø±ÙˆÙ†Ù‚ Ú©ÙˆÙ¾Ø§ÛŒÙ„ÙˆØªâ€ŒÙ‡Ø§ Ø¨ÙˆØ¯ØŒ Ø³Ø§Ù„ Û²Û°Û²Ûµ Ù…ØªØ¹Ù„Ù‚ Ø¨Ù‡ Ø¹ÙˆØ§Ù…Ù„ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ Ø§Ø³Øª â€” Ø³ÛŒØ³ØªÙ…â€ŒÙ‡Ø§ÛŒ Ù‡ÙˆØ´Ù…Ù†Ø¯ÛŒ Ú©Ù‡ ÙÚ©Ø± Ù…ÛŒâ€ŒÚ©Ù†Ù†Ø¯ØŒ Ø§Ø³ØªØ¯Ù„Ø§Ù„ Ù…ÛŒâ€ŒÚ©Ù†Ù†Ø¯ØŒ Ø¨Ø±Ù†Ø§Ù…Ù‡â€ŒØ±ÛŒØ²ÛŒ Ù…ÛŒâ€ŒÚ©Ù†Ù†Ø¯ØŒ Ø§Ø² Ø§Ø¨Ø²Ø§Ø±Ù‡Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒÚ©Ù†Ù†Ø¯ Ùˆ ÙˆØ¸Ø§ÛŒÙ Ø±Ø§ Ø¨Ø§ Ú©Ù…ØªØ±ÛŒÙ† ÙˆØ±ÙˆØ¯ÛŒ Ø§Ù†Ø³Ø§Ù†ÛŒ Ø§Ø¬Ø±Ø§ Ù…ÛŒâ€ŒÚ©Ù†Ù†Ø¯ØŒ Ú©Ù‡ Ø¨Ù‡ Ø·ÙˆØ± ÙØ²Ø§ÛŒÙ†Ø¯Ù‡â€ŒØ§ÛŒ ØªÙˆØ³Ø· Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ø²Ø¨Ø§Ù† Ú©ÙˆÚ†Ú© Ú©Ø§Ø±Ø¢Ù…Ø¯ Ù‚Ø¯Ø±Øª Ù…ÛŒâ€ŒÚ¯ÛŒØ±Ù†Ø¯. Ú†Ø§Ø±Ú†ÙˆØ¨ Ø¹Ø§Ù…Ù„ Ù…Ø§ÛŒÚ©Ø±ÙˆØ³Ø§ÙØª Ø¨Ù‡ Ø¹Ù†ÙˆØ§Ù† ÛŒÚ© Ø±Ø§Ù‡â€ŒØ­Ù„ Ù¾ÛŒØ´Ø±Ùˆ Ø¨Ø±Ø§ÛŒ Ø³Ø§Ø®Øª Ø§ÛŒÙ† Ø³ÛŒØ³ØªÙ…â€ŒÙ‡Ø§ÛŒ Ù‡ÙˆØ´Ù…Ù†Ø¯ Ø¨Ø§ Ù‚Ø§Ø¨Ù„ÛŒØªâ€ŒÙ‡Ø§ÛŒ Ù…Ø¨ØªÙ†ÛŒ Ø¨Ø± Ù„Ø¨Ù‡ Ø¢ÙÙ„Ø§ÛŒÙ† Ø¸Ø§Ù‡Ø± Ø´Ø¯Ù‡ Ø§Ø³Øª.

## Ø§Ù‡Ø¯Ø§Ù Ø¢Ù…ÙˆØ²Ø´ÛŒ

Ø¯Ø± Ù¾Ø§ÛŒØ§Ù† Ø§ÛŒÙ† Ø¢Ù…ÙˆØ²Ø´ØŒ Ø´Ù…Ø§ Ù‚Ø§Ø¯Ø± Ø®ÙˆØ§Ù‡ÛŒØ¯ Ø¨ÙˆØ¯:

- ðŸ¤– Ù…ÙØ§Ù‡ÛŒÙ… Ø¨Ù†ÛŒØ§Ø¯ÛŒ Ø¹ÙˆØ§Ù…Ù„ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ Ùˆ Ø³ÛŒØ³ØªÙ…â€ŒÙ‡Ø§ÛŒ Ø¹Ø§Ù…Ù„â€ŒÙ…Ø­ÙˆØ± Ø±Ø§ Ø¯Ø±Ú© Ú©Ù†ÛŒØ¯
- ðŸ”¬ Ù…Ø²Ø§ÛŒØ§ÛŒ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ø²Ø¨Ø§Ù† Ú©ÙˆÚ†Ú© Ù†Ø³Ø¨Øª Ø¨Ù‡ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ø²Ø¨Ø§Ù† Ø¨Ø²Ø±Ú¯ Ø¯Ø± Ú©Ø§Ø±Ø¨Ø±Ø¯Ù‡Ø§ÛŒ Ø¹Ø§Ù…Ù„â€ŒÙ…Ø­ÙˆØ± Ø±Ø§ Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ú©Ù†ÛŒØ¯
- ðŸš€ Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒâ€ŒÙ‡Ø§ÛŒ Ù¾ÛŒØ´Ø±ÙØªÙ‡ Ø§Ø³ØªÙ‚Ø±Ø§Ø± SLM Ø¨Ø±Ø§ÛŒ Ù…Ø­ÛŒØ·â€ŒÙ‡Ø§ÛŒ Ù…Ø­Ø§Ø³Ø¨Ø§ØªÛŒ Ù„Ø¨Ù‡ Ø±Ø§ ÛŒØ§Ø¯ Ø¨Ú¯ÛŒØ±ÛŒØ¯
- ðŸ“± Ø¹ÙˆØ§Ù…Ù„ Ø¹Ù…Ù„ÛŒ Ù…Ø¨ØªÙ†ÛŒ Ø¨Ø± SLM Ø±Ø§ Ø¨Ø±Ø§ÛŒ Ú©Ø§Ø±Ø¨Ø±Ø¯Ù‡Ø§ÛŒ Ø¯Ù†ÛŒØ§ÛŒ ÙˆØ§Ù‚Ø¹ÛŒ Ù¾ÛŒØ§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ú©Ù†ÛŒØ¯
- ðŸ—ï¸ Ø¹ÙˆØ§Ù…Ù„ Ø¢Ù…Ø§Ø¯Ù‡ ØªÙˆÙ„ÛŒØ¯ Ø±Ø§ Ø¨Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ú†Ø§Ø±Ú†ÙˆØ¨ Ø¹Ø§Ù…Ù„ Ù…Ø§ÛŒÚ©Ø±ÙˆØ³Ø§ÙØª Ø¨Ø³Ø§Ø²ÛŒØ¯
- ðŸŒ Ø¹ÙˆØ§Ù…Ù„ Ù…Ø¨ØªÙ†ÛŒ Ø¨Ø± Ù„Ø¨Ù‡ Ø¢ÙÙ„Ø§ÛŒÙ† Ø±Ø§ Ø¨Ø§ Ø§Ø¯ØºØ§Ù… LLM Ùˆ SLM Ù…Ø­Ù„ÛŒ Ù…Ø³ØªÙ‚Ø± Ú©Ù†ÛŒØ¯
- ðŸ”§ Ú†Ø§Ø±Ú†ÙˆØ¨ Ø¹Ø§Ù…Ù„ Ù…Ø§ÛŒÚ©Ø±ÙˆØ³Ø§ÙØª Ø±Ø§ Ø¨Ø§ Foundry Local Ø¨Ø±Ø§ÛŒ Ø§Ø³ØªÙ‚Ø±Ø§Ø± Ù„Ø¨Ù‡ Ø§Ø¯ØºØ§Ù… Ú©Ù†ÛŒØ¯

## Ø¯Ø±Ú© Ø¹ÙˆØ§Ù…Ù„ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ: Ù…Ø¨Ø§Ù†ÛŒ Ùˆ Ø·Ø¨Ù‚Ù‡â€ŒØ¨Ù†Ø¯ÛŒâ€ŒÙ‡Ø§

### ØªØ¹Ø±ÛŒÙ Ùˆ Ù…ÙØ§Ù‡ÛŒÙ… Ø§ØµÙ„ÛŒ

Ø¹Ø§Ù…Ù„ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ (AI) Ø¨Ù‡ Ø³ÛŒØ³ØªÙ…ÛŒ ÛŒØ§ Ø¨Ø±Ù†Ø§Ù…Ù‡â€ŒØ§ÛŒ Ø§Ø´Ø§Ø±Ù‡ Ø¯Ø§Ø±Ø¯ Ú©Ù‡ Ù‚Ø§Ø¯Ø± Ø§Ø³Øª Ø¨Ù‡ Ø·ÙˆØ± Ø®ÙˆØ¯Ú©Ø§Ø± ÙˆØ¸Ø§ÛŒÙÛŒ Ø±Ø§ Ø¨Ù‡ Ù†Ù…Ø§ÛŒÙ†Ø¯Ú¯ÛŒ Ø§Ø² ÛŒÚ© Ú©Ø§Ø±Ø¨Ø± ÛŒØ§ Ø³ÛŒØ³ØªÙ… Ø¯ÛŒÚ¯Ø± Ø§Ù†Ø¬Ø§Ù… Ø¯Ù‡Ø¯ØŒ Ø¨Ø§ Ø·Ø±Ø§Ø­ÛŒ Ø¬Ø±ÛŒØ§Ù† Ú©Ø§Ø±ÛŒ Ø®ÙˆØ¯ Ùˆ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø§Ø¨Ø²Ø§Ø±Ù‡Ø§ÛŒ Ù…ÙˆØ¬ÙˆØ¯. Ø¨Ø±Ø®Ù„Ø§Ù Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ Ø³Ù†ØªÛŒ Ú©Ù‡ ÙÙ‚Ø· Ø¨Ù‡ Ø³ÙˆØ§Ù„Ø§Øª Ø´Ù…Ø§ Ù¾Ø§Ø³Ø® Ù…ÛŒâ€ŒØ¯Ù‡Ø¯ØŒ ÛŒÚ© Ø¹Ø§Ù…Ù„ Ù…ÛŒâ€ŒØªÙˆØ§Ù†Ø¯ Ø¨Ù‡ Ø·ÙˆØ± Ù…Ø³ØªÙ‚Ù„ Ø¨Ø±Ø§ÛŒ Ø¯Ø³ØªÛŒØ§Ø¨ÛŒ Ø¨Ù‡ Ø§Ù‡Ø¯Ø§Ù Ø¹Ù…Ù„ Ú©Ù†Ø¯.

### Ú†Ø§Ø±Ú†ÙˆØ¨ Ø·Ø¨Ù‚Ù‡â€ŒØ¨Ù†Ø¯ÛŒ Ø¹Ø§Ù…Ù„

Ø¯Ø±Ú© Ù…Ø±Ø²Ù‡Ø§ÛŒ Ø¹Ø§Ù…Ù„ Ø¨Ù‡ Ø§Ù†ØªØ®Ø§Ø¨ Ø§Ù†ÙˆØ§Ø¹ Ù…Ù†Ø§Ø³Ø¨ Ø¹Ø§Ù…Ù„ Ø¨Ø±Ø§ÛŒ Ø³Ù†Ø§Ø±ÛŒÙˆÙ‡Ø§ÛŒ Ù…Ø®ØªÙ„Ù Ù…Ø­Ø§Ø³Ø¨Ø§ØªÛŒ Ú©Ù…Ú© Ù…ÛŒâ€ŒÚ©Ù†Ø¯:

- **ðŸ”¬ Ø¹ÙˆØ§Ù…Ù„ Ø¨Ø§Ø²ØªØ§Ø¨ Ø³Ø§Ø¯Ù‡**: Ø³ÛŒØ³ØªÙ…â€ŒÙ‡Ø§ÛŒ Ù…Ø¨ØªÙ†ÛŒ Ø¨Ø± Ù‚ÙˆØ§Ù†ÛŒÙ† Ú©Ù‡ Ø¨Ù‡ Ø§Ø¯Ø±Ø§Ú©Ø§Øª ÙÙˆØ±ÛŒ Ù¾Ø§Ø³Ø® Ù…ÛŒâ€ŒØ¯Ù‡Ù†Ø¯ (ØªØ±Ù…ÙˆØ³ØªØ§Øªâ€ŒÙ‡Ø§ØŒ Ø§ØªÙˆÙ…Ø§Ø³ÛŒÙˆÙ† Ù¾Ø§ÛŒÙ‡)
- **ðŸ“± Ø¹ÙˆØ§Ù…Ù„ Ù…Ø¨ØªÙ†ÛŒ Ø¨Ø± Ù…Ø¯Ù„**: Ø³ÛŒØ³ØªÙ…â€ŒÙ‡Ø§ÛŒÛŒ Ú©Ù‡ Ø­Ø§Ù„Øª Ø¯Ø§Ø®Ù„ÛŒ Ùˆ Ø­Ø§ÙØ¸Ù‡ Ø±Ø§ Ø­ÙØ¸ Ù…ÛŒâ€ŒÚ©Ù†Ù†Ø¯ (Ø¬Ø§Ø±ÙˆØ¨Ø±Ù‚ÛŒâ€ŒÙ‡Ø§ÛŒ Ø±Ø¨Ø§ØªÛŒÚ©ØŒ Ø³ÛŒØ³ØªÙ…â€ŒÙ‡Ø§ÛŒ Ù†Ø§ÙˆØ¨Ø±ÛŒ)
- **âš–ï¸ Ø¹ÙˆØ§Ù…Ù„ Ù…Ø¨ØªÙ†ÛŒ Ø¨Ø± Ù‡Ø¯Ù**: Ø³ÛŒØ³ØªÙ…â€ŒÙ‡Ø§ÛŒÛŒ Ú©Ù‡ Ø¨Ø±Ø§ÛŒ Ø¯Ø³ØªÛŒØ§Ø¨ÛŒ Ø¨Ù‡ Ø§Ù‡Ø¯Ø§ÙØŒ ØªÙˆØ§Ù„ÛŒâ€ŒÙ‡Ø§ Ø±Ø§ Ø¨Ø±Ù†Ø§Ù…Ù‡â€ŒØ±ÛŒØ²ÛŒ Ùˆ Ø§Ø¬Ø±Ø§ Ù…ÛŒâ€ŒÚ©Ù†Ù†Ø¯ (Ø¨Ø±Ù†Ø§Ù…Ù‡â€ŒØ±ÛŒØ²Ø§Ù† Ù…Ø³ÛŒØ±ØŒ Ø²Ù…Ø§Ù†â€ŒØ¨Ù†Ø¯Ù‡Ø§ÛŒ ÙˆØ¸ÛŒÙÙ‡)
- **ðŸ§  Ø¹ÙˆØ§Ù…Ù„ ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ**: Ø³ÛŒØ³ØªÙ…â€ŒÙ‡Ø§ÛŒ ØªØ·Ø¨ÛŒÙ‚ÛŒ Ú©Ù‡ Ø¹Ù…Ù„Ú©Ø±Ø¯ Ø±Ø§ Ø¯Ø± Ø·ÙˆÙ„ Ø²Ù…Ø§Ù† Ø¨Ù‡Ø¨ÙˆØ¯ Ù…ÛŒâ€ŒØ¨Ø®Ø´Ù†Ø¯ (Ø³ÛŒØ³ØªÙ…â€ŒÙ‡Ø§ÛŒ ØªÙˆØµÛŒÙ‡â€ŒÚ¯Ø±ØŒ Ø¯Ø³ØªÛŒØ§Ø±Ù‡Ø§ÛŒ Ø´Ø®ØµÛŒ)

### Ù…Ø²Ø§ÛŒØ§ÛŒ Ú©Ù„ÛŒØ¯ÛŒ Ø¹ÙˆØ§Ù…Ù„ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ

Ø¹ÙˆØ§Ù…Ù„ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ Ú†Ù†Ø¯ÛŒÙ† Ù…Ø²ÛŒØª Ø¨Ù†ÛŒØ§Ø¯ÛŒ Ø§Ø±Ø§Ø¦Ù‡ Ù…ÛŒâ€ŒØ¯Ù‡Ù†Ø¯ Ú©Ù‡ Ø¢Ù†â€ŒÙ‡Ø§ Ø±Ø§ Ø¨Ø±Ø§ÛŒ Ú©Ø§Ø±Ø¨Ø±Ø¯Ù‡Ø§ÛŒ Ù…Ø­Ø§Ø³Ø¨Ø§ØªÛŒ Ù„Ø¨Ù‡ Ø§ÛŒØ¯Ù‡â€ŒØ¢Ù„ Ù…ÛŒâ€ŒÚ©Ù†Ø¯:

**Ø®ÙˆØ¯Ù…Ø®ØªØ§Ø±ÛŒ Ø¹Ù…Ù„ÛŒØ§ØªÛŒ**: Ø¹ÙˆØ§Ù…Ù„ Ø§Ø¬Ø±Ø§ÛŒ ÙˆØ¸Ø§ÛŒÙ Ù…Ø³ØªÙ‚Ù„ Ø±Ø§ Ø¨Ø¯ÙˆÙ† Ù†Ø¸Ø§Ø±Øª Ù…Ø¯Ø§ÙˆÙ… Ø§Ù†Ø³Ø§Ù†ÛŒ ÙØ±Ø§Ù‡Ù… Ù…ÛŒâ€ŒÚ©Ù†Ù†Ø¯ØŒ Ú©Ù‡ Ø¢Ù†â€ŒÙ‡Ø§ Ø±Ø§ Ø¨Ø±Ø§ÛŒ Ú©Ø§Ø±Ø¨Ø±Ø¯Ù‡Ø§ÛŒ Ø¨Ù„Ø§Ø¯Ø±Ù†Ú¯ Ø§ÛŒØ¯Ù‡â€ŒØ¢Ù„ Ù…ÛŒâ€ŒÚ©Ù†Ø¯. Ø¢Ù†â€ŒÙ‡Ø§ Ø¨Ù‡ Ù†Ø¸Ø§Ø±Øª Ø­Ø¯Ø§Ù‚Ù„ÛŒ Ù†ÛŒØ§Ø² Ø¯Ø§Ø±Ù†Ø¯ Ùˆ Ø¯Ø± Ø¹ÛŒÙ† Ø­Ø§Ù„ Ø±ÙØªØ§Ø± ØªØ·Ø¨ÛŒÙ‚ÛŒ Ø±Ø§ Ø­ÙØ¸ Ù…ÛŒâ€ŒÚ©Ù†Ù†Ø¯ØŒ Ú©Ù‡ Ø§Ù…Ú©Ø§Ù† Ø§Ø³ØªÙ‚Ø±Ø§Ø± Ø¯Ø± Ø¯Ø³ØªÚ¯Ø§Ù‡â€ŒÙ‡Ø§ÛŒ Ù…Ø­Ø¯ÙˆØ¯ Ù…Ù†Ø§Ø¨Ø¹ Ø¨Ø§ Ú©Ø§Ù‡Ø´ Ø³Ø±Ø¨Ø§Ø± Ø¹Ù…Ù„ÛŒØ§ØªÛŒ Ø±Ø§ ÙØ±Ø§Ù‡Ù… Ù…ÛŒâ€ŒÚ©Ù†Ø¯.

**Ø§Ù†Ø¹Ø·Ø§Ùâ€ŒÙ¾Ø°ÛŒØ±ÛŒ Ø§Ø³ØªÙ‚Ø±Ø§Ø±**: Ø§ÛŒÙ† Ø³ÛŒØ³ØªÙ…â€ŒÙ‡Ø§ Ù‚Ø§Ø¨Ù„ÛŒØªâ€ŒÙ‡Ø§ÛŒ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ Ø¯Ø± Ø¯Ø³ØªÚ¯Ø§Ù‡ Ø±Ø§ Ø¨Ø¯ÙˆÙ† Ù†ÛŒØ§Ø² Ø¨Ù‡ Ø§ØªØµØ§Ù„ Ø§ÛŒÙ†ØªØ±Ù†Øª ÙØ¹Ø§Ù„ Ù…ÛŒâ€ŒÚ©Ù†Ù†Ø¯ØŒ Ø­Ø±ÛŒÙ… Ø®ØµÙˆØµÛŒ Ùˆ Ø§Ù…Ù†ÛŒØª Ø±Ø§ Ø§Ø² Ø·Ø±ÛŒÙ‚ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù…Ø­Ù„ÛŒ Ø§ÙØ²Ø§ÛŒØ´ Ù…ÛŒâ€ŒØ¯Ù‡Ù†Ø¯ØŒ Ù…ÛŒâ€ŒØªÙˆØ§Ù†Ù†Ø¯ Ø¨Ø±Ø§ÛŒ Ú©Ø§Ø±Ø¨Ø±Ø¯Ù‡Ø§ÛŒ Ø®Ø§Øµ Ø¯Ø§Ù…Ù†Ù‡ Ø³ÙØ§Ø±Ø´ÛŒ Ø´ÙˆÙ†Ø¯ Ùˆ Ø¨Ø±Ø§ÛŒ Ù…Ø­ÛŒØ·â€ŒÙ‡Ø§ÛŒ Ù…Ø®ØªÙ„Ù Ù…Ø­Ø§Ø³Ø¨Ø§ØªÛŒ Ù„Ø¨Ù‡ Ù…Ù†Ø§Ø³Ø¨ Ù‡Ø³ØªÙ†Ø¯.

**Ù…Ù‚Ø±ÙˆÙ†â€ŒØ¨Ù‡â€ŒØµØ±ÙÙ‡ Ø¨ÙˆØ¯Ù†**: Ø³ÛŒØ³ØªÙ…â€ŒÙ‡Ø§ÛŒ Ø¹Ø§Ù…Ù„ Ø§Ø³ØªÙ‚Ø±Ø§Ø± Ù…Ù‚Ø±ÙˆÙ†â€ŒØ¨Ù‡â€ŒØµØ±ÙÙ‡â€ŒØ§ÛŒ Ø±Ø§ Ø¯Ø± Ù…Ù‚Ø§ÛŒØ³Ù‡ Ø¨Ø§ Ø±Ø§Ù‡â€ŒØ­Ù„â€ŒÙ‡Ø§ÛŒ Ù…Ø¨ØªÙ†ÛŒ Ø¨Ø± Ø§Ø¨Ø± Ø§Ø±Ø§Ø¦Ù‡ Ù…ÛŒâ€ŒØ¯Ù‡Ù†Ø¯ØŒ Ø¨Ø§ Ú©Ø§Ù‡Ø´ Ù‡Ø²ÛŒÙ†Ù‡â€ŒÙ‡Ø§ÛŒ Ø¹Ù…Ù„ÛŒØ§ØªÛŒ Ùˆ Ù†ÛŒØ§Ø²Ù‡Ø§ÛŒ Ù¾Ù‡Ù†Ø§ÛŒ Ø¨Ø§Ù†Ø¯ Ú©Ù…ØªØ± Ø¨Ø±Ø§ÛŒ Ú©Ø§Ø±Ø¨Ø±Ø¯Ù‡Ø§ÛŒ Ù„Ø¨Ù‡.

## Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒâ€ŒÙ‡Ø§ÛŒ Ù¾ÛŒØ´Ø±ÙØªÙ‡ Ù…Ø¯Ù„ Ø²Ø¨Ø§Ù† Ú©ÙˆÚ†Ú©

### Ù…Ø¨Ø§Ù†ÛŒ SLM (Ù…Ø¯Ù„ Ø²Ø¨Ø§Ù† Ú©ÙˆÚ†Ú©)

Ù…Ø¯Ù„ Ø²Ø¨Ø§Ù† Ú©ÙˆÚ†Ú© (SLM) Ù…Ø¯Ù„ÛŒ Ø²Ø¨Ø§Ù†ÛŒ Ø§Ø³Øª Ú©Ù‡ Ù…ÛŒâ€ŒØªÙˆØ§Ù†Ø¯ Ø¨Ø± Ø±ÙˆÛŒ ÛŒÚ© Ø¯Ø³ØªÚ¯Ø§Ù‡ Ø§Ù„Ú©ØªØ±ÙˆÙ†ÛŒÚ©ÛŒ Ù…ØµØ±Ùâ€ŒÚ©Ù†Ù†Ø¯Ù‡ Ù…Ø¹Ù…ÙˆÙ„ÛŒ Ù‚Ø±Ø§Ø± Ú¯ÛŒØ±Ø¯ Ùˆ Ø§Ø³ØªÙ†ØªØ§Ø¬ Ø±Ø§ Ø¨Ø§ ØªØ£Ø®ÛŒØ± Ú©Ø§ÙÛŒ Ú©Ù… Ø¨Ø±Ø§ÛŒ Ù¾Ø§Ø³Ø®Ú¯ÙˆÛŒÛŒ Ø¨Ù‡ Ø¯Ø±Ø®ÙˆØ§Ø³Øªâ€ŒÙ‡Ø§ÛŒ Ø¹Ø§Ù…Ù„â€ŒÙ…Ø­ÙˆØ± ÛŒÚ© Ú©Ø§Ø±Ø¨Ø± Ø§Ù†Ø¬Ø§Ù… Ø¯Ù‡Ø¯. Ø¨Ù‡ Ø·ÙˆØ± Ø¹Ù…Ù„ÛŒØŒ SLMâ€ŒÙ‡Ø§ Ù…Ø¹Ù…ÙˆÙ„Ø§Ù‹ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒÛŒ Ø¨Ø§ Ú©Ù…ØªØ± Ø§Ø² Û±Û° Ù…ÛŒÙ„ÛŒØ§Ø±Ø¯ Ù¾Ø§Ø±Ø§Ù…ØªØ± Ù‡Ø³ØªÙ†Ø¯.

**ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ú©Ø´Ù ÙØ±Ù…Øª**: SLMâ€ŒÙ‡Ø§ Ù¾Ø´ØªÛŒØ¨Ø§Ù†ÛŒ Ù¾ÛŒØ´Ø±ÙØªÙ‡â€ŒØ§ÛŒ Ø¨Ø±Ø§ÛŒ Ø³Ø·ÙˆØ­ Ù…Ø®ØªÙ„Ù Ú©Ù…ÛŒØªâ€ŒØ³Ø§Ø²ÛŒØŒ Ø³Ø§Ø²Ú¯Ø§Ø±ÛŒ Ø¨ÛŒÙ† Ù¾Ù„ØªÙØ±Ù…ÛŒØŒ Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø¹Ù…Ù„Ú©Ø±Ø¯ Ø¨Ù„Ø§Ø¯Ø±Ù†Ú¯ Ùˆ Ù‚Ø§Ø¨Ù„ÛŒØªâ€ŒÙ‡Ø§ÛŒ Ø§Ø³ØªÙ‚Ø±Ø§Ø± Ù„Ø¨Ù‡ Ø§Ø±Ø§Ø¦Ù‡ Ù…ÛŒâ€ŒØ¯Ù‡Ù†Ø¯. Ú©Ø§Ø±Ø¨Ø±Ø§Ù† Ù…ÛŒâ€ŒØªÙˆØ§Ù†Ù†Ø¯ Ø§Ø² Ø­Ø±ÛŒÙ… Ø®ØµÙˆØµÛŒ Ù¾ÛŒØ´Ø±ÙØªÙ‡ Ø§Ø² Ø·Ø±ÛŒÙ‚ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù…Ø­Ù„ÛŒ Ùˆ Ù¾Ø´ØªÛŒØ¨Ø§Ù†ÛŒ WebGPU Ø¨Ø±Ø§ÛŒ Ø§Ø³ØªÙ‚Ø±Ø§Ø± Ù…Ø¨ØªÙ†ÛŒ Ø¨Ø± Ù…Ø±ÙˆØ±Ú¯Ø± Ø¨Ù‡Ø±Ù‡â€ŒÙ…Ù†Ø¯ Ø´ÙˆÙ†Ø¯.

**Ù…Ø¬Ù…ÙˆØ¹Ù‡â€ŒÙ‡Ø§ÛŒ Ø³Ø·Ø­ Ú©Ù…ÛŒØªâ€ŒØ³Ø§Ø²ÛŒ**: ÙØ±Ù…Øªâ€ŒÙ‡Ø§ÛŒ Ù…Ø­Ø¨ÙˆØ¨ SLM Ø´Ø§Ù…Ù„ Q4_K_M Ø¨Ø±Ø§ÛŒ ÙØ´Ø±Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ù…ØªØ¹Ø§Ø¯Ù„ Ø¯Ø± Ú©Ø§Ø±Ø¨Ø±Ø¯Ù‡Ø§ÛŒ Ù…ÙˆØ¨Ø§ÛŒÙ„ØŒ Ø³Ø±ÛŒ Q5_K_S Ø¨Ø±Ø§ÛŒ Ø§Ø³ØªÙ‚Ø±Ø§Ø± Ù„Ø¨Ù‡ Ø¨Ø§ ØªÙ…Ø±Ú©Ø² Ø¨Ø± Ú©ÛŒÙÛŒØªØŒ Q8_0 Ø¨Ø±Ø§ÛŒ Ø¯Ù‚Øª Ù†Ø²Ø¯ÛŒÚ© Ø¨Ù‡ Ø§ØµÙ„ Ø¯Ø± Ø¯Ø³ØªÚ¯Ø§Ù‡â€ŒÙ‡Ø§ÛŒ Ù‚Ø¯Ø±ØªÙ…Ù†Ø¯ Ù„Ø¨Ù‡ Ùˆ ÙØ±Ù…Øªâ€ŒÙ‡Ø§ÛŒ Ø¢Ø²Ù…Ø§ÛŒØ´ÛŒ Ù…Ø§Ù†Ù†Ø¯ Q2_K Ø¨Ø±Ø§ÛŒ Ø³Ù†Ø§Ø±ÛŒÙˆÙ‡Ø§ÛŒ Ù…Ù†Ø§Ø¨Ø¹ ÙÙˆÙ‚â€ŒØ§Ù„Ø¹Ø§Ø¯Ù‡ Ú©Ù… Ù‡Ø³ØªÙ†Ø¯.

### GGUF (ÙØ±Ù…Øª Ø¹Ù…ÙˆÙ…ÛŒ Ø¬Ù‡Ø§Ù†ÛŒ GGML) Ø¨Ø±Ø§ÛŒ Ø§Ø³ØªÙ‚Ø±Ø§Ø± SLM

GGUF Ø¨Ù‡ Ø¹Ù†ÙˆØ§Ù† ÙØ±Ù…Øª Ø§ØµÙ„ÛŒ Ø¨Ø±Ø§ÛŒ Ø§Ø³ØªÙ‚Ø±Ø§Ø± SLMâ€ŒÙ‡Ø§ÛŒ Ú©Ù…ÛŒØªâ€ŒØ³Ø§Ø²ÛŒ Ø´Ø¯Ù‡ Ø¨Ø± Ø±ÙˆÛŒ CPU Ùˆ Ø¯Ø³ØªÚ¯Ø§Ù‡â€ŒÙ‡Ø§ÛŒ Ù„Ø¨Ù‡ØŒ Ø¨Ù‡ Ø·ÙˆØ± Ø®Ø§Øµ Ø¨Ø±Ø§ÛŒ Ú©Ø§Ø±Ø¨Ø±Ø¯Ù‡Ø§ÛŒ Ø¹Ø§Ù…Ù„â€ŒÙ…Ø­ÙˆØ± Ø¨Ù‡ÛŒÙ†Ù‡ Ø´Ø¯Ù‡ Ø§Ø³Øª:

**ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ´Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ Ø¹Ø§Ù…Ù„**: Ø§ÛŒÙ† ÙØ±Ù…Øª Ù…Ù†Ø§Ø¨Ø¹ Ø¬Ø§Ù…Ø¹ÛŒ Ø¨Ø±Ø§ÛŒ ØªØ¨Ø¯ÛŒÙ„ Ùˆ Ø§Ø³ØªÙ‚Ø±Ø§Ø± SLM Ø¨Ø§ Ù¾Ø´ØªÛŒØ¨Ø§Ù†ÛŒ Ù¾ÛŒØ´Ø±ÙØªÙ‡ Ø¨Ø±Ø§ÛŒ ÙØ±Ø§Ø®ÙˆØ§Ù†ÛŒ Ø§Ø¨Ø²Ø§Ø±ØŒ ØªÙˆÙ„ÛŒØ¯ Ø®Ø±ÙˆØ¬ÛŒ Ø³Ø§Ø®ØªØ§Ø±ÛŒØ§ÙØªÙ‡ Ùˆ Ù…Ú©Ø§Ù„Ù…Ø§Øª Ú†Ù†Ø¯ Ù†ÙˆØ¨ØªÛŒ Ø§Ø±Ø§Ø¦Ù‡ Ù…ÛŒâ€ŒØ¯Ù‡Ø¯. Ø³Ø§Ø²Ú¯Ø§Ø±ÛŒ Ø¨ÛŒÙ† Ù¾Ù„ØªÙØ±Ù…ÛŒ Ø±ÙØªØ§Ø± Ø¹Ø§Ù…Ù„ Ø³Ø§Ø²Ú¯Ø§Ø± Ø±Ø§ Ø¯Ø± Ø¯Ø³ØªÚ¯Ø§Ù‡â€ŒÙ‡Ø§ÛŒ Ù…Ø®ØªÙ„Ù Ù„Ø¨Ù‡ ØªØ¶Ù…ÛŒÙ† Ù…ÛŒâ€ŒÚ©Ù†Ø¯.

**Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø¹Ù…Ù„Ú©Ø±Ø¯**: GGUF Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ø§Ø±Ø¢Ù…Ø¯ Ø§Ø² Ø­Ø§ÙØ¸Ù‡ Ø¨Ø±Ø§ÛŒ Ø¬Ø±ÛŒØ§Ù†â€ŒÙ‡Ø§ÛŒ Ú©Ø§Ø±ÛŒ Ø¹Ø§Ù…Ù„ØŒ Ù¾Ø´ØªÛŒØ¨Ø§Ù†ÛŒ Ø§Ø² Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù¾ÙˆÛŒØ§ Ù…Ø¯Ù„ Ø¨Ø±Ø§ÛŒ Ø³ÛŒØ³ØªÙ…â€ŒÙ‡Ø§ÛŒ Ú†Ù†Ø¯ Ø¹Ø§Ù…Ù„ÛŒ Ùˆ Ø§Ø³ØªÙ†ØªØ§Ø¬ Ø¨Ù‡ÛŒÙ†Ù‡ Ø¨Ø±Ø§ÛŒ ØªØ¹Ø§Ù…Ù„Ø§Øª Ø¨Ù„Ø§Ø¯Ø±Ù†Ú¯ Ø¹Ø§Ù…Ù„ Ø±Ø§ Ø§Ù…Ú©Ø§Ù†â€ŒÙ¾Ø°ÛŒØ± Ù…ÛŒâ€ŒÚ©Ù†Ø¯.

### Ú†Ø§Ø±Ú†ÙˆØ¨â€ŒÙ‡Ø§ÛŒ Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ´Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ SLM Ø¯Ø± Ù„Ø¨Ù‡

#### Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ Llama.cpp Ø¨Ø±Ø§ÛŒ Ø¹ÙˆØ§Ù…Ù„

Llama.cpp ØªÚ©Ù†ÛŒÚ©â€ŒÙ‡Ø§ÛŒ Ú©Ù…ÛŒØªâ€ŒØ³Ø§Ø²ÛŒ Ù¾ÛŒØ´Ø±ÙØªÙ‡â€ŒØ§ÛŒ Ø±Ø§ Ø¨Ù‡ Ø·ÙˆØ± Ø®Ø§Øµ Ø¨Ø±Ø§ÛŒ Ø§Ø³ØªÙ‚Ø±Ø§Ø± Ø¹Ø§Ù…Ù„â€ŒÙ…Ø­ÙˆØ± SLM Ø§Ø±Ø§Ø¦Ù‡ Ù…ÛŒâ€ŒØ¯Ù‡Ø¯:

**Ú©Ù…ÛŒØªâ€ŒØ³Ø§Ø²ÛŒ Ø®Ø§Øµ Ø¹Ø§Ù…Ù„**: Ø§ÛŒÙ† Ú†Ø§Ø±Ú†ÙˆØ¨ Ø§Ø² Q4_0 (Ø¨Ù‡ÛŒÙ†Ù‡ Ø¨Ø±Ø§ÛŒ Ø§Ø³ØªÙ‚Ø±Ø§Ø± Ø¹Ø§Ù…Ù„ Ù…ÙˆØ¨Ø§ÛŒÙ„ Ø¨Ø§ Ú©Ø§Ù‡Ø´ Ø§Ù†Ø¯Ø§Ø²Ù‡ Û·ÛµÙª)ØŒ Q5_1 (Ú©ÛŒÙÛŒØª-ÙØ´Ø±Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ù…ØªØ¹Ø§Ø¯Ù„ Ø¨Ø±Ø§ÛŒ Ø¹ÙˆØ§Ù…Ù„ Ø§Ø³ØªÙ†ØªØ§Ø¬ Ù„Ø¨Ù‡) Ùˆ Q8_0 (Ú©ÛŒÙÛŒØª Ù†Ø²Ø¯ÛŒÚ© Ø¨Ù‡ Ø§ØµÙ„ Ø¨Ø±Ø§ÛŒ Ø³ÛŒØ³ØªÙ…â€ŒÙ‡Ø§ÛŒ Ø¹Ø§Ù…Ù„ ØªÙˆÙ„ÛŒØ¯ÛŒ) Ù¾Ø´ØªÛŒØ¨Ø§Ù†ÛŒ Ù…ÛŒâ€ŒÚ©Ù†Ø¯. ÙØ±Ù…Øªâ€ŒÙ‡Ø§ÛŒ Ù¾ÛŒØ´Ø±ÙØªÙ‡ Ø¹ÙˆØ§Ù…Ù„ ÙÙˆÙ‚â€ŒØ§Ù„Ø¹Ø§Ø¯Ù‡ ÙØ´Ø±Ø¯Ù‡ Ø±Ø§ Ø¨Ø±Ø§ÛŒ Ø³Ù†Ø§Ø±ÛŒÙˆÙ‡Ø§ÛŒ Ù„Ø¨Ù‡ Ø´Ø¯ÛŒØ¯ Ø§Ù…Ú©Ø§Ù†â€ŒÙ¾Ø°ÛŒØ± Ù…ÛŒâ€ŒÚ©Ù†Ù†Ø¯.

**Ù…Ø²Ø§ÛŒØ§ÛŒ Ù¾ÛŒØ§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ**: Ø§Ø³ØªÙ†ØªØ§Ø¬ Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ´Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ CPU Ø¨Ø§ Ø´ØªØ§Ø¨ SIMD Ø§Ø¬Ø±Ø§ÛŒ Ø¹Ø§Ù…Ù„ Ø­Ø§ÙØ¸Ù‡â€ŒÚ©Ø§Ø±Ø¢Ù…Ø¯ Ø±Ø§ ÙØ±Ø§Ù‡Ù… Ù…ÛŒâ€ŒÚ©Ù†Ø¯. Ø³Ø§Ø²Ú¯Ø§Ø±ÛŒ Ø¨ÛŒÙ† Ù¾Ù„ØªÙØ±Ù…ÛŒ Ø¯Ø± Ù…Ø¹Ù…Ø§Ø±ÛŒâ€ŒÙ‡Ø§ÛŒ x86ØŒ ARM Ùˆ Apple Silicon Ù‚Ø§Ø¨Ù„ÛŒØªâ€ŒÙ‡Ø§ÛŒ Ø§Ø³ØªÙ‚Ø±Ø§Ø± Ø¬Ù‡Ø§Ù†ÛŒ Ø¹Ø§Ù…Ù„ Ø±Ø§ Ø§Ù…Ú©Ø§Ù†â€ŒÙ¾Ø°ÛŒØ± Ù…ÛŒâ€ŒÚ©Ù†Ø¯.

#### Ú†Ø§Ø±Ú†ÙˆØ¨ Apple MLX Ø¨Ø±Ø§ÛŒ Ø¹ÙˆØ§Ù…Ù„ SLM

Apple MLX Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø¨ÙˆÙ…ÛŒ Ø±Ø§ Ø¨Ù‡ Ø·ÙˆØ± Ø®Ø§Øµ Ø¨Ø±Ø§ÛŒ Ø¹ÙˆØ§Ù…Ù„ Ù…Ø¨ØªÙ†ÛŒ Ø¨Ø± SLM Ø¯Ø± Ø¯Ø³ØªÚ¯Ø§Ù‡â€ŒÙ‡Ø§ÛŒ Apple Silicon Ø·Ø±Ø§Ø­ÛŒ Ú©Ø±Ø¯Ù‡ Ø§Ø³Øª:

**Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø¹Ø§Ù…Ù„ Apple Silicon**: Ø§ÛŒÙ† Ú†Ø§Ø±Ú†ÙˆØ¨ Ø§Ø² Ù…Ø¹Ù…Ø§Ø±ÛŒ Ø­Ø§ÙØ¸Ù‡ ÛŒÚ©Ù¾Ø§Ø±Ú†Ù‡ Ø¨Ø§ Ø§Ø¯ØºØ§Ù… Metal Performance ShadersØŒ Ø¯Ù‚Øª Ù…Ø®ØªÙ„Ø· Ø®ÙˆØ¯Ú©Ø§Ø± Ø¨Ø±Ø§ÛŒ Ø§Ø³ØªÙ†ØªØ§Ø¬ Ø¹Ø§Ù…Ù„ Ùˆ Ù¾Ù‡Ù†Ø§ÛŒ Ø¨Ø§Ù†Ø¯ Ø­Ø§ÙØ¸Ù‡ Ø¨Ù‡ÛŒÙ†Ù‡ Ø¨Ø±Ø§ÛŒ Ø³ÛŒØ³ØªÙ…â€ŒÙ‡Ø§ÛŒ Ú†Ù†Ø¯ Ø¹Ø§Ù…Ù„ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒÚ©Ù†Ø¯. Ø¹ÙˆØ§Ù…Ù„ SLM Ø¹Ù…Ù„Ú©Ø±Ø¯ Ø§Ø³ØªØ«Ù†Ø§ÛŒÛŒ Ø±Ø§ Ø¨Ø± Ø±ÙˆÛŒ ØªØ±Ø§Ø´Ù‡â€ŒÙ‡Ø§ÛŒ Ø³Ø±ÛŒ M Ù†Ø´Ø§Ù† Ù…ÛŒâ€ŒØ¯Ù‡Ù†Ø¯.

**ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒ ØªÙˆØ³Ø¹Ù‡**: Ù¾Ø´ØªÛŒØ¨Ø§Ù†ÛŒ API Python Ùˆ Swift Ø¨Ø§ Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒâ€ŒÙ‡Ø§ÛŒ Ø®Ø§Øµ Ø¹Ø§Ù…Ù„ØŒ ØªÙÚ©ÛŒÚ© Ø®ÙˆØ¯Ú©Ø§Ø± Ø¨Ø±Ø§ÛŒ ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ Ø¹Ø§Ù…Ù„ Ùˆ Ø§Ø¯ØºØ§Ù… Ø¨ÛŒâ€ŒØ¯Ø±Ø¯Ø³Ø± Ø¨Ø§ Ø§Ø¨Ø²Ø§Ø±Ù‡Ø§ÛŒ ØªÙˆØ³Ø¹Ù‡ Apple Ù…Ø­ÛŒØ·â€ŒÙ‡Ø§ÛŒ Ø¬Ø§Ù…Ø¹ ØªÙˆØ³Ø¹Ù‡ Ø¹Ø§Ù…Ù„ Ø±Ø§ ÙØ±Ø§Ù‡Ù… Ù…ÛŒâ€ŒÚ©Ù†Ø¯.

#### ONNX Runtime Ø¨Ø±Ø§ÛŒ Ø¹ÙˆØ§Ù…Ù„ SLM Ú†Ù†Ø¯ Ù¾Ù„ØªÙØ±Ù…ÛŒ

ONNX Runtime ÛŒÚ© Ù…ÙˆØªÙˆØ± Ø§Ø³ØªÙ†ØªØ§Ø¬ Ø¬Ù‡Ø§Ù†ÛŒ Ø§Ø±Ø§Ø¦Ù‡ Ù…ÛŒâ€ŒØ¯Ù‡Ø¯ Ú©Ù‡ Ø§Ù…Ú©Ø§Ù† Ø§Ø¬Ø±Ø§ÛŒ Ø¹ÙˆØ§Ù…Ù„ SLM Ø±Ø§ Ø¨Ù‡ Ø·ÙˆØ± Ø³Ø§Ø²Ú¯Ø§Ø± Ø¯Ø± Ù¾Ù„ØªÙØ±Ù…â€ŒÙ‡Ø§ÛŒ Ø³Ø®Øªâ€ŒØ§ÙØ²Ø§Ø±ÛŒ Ùˆ Ø³ÛŒØ³ØªÙ…â€ŒØ¹Ø§Ù…Ù„â€ŒÙ‡Ø§ÛŒ Ù…Ø®ØªÙ„Ù ÙØ±Ø§Ù‡Ù… Ù…ÛŒâ€ŒÚ©Ù†Ø¯:

**Ø§Ø³ØªÙ‚Ø±Ø§Ø± Ø¬Ù‡Ø§Ù†ÛŒ**: ONNX Runtime Ø±ÙØªØ§Ø± Ø³Ø§Ø²Ú¯Ø§Ø± Ø¹Ø§Ù…Ù„ SLM Ø±Ø§ Ø¯Ø± Ù¾Ù„ØªÙØ±Ù…â€ŒÙ‡Ø§ÛŒ WindowsØŒ LinuxØŒ macOSØŒ iOS Ùˆ Android ØªØ¶Ù…ÛŒÙ† Ù…ÛŒâ€ŒÚ©Ù†Ø¯. Ø§ÛŒÙ† Ø³Ø§Ø²Ú¯Ø§Ø±ÛŒ Ø¨ÛŒÙ† Ù¾Ù„ØªÙØ±Ù…ÛŒ Ø¨Ù‡ ØªÙˆØ³Ø¹Ù‡â€ŒØ¯Ù‡Ù†Ø¯Ú¯Ø§Ù† Ø§Ù…Ú©Ø§Ù† Ù…ÛŒâ€ŒØ¯Ù‡Ø¯ ÛŒÚ© Ø¨Ø§Ø± Ø¨Ù†ÙˆÛŒØ³Ù†Ø¯ Ùˆ Ø¯Ø± Ù‡Ù…Ù‡ Ø¬Ø§ Ù…Ø³ØªÙ‚Ø± Ú©Ù†Ù†Ø¯ØŒ Ú©Ù‡ Ø¨Ù‡ Ø·ÙˆØ± Ù‚Ø§Ø¨Ù„ ØªÙˆØ¬Ù‡ÛŒ Ù‡Ø²ÛŒÙ†Ù‡â€ŒÙ‡Ø§ÛŒ ØªÙˆØ³Ø¹Ù‡ Ùˆ Ù†Ú¯Ù‡Ø¯Ø§Ø±ÛŒ Ø±Ø§ Ø¨Ø±Ø§ÛŒ Ú©Ø§Ø±Ø¨Ø±Ø¯Ù‡Ø§ÛŒ Ú†Ù†Ø¯ Ù¾Ù„ØªÙØ±Ù…ÛŒ Ú©Ø§Ù‡Ø´ Ù…ÛŒâ€ŒØ¯Ù‡Ø¯.

**Ú¯Ø²ÛŒÙ†Ù‡â€ŒÙ‡Ø§ÛŒ Ø´ØªØ§Ø¨ Ø³Ø®Øªâ€ŒØ§ÙØ²Ø§Ø±ÛŒ**: Ø§ÛŒÙ† Ú†Ø§Ø±Ú†ÙˆØ¨ Ø§Ø±Ø§Ø¦Ù‡â€ŒØ¯Ù‡Ù†Ø¯Ú¯Ø§Ù† Ø§Ø¬Ø±Ø§ÛŒ Ø¨Ù‡ÛŒÙ†Ù‡ Ø¨Ø±Ø§ÛŒ Ù¾ÛŒÚ©Ø±Ø¨Ù†Ø¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ø³Ø®Øªâ€ŒØ§ÙØ²Ø§Ø±ÛŒ Ù…Ø®ØªÙ„Ù Ø§Ø² Ø¬Ù…Ù„Ù‡ CPU (IntelØŒ AMDØŒ ARM)ØŒ GPU (NVIDIA CUDAØŒ AMD ROCm) Ùˆ Ø´ØªØ§Ø¨â€ŒØ¯Ù‡Ù†Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ØªØ®ØµØµÛŒ (Intel VPUØŒ Qualcomm NPU) Ø§Ø±Ø§Ø¦Ù‡ Ù…ÛŒâ€ŒØ¯Ù‡Ø¯. Ø¹ÙˆØ§Ù…Ù„ SLM Ù…ÛŒâ€ŒØªÙˆØ§Ù†Ù†Ø¯ Ø¨Ù‡ Ø·ÙˆØ± Ø®ÙˆØ¯Ú©Ø§Ø± Ø§Ø² Ø¨Ù‡ØªØ±ÛŒÙ† Ø³Ø®Øªâ€ŒØ§ÙØ²Ø§Ø± Ù…ÙˆØ¬ÙˆØ¯ Ø¨Ø¯ÙˆÙ† ØªØºÛŒÛŒØ± Ú©Ø¯ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†Ù†Ø¯.

**ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ø¢Ù…Ø§Ø¯Ù‡ ØªÙˆÙ„ÛŒØ¯**: ONNX Runtime ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ø¯Ø±Ø¬Ù‡ Ø³Ø§Ø²Ù…Ø§Ù†ÛŒ Ø¶Ø±ÙˆØ±ÛŒ Ø¨Ø±Ø§ÛŒ Ø§Ø³ØªÙ‚Ø±Ø§Ø± Ø¹Ø§Ù…Ù„ ØªÙˆÙ„ÛŒØ¯ÛŒ Ø§Ø² Ø¬Ù…Ù„Ù‡ Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ú¯Ø±Ø§Ù Ø¨Ø±Ø§ÛŒ Ø§Ø³ØªÙ†ØªØ§Ø¬ Ø³Ø±ÛŒØ¹â€ŒØªØ±ØŒ Ù…Ø¯ÛŒØ±ÛŒØª Ø­Ø§ÙØ¸Ù‡ Ø¨Ø±Ø§ÛŒ Ù…Ø­ÛŒØ·â€ŒÙ‡Ø§ÛŒ Ù…Ø­Ø¯ÙˆØ¯ Ù…Ù†Ø§Ø¨Ø¹ Ùˆ Ø§Ø¨Ø²Ø§Ø±Ù‡Ø§ÛŒ Ø¬Ø§Ù…Ø¹ Ù¾Ø±ÙˆÙØ§ÛŒÙ„ÛŒÙ†Ú¯ Ø¨Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ Ø¹Ù…Ù„Ú©Ø±Ø¯ Ø§Ø±Ø§Ø¦Ù‡ Ù…ÛŒâ€ŒØ¯Ù‡Ø¯. Ø§ÛŒÙ† Ú†Ø§Ø±Ú†ÙˆØ¨ Ø§Ø² APIâ€ŒÙ‡Ø§ÛŒ Python Ùˆ C++ Ø¨Ø±Ø§ÛŒ Ø§Ø¯ØºØ§Ù… Ø§Ù†Ø¹Ø·Ø§Ùâ€ŒÙ¾Ø°ÛŒØ± Ù¾Ø´ØªÛŒØ¨Ø§Ù†ÛŒ Ù…ÛŒâ€ŒÚ©Ù†Ø¯.

## SLM Ø¯Ø± Ù…Ù‚Ø§Ø¨Ù„ LLM Ø¯Ø± Ø³ÛŒØ³ØªÙ…â€ŒÙ‡Ø§ÛŒ Ø¹Ø§Ù…Ù„â€ŒÙ…Ø­
- Ø¢Ø²Ù…Ø§ÛŒØ´ ÛŒÚ©Ù¾Ø§Ø±Ú†Ú¯ÛŒ Microsoft Agent Framework  
- Ø¨Ø±Ø±Ø³ÛŒ Ù‚Ø§Ø¨Ù„ÛŒØªâ€ŒÙ‡Ø§ÛŒ Ø¹Ù…Ù„Ú©Ø±Ø¯ Ø¢ÙÙ„Ø§ÛŒÙ†  
- Ø¢Ø²Ù…Ø§ÛŒØ´ Ø³Ù†Ø§Ø±ÛŒÙˆÙ‡Ø§ÛŒ Ø®Ø±Ø§Ø¨ÛŒ Ùˆ Ù…Ø¯ÛŒØ±ÛŒØª Ø®Ø·Ø§  
- Ø§Ø¹ØªØ¨Ø§Ø±Ø³Ù†Ø¬ÛŒ Ø¬Ø±ÛŒØ§Ù†â€ŒÙ‡Ø§ÛŒ Ú©Ø§Ø±ÛŒ Ú©Ø§Ù…Ù„ Ø¹Ø§Ù…Ù„  

**Ù…Ù‚Ø§ÛŒØ³Ù‡ Ø¨Ø§ Foundry Local**:

| ÙˆÛŒÚ˜Ú¯ÛŒ | Foundry Local | Ollama |
|-------|---------------|--------|
| **Ù…ÙˆØ±Ø¯ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù‡Ø¯Ù** | ØªÙˆÙ„ÛŒØ¯ Ø³Ø§Ø²Ù…Ø§Ù†ÛŒ | ØªÙˆØ³Ø¹Ù‡ Ùˆ Ø¬Ø§Ù…Ø¹Ù‡ |
| **Ø§Ú©ÙˆØ³ÛŒØ³ØªÙ… Ù…Ø¯Ù„** | Ø§Ù†ØªØ®Ø§Ø¨ Ø´Ø¯Ù‡ ØªÙˆØ³Ø· Ù…Ø§ÛŒÚ©Ø±ÙˆØ³Ø§ÙØª | Ø¬Ø§Ù…Ø¹Ù‡ Ú¯Ø³ØªØ±Ø¯Ù‡ |
| **Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø³Ø®Øªâ€ŒØ§ÙØ²Ø§Ø±** | Ø®ÙˆØ¯Ú©Ø§Ø± (CUDA/NPU/CPU) | ØªÙ†Ø¸ÛŒÙ… Ø¯Ø³ØªÛŒ |
| **ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ø³Ø§Ø²Ù…Ø§Ù†ÛŒ** | Ù†Ø¸Ø§Ø±Øª Ùˆ Ø§Ù…Ù†ÛŒØª Ø¯Ø§Ø®Ù„ÛŒ | Ø§Ø¨Ø²Ø§Ø±Ù‡Ø§ÛŒ Ø¬Ø§Ù…Ø¹Ù‡ |
| **Ù¾ÛŒÚ†ÛŒØ¯Ú¯ÛŒ Ø§Ø³ØªÙ‚Ø±Ø§Ø±** | Ø³Ø§Ø¯Ù‡ (Ù†ØµØ¨ Ø¨Ø§ winget) | Ø³Ø§Ø¯Ù‡ (Ù†ØµØ¨ Ø¨Ø§ curl) |
| **Ø³Ø§Ø²Ú¯Ø§Ø±ÛŒ API** | OpenAI + Ø§ÙØ²ÙˆÙ†Ù‡â€ŒÙ‡Ø§ | Ø§Ø³ØªØ§Ù†Ø¯Ø§Ø±Ø¯ OpenAI |
| **Ù¾Ø´ØªÛŒØ¨Ø§Ù†ÛŒ** | Ø±Ø³Ù…ÛŒ Ù…Ø§ÛŒÚ©Ø±ÙˆØ³Ø§ÙØª | Ù…Ø¨ØªÙ†ÛŒ Ø¨Ø± Ø¬Ø§Ù…Ø¹Ù‡ |
| **Ø¨Ù‡ØªØ±ÛŒÙ† Ø¨Ø±Ø§ÛŒ** | Ø¹ÙˆØ§Ù…Ù„ ØªÙˆÙ„ÛŒØ¯ÛŒ | Ù†Ù…ÙˆÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø§ÙˆÙ„ÛŒÙ‡ Ùˆ ØªØ­Ù‚ÛŒÙ‚ |

**Ø²Ù…Ø§Ù† Ø§Ù†ØªØ®Ø§Ø¨ Ollama**:
- **ØªÙˆØ³Ø¹Ù‡ Ùˆ Ù†Ù…ÙˆÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø§ÙˆÙ„ÛŒÙ‡**: Ø¢Ø²Ù…Ø§ÛŒØ´ Ø³Ø±ÛŒØ¹ Ø¨Ø§ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ù…Ø®ØªÙ„Ù  
- **Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ø¬Ø§Ù…Ø¹Ù‡**: Ø¯Ø³ØªØ±Ø³ÛŒ Ø¨Ù‡ Ø¬Ø¯ÛŒØ¯ØªØ±ÛŒÙ† Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ø§Ø±Ø§Ø¦Ù‡ Ø´Ø¯Ù‡ ØªÙˆØ³Ø· Ø¬Ø§Ù…Ø¹Ù‡  
- **Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø¢Ù…ÙˆØ²Ø´ÛŒ**: ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ Ùˆ Ø¢Ù…ÙˆØ²Ø´ ØªÙˆØ³Ø¹Ù‡ Ø¹ÙˆØ§Ù…Ù„ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ  
- **Ù¾Ø±ÙˆÚ˜Ù‡â€ŒÙ‡Ø§ÛŒ ØªØ­Ù‚ÛŒÙ‚Ø§ØªÛŒ**: ØªØ­Ù‚ÛŒÙ‚Ø§Øª Ø¢Ú©Ø§Ø¯Ù…ÛŒÚ© Ø¨Ø§ Ù†ÛŒØ§Ø² Ø¨Ù‡ Ø¯Ø³ØªØ±Ø³ÛŒ Ø¨Ù‡ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ù…ØªÙ†ÙˆØ¹  
- **Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ø³ÙØ§Ø±Ø´ÛŒ**: Ø³Ø§Ø®Øª Ùˆ Ø¢Ø²Ù…Ø§ÛŒØ´ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ ØªÙ†Ø¸ÛŒÙ…â€ŒØ´Ø¯Ù‡ Ø³ÙØ§Ø±Ø´ÛŒ  

### VLLM: Ø§Ø³ØªÙ†ØªØ§Ø¬ Ø¹Ø§Ù…Ù„ SLM Ø¨Ø§ Ø¹Ù…Ù„Ú©Ø±Ø¯ Ø¨Ø§Ù„Ø§

VLLM (Ø§Ø³ØªÙ†ØªØ§Ø¬ Ù…Ø¯Ù„ Ø²Ø¨Ø§Ù† Ø¨Ø³ÛŒØ§Ø± Ø¨Ø²Ø±Ú¯) ÛŒÚ© Ù…ÙˆØªÙˆØ± Ø§Ø³ØªÙ†ØªØ§Ø¬ Ø¨Ø§ ØªÙˆØ§Ù† Ø¨Ø§Ù„Ø§ Ùˆ Ú©Ø§Ø±Ø¢Ù…Ø¯ Ø§Ø² Ù†Ø¸Ø± Ø­Ø§ÙØ¸Ù‡ Ø§Ø³Øª Ú©Ù‡ Ø¨Ù‡ Ø·ÙˆØ± Ø®Ø§Øµ Ø¨Ø±Ø§ÛŒ Ø§Ø³ØªÙ‚Ø±Ø§Ø±Ù‡Ø§ÛŒ ØªÙˆÙ„ÛŒØ¯ÛŒ SLM Ø¯Ø± Ù…Ù‚ÛŒØ§Ø³ Ø¨Ù‡ÛŒÙ†Ù‡ Ø´Ø¯Ù‡ Ø§Ø³Øª. Ø¯Ø± Ø­Ø§Ù„ÛŒ Ú©Ù‡ Foundry Local Ø¨Ø± Ø³Ù‡ÙˆÙ„Øª Ø§Ø³ØªÙØ§Ø¯Ù‡ ØªÙ…Ø±Ú©Ø² Ø¯Ø§Ø±Ø¯ Ùˆ Ollama Ø¨Ø± Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ø¬Ø§Ù…Ø¹Ù‡ ØªØ£Ú©ÛŒØ¯ Ø¯Ø§Ø±Ø¯ØŒ VLLM Ø¯Ø± Ø³Ù†Ø§Ø±ÛŒÙˆÙ‡Ø§ÛŒ Ø¨Ø§ Ø¹Ù…Ù„Ú©Ø±Ø¯ Ø¨Ø§Ù„Ø§ Ú©Ù‡ Ù†ÛŒØ§Ø² Ø¨Ù‡ Ø­Ø¯Ø§Ú©Ø«Ø± ØªÙˆØ§Ù† Ùˆ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ø§Ø±Ø¢Ù…Ø¯ Ø§Ø² Ù…Ù†Ø§Ø¨Ø¹ Ø¯Ø§Ø±Ù†Ø¯ØŒ Ø¨Ø±Ø¬Ø³ØªÙ‡ Ø§Ø³Øª.

**Ù…Ø¹Ù…Ø§Ø±ÛŒ Ùˆ ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ø§ØµÙ„ÛŒ**:
- **PagedAttention**: Ù…Ø¯ÛŒØ±ÛŒØª Ø­Ø§ÙØ¸Ù‡ Ø§Ù†Ù‚Ù„Ø§Ø¨ÛŒ Ø¨Ø±Ø§ÛŒ Ù…Ø­Ø§Ø³Ø¨Ø§Øª ØªÙˆØ¬Ù‡ Ú©Ø§Ø±Ø¢Ù…Ø¯  
- **Batching Ù¾ÙˆÛŒØ§**: Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒ Ù‡ÙˆØ´Ù…Ù†Ø¯ Ø¯Ø±Ø®ÙˆØ§Ø³Øªâ€ŒÙ‡Ø§ Ø¨Ø±Ø§ÛŒ ØªÙˆØ§Ù† Ø¨Ù‡ÛŒÙ†Ù‡  
- **Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ GPU**: Ù‡Ø³ØªÙ‡â€ŒÙ‡Ø§ÛŒ Ù¾ÛŒØ´Ø±ÙØªÙ‡ CUDA Ùˆ Ù¾Ø´ØªÛŒØ¨Ø§Ù†ÛŒ Ø§Ø² Ù…ÙˆØ§Ø²ÛŒâ€ŒØ³Ø§Ø²ÛŒ ØªÙ†Ø³ÙˆØ±  
- **Ø³Ø§Ø²Ú¯Ø§Ø±ÛŒ Ø¨Ø§ OpenAI**: Ø³Ø§Ø²Ú¯Ø§Ø±ÛŒ Ú©Ø§Ù…Ù„ API Ø¨Ø±Ø§ÛŒ ÛŒÚ©Ù¾Ø§Ø±Ú†Ú¯ÛŒ Ø¨ÛŒâ€ŒØ¯Ø±Ø¯Ø³Ø±  
- **Ø±Ù…Ø²Ú¯Ø´Ø§ÛŒÛŒ Ø­Ø¯Ø³ÛŒ**: ØªÚ©Ù†ÛŒÚ©â€ŒÙ‡Ø§ÛŒ Ù¾ÛŒØ´Ø±ÙØªÙ‡ ØªØ³Ø±ÛŒØ¹ Ø§Ø³ØªÙ†ØªØ§Ø¬  
- **Ù¾Ø´ØªÛŒØ¨Ø§Ù†ÛŒ Ø§Ø² Ú©Ù…ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ**: Ú©Ù…ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ INT4ØŒ INT8 Ùˆ FP16 Ø¨Ø±Ø§ÛŒ Ú©Ø§Ø±Ø§ÛŒÛŒ Ø­Ø§ÙØ¸Ù‡  

#### Ù†ØµØ¨ Ùˆ Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ

**Ú¯Ø²ÛŒÙ†Ù‡â€ŒÙ‡Ø§ÛŒ Ù†ØµØ¨**:
```bash
# Standard installation
pip install vllm

# With additional dependencies for agent frameworks
pip install vllm[agent] openai

# Docker deployment for production
docker pull vllm/vllm-openai:latest

# From source for latest features
git clone https://github.com/vllm-project/vllm.git
cd vllm
pip install -e .
```
  
**Ø´Ø±ÙˆØ¹ Ø³Ø±ÛŒØ¹ Ø¨Ø±Ø§ÛŒ ØªÙˆØ³Ø¹Ù‡ Ø¹Ø§Ù…Ù„**:
```bash
# Start VLLM server with SLM model
python -m vllm.entrypoints.openai.api_server \
    --model microsoft/Phi-3.5-mini-instruct \
    --trust-remote-code \
    --max-model-len 4096 \
    --gpu-memory-utilization 0.8

# Alternative: Start with Qwen2.5 for lightweight agents
python -m vllm.entrypoints.openai.api_server \
    --model Qwen/Qwen2.5-0.5B-Instruct \
    --trust-remote-code \
    --max-model-len 2048 \
    --tensor-parallel-size 1

# Test API endpoint
curl http://localhost:8000/v1/models

# Test chat completion
curl http://localhost:8000/v1/chat/completions \
    -H "Content-Type: application/json" \
    -d '{
        "model": "microsoft/Phi-3.5-mini-instruct",
        "messages": [{"role": "user", "content": "Hello!"}]
    }'
```
  

#### ÛŒÚ©Ù¾Ø§Ø±Ú†Ú¯ÛŒ Ø¨Ø§ Ú†Ø§Ø±Ú†ÙˆØ¨ Ø¹Ø§Ù…Ù„

**VLLM Ø¨Ø§ Microsoft Agent Framework**:
```python
from microsoft_agent_framework import Agent, Config
import openai
import subprocess
import time
import requests
from typing import Optional, Dict, Any

class VLLMManager:
    def __init__(self, model_name: str, 
                 host: str = "localhost", 
                 port: int = 8000,
                 gpu_memory_utilization: float = 0.8,
                 max_model_len: int = 4096):
        self.model_name = model_name
        self.host = host
        self.port = port
        self.base_url = f"http://{host}:{port}"
        self.gpu_memory_utilization = gpu_memory_utilization
        self.max_model_len = max_model_len
        self.process = None
        self.client = None
        
    def start_server(self) -> bool:
        """Start VLLM server with optimized settings for agents."""
        try:
            cmd = [
                "python", "-m", "vllm.entrypoints.openai.api_server",
                "--model", self.model_name,
                "--host", self.host,
                "--port", str(self.port),
                "--gpu-memory-utilization", str(self.gpu_memory_utilization),
                "--max-model-len", str(self.max_model_len),
                "--trust-remote-code",
                "--disable-log-requests",  # Reduce logging for agents
                "--served-model-name", self.get_served_model_name()
            ]
            
            self.process = subprocess.Popen(cmd, 
                stdout=subprocess.PIPE, 
                stderr=subprocess.PIPE)
            
            # Wait for server to start
            max_retries = 30
            for _ in range(max_retries):
                if self.health_check():
                    self.client = openai.OpenAI(base_url=f"{self.base_url}/v1")
                    return True
                time.sleep(2)
                
            return False
            
        except Exception as e:
            print(f"Failed to start VLLM server: {e}")
            return False
    
    def get_served_model_name(self) -> str:
        """Get a clean model name for serving."""
        return self.model_name.replace("/", "--")
    
    def health_check(self) -> bool:
        """Check if VLLM server is healthy."""
        try:
            response = requests.get(f"{self.base_url}/health", timeout=5)
            return response.status_code == 200
        except:
            return False
    
    def get_openai_client(self) -> openai.OpenAI:
        """Get OpenAI-compatible client for VLLM."""
        if not self.client:
            self.client = openai.OpenAI(base_url=f"{self.base_url}/v1")
        return self.client
    
    def get_model_info(self) -> Dict[str, Any]:
        """Get model information and statistics."""
        try:
            response = requests.get(f"{self.base_url}/v1/models")
            if response.status_code == 200:
                return response.json()
        except:
            pass
        return {}
    
    def shutdown(self):
        """Shutdown VLLM server."""
        if self.process:
            self.process.terminate()
            self.process.wait()

# Initialize VLLM for high-performance agents
vllm_manager = VLLMManager("microsoft/Phi-3.5-mini-instruct")
if vllm_manager.start_server():
    print("VLLM server started successfully")
    
    # Configure agent with VLLM backend
    agent_config = Config(
        name="vllm-performance-agent",
        model_provider="vllm",
        model_id=vllm_manager.get_served_model_name(),
        endpoint=f"{vllm_manager.base_url}/v1",
        api_key="none"  # VLLM doesn't require API key
    )
    
    agent = Agent(config=agent_config)
else:
    print("Failed to start VLLM server")
```
  
**Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ Ú†Ù†Ø¯ Ø¹Ø§Ù…Ù„ÛŒ Ø¨Ø§ ØªÙˆØ§Ù† Ø¨Ø§Ù„Ø§**:
```python
import asyncio
from concurrent.futures import ThreadPoolExecutor
from microsoft_agent_framework import Agent, Config
import openai

class VLLMHighThroughputManager:
    def __init__(self):
        self.model_configs = {
            "lightweight": {
                "model": "Qwen/Qwen2.5-0.5B-Instruct",
                "port": 8000,
                "max_model_len": 2048,
                "gpu_memory_utilization": 0.3
            },
            "balanced": {
                "model": "microsoft/Phi-3.5-mini-instruct",
                "port": 8001,
                "max_model_len": 4096,
                "gpu_memory_utilization": 0.5
            },
            "capable": {
                "model": "meta-llama/Llama-3.2-3B-Instruct",
                "port": 8002,
                "max_model_len": 8192,
                "gpu_memory_utilization": 0.7
            }
        }
        self.managers = {}
        self.agents = {}
        self.client_pool = {}
        
    async def initialize_all_models(self):
        """Initialize all VLLM models in parallel."""
        initialization_tasks = []
        
        for category, config in self.model_configs.items():
            task = self._initialize_model(category, config)
            initialization_tasks.append(task)
        
        results = await asyncio.gather(*initialization_tasks, return_exceptions=True)
        
        successful_inits = 0
        for i, result in enumerate(results):
            category = list(self.model_configs.keys())[i]
            if isinstance(result, Exception):
                print(f"Failed to initialize {category}: {result}")
            else:
                successful_inits += 1
                print(f"Successfully initialized {category} model")
        
        return successful_inits
    
    async def _initialize_model(self, category: str, config: Dict[str, Any]):
        """Initialize a single VLLM model instance."""
        manager = VLLMManager(
            model_name=config["model"],
            port=config["port"],
            max_model_len=config["max_model_len"],
            gpu_memory_utilization=config["gpu_memory_utilization"]
        )
        
        # Start server in thread to avoid blocking
        loop = asyncio.get_event_loop()
        with ThreadPoolExecutor() as executor:
            success = await loop.run_in_executor(executor, manager.start_server)
        
        if success:
            self.managers[category] = manager
            
            # Create agent
            agent_config = Config(
                name=f"vllm-{category}-agent",
                model_provider="vllm",
                model_id=manager.get_served_model_name(),
                endpoint=f"{manager.base_url}/v1",
                api_key="none"
            )
            
            self.agents[category] = Agent(config=agent_config)
            
            # Create client pool for high throughput
            self.client_pool[category] = [
                openai.OpenAI(base_url=f"{manager.base_url}/v1")
                for _ in range(5)  # 5 clients per model for parallelism
            ]
            
            return True
        else:
            raise Exception(f"Failed to start VLLM server for {category}")
    
    def get_optimal_agent(self, request_complexity: str, current_load: Dict[str, int]) -> str:
        """Select optimal agent based on request complexity and current load."""
        complexity_mapping = {
            "simple": "lightweight",
            "moderate": "balanced", 
            "complex": "capable"
        }
        
        preferred_category = complexity_mapping.get(request_complexity, "balanced")
        
        # Check if preferred agent is available and not overloaded
        if (preferred_category in self.agents and 
            current_load.get(preferred_category, 0) < 10):  # Max 10 concurrent per agent
            return preferred_category
        
        # Fallback to least loaded available agent
        available_agents = [(cat, load) for cat, load in current_load.items() 
                          if cat in self.agents and load < 10]
        
        if available_agents:
            return min(available_agents, key=lambda x: x[1])[0]
        
        return "balanced"  # Default fallback
    
    async def process_batch_requests(self, requests: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """Process multiple requests in parallel for maximum throughput."""
        current_load = {cat: 0 for cat in self.agents.keys()}
        tasks = []
        
        for request in requests:
            # Determine optimal agent
            complexity = request.get("complexity", "moderate")
            agent_category = self.get_optimal_agent(complexity, current_load)
            current_load[agent_category] += 1
            
            # Create processing task
            task = self._process_single_request(request, agent_category)
            tasks.append(task)
        
        # Process all requests in parallel
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # Format results
        formatted_results = []
        for i, result in enumerate(results):
            if isinstance(result, Exception):
                formatted_results.append({
                    "request_id": requests[i].get("id", i),
                    "status": "error",
                    "error": str(result)
                })
            else:
                formatted_results.append(result)
        
        return formatted_results
    
    async def _process_single_request(self, request: Dict[str, Any], agent_category: str) -> Dict[str, Any]:
        """Process a single request with the specified agent."""
        start_time = time.time()
        
        try:
            agent = self.agents[agent_category]
            response = await agent.chat_async(request["message"])
            
            processing_time = time.time() - start_time
            
            return {
                "request_id": request.get("id"),
                "status": "success",
                "response": response,
                "agent_used": agent_category,
                "processing_time": processing_time
            }
            
        except Exception as e:
            return {
                "request_id": request.get("id"),
                "status": "error",
                "error": str(e),
                "agent_used": agent_category,
                "processing_time": time.time() - start_time
            }

# High-throughput usage example
throughput_manager = VLLMHighThroughputManager()

# Initialize all models
initialized_count = await throughput_manager.initialize_all_models()
print(f"Initialized {initialized_count} models")

# Process batch requests
batch_requests = [
    {"id": 1, "message": "Simple question", "complexity": "simple"},
    {"id": 2, "message": "Complex analysis needed", "complexity": "complex"},
    {"id": 3, "message": "Moderate difficulty task", "complexity": "moderate"}
]

results = await throughput_manager.process_batch_requests(batch_requests)
for result in results:
    print(f"Request {result['request_id']}: {result['status']} in {result.get('processing_time', 0):.2f}s")
```
  

#### Ø§Ù„Ú¯ÙˆÙ‡Ø§ÛŒ Ø§Ø³ØªÙ‚Ø±Ø§Ø± ØªÙˆÙ„ÛŒØ¯ÛŒ

**Ø®Ø¯Ù…Ø§Øª ØªÙˆÙ„ÛŒØ¯ÛŒ VLLM Ø³Ø§Ø²Ù…Ø§Ù†ÛŒ**:
```python
import asyncio
import logging
import time
from typing import Dict, List, Optional
from dataclasses import dataclass
from microsoft_agent_framework import Agent, Config
import uvicorn
from fastapi import FastAPI, HTTPException, BackgroundTasks
from pydantic import BaseModel

@dataclass
class VLLMServerConfig:
    model_name: str
    port: int
    gpu_memory_utilization: float
    max_model_len: int
    tensor_parallel_size: int = 1
    quantization: Optional[str] = None

class AgentRequest(BaseModel):
    message: str
    agent_type: str = "general"
    priority: str = "normal"
    timeout: int = 30

class VLLMProductionService:
    def __init__(self, server_configs: Dict[str, VLLMServerConfig]):
        self.server_configs = server_configs
        self.managers = {}
        self.agents = {}
        self.metrics = {
            "requests_processed": 0,
            "requests_failed": 0,
            "total_processing_time": 0,
            "agent_usage": {name: 0 for name in server_configs.keys()},
            "throughput_per_minute": 0
        }
        self.request_queue = asyncio.Queue(maxsize=1000)
        self.processing_workers = []
        self.app = FastAPI(title="VLLM Agent Service")
        self._setup_routes()
        
    async def initialize_production_environment(self):
        """Initialize all VLLM servers for production."""
        logging.info("Initializing VLLM production environment...")
        
        initialization_tasks = []
        for name, config in self.server_configs.items():
            task = self._initialize_server(name, config)
            initialization_tasks.append(task)
        
        results = await asyncio.gather(*initialization_tasks, return_exceptions=True)
        
        successful_servers = 0
        for i, result in enumerate(results):
            server_name = list(self.server_configs.keys())[i]
            if isinstance(result, Exception):
                logging.error(f"Failed to initialize {server_name}: {result}")
            else:
                successful_servers += 1
                logging.info(f"Successfully initialized {server_name}")
        
        if successful_servers == 0:
            raise Exception("No VLLM servers could be initialized")
        
        # Start processing workers
        self.processing_workers = [
            asyncio.create_task(self._processing_worker(i))
            for i in range(min(4, successful_servers))  # 4 workers max
        ]
        
        logging.info(f"Production environment ready with {successful_servers} servers")
        return successful_servers
    
    async def _initialize_server(self, name: str, config: VLLMServerConfig):
        """Initialize a single VLLM server."""
        manager = VLLMManager(
            model_name=config.model_name,
            port=config.port,
            gpu_memory_utilization=config.gpu_memory_utilization,
            max_model_len=config.max_model_len
        )
        
        # Add quantization if specified
        if config.quantization:
            # This would be added to the manager's start command
            pass
        
        success = manager.start_server()
        if success:
            self.managers[name] = manager
            
            # Create production agent
            agent_config = Config(
                name=f"vllm-production-{name}",
                model_provider="vllm",
                model_id=manager.get_served_model_name(),
                endpoint=f"{manager.base_url}/v1",
                api_key="none",
                timeout=30.0
            )
            
            agent = Agent(config=agent_config)
            
            # Add production tools
            self._add_production_tools(agent, name)
            
            self.agents[name] = agent
            return True
        else:
            raise Exception(f"Failed to start VLLM server for {name}")
    
    def _add_production_tools(self, agent: Agent, server_type: str):
        """Add production tools based on server type."""
        if server_type == "customer_service":
            @agent.tool
            def escalate_to_human(issue: str, customer_id: str) -> str:
                """Escalate complex issues to human agents."""
                return f"Escalated issue for customer {customer_id}: {issue}"
            
            @agent.tool
            def lookup_order_status(order_id: str) -> dict:
                """Look up order status from production database."""
                # Production database lookup
                return {"order_id": order_id, "status": "shipped", "eta": "2 days"}
        
        elif server_type == "technical_support":
            @agent.tool
            def run_system_diagnostics(system_id: str) -> dict:
                """Run comprehensive system diagnostics."""
                return {"system_id": system_id, "status": "healthy", "issues": []}
            
            @agent.tool
            def create_incident_report(description: str, severity: str) -> str:
                """Create incident report in production system."""
                incident_id = f"INC-{hash(description) % 100000:05d}"
                return f"Created incident {incident_id} with severity {severity}"
    
    def _setup_routes(self):
        """Set up FastAPI routes for production service."""
        @self.app.post("/chat")
        async def chat_endpoint(request: AgentRequest, background_tasks: BackgroundTasks):
            try:
                # Add request to queue
                await self.request_queue.put({
                    "request": request,
                    "timestamp": time.time(),
                    "future": asyncio.Future()
                })
                
                # Wait for processing (with timeout)
                result = await asyncio.wait_for(
                    self._wait_for_result(request),
                    timeout=request.timeout
                )
                
                return result
                
            except asyncio.TimeoutError:
                raise HTTPException(status_code=408, detail="Request timeout")
            except Exception as e:
                raise HTTPException(status_code=500, detail=str(e))
        
        @self.app.get("/health")
        async def health_endpoint():
            return await self.get_health_status()
        
        @self.app.get("/metrics")
        async def metrics_endpoint():
            return self.get_production_metrics()
    
    async def _processing_worker(self, worker_id: int):
        """Background worker for processing agent requests."""
        logging.info(f"Starting processing worker {worker_id}")
        
        while True:
            try:
                # Get request from queue
                queue_item = await self.request_queue.get()
                request_data = queue_item["request"]
                request_future = queue_item["future"]
                
                # Select appropriate agent
                agent_name = self._select_agent(request_data.agent_type)
                
                if agent_name not in self.agents:
                    request_future.set_exception(Exception(f"Agent {agent_name} not available"))
                    continue
                
                # Process request
                start_time = time.time()
                try:
                    agent = self.agents[agent_name]
                    response = await agent.chat_async(request_data.message)
                    
                    processing_time = time.time() - start_time
                    
                    # Update metrics
                    self.metrics["requests_processed"] += 1
                    self.metrics["total_processing_time"] += processing_time
                    self.metrics["agent_usage"][agent_name] += 1
                    
                    result = {
                        "response": response,
                        "agent_used": agent_name,
                        "processing_time": processing_time,
                        "worker_id": worker_id
                    }
                    
                    request_future.set_result(result)
                    
                except Exception as e:
                    self.metrics["requests_failed"] += 1
                    request_future.set_exception(e)
                
                finally:
                    self.request_queue.task_done()
                    
            except Exception as e:
                logging.error(f"Worker {worker_id} error: {e}")
                await asyncio.sleep(1)
    
    def _select_agent(self, agent_type: str) -> str:
        """Select appropriate agent based on request type."""
        agent_mapping = {
            "customer_service": "customer_service",
            "technical": "technical_support",
            "general": "general_purpose"
        }
        
        return agent_mapping.get(agent_type, "general_purpose")
    
    async def _wait_for_result(self, request: AgentRequest):
        """Wait for request processing to complete."""
        # This is simplified - in production you'd track futures properly
        await asyncio.sleep(0.1)  # Placeholder
        return {"response": "Processed", "status": "success"}
    
    async def get_health_status(self) -> dict:
        """Get comprehensive health status of all services."""
        health_status = {
            "overall_status": "healthy",
            "servers": {},
            "queue_size": self.request_queue.qsize(),
            "active_workers": len([w for w in self.processing_workers if not w.done()]),
            "timestamp": time.time()
        }
        
        unhealthy_servers = 0
        for name, manager in self.managers.items():
            try:
                is_healthy = manager.health_check()
                health_status["servers"][name] = {
                    "status": "healthy" if is_healthy else "unhealthy",
                    "endpoint": manager.base_url,
                    "model": manager.model_name
                }
                if not is_healthy:
                    unhealthy_servers += 1
            except Exception as e:
                health_status["servers"][name] = {
                    "status": "error",
                    "error": str(e)
                }
                unhealthy_servers += 1
        
        if unhealthy_servers > 0:
            health_status["overall_status"] = "degraded" if unhealthy_servers < len(self.managers) else "unhealthy"
        
        return health_status
    
    def get_production_metrics(self) -> dict:
        """Get production performance metrics."""
        total_requests = self.metrics["requests_processed"] + self.metrics["requests_failed"]
        avg_processing_time = (
            self.metrics["total_processing_time"] / self.metrics["requests_processed"]
            if self.metrics["requests_processed"] > 0 else 0
        )
        
        success_rate = (
            self.metrics["requests_processed"] / total_requests * 100
            if total_requests > 0 else 0
        )
        
        return {
            "total_requests": total_requests,
            "successful_requests": self.metrics["requests_processed"],
            "failed_requests": self.metrics["requests_failed"],
            "success_rate_percent": success_rate,
            "average_processing_time_seconds": avg_processing_time,
            "agent_usage_distribution": self.metrics["agent_usage"],
            "queue_size": self.request_queue.qsize()
        }
    
    async def start_production_server(self, host: str = "0.0.0.0", port: int = 8080):
        """Start the production FastAPI server."""
        config = uvicorn.Config(
            self.app,
            host=host,
            port=port,
            log_level="info",
            workers=1  # Single worker for simplicity
        )
        server = uvicorn.Server(config)
        await server.serve()

# Production deployment example
production_configs = {
    "customer_service": VLLMServerConfig(
        model_name="microsoft/Phi-3.5-mini-instruct",
        port=8000,
        gpu_memory_utilization=0.4,
        max_model_len=4096
    ),
    "technical_support": VLLMServerConfig(
        model_name="meta-llama/Llama-3.2-3B-Instruct",
        port=8001,
        gpu_memory_utilization=0.6,
        max_model_len=8192
    ),
    "general_purpose": VLLMServerConfig(
        model_name="Qwen/Qwen2.5-1.5B-Instruct",
        port=8002,
        gpu_memory_utilization=0.3,
        max_model_len=2048
    )
}

production_service = VLLMProductionService(production_configs)

# Initialize and start production service
# await production_service.initialize_production_environment()
# await production_service.start_production_server()
```
  

#### ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ø³Ø§Ø²Ù…Ø§Ù†ÛŒ Ùˆ Ù†Ø¸Ø§Ø±Øª

**Ù†Ø¸Ø§Ø±Øª Ù¾ÛŒØ´Ø±ÙØªÙ‡ Ø¹Ù…Ù„Ú©Ø±Ø¯ VLLM**:
```python
import psutil
import nvidia_ml_py3 as nvml
from dataclasses import dataclass
from typing import List, Dict, Optional
import json
import asyncio

@dataclass
class PerformanceMetrics:
    timestamp: float
    requests_per_second: float
    average_latency_ms: float
    gpu_utilization_percent: float
    gpu_memory_used_gb: float
    cpu_utilization_percent: float
    memory_used_gb: float
    queue_length: int
    active_requests: int

class VLLMAdvancedMonitoring:
    def __init__(self, vllm_managers: Dict[str, VLLMManager]):
        self.managers = vllm_managers
        self.metrics_history = []
        self.alert_thresholds = {
            "gpu_utilization_max": 95,
            "gpu_memory_max_gb": 10,
            "latency_max_ms": 3000,
            "queue_length_max": 50,
            "error_rate_max_percent": 10
        }
        
        # Initialize NVIDIA ML for GPU monitoring
        try:
            nvml.nvmlInit()
            self.gpu_monitoring_available = True
            self.gpu_count = nvml.nvmlDeviceGetCount()
        except:
            self.gpu_monitoring_available = False
            self.gpu_count = 0
    
    async def collect_comprehensive_metrics(self) -> Dict[str, PerformanceMetrics]:
        """Collect detailed performance metrics for all VLLM instances."""
        all_metrics = {}
        
        for name, manager in self.managers.items():
            try:
                metrics = await self._collect_single_instance_metrics(name, manager)
                all_metrics[name] = metrics
            except Exception as e:
                logging.error(f"Failed to collect metrics for {name}: {e}")
                # Create error metrics
                all_metrics[name] = PerformanceMetrics(
                    timestamp=time.time(),
                    requests_per_second=0,
                    average_latency_ms=0,
                    gpu_utilization_percent=0,
                    gpu_memory_used_gb=0,
                    cpu_utilization_percent=0,
                    memory_used_gb=0,
                    queue_length=0,
                    active_requests=0
                )
        
        return all_metrics
    
    async def _collect_single_instance_metrics(self, name: str, manager: VLLMManager) -> PerformanceMetrics:
        """Collect metrics for a single VLLM instance."""
        timestamp = time.time()
        
        # Get VLLM-specific metrics via API
        vllm_stats = await self._get_vllm_stats(manager)
        
        # Get system metrics
        cpu_percent = psutil.cpu_percent(interval=0.1)
        memory_info = psutil.virtual_memory()
        memory_used_gb = memory_info.used / (1024**3)
        
        # Get GPU metrics if available
        gpu_utilization = 0
        gpu_memory_used = 0
        
        if self.gpu_monitoring_available and self.gpu_count > 0:
            try:
                # Assuming first GPU for simplicity
                handle = nvml.nvmlDeviceGetHandleByIndex(0)
                gpu_util = nvml.nvmlDeviceGetUtilizationRates(handle)
                gpu_utilization = gpu_util.gpu
                
                gpu_mem = nvml.nvmlDeviceGetMemoryInfo(handle)
                gpu_memory_used = gpu_mem.used / (1024**3)
                
            except Exception as e:
                logging.warning(f"GPU monitoring failed: {e}")
        
        return PerformanceMetrics(
            timestamp=timestamp,
            requests_per_second=vllm_stats.get("requests_per_second", 0),
            average_latency_ms=vllm_stats.get("average_latency_ms", 0),
            gpu_utilization_percent=gpu_utilization,
            gpu_memory_used_gb=gpu_memory_used,
            cpu_utilization_percent=cpu_percent,
            memory_used_gb=memory_used_gb,
            queue_length=vllm_stats.get("queue_length", 0),
            active_requests=vllm_stats.get("active_requests", 0)
        )
    
    async def _get_vllm_stats(self, manager: VLLMManager) -> dict:
        """Get VLLM-specific statistics via API calls."""
        try:
            # Test inference to measure latency
            start_time = time.time()
            client = manager.get_openai_client()
            
            response = await asyncio.wait_for(
                asyncio.to_thread(
                    client.chat.completions.create,
                    model=manager.get_served_model_name(),
                    messages=[{"role": "user", "content": "ping"}],
                    max_tokens=1
                ),
                timeout=5.0
            )
            
            latency_ms = (time.time() - start_time) * 1000
            
            return {
                "average_latency_ms": latency_ms,
                "requests_per_second": 1000 / latency_ms if latency_ms > 0 else 0,
                "queue_length": 0,  # Would need to be exposed by VLLM
                "active_requests": 1  # Approximation
            }
            
        except Exception as e:
            logging.warning(f"Failed to get VLLM stats: {e}")
            return {
                "average_latency_ms": 0,
                "requests_per_second": 0,
                "queue_length": 0,
                "active_requests": 0
            }
    
    def generate_performance_report(self, time_window_minutes: int = 60) -> dict:
        """Generate comprehensive performance report."""
        cutoff_time = time.time() - (time_window_minutes * 60)
        recent_metrics = [
            metrics for metrics in self.metrics_history
            if any(m.timestamp > cutoff_time for m in metrics.values())
        ]
        
        if not recent_metrics:
            return {"error": "No recent metrics available"}
        
        report = {
            "time_window_minutes": time_window_minutes,
            "total_samples": len(recent_metrics),
            "instances": {}
        }
        
        # Analyze each instance
        for instance_name in self.managers.keys():
            instance_metrics = [
                metrics[instance_name] for metrics in recent_metrics
                if instance_name in metrics
            ]
            
            if instance_metrics:
                report["instances"][instance_name] = {
                    "avg_latency_ms": sum(m.average_latency_ms for m in instance_metrics) / len(instance_metrics),
                    "max_latency_ms": max(m.average_latency_ms for m in instance_metrics),
                    "avg_gpu_utilization": sum(m.gpu_utilization_percent for m in instance_metrics) / len(instance_metrics),
                    "avg_requests_per_second": sum(m.requests_per_second for m in instance_metrics) / len(instance_metrics),
                    "max_queue_length": max(m.queue_length for m in instance_metrics),
                    "availability_percent": (len(instance_metrics) / len(recent_metrics)) * 100
                }
        
        return report
    
    async def auto_scaling_recommendations(self) -> List[dict]:
        """Generate auto-scaling recommendations based on performance metrics."""
        recommendations = []
        
        if not self.metrics_history:
            return recommendations
        
        latest_metrics = self.metrics_history[-1]
        
        for instance_name, metrics in latest_metrics.items():
            # High latency recommendation
            if metrics.average_latency_ms > self.alert_thresholds["latency_max_ms"]:
                recommendations.append({
                    "instance": instance_name,
                    "type": "scale_up",
                    "reason": f"High latency: {metrics.average_latency_ms:.0f}ms",
                    "suggestion": "Consider adding tensor parallelism or increasing GPU memory"
                })
            
            # High GPU utilization recommendation
            if metrics.gpu_utilization_percent > self.alert_thresholds["gpu_utilization_max"]:
                recommendations.append({
                    "instance": instance_name,
                    "type": "scale_out",
                    "reason": f"High GPU utilization: {metrics.gpu_utilization_percent:.1f}%",
                    "suggestion": "Consider adding additional GPU instances"
                })
            
            # Low utilization recommendation
            if (metrics.gpu_utilization_percent < 20 and 
                metrics.requests_per_second < 1):
                recommendations.append({
                    "instance": instance_name,
                    "type": "scale_down",
                    "reason": f"Low utilization: {metrics.gpu_utilization_percent:.1f}% GPU, {metrics.requests_per_second:.1f} RPS",
                    "suggestion": "Consider consolidating workloads or reducing resources"
                })
        
        return recommendations

# Advanced monitoring setup
monitoring = VLLMAdvancedMonitoring({
    "customer_service": vllm_manager,
    # Add other managers as needed
})

async def advanced_monitoring_loop():
    """Advanced monitoring with auto-scaling recommendations."""
    while True:
        try:
            # Collect metrics
            metrics = await monitoring.collect_comprehensive_metrics()
            monitoring.metrics_history.append(metrics)
            
            # Keep only last 1000 entries
            if len(monitoring.metrics_history) > 1000:
                monitoring.metrics_history = monitoring.metrics_history[-1000:]
            
            # Generate recommendations every 5 minutes
            if len(monitoring.metrics_history) % 10 == 0:  # Every 10th collection (5 minutes if collecting every 30s)
                recommendations = await monitoring.auto_scaling_recommendations()
                
                if recommendations:
                    logging.info(f"Auto-scaling recommendations: {recommendations}")
            
            # Generate performance report every hour
            if len(monitoring.metrics_history) % 120 == 0:  # Every 120th collection (1 hour)
                report = monitoring.generate_performance_report(60)
                logging.info(f"Performance report: {json.dumps(report, indent=2)}")
            
        except Exception as e:
            logging.error(f"Advanced monitoring error: {e}")
        
        await asyncio.sleep(30)  # Collect metrics every 30 seconds

# Start advanced monitoring
# asyncio.create_task(advanced_monitoring_loop())
```
  

#### ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ùˆ Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ù¾ÛŒØ´Ø±ÙØªÙ‡

**Ø§Ù„Ú¯ÙˆÙ‡Ø§ÛŒ ØªÙ†Ø¸ÛŒÙ…Ø§Øª ØªÙˆÙ„ÛŒØ¯ÛŒ VLLM**:
```python
from enum import Enum
from typing import Dict, Any

class DeploymentScenario(Enum):
    DEVELOPMENT = "development"
    STAGING = "staging"
    PRODUCTION_LOW = "production_low"
    PRODUCTION_HIGH = "production_high"
    ENTERPRISE = "enterprise"

class VLLMConfigTemplates:
    """Production-ready VLLM configuration templates."""
    
    @staticmethod
    def get_config_template(scenario: DeploymentScenario) -> Dict[str, Any]:
        """Get optimized configuration for deployment scenario."""
        
        templates = {
            DeploymentScenario.DEVELOPMENT: {
                "gpu_memory_utilization": 0.6,
                "max_model_len": 2048,
                "tensor_parallel_size": 1,
                "pipeline_parallel_size": 1,
                "quantization": None,
                "enable_prefix_caching": False,
                "max_num_seqs": 32,
                "max_num_batched_tokens": 2048
            },
            
            DeploymentScenario.STAGING: {
                "gpu_memory_utilization": 0.8,
                "max_model_len": 4096,
                "tensor_parallel_size": 1,
                "pipeline_parallel_size": 1,
                "quantization": "awq",
                "enable_prefix_caching": True,
                "max_num_seqs": 64,
                "max_num_batched_tokens": 4096
            },
            
            DeploymentScenario.PRODUCTION_LOW: {
                "gpu_memory_utilization": 0.85,
                "max_model_len": 4096,
                "tensor_parallel_size": 1,
                "pipeline_parallel_size": 1,
                "quantization": "awq",
                "enable_prefix_caching": True,
                "max_num_seqs": 128,
                "max_num_batched_tokens": 8192,
                "enable_chunked_prefill": True
            },
            
            DeploymentScenario.PRODUCTION_HIGH: {
                "gpu_memory_utilization": 0.9,
                "max_model_len": 8192,
                "tensor_parallel_size": 2,
                "pipeline_parallel_size": 1,
                "quantization": "awq",
                "enable_prefix_caching": True,
                "max_num_seqs": 256,
                "max_num_batched_tokens": 16384,
                "enable_chunked_prefill": True,
                "speculative_model": "small_draft_model"
            },
            
            DeploymentScenario.ENTERPRISE: {
                "gpu_memory_utilization": 0.95,
                "max_model_len": 16384,
                "tensor_parallel_size": 4,
                "pipeline_parallel_size": 2,
                "quantization": "awq",
                "enable_prefix_caching": True,
                "max_num_seqs": 512,
                "max_num_batched_tokens": 32768,
                "enable_chunked_prefill": True,
                "speculative_model": "optimized_draft_model",
                "guided_decoding_backend": "outlines"
            }
        }
        
        return templates[scenario]
    
    @staticmethod
    def generate_vllm_command(model_name: str, 
                             scenario: DeploymentScenario,
                             port: int = 8000,
                             host: str = "0.0.0.0") -> List[str]:
        """Generate optimized VLLM command for deployment scenario."""
        
        config = VLLMConfigTemplates.get_config_template(scenario)
        
        cmd = [
            "python", "-m", "vllm.entrypoints.openai.api_server",
            "--model", model_name,
            "--host", host,
            "--port", str(port),
            "--gpu-memory-utilization", str(config["gpu_memory_utilization"]),
            "--max-model-len", str(config["max_model_len"]),
            "--tensor-parallel-size", str(config["tensor_parallel_size"]),
            "--max-num-seqs", str(config["max_num_seqs"]),
            "--max-num-batched-tokens", str(config["max_num_batched_tokens"]),
            "--trust-remote-code",
            "--disable-log-requests"
        ]
        
        # Add optional parameters
        if config.get("quantization"):
            cmd.extend(["--quantization", config["quantization"]])
        
        if config.get("enable_prefix_caching"):
            cmd.append("--enable-prefix-caching")
        
        if config.get("enable_chunked_prefill"):
            cmd.append("--enable-chunked-prefill")
        
        if config.get("pipeline_parallel_size", 1) > 1:
            cmd.extend(["--pipeline-parallel-size", str(config["pipeline_parallel_size"])])
        
        if config.get("speculative_model"):
            cmd.extend(["--speculative-model", config["speculative_model"]])
        
        return cmd

# Usage examples
dev_cmd = VLLMConfigTemplates.generate_vllm_command(
    "microsoft/Phi-3.5-mini-instruct",
    DeploymentScenario.DEVELOPMENT,
    port=8000
)

prod_cmd = VLLMConfigTemplates.generate_vllm_command(
    "microsoft/Phi-3.5-mini-instruct",
    DeploymentScenario.PRODUCTION_HIGH,
    port=8001
)

print(f"Development command: {' '.join(dev_cmd)}")
print(f"Production command: {' '.join(prod_cmd)}")
```
  
**Ú†Ú©â€ŒÙ„ÛŒØ³Øª Ø§Ø³ØªÙ‚Ø±Ø§Ø± ØªÙˆÙ„ÛŒØ¯ÛŒ Ø¨Ø±Ø§ÛŒ VLLM**:

âœ… **Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø³Ø®Øªâ€ŒØ§ÙØ²Ø§Ø±**:
- ØªÙ†Ø¸ÛŒÙ… Ù…ÙˆØ§Ø²ÛŒâ€ŒØ³Ø§Ø²ÛŒ ØªÙ†Ø³ÙˆØ± Ø¨Ø±Ø§ÛŒ ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ú†Ù†Ø¯ GPU  
- ÙØ¹Ø§Ù„â€ŒØ³Ø§Ø²ÛŒ Ú©Ù…ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ (AWQ/GPTQ) Ø¨Ø±Ø§ÛŒ Ú©Ø§Ø±Ø§ÛŒÛŒ Ø­Ø§ÙØ¸Ù‡  
- ØªÙ†Ø¸ÛŒÙ… Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø¨Ù‡ÛŒÙ†Ù‡ Ø§Ø² Ø­Ø§ÙØ¸Ù‡ GPU (85-95%)  
- ØªÙ†Ø¸ÛŒÙ… Ø§Ù†Ø¯Ø§Ø²Ù‡ Ø¯Ø³ØªÙ‡â€ŒÙ‡Ø§ÛŒ Ù…Ù†Ø§Ø³Ø¨ Ø¨Ø±Ø§ÛŒ ØªÙˆØ§Ù†  

âœ… **ØªÙ†Ø¸ÛŒÙ… Ø¹Ù…Ù„Ú©Ø±Ø¯**:
- ÙØ¹Ø§Ù„â€ŒØ³Ø§Ø²ÛŒ Ú©Ø´ Ù¾ÛŒØ´ÙˆÙ†Ø¯ Ø¨Ø±Ø§ÛŒ Ù¾Ø±Ø³Ø´â€ŒÙ‡Ø§ÛŒ ØªÚ©Ø±Ø§Ø±ÛŒ  
- ØªÙ†Ø¸ÛŒÙ… Ù¾ÛŒØ´â€ŒÙ¾Ø± Ú©Ø±Ø¯Ù† Ù‚Ø·Ø¹Ù‡â€ŒØ§ÛŒ Ø¨Ø±Ø§ÛŒ Ø¯Ù†Ø¨Ø§Ù„Ù‡â€ŒÙ‡Ø§ÛŒ Ø·ÙˆÙ„Ø§Ù†ÛŒ  
- Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ Ø±Ù…Ø²Ú¯Ø´Ø§ÛŒÛŒ Ø­Ø¯Ø³ÛŒ Ø¨Ø±Ø§ÛŒ Ø§Ø³ØªÙ†ØªØ§Ø¬ Ø³Ø±ÛŒØ¹â€ŒØªØ±  
- Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ max_num_seqs Ø¨Ø± Ø§Ø³Ø§Ø³ Ø³Ø®Øªâ€ŒØ§ÙØ²Ø§Ø±  

âœ… **ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒ ØªÙˆÙ„ÛŒØ¯ÛŒ**:
- Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ Ù†Ø¸Ø§Ø±Øª Ø¨Ø± Ø³Ù„Ø§Ù…Øª Ùˆ Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒ Ù…Ø¹ÛŒØ§Ø±Ù‡Ø§  
- ØªÙ†Ø¸ÛŒÙ… Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ Ù…Ø¬Ø¯Ø¯ Ø®ÙˆØ¯Ú©Ø§Ø± Ùˆ Ø®Ø±Ø§Ø¨ÛŒ  
- Ù¾ÛŒØ§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ ØµÙ Ø¯Ø±Ø®ÙˆØ§Ø³Øª Ùˆ ØªØ¹Ø§Ø¯Ù„ Ø¨Ø§Ø±  
- Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ Ø«Ø¨Øª Ø¬Ø§Ù…Ø¹ Ùˆ Ù‡Ø´Ø¯Ø§Ø±Ø¯Ù‡ÛŒ  

âœ… **Ø§Ù…Ù†ÛŒØª Ùˆ Ù‚Ø§Ø¨Ù„ÛŒØª Ø§Ø·Ù…ÛŒÙ†Ø§Ù†**:
- ØªÙ†Ø¸ÛŒÙ… Ù‚ÙˆØ§Ù†ÛŒÙ† ÙØ§ÛŒØ±ÙˆØ§Ù„ Ùˆ Ú©Ù†ØªØ±Ù„â€ŒÙ‡Ø§ÛŒ Ø¯Ø³ØªØ±Ø³ÛŒ  
- Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ Ù…Ø­Ø¯ÙˆØ¯ÛŒØª Ù†Ø±Ø® API Ùˆ Ø§Ø­Ø±Ø§Ø² Ù‡ÙˆÛŒØª  
- Ù¾ÛŒØ§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø®Ø§Ù…ÙˆØ´ÛŒ Ùˆ Ù¾Ø§Ú©Ø³Ø§Ø²ÛŒ Ø¢Ø±Ø§Ù…  
- ØªÙ†Ø¸ÛŒÙ… Ù¾Ø´ØªÛŒØ¨Ø§Ù†â€ŒÚ¯ÛŒØ±ÛŒ Ùˆ Ø¨Ø§Ø²ÛŒØ§Ø¨ÛŒ Ø¯Ø± Ø¨Ø±Ø§Ø¨Ø± Ø¨Ù„Ø§ÛŒØ§  

âœ… **Ø¢Ø²Ù…Ø§ÛŒØ´ ÛŒÚ©Ù¾Ø§Ø±Ú†Ú¯ÛŒ**:
- Ø¢Ø²Ù…Ø§ÛŒØ´ ÛŒÚ©Ù¾Ø§Ø±Ú†Ú¯ÛŒ Microsoft Agent Framework  
- Ø§Ø¹ØªØ¨Ø§Ø±Ø³Ù†Ø¬ÛŒ Ø³Ù†Ø§Ø±ÛŒÙˆÙ‡Ø§ÛŒ Ø¨Ø§ ØªÙˆØ§Ù† Ø¨Ø§Ù„Ø§  
- Ø¢Ø²Ù…Ø§ÛŒØ´ Ø®Ø±Ø§Ø¨ÛŒ Ùˆ Ø±ÙˆØ´â€ŒÙ‡Ø§ÛŒ Ø¨Ø§Ø²ÛŒØ§Ø¨ÛŒ  
- Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ Ø¹Ù…Ù„Ú©Ø±Ø¯ ØªØ­Øª Ø¨Ø§Ø±  

**Ù…Ù‚Ø§ÛŒØ³Ù‡ Ø¨Ø§ Ø³Ø§ÛŒØ± Ø±Ø§Ù‡â€ŒØ­Ù„â€ŒÙ‡Ø§**:

| ÙˆÛŒÚ˜Ú¯ÛŒ | VLLM | Foundry Local | Ollama |
|-------|------|---------------|--------|
| **Ù…ÙˆØ±Ø¯ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù‡Ø¯Ù** | ØªÙˆÙ„ÛŒØ¯ Ø¨Ø§ ØªÙˆØ§Ù† Ø¨Ø§Ù„Ø§ | Ø³Ù‡ÙˆÙ„Øª Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø³Ø§Ø²Ù…Ø§Ù†ÛŒ | ØªÙˆØ³Ø¹Ù‡ Ùˆ Ø¬Ø§Ù…Ø¹Ù‡ |
| **Ø¹Ù…Ù„Ú©Ø±Ø¯** | ØªÙˆØ§Ù† Ø­Ø¯Ø§Ú©Ø«Ø±ÛŒ | Ù…ØªØ¹Ø§Ø¯Ù„ | Ø®ÙˆØ¨ |
| **Ú©Ø§Ø±Ø§ÛŒÛŒ Ø­Ø§ÙØ¸Ù‡** | Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ PagedAttention | Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø®ÙˆØ¯Ú©Ø§Ø± | Ø§Ø³ØªØ§Ù†Ø¯Ø§Ø±Ø¯ |
| **Ù¾ÛŒÚ†ÛŒØ¯Ú¯ÛŒ ØªÙ†Ø¸ÛŒÙ…Ø§Øª** | Ø¨Ø§Ù„Ø§ (Ù¾Ø§Ø±Ø§Ù…ØªØ±Ù‡Ø§ÛŒ Ø²ÛŒØ§Ø¯) | Ù¾Ø§ÛŒÛŒÙ† (Ø®ÙˆØ¯Ú©Ø§Ø±) | Ù¾Ø§ÛŒÛŒÙ† (Ø³Ø§Ø¯Ù‡) |
| **Ù…Ù‚ÛŒØ§Ø³â€ŒÙ¾Ø°ÛŒØ±ÛŒ** | Ø¹Ø§Ù„ÛŒ (Ù…ÙˆØ§Ø²ÛŒâ€ŒØ³Ø§Ø²ÛŒ ØªÙ†Ø³ÙˆØ±/Ø®Ø· Ù„ÙˆÙ„Ù‡) | Ø®ÙˆØ¨ | Ù…Ø­Ø¯ÙˆØ¯ |
| **Ú©Ù…ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ** | Ù¾ÛŒØ´Ø±ÙØªÙ‡ (AWQØŒ GPTQØŒ FP8) | Ø®ÙˆØ¯Ú©Ø§Ø± | Ø§Ø³ØªØ§Ù†Ø¯Ø§Ø±Ø¯ GGUF |
| **ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ø³Ø§Ø²Ù…Ø§Ù†ÛŒ** | Ù†ÛŒØ§Ø² Ø¨Ù‡ Ù¾ÛŒØ§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø³ÙØ§Ø±Ø´ÛŒ | Ø¯Ø§Ø®Ù„ÛŒ | Ø§Ø¨Ø²Ø§Ø±Ù‡Ø§ÛŒ Ø¬Ø§Ù…Ø¹Ù‡ |
| **Ø¨Ù‡ØªØ±ÛŒÙ† Ø¨Ø±Ø§ÛŒ** | Ø¹ÙˆØ§Ù…Ù„ ØªÙˆÙ„ÛŒØ¯ÛŒ Ø¯Ø± Ù…Ù‚ÛŒØ§Ø³ Ø¨Ø§Ù„Ø§ | ØªÙˆÙ„ÛŒØ¯ Ø³Ø§Ø²Ù…Ø§Ù†ÛŒ | ØªÙˆØ³Ø¹Ù‡ |

**Ø²Ù…Ø§Ù† Ø§Ù†ØªØ®Ø§Ø¨ VLLM**:
- **Ù†ÛŒØ§Ø²Ù‡Ø§ÛŒ ØªÙˆØ§Ù† Ø¨Ø§Ù„Ø§**: Ù¾Ø±Ø¯Ø§Ø²Ø´ ØµØ¯Ù‡Ø§ Ø¯Ø±Ø®ÙˆØ§Ø³Øª Ø¯Ø± Ø«Ø§Ù†ÛŒÙ‡  
- **Ø§Ø³ØªÙ‚Ø±Ø§Ø±Ù‡Ø§ÛŒ Ø¨Ø²Ø±Ú¯â€ŒÙ…Ù‚ÛŒØ§Ø³**: ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ú†Ù†Ø¯ GPUØŒ Ú†Ù†Ø¯ Ú¯Ø±Ù‡  
- **Ø¹Ù…Ù„Ú©Ø±Ø¯ Ø­ÛŒØ§ØªÛŒ**: Ø²Ù…Ø§Ù† Ù¾Ø§Ø³Ø® Ø²ÛŒØ± Ø«Ø§Ù†ÛŒÙ‡ Ø¯Ø± Ù…Ù‚ÛŒØ§Ø³  
- **Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ù¾ÛŒØ´Ø±ÙØªÙ‡**: Ù†ÛŒØ§Ø² Ø¨Ù‡ Ú©Ù…ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ùˆ Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒ Ø³ÙØ§Ø±Ø´ÛŒ  
- **Ú©Ø§Ø±Ø§ÛŒÛŒ Ù…Ù†Ø§Ø¨Ø¹**: Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø­Ø¯Ø§Ú©Ø«Ø±ÛŒ Ø§Ø² Ø³Ø®Øªâ€ŒØ§ÙØ²Ø§Ø± GPU Ú¯Ø±Ø§Ù†â€ŒÙ‚ÛŒÙ…Øª  

## Ú©Ø§Ø±Ø¨Ø±Ø¯Ù‡Ø§ÛŒ ÙˆØ§Ù‚Ø¹ÛŒ Ø¹ÙˆØ§Ù…Ù„ SLM

### Ø¹ÙˆØ§Ù…Ù„ SLM Ø®Ø¯Ù…Ø§Øª Ù…Ø´ØªØ±ÛŒ
- **Ù‚Ø§Ø¨Ù„ÛŒØªâ€ŒÙ‡Ø§ÛŒ SLM**: Ø¬Ø³ØªØ¬ÙˆÛŒ Ø­Ø³Ø§Ø¨â€ŒÙ‡Ø§ØŒ ØªÙ†Ø¸ÛŒÙ… Ù…Ø¬Ø¯Ø¯ Ø±Ù…Ø² Ø¹Ø¨ÙˆØ±ØŒ Ø¨Ø±Ø±Ø³ÛŒ ÙˆØ¶Ø¹ÛŒØª Ø³ÙØ§Ø±Ø´  
- **Ù…Ø²Ø§ÛŒØ§ÛŒ Ù‡Ø²ÛŒÙ†Ù‡**: Ú©Ø§Ù‡Ø´ 10 Ø¨Ø±Ø§Ø¨Ø±ÛŒ Ù‡Ø²ÛŒÙ†Ù‡â€ŒÙ‡Ø§ÛŒ Ø§Ø³ØªÙ†ØªØ§Ø¬ Ù†Ø³Ø¨Øª Ø¨Ù‡ Ø¹ÙˆØ§Ù…Ù„ LLM  
- **Ø¹Ù…Ù„Ú©Ø±Ø¯**: Ø²Ù…Ø§Ù†â€ŒÙ‡Ø§ÛŒ Ù¾Ø§Ø³Ø® Ø³Ø±ÛŒØ¹â€ŒØªØ± Ø¨Ø§ Ú©ÛŒÙÛŒØª Ø«Ø§Ø¨Øª Ø¨Ø±Ø§ÛŒ Ù¾Ø±Ø³Ø´â€ŒÙ‡Ø§ÛŒ Ù…Ø¹Ù…ÙˆÙ„  

### Ø¹ÙˆØ§Ù…Ù„ SLM ÙØ±Ø¢ÛŒÙ†Ø¯Ù‡Ø§ÛŒ Ú©Ø³Ø¨â€ŒÙˆÚ©Ø§Ø±
- **Ø¹ÙˆØ§Ù…Ù„ Ù¾Ø±Ø¯Ø§Ø²Ø´ ÙØ§Ú©ØªÙˆØ±**: Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ØŒ Ø§Ø¹ØªØ¨Ø§Ø±Ø³Ù†Ø¬ÛŒ Ø§Ø·Ù„Ø§Ø¹Ø§ØªØŒ Ø§Ø±Ø³Ø§Ù„ Ø¨Ø±Ø§ÛŒ ØªØ£ÛŒÛŒØ¯  
- **Ø¹ÙˆØ§Ù…Ù„ Ù…Ø¯ÛŒØ±ÛŒØª Ø§ÛŒÙ…ÛŒÙ„**: Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒØŒ Ø§ÙˆÙ„ÙˆÛŒØªâ€ŒØ¨Ù†Ø¯ÛŒØŒ Ù¾ÛŒØ´â€ŒÙ†ÙˆÛŒØ³ Ù¾Ø§Ø³Ø®â€ŒÙ‡Ø§ Ø¨Ù‡ ØµÙˆØ±Øª Ø®ÙˆØ¯Ú©Ø§Ø±  
- **Ø¹ÙˆØ§Ù…Ù„ Ø²Ù…Ø§Ù†â€ŒØ¨Ù†Ø¯ÛŒ**: Ù‡Ù…Ø§Ù‡Ù†Ú¯ÛŒ Ø¬Ù„Ø³Ø§ØªØŒ Ù…Ø¯ÛŒØ±ÛŒØª ØªÙ‚ÙˆÛŒÙ…â€ŒÙ‡Ø§ØŒ Ø§Ø±Ø³Ø§Ù„ ÛŒØ§Ø¯Ø¢ÙˆØ±ÛŒâ€ŒÙ‡Ø§  

### Ø¯Ø³ØªÛŒØ§Ø±Ù‡Ø§ÛŒ Ø¯ÛŒØ¬ÛŒØªØ§Ù„ Ø´Ø®ØµÛŒ SLM
- **Ø¹ÙˆØ§Ù…Ù„ Ù…Ø¯ÛŒØ±ÛŒØª ÙˆØ¸Ø§ÛŒÙ**: Ø§ÛŒØ¬Ø§Ø¯ØŒ Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒØŒ Ø³Ø§Ø²Ù…Ø§Ù†Ø¯Ù‡ÛŒ Ù„ÛŒØ³Øªâ€ŒÙ‡Ø§ÛŒ Ú©Ø§Ø±Ù‡Ø§ Ø¨Ù‡ ØµÙˆØ±Øª Ú©Ø§Ø±Ø¢Ù…Ø¯  
- **Ø¹ÙˆØ§Ù…Ù„ Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒ Ø§Ø·Ù„Ø§Ø¹Ø§Øª**: ØªØ­Ù‚ÛŒÙ‚ Ø¯Ø± Ù…ÙˆØ±Ø¯ Ù…ÙˆØ¶ÙˆØ¹Ø§ØªØŒ Ø®Ù„Ø§ØµÙ‡â€ŒØ³Ø§Ø²ÛŒ ÛŒØ§ÙØªÙ‡â€ŒÙ‡Ø§ Ø¨Ù‡ ØµÙˆØ±Øª Ù…Ø­Ù„ÛŒ  
- **Ø¹ÙˆØ§Ù…Ù„ Ø§Ø±ØªØ¨Ø§Ø·ÛŒ**: Ù¾ÛŒØ´â€ŒÙ†ÙˆÛŒØ³ Ø§ÛŒÙ…ÛŒÙ„â€ŒÙ‡Ø§ØŒ Ù¾ÛŒØ§Ù…â€ŒÙ‡Ø§ØŒ Ù¾Ø³Øªâ€ŒÙ‡Ø§ÛŒ Ø´Ø¨Ú©Ù‡â€ŒÙ‡Ø§ÛŒ Ø§Ø¬ØªÙ…Ø§Ø¹ÛŒ Ø¨Ù‡ ØµÙˆØ±Øª Ø®ØµÙˆØµÛŒ  

### Ø¹ÙˆØ§Ù…Ù„ SLM Ù…Ø§Ù„ÛŒ Ùˆ ØªØ¬Ø§Ø±ÛŒ
- **Ø¹ÙˆØ§Ù…Ù„ Ù†Ø¸Ø§Ø±Øª Ø¨Ø± Ø¨Ø§Ø²Ø§Ø±**: Ø±Ø¯ÛŒØ§Ø¨ÛŒ Ù‚ÛŒÙ…Øªâ€ŒÙ‡Ø§ØŒ Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ø±ÙˆÙ†Ø¯Ù‡Ø§ Ø¯Ø± Ø²Ù…Ø§Ù† ÙˆØ§Ù‚Ø¹ÛŒ  
- **Ø¹ÙˆØ§Ù…Ù„ ØªÙˆÙ„ÛŒØ¯ Ú¯Ø²Ø§Ø±Ø´**: Ø§ÛŒØ¬Ø§Ø¯ Ø®Ù„Ø§ØµÙ‡â€ŒÙ‡Ø§ÛŒ Ø±ÙˆØ²Ø§Ù†Ù‡/Ù‡ÙØªÚ¯ÛŒ Ø¨Ù‡ ØµÙˆØ±Øª Ø®ÙˆØ¯Ú©Ø§Ø±  
- **Ø¹ÙˆØ§Ù…Ù„ Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ Ø±ÛŒØ³Ú©**: Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ Ù…ÙˆÙ‚Ø¹ÛŒØªâ€ŒÙ‡Ø§ÛŒ Ù¾Ø±ØªÙÙˆÛŒ Ø¨Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù…Ø­Ù„ÛŒ  

### Ø¹ÙˆØ§Ù…Ù„ SLM Ù¾Ø´ØªÛŒØ¨Ø§Ù†ÛŒ Ø³Ù„Ø§Ù…Øª
- **Ø¹ÙˆØ§Ù…Ù„ Ø²Ù…Ø§Ù†â€ŒØ¨Ù†Ø¯ÛŒ Ø¨ÛŒÙ…Ø§Ø±Ø§Ù†**: Ù‡Ù…Ø§Ù‡Ù†Ú¯ÛŒ Ù‚Ø±Ø§Ø± Ù…Ù„Ø§Ù‚Ø§Øªâ€ŒÙ‡Ø§ØŒ Ø§Ø±Ø³Ø§Ù„ ÛŒØ§Ø¯Ø¢ÙˆØ±ÛŒâ€ŒÙ‡Ø§ÛŒ Ø®ÙˆØ¯Ú©Ø§Ø±  
- **Ø¹ÙˆØ§Ù…Ù„ Ù…Ø³ØªÙ†Ø¯Ø³Ø§Ø²ÛŒ**: ØªÙˆÙ„ÛŒØ¯ Ø®Ù„Ø§ØµÙ‡â€ŒÙ‡Ø§ÛŒ Ù¾Ø²Ø´Ú©ÛŒØŒ Ú¯Ø²Ø§Ø±Ø´â€ŒÙ‡Ø§ Ø¨Ù‡ ØµÙˆØ±Øª Ù…Ø­Ù„ÛŒ  
- **Ø¹ÙˆØ§Ù…Ù„ Ù…Ø¯ÛŒØ±ÛŒØª Ù†Ø³Ø®Ù‡â€ŒÙ‡Ø§**: Ø±Ø¯ÛŒØ§Ø¨ÛŒ ØªØ¬Ø¯ÛŒØ¯Ù‡Ø§ØŒ Ø¨Ø±Ø±Ø³ÛŒ ØªØ¹Ø§Ù…Ù„Ø§Øª Ø¨Ù‡ ØµÙˆØ±Øª Ø®ØµÙˆØµÛŒ  

## Microsoft Agent Framework: ØªÙˆØ³Ø¹Ù‡ Ø¹Ø§Ù…Ù„ Ø¢Ù…Ø§Ø¯Ù‡ ØªÙˆÙ„ÛŒØ¯

### Ù…Ø±ÙˆØ± Ú©Ù„ÛŒ Ùˆ Ù…Ø¹Ù…Ø§Ø±ÛŒ

Microsoft Agent Framework ÛŒÚ© Ù¾Ù„ØªÙØ±Ù… Ø¬Ø§Ù…Ø¹ Ùˆ Ø¯Ø±Ø¬Ù‡ Ø³Ø§Ø²Ù…Ø§Ù†ÛŒ Ø¨Ø±Ø§ÛŒ Ø³Ø§Ø®ØªØŒ Ø§Ø³ØªÙ‚Ø±Ø§Ø± Ùˆ Ù…Ø¯ÛŒØ±ÛŒØª Ø¹ÙˆØ§Ù…Ù„ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ Ø§Ø±Ø§Ø¦Ù‡ Ù…ÛŒâ€ŒØ¯Ù‡Ø¯ Ú©Ù‡ Ù…ÛŒâ€ŒØªÙˆØ§Ù†Ù†Ø¯ Ù‡Ù… Ø¯Ø± ÙØ¶Ø§ÛŒ Ø§Ø¨Ø±ÛŒ Ùˆ Ù‡Ù… Ø¯Ø± Ù…Ø­ÛŒØ·â€ŒÙ‡Ø§ÛŒ Ù„Ø¨Ù‡ Ø¢ÙÙ„Ø§ÛŒÙ† Ø¹Ù…Ù„ Ú©Ù†Ù†Ø¯. Ø§ÛŒÙ† Ú†Ø§Ø±Ú†ÙˆØ¨ Ø¨Ù‡ Ø·ÙˆØ± Ø®Ø§Øµ Ø¨Ø±Ø§ÛŒ Ú©Ø§Ø± Ø¨Ø§ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ø²Ø¨Ø§Ù† Ú©ÙˆÚ†Ú© Ùˆ Ø³Ù†Ø§Ø±ÛŒÙˆÙ‡Ø§ÛŒ Ù…Ø­Ø§Ø³Ø¨Ø§Øª Ù„Ø¨Ù‡ Ø·Ø±Ø§Ø­ÛŒ Ø´Ø¯Ù‡ Ø§Ø³ØªØŒ Ú©Ù‡ Ø¢Ù† Ø±Ø§ Ø¨Ø±Ø§ÛŒ Ø§Ø³ØªÙ‚Ø±Ø§Ø±Ù‡Ø§ÛŒ Ø­Ø³Ø§Ø³ Ø¨Ù‡ Ø­Ø±ÛŒÙ… Ø®ØµÙˆØµÛŒ Ùˆ Ù…Ø­Ø¯ÙˆØ¯ Ø¨Ù‡ Ù…Ù†Ø§Ø¨Ø¹ Ø§ÛŒØ¯Ù‡â€ŒØ¢Ù„ Ù…ÛŒâ€ŒÚ©Ù†Ø¯.

**Ø§Ø¬Ø²Ø§ÛŒ Ø§ØµÙ„ÛŒ Ú†Ø§Ø±Ú†ÙˆØ¨**:
- **Ø²Ù…Ø§Ù† Ø§Ø¬Ø±Ø§ÛŒ Ø¹Ø§Ù…Ù„**: Ù…Ø­ÛŒØ· Ø§Ø¬Ø±Ø§ÛŒ Ø³Ø¨Ú© Ø¨Ù‡ÛŒÙ†Ù‡ Ø´Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ Ø¯Ø³ØªÚ¯Ø§Ù‡â€ŒÙ‡Ø§ÛŒ Ù„Ø¨Ù‡  
- **Ø³ÛŒØ³ØªÙ… ÛŒÚ©Ù¾Ø§Ø±Ú†Ú¯ÛŒ Ø§Ø¨Ø²Ø§Ø±**: Ù…Ø¹Ù…Ø§Ø±ÛŒ Ø§ÙØ²ÙˆÙ†Ù‡ Ù‚Ø§Ø¨Ù„ ØªÙˆØ³Ø¹Ù‡ Ø¨Ø±Ø§ÛŒ Ø§ØªØµØ§Ù„ Ø®Ø¯Ù…Ø§Øª Ùˆ APIÙ‡Ø§ÛŒ Ø®Ø§Ø±Ø¬ÛŒ  
- **Ù…Ø¯ÛŒØ±ÛŒØª Ø­Ø§Ù„Øª**: Ø­Ø§ÙØ¸Ù‡ Ù¾Ø§ÛŒØ¯Ø§Ø± Ø¹Ø§Ù…Ù„ Ùˆ Ù…Ø¯ÛŒØ±ÛŒØª Ø²Ù…ÛŒÙ†Ù‡ Ø¯Ø± Ø¬Ù„Ø³Ø§Øª  
- **Ù„Ø§ÛŒÙ‡ Ø§Ù…Ù†ÛŒØªÛŒ**: Ú©Ù†ØªØ±Ù„â€ŒÙ‡Ø§ÛŒ Ø§Ù…Ù†ÛŒØªÛŒ Ø¯Ø§Ø®Ù„ÛŒ Ø¨Ø±Ø§ÛŒ Ø§Ø³ØªÙ‚Ø±Ø§Ø± Ø³Ø§Ø²Ù…Ø§Ù†ÛŒ  
- **Ù…ÙˆØªÙˆØ± Ø§Ø±Ú©Ø³ØªØ±Ø§Ø³ÛŒÙˆÙ†**: Ù‡Ù…Ø§Ù‡Ù†Ú¯ÛŒ Ú†Ù†Ø¯ Ø¹Ø§Ù…Ù„ÛŒ Ùˆ Ù…Ø¯ÛŒØ±ÛŒØª Ø¬Ø±ÛŒØ§Ù† Ú©Ø§Ø±ÛŒ  

### ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ú©Ù„ÛŒØ¯ÛŒ Ø¨Ø±Ø§ÛŒ Ø§Ø³ØªÙ‚Ø±Ø§Ø± Ù„Ø¨Ù‡

**Ù…Ø¹Ù…Ø§Ø±ÛŒ Ø¢ÙÙ„Ø§ÛŒÙ†-Ø§ÙˆÙ„**: Microsoft Agent Framework Ø¨Ø§ Ø§ØµÙˆÙ„ Ø¢ÙÙ„Ø§ÛŒÙ†-Ø§ÙˆÙ„ Ø·Ø±Ø§Ø­ÛŒ Ø´Ø¯Ù‡ Ø§Ø³ØªØŒ Ú©Ù‡ Ø¨Ù‡ Ø¹ÙˆØ§Ù…Ù„ Ø§Ù…Ú©Ø§Ù† Ù…ÛŒâ€ŒØ¯Ù‡Ø¯ Ø¨Ø¯ÙˆÙ† Ø§ØªØµØ§Ù„ Ø¯Ø§Ø¦Ù…ÛŒ Ø¨Ù‡ Ø§ÛŒÙ†ØªØ±Ù†Øª Ø¨Ù‡ Ø·ÙˆØ± Ù…Ø¤Ø«Ø± Ø¹Ù…Ù„ Ú©Ù†Ù†Ø¯. Ø§ÛŒÙ† Ø´Ø§Ù…Ù„ Ø§Ø³ØªÙ†ØªØ§Ø¬ Ù…Ø¯Ù„ Ù…Ø­Ù„ÛŒØŒ Ù¾Ø§ÛŒÚ¯Ø§Ù‡â€ŒÙ‡Ø§ÛŒ Ø¯Ø§Ù†Ø´ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯Ù‡ØŒ Ø§Ø¬Ø±Ø§ÛŒ Ø§Ø¨Ø²Ø§Ø± Ø¢ÙÙ„Ø§ÛŒÙ†ØŒ Ùˆ Ú©Ø§Ù‡Ø´ ØªØ¯Ø±ÛŒØ¬ÛŒ Ø²Ù…Ø§Ù†ÛŒ Ú©Ù‡ Ø®Ø¯Ù…Ø§Øª Ø§Ø¨Ø±ÛŒ Ø¯Ø± Ø¯Ø³ØªØ±Ø³ Ù†ÛŒØ³ØªÙ†Ø¯.

**Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ù…Ù†Ø§Ø¨Ø¹**: Ø§ÛŒÙ† Ú†Ø§Ø±Ú†ÙˆØ¨ Ù…Ø¯ÛŒØ±ÛŒØª Ù…Ù†Ø§Ø¨Ø¹ Ù‡ÙˆØ´Ù…Ù†Ø¯ Ø±Ø§ Ø¨Ø§ Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø®ÙˆØ¯Ú©Ø§Ø± Ø­Ø§ÙØ¸Ù‡ Ø¨Ø±Ø§ÛŒ SLMÙ‡Ø§ØŒ ØªØ¹Ø§Ø¯Ù„ Ø¨Ø§Ø± CPU/GPU Ø¨Ø±Ø§ÛŒ Ø¯Ø³ØªÚ¯Ø§Ù‡â€ŒÙ‡Ø§ÛŒ Ù„Ø¨Ù‡ØŒ Ø§Ù†ØªØ®Ø§Ø¨ ØªØ·Ø¨ÛŒÙ‚ÛŒ Ù…Ø¯Ù„ Ø¨Ø± Ø§Ø³Ø§Ø³ Ù…Ù†Ø§Ø¨Ø¹ Ù…ÙˆØ¬ÙˆØ¯ØŒ Ùˆ Ø§Ù„Ú¯ÙˆÙ‡Ø§ÛŒ Ø§Ø³ØªÙ†ØªØ§Ø¬ Ú©Ù…â€ŒÙ…ØµØ±Ù Ø¨Ø±Ø§ÛŒ Ø§Ø³ØªÙ‚Ø±Ø§Ø± Ù…ÙˆØ¨Ø§ÛŒÙ„ Ø§Ø±Ø§Ø¦Ù‡ Ù…ÛŒâ€ŒØ¯Ù‡Ø¯.

**Ø§Ù…Ù†ÛŒØª Ùˆ Ø­Ø±ÛŒÙ… Ø®ØµÙˆØµÛŒ**: ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ø§Ù…Ù†ÛŒØªÛŒ Ø¯Ø±Ø¬Ù‡ Ø³Ø§Ø²Ù…Ø§Ù†ÛŒ Ø´Ø§Ù…Ù„ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù…Ø­Ù„ÛŒ Ø¨Ø±Ø§ÛŒ Ø­ÙØ¸ Ø­Ø±ÛŒÙ… Ø®ØµÙˆØµÛŒØŒ Ú©Ø§Ù†Ø§Ù„â€ŒÙ‡Ø§ÛŒ Ø§Ø±ØªØ¨Ø§Ø·ÛŒ Ø±Ù…Ø²Ú¯Ø°Ø§Ø±ÛŒ Ø´Ø¯Ù‡ Ø¹Ø§Ù…Ù„ØŒ Ú©Ù†ØªØ±Ù„â€ŒÙ‡Ø§ÛŒ Ø¯Ø³ØªØ±Ø³ÛŒ Ù…Ø¨ØªÙ†ÛŒ Ø¨Ø± Ù†Ù‚Ø´ Ø¨Ø±Ø§ÛŒ Ù‚Ø§Ø¨Ù„ÛŒØªâ€ŒÙ‡Ø§ÛŒ Ø¹Ø§Ù…Ù„ØŒ Ùˆ Ø«Ø¨Øª Ø­Ø³Ø§Ø¨Ø±Ø³ÛŒ Ø¨Ø±Ø§ÛŒ Ø§Ù„Ø²Ø§Ù…Ø§Øª Ø§Ù†Ø·Ø¨Ø§Ù‚ Ø§Ø³Øª.

### ÛŒÚ©Ù¾Ø§Ø±Ú†Ú¯ÛŒ Ø¨Ø§ Foundry Local

Microsoft Agent Framework Ø¨Ù‡ Ø·ÙˆØ± ÛŒÚ©Ù¾Ø§Ø±Ú†Ù‡ Ø¨Ø§ Foundry Local Ø§Ø¯ØºØ§Ù… Ù…ÛŒâ€ŒØ´ÙˆØ¯ ØªØ§ ÛŒÚ© Ø±Ø§Ù‡â€ŒØ­Ù„ Ú©Ø§Ù…Ù„ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ Ù„Ø¨Ù‡ Ø§Ø±Ø§Ø¦Ù‡ Ø¯Ù‡Ø¯:

**Ú©Ø´Ù Ø®ÙˆØ¯Ú©Ø§Ø± Ù…Ø¯Ù„**: Ø§ÛŒÙ† Ú†Ø§Ø±Ú†ÙˆØ¨ Ø¨Ù‡ Ø·ÙˆØ± Ø®ÙˆØ¯Ú©Ø§Ø± Ù†Ù…ÙˆÙ†Ù‡â€ŒÙ‡Ø§ÛŒ Foundry Local Ø±Ø§ Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ùˆ Ù…ØªØµÙ„ Ù…ÛŒâ€ŒÚ©Ù†Ø¯ØŒ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ SLM Ù…ÙˆØ¬ÙˆØ¯ Ø±Ø§ Ú©Ø´Ù Ù…ÛŒâ€ŒÚ©Ù†Ø¯ØŒ Ùˆ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ø¨Ù‡ÛŒÙ†Ù‡ Ø±Ø§ Ø¨Ø± Ø§Ø³Ø§Ø³ Ù†ÛŒØ§Ø²Ù‡Ø§ÛŒ Ø¹Ø§Ù…Ù„ Ùˆ Ù‚Ø§Ø¨Ù„ÛŒØªâ€ŒÙ‡Ø§ÛŒ Ø³Ø®Øªâ€ŒØ§ÙØ²Ø§Ø±ÛŒ Ø§Ù†ØªØ®Ø§Ø¨ Ù…ÛŒâ€ŒÚ©Ù†Ø¯.

**Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù¾ÙˆÛŒØ§ Ù…Ø¯Ù„**: Ø¹ÙˆØ§Ù…Ù„ Ù…ÛŒâ€ŒØªÙˆØ§Ù†Ù†Ø¯ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ù…Ø®ØªÙ„Ù SLM Ø±Ø§ Ø¨Ø±Ø§ÛŒ ÙˆØ¸Ø§ÛŒÙ Ø®Ø§Øµ Ø¨Ù‡ ØµÙˆØ±Øª Ù¾ÙˆÛŒØ§ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ú©Ù†Ù†Ø¯ØŒ Ú©Ù‡ Ø§Ù…Ú©Ø§Ù† Ø³ÛŒØ³ØªÙ…â€ŒÙ‡Ø§ÛŒ Ú†Ù†Ø¯ Ù…Ø¯Ù„ÛŒ Ø¹Ø§Ù…Ù„ Ø±Ø§ ÙØ±Ø§Ù‡Ù… Ù…ÛŒâ€ŒÚ©Ù†Ø¯ Ú©Ù‡ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ù…Ø®ØªÙ„Ù Ø¯Ø±Ø®ÙˆØ§Ø³Øªâ€ŒÙ‡Ø§ÛŒ Ù…Ø®ØªÙ„Ù Ø±Ø§ Ù…Ø¯ÛŒØ±ÛŒØª Ù…ÛŒâ€ŒÚ©Ù†Ù†Ø¯ØŒ Ùˆ Ø®Ø±Ø§Ø¨ÛŒ Ø®ÙˆØ¯Ú©Ø§Ø± Ø¨ÛŒÙ† Ù…Ø¯Ù„â€ŒÙ‡Ø§ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø¯Ø³ØªØ±Ø³ÛŒ Ùˆ Ø¹Ù…Ù„Ú©Ø±Ø¯.

**Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø¹Ù…Ù„Ú©Ø±Ø¯**: Ù…Ú©Ø§Ù†ÛŒØ²Ù…â€ŒÙ‡Ø§ÛŒ Ú©Ø´ ÛŒÚ©Ù¾Ø§Ø±Ú†Ù‡ Ø²Ù…Ø§Ù†â€ŒÙ‡Ø§ÛŒ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…Ø¯Ù„ Ø±Ø§ Ú©Ø§Ù‡Ø´ Ù…ÛŒâ€ŒØ¯Ù‡Ù†Ø¯ØŒ Ø§ØªØµØ§Ù„ Ø§Ø³ØªØ®Ø± ØªÙ…Ø§Ø³â€ŒÙ‡Ø§ÛŒ API Ø¨Ù‡ Foundry Local Ø±Ø§ Ø¨Ù‡ÛŒÙ†Ù‡ Ù…ÛŒâ€ŒÚ©Ù†Ø¯ØŒ Ùˆ Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒ Ù‡ÙˆØ´Ù…Ù†Ø¯ ØªÙˆØ§Ù† Ø±Ø§ Ø¨Ø±Ø§ÛŒ Ø¯Ø±Ø®ÙˆØ§Ø³Øªâ€ŒÙ‡Ø§ÛŒ Ú†Ù†Ø¯ Ø¹Ø§Ù…Ù„ÛŒ Ø¨Ù‡Ø¨ÙˆØ¯ Ù…ÛŒâ€ŒØ¨Ø®Ø´Ø¯.

### Ø³Ø§Ø®Øª Ø¹ÙˆØ§Ù…Ù„ Ø¨Ø§ Microsoft Agent Framework

#### ØªØ¹Ø±ÛŒÙ Ùˆ ØªÙ†Ø¸ÛŒÙ… Ø¹Ø§Ù…Ù„

```python
from microsoft_agent_framework import Agent, Tool, Config
from foundry_local import FoundryLocalManager

# Configure agent with Foundry Local integration
config = Config(
    name="customer-service-agent",
    model_provider="foundry-local",
    model_alias="phi-4-mini",
    max_tokens=512,
    temperature=0.1,
    offline_mode=True
)

# Initialize Foundry Local connection
foundry = FoundryLocalManager("phi-4-mini")

# Create agent instance
agent = Agent(
    config=config,
    model_endpoint=foundry.endpoint,
    api_key=foundry.api_key
)
```
  
#### ÛŒÚ©Ù¾Ø§Ø±Ú†Ú¯ÛŒ Ø§Ø¨Ø²Ø§Ø± Ø¨Ø±Ø§ÛŒ Ø³Ù†Ø§Ø±ÛŒÙˆÙ‡Ø§ÛŒ Ù„Ø¨Ù‡

```python
# Define tools for offline operation
@agent.tool
def lookup_customer_info(customer_id: str) -> dict:
    """Look up customer information from local database."""
    # Local database query - works offline
    return local_db.get_customer(customer_id)

@agent.tool
def create_support_ticket(issue: str, priority: str) -> str:
    """Create a support ticket in local system."""
    # Local ticket creation with sync when online
    ticket_id = local_system.create_ticket(issue, priority)
    return f"Ticket {ticket_id} created successfully"

@agent.tool
def schedule_callback(customer_id: str, preferred_time: str) -> str:
    """Schedule a callback for the customer."""
    # Local scheduling with calendar integration
    return local_calendar.schedule(customer_id, preferred_time)
```
  
#### Ø§Ø±Ú©Ø³ØªØ±Ø§Ø³ÛŒÙˆÙ† Ú†Ù†Ø¯ Ø¹Ø§Ù…Ù„ÛŒ

```python
from microsoft_agent_framework import AgentOrchestrator

# Create specialized agents for different domains
scheduling_agent = Agent(
    config=Config(
        name="scheduling-agent",
        model_alias="qwen2.5-0.5b",  # Lightweight for simple tasks
        specialized_for="scheduling"
    )
)

technical_support_agent = Agent(
    config=Config(
        name="technical-agent",
        model_alias="phi-4-mini",  # More capable for complex issues
        specialized_for="technical_support"
    )
)

# Orchestrate multiple agents
orchestrator = AgentOrchestrator([
    scheduling_agent,
    technical_support_agent
])

# Route requests based on intent
result = orchestrator.process_request(
    "I need to schedule a callback for a technical issue",
    routing_strategy="intent-based"
)
```
  

### Ø§Ù„Ú¯ÙˆÙ‡Ø§ÛŒ Ø§Ø³ØªÙ‚Ø±Ø§Ø± Ù¾ÛŒØ´Ø±ÙØªÙ‡ Ù„Ø¨Ù‡

#### Ù…Ø¹Ù…Ø§Ø±ÛŒ Ø¹Ø§Ù…Ù„ Ø³Ù„Ø³Ù„Ù‡â€ŒÙ…Ø±Ø§ØªØ¨ÛŒ

**Ø®ÙˆØ´Ù‡â€ŒÙ‡Ø§ÛŒ Ø¹Ø§Ù…Ù„ Ù…Ø­Ù„ÛŒ**: Ø§Ø³ØªÙ‚Ø±Ø§Ø± Ú†Ù†Ø¯ÛŒÙ† Ø¹Ø§Ù…Ù„ SLM ØªØ®ØµØµÛŒ Ø¨Ø± Ø±ÙˆÛŒ Ø¯Ø³ØªÚ¯Ø§Ù‡â€ŒÙ‡Ø§ÛŒ Ù„Ø¨Ù‡ØŒ Ù‡Ø± Ú©Ø¯Ø§Ù… Ø¨Ø±Ø§ÛŒ ÙˆØ¸Ø§ÛŒÙ Ø®Ø§Øµ Ø¨Ù‡ÛŒÙ†Ù‡ Ø´Ø¯Ù‡â€ŒØ§Ù†Ø¯. Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ø³Ø¨Ú© Ù…Ø§Ù†Ù†Ø¯ Qwen2.5-0.5B Ø¨Ø±Ø§ÛŒ Ù…Ø³ÛŒØ±ÛŒØ§Ø¨ÛŒ Ùˆ Ø²Ù…Ø§Ù†â€ŒØ¨Ù†Ø¯ÛŒ Ø³Ø§Ø¯Ù‡ØŒ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ù…ØªÙˆØ³Ø· Ù…Ø§Ù†Ù†Ø¯ Phi-4-Mini Ø¨Ø±Ø§ÛŒ Ø®Ø¯Ù…Ø§Øª Ù…Ø´ØªØ±ÛŒ Ùˆ Ù…Ø³ØªÙ†Ø¯Ø³Ø§Ø²ÛŒØŒ Ùˆ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ø¨Ø²Ø±Ú¯â€ŒØªØ± Ø¨Ø±Ø§ÛŒ Ø§Ø³ØªØ¯Ù„Ø§Ù„ Ù¾ÛŒÚ†ÛŒØ¯Ù‡ Ø²Ù…Ø§Ù†ÛŒ Ú©Ù‡ Ù…Ù†Ø§Ø¨Ø¹ Ø§Ø¬Ø§Ø²Ù‡ Ù…ÛŒâ€ŒØ¯Ù‡Ù†Ø¯.

**Ù‡Ù…Ø§Ù‡Ù†Ú¯ÛŒ Ù„Ø¨Ù‡-Ø¨Ù‡-Ø§Ø¨Ø±**: Ù¾ÛŒØ§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø§Ù„Ú¯ÙˆÙ‡Ø§ÛŒ ØªØ´Ø¯ÛŒØ¯ Ù‡ÙˆØ´Ù…Ù†Ø¯ Ú©Ù‡ Ø¯Ø± Ø¢Ù† Ø¹ÙˆØ§Ù…Ù„ Ù…Ø­Ù„ÛŒ ÙˆØ¸Ø§ÛŒÙ Ù…Ø¹Ù…ÙˆÙ„ Ø±Ø§ Ù…Ø¯ÛŒØ±ÛŒØª Ù…ÛŒâ€ŒÚ©Ù†Ù†Ø¯ØŒ Ø¹ÙˆØ§Ù…Ù„ Ø§Ø¨Ø±ÛŒ Ø§Ø³ØªØ¯Ù„Ø§Ù„ Ù¾ÛŒÚ†ÛŒØ¯Ù‡ Ø±Ø§ Ø²Ù…Ø§Ù†ÛŒ Ú©Ù‡ Ø§ØªØµØ§Ù„ Ø§Ø¬Ø§Ø²Ù‡ Ù…ÛŒâ€ŒØ¯Ù‡Ø¯ Ø§Ø±Ø§Ø¦Ù‡ Ù…ÛŒâ€ŒØ¯Ù‡Ù†Ø¯ØŒ Ùˆ Ø§Ù†ØªÙ‚Ø§Ù„ Ø¨ÛŒâ€ŒÙˆÙ‚ÙÙ‡ Ø¨ÛŒÙ† Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù„Ø¨Ù‡ Ùˆ Ø§Ø¨Ø± ØªØ¯Ø§ÙˆÙ… Ø±Ø§ Ø­ÙØ¸ Ù…ÛŒâ€ŒÚ©Ù†Ø¯.

#### ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø§Ø³ØªÙ‚Ø±Ø§Ø±

**Ø§Ø³ØªÙ‚Ø±Ø§Ø± Ø¯Ø³ØªÚ¯Ø§Ù‡ ÙˆØ§Ø­Ø¯**:
```yaml
deployment:
  type: single-device
  hardware: edge-device
  models:
    - alias: "phi-4-mini"
      primary: true
      tasks: ["conversation", "reasoning"]
    - alias: "qwen2.5-0.5b"
      secondary: true
      tasks: ["routing", "classification"]
  agents:
    - name: "primary-agent"
      model: "phi-4-mini"
      tools: ["database", "calendar", "email"]
```
  
**Ø§Ø³ØªÙ‚Ø±Ø§Ø± Ù„Ø¨Ù‡ ØªÙˆØ²ÛŒØ¹â€ŒØ´Ø¯Ù‡**:
```yaml
deployment:
  type: distributed-edge
  nodes:
    - id: "edge-1"
      agents: ["customer-service", "scheduling"]
      models: ["phi-4-mini"]
    - id: "edge-2"
      agents: ["technical-support", "documentation"]
      models: ["qwen2.5-coder-0.5b"]
  coordination:
    load_balancing: true
    failover: automatic
```
  

### Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø¹Ù…Ù„Ú©Ø±Ø¯ Ø¨Ø±Ø§ÛŒ Ø¹ÙˆØ§Ù…Ù„ Ù„Ø¨Ù‡

#### Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒâ€ŒÙ‡Ø§ÛŒ Ø§Ù†ØªØ®Ø§Ø¨ Ù…Ø¯Ù„

**ØªØ®ØµÛŒØµ Ù…Ø¯Ù„ Ù…Ø¨ØªÙ†ÛŒ Ø¨Ø± ÙˆØ¸ÛŒÙÙ‡**: Microsoft Agent Framework Ø§Ù…Ú©Ø§Ù† Ø§Ù†ØªØ®Ø§Ø¨ Ù‡ÙˆØ´Ù…Ù†Ø¯ Ù…Ø¯Ù„ Ø¨Ø± Ø§Ø³Ø§Ø³ Ù¾ÛŒÚ†ÛŒØ¯Ú¯ÛŒ ÙˆØ¸ÛŒÙÙ‡ Ùˆ Ù†ÛŒØ§Ø²Ù‡Ø§ Ø±Ø§ ÙØ±Ø§Ù‡Ù… Ù…ÛŒâ€ŒÚ©Ù†Ø¯:

- **ÙˆØ¸Ø§ÛŒÙ Ø³Ø§Ø¯Ù‡** (Ù¾Ø±Ø³Ø´ Ùˆ Ù¾Ø§Ø³Ø®ØŒ Ù…Ø³ÛŒØ±ÛŒØ§Ø¨ÛŒ): Qwen2.5-0.5B (500MBØŒ Ù¾Ø§Ø³Ø® <100ms)  
- **ÙˆØ¸Ø§ÛŒÙ Ù…ØªÙˆØ³Ø·** (Ø®Ø¯Ù…Ø§Øª Ù…Ø´ØªØ±ÛŒØŒ Ø²Ù…Ø§Ù†â€ŒØ¨Ù†Ø¯ÛŒ): Phi-4-Mini (2.4GBØŒ Ù¾Ø§Ø³Ø® 200-500ms)  
- **ÙˆØ¸Ø§ÛŒÙ Ù¾ÛŒÚ†ÛŒØ¯Ù‡** (ØªØ­Ù„ÛŒÙ„ ÙÙ†ÛŒØŒ Ø¨Ø±Ù†Ø§Ù…Ù‡â€ŒØ±ÛŒØ²ÛŒ): Phi-4 (7GBØŒ Ù¾Ø§Ø³Ø® 1-3s Ø²Ù…Ø§Ù†ÛŒ Ú©Ù‡ Ù…Ù†Ø§Ø¨Ø¹ Ø§Ø¬Ø§Ø²Ù‡ Ù…ÛŒâ€ŒØ¯Ù‡Ù†Ø¯)  

**ØªØºÛŒÛŒØ± Ù…Ø¯Ù„ Ù¾ÙˆÛŒØ§**: Ø¹ÙˆØ§Ù…Ù„ Ù…ÛŒâ€ŒØªÙˆØ§Ù†Ù†Ø¯ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø¨Ø§Ø± ÙØ¹Ù„ÛŒ Ø³ÛŒØ³ØªÙ…ØŒ Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ Ù¾ÛŒÚ†ÛŒØ¯Ú¯ÛŒ ÙˆØ¸ÛŒÙÙ‡ØŒ Ø³Ø·Ø­ Ø§ÙˆÙ„ÙˆÛŒØª Ú©Ø§Ø±Ø¨Ø±ØŒ Ùˆ Ù…Ù†Ø§Ø¨Ø¹ Ø³Ø®Øªâ€ŒØ§ÙØ²Ø§Ø±ÛŒ Ù…ÙˆØ¬ÙˆØ¯ Ø¨ÛŒÙ† Ù…Ø¯Ù„â€ŒÙ‡Ø§ ØªØºÛŒÛŒØ± Ú©Ù†Ù†Ø¯.

#### Ù…Ø¯ÛŒØ±ÛŒØª Ø­Ø§ÙØ¸Ù‡ Ùˆ Ù…Ù†Ø§Ø¨Ø¹

```python
# Configure resource constraints for edge deployment
resource_config = ResourceConfig(
    max_memory_usage="4GB",
    max_concurrent_agents=3,
    model_cache_size="2GB",
    auto_unload_idle_models=True,
    power_management=True
)

agent = Agent(
    config=config,
    resource_limits=resource_config
)
```
  

### Ø§Ù„Ú¯ÙˆÙ‡Ø§ÛŒ ÛŒÚ©Ù¾Ø§Ø±Ú†Ú¯ÛŒ Ø³Ø§Ø²Ù…Ø§Ù†ÛŒ

#### Ø§Ù…Ù†ÛŒØª Ùˆ Ø§Ù†Ø·Ø¨Ø§Ù‚

**Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù…Ø­Ù„ÛŒ**: ØªÙ…Ø§Ù… Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø¹Ø§Ù…Ù„ Ø¨Ù‡ ØµÙˆØ±Øª Ù…Ø­Ù„ÛŒ Ø§Ù†Ø¬Ø§Ù… Ù…ÛŒâ€ŒØ´ÙˆØ¯ØŒ Ú©Ù‡ Ø§Ø·Ù…ÛŒÙ†Ø§Ù† Ù…ÛŒâ€ŒØ¯Ù‡Ø¯ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø­Ø³Ø§Ø³ Ù‡Ø±Ú¯Ø² Ø¯Ø³ØªÚ¯Ø§Ù‡ Ù„Ø¨Ù‡ Ø±Ø§ ØªØ±Ú© Ù†Ù…ÛŒâ€ŒÚ©Ù†Ù†Ø¯. Ø§ÛŒÙ† Ø´Ø§Ù…Ù„ Ø­ÙØ§Ø¸Øª Ø§Ø² Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ù…Ø´ØªØ±ÛŒØŒ Ø§Ù†Ø·Ø¨Ø§Ù‚ HIPAA Ø¨Ø±Ø§ÛŒ Ø¹ÙˆØ§Ù…Ù„ Ø³Ù„Ø§Ù…ØªØŒ Ø§Ù…Ù†ÛŒØª Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù…Ø§Ù„ÛŒ Ø¨Ø±Ø§ÛŒ Ø¹ÙˆØ§Ù…Ù„ Ø¨Ø§Ù†Ú©ÛŒØŒ Ùˆ Ø§Ù†Ø·Ø¨Ø§Ù‚ GDPR Ø¨Ø±Ø§ÛŒ Ø§Ø³ØªÙ‚Ø±Ø§Ø±Ù‡Ø§ÛŒ Ø§Ø±ÙˆÙ¾Ø§ÛŒÛŒ Ø§Ø³Øª.

**Ú©Ù†ØªØ±Ù„ Ø¯Ø³ØªØ±Ø³ÛŒ**: Ù…Ø¬ÙˆØ²Ù‡Ø§ÛŒ Ù…Ø¨ØªÙ†ÛŒ Ø¨Ø± Ù†Ù‚Ø´ Ú©Ù†ØªØ±Ù„ Ù…ÛŒâ€ŒÚ©Ù†Ù†Ø¯ Ú©Ù‡ Ú©Ø¯Ø§Ù… Ø§Ø¨Ø²Ø§Ø±Ù‡Ø§ Ø¹ÙˆØ§Ù…Ù„ Ù…ÛŒâ€ŒØªÙˆØ§Ù†Ù†Ø¯ Ø¨Ù‡ Ø¢Ù†â€ŒÙ‡Ø§ Ø¯Ø³ØªØ±Ø³ÛŒ Ø¯Ø§Ø´ØªÙ‡ Ø¨Ø§Ø´Ù†Ø¯ØŒ Ø§Ø­Ø±Ø§Ø² Ù‡ÙˆÛŒØª Ú©Ø§Ø±Ø¨Ø± Ø¨Ø±Ø§ÛŒ ØªØ¹Ø§Ù…Ù„Ø§Øª Ø¹Ø§Ù…Ù„ØŒ Ùˆ Ù…Ø³ÛŒØ±Ù‡Ø§ÛŒ Ø­Ø³Ø§Ø¨Ø±Ø³ÛŒ Ø¨Ø±Ø§ÛŒ ØªÙ…Ø§Ù… Ø§Ù‚Ø¯Ø§Ù…Ø§Øª Ùˆ ØªØµÙ…ÛŒÙ…Ø§Øª Ø¹Ø§Ù…Ù„.

#### Ù†Ø¸Ø§Ø±Øª Ùˆ Ù…Ø´Ø§Ù‡Ø¯Ù‡â€ŒÙ¾Ø°ÛŒØ±ÛŒ

```python
from microsoft_agent_framework import AgentMonitor

# Set up monitoring for edge agents
monitor = AgentMonitor(
    metrics=["response_time", "success_rate", "resource_usage"],
    alerts=[
        {"metric": "response_time", "threshold": "2s", "action": "scale_down_model"},
        {"metric": "memory_usage", "threshold": "80%", "action": "unload_idle_agents"}
    ],
    local_storage=True  # Store metrics locally for offline operation
)

agent.add_monitor(monitor)
```
  

### Ù†Ù…ÙˆÙ†Ù‡â€ŒÙ‡Ø§ÛŒ Ù¾ÛŒØ§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ ÙˆØ§Ù‚Ø¹ÛŒ

#### Ø³ÛŒØ³ØªÙ… Ø¹Ø§Ù…Ù„ Ù„Ø¨Ù‡ Ø®Ø±Ø¯Ù‡â€ŒÙØ±ÙˆØ´ÛŒ

```python
# Retail kiosk agent for in-store customer assistance
retail_agent = Agent(
    config=Config(
        name="retail-assistant",
        model_alias="phi-4-mini",
        context="You are a helpful retail assistant in an electronics store."
    )
)

@retail_agent.tool
def check_inventory(product_sku: str) -> dict:
    """Check local inventory for a product."""
    return local_inventory.lookup(product_sku)

@retail_agent.tool
def find_alternatives(product_category: str) -> list:
    """Find alternative products in the same category."""
    return local_catalog.find_similar(product_category)

@retail_agent.tool
def create_price_quote(items: list) -> dict:
    """Generate a price quote for multiple items."""
    return pricing_engine.calculate_quote(items)
```
  
#### Ø¹Ø§Ù…Ù„ Ù¾Ø´ØªÛŒØ¨Ø§Ù†ÛŒ Ø³Ù„Ø§Ù…Øª

```python
# HIPAA-compliant patient support agent
healthcare_agent = Agent(
    config=Config(
        name="patient-support",
        model_alias="phi-4-mini",
        privacy_mode=True,  # Enhanced privacy for healthcare
        compliance=["HIPAA"]
    )
)

@healthcare_agent.tool
def check_appointment_availability(provider_id: str, date_range: str) -> list:
    """Check appointment slots with healthcare provider."""
    return local_scheduling.get_availability(provider_id, date_range)

@healthcare_agent.tool
def access_patient_portal(patient_id: str, auth_token: str) -> dict:
    """Secure access to patient information."""
    if security.validate_token(auth_token):
        return patient_portal.get_summary(patient_id)
    return {"error": "Authentication failed"}
```
  

### Ø¨Ù‡ØªØ±ÛŒÙ† Ø±ÙˆØ´â€ŒÙ‡Ø§ Ø¨Ø±Ø§ÛŒ Microsoft Agent Framework

#### Ø¯Ø³ØªÙˆØ±Ø§Ù„Ø¹Ù…Ù„â€ŒÙ‡Ø§ÛŒ ØªÙˆØ³Ø¹Ù‡

1. **Ø´Ø±ÙˆØ¹ Ø³Ø§Ø¯Ù‡**: Ø§Ø¨ØªØ¯Ø§ Ø¨Ø§ Ø³Ù†Ø§Ø±ÛŒÙˆÙ‡Ø§ÛŒ ØªÚ©â€ŒØ¹Ø§Ù…Ù„ÛŒ Ø´Ø±ÙˆØ¹ Ú©Ù†ÛŒØ¯ Ù‚Ø¨Ù„ Ø§Ø² Ø³Ø§Ø®Øª Ø³ÛŒØ³ØªÙ…â€ŒÙ‡Ø§ÛŒ Ù¾ÛŒÚ†ÛŒØ¯Ù‡ Ú†Ù†Ø¯ Ø¹Ø§Ù…Ù„ÛŒ  
2. **Ø§Ù†Ø¯Ø§Ø²Ù‡â€ŒÚ¯ÛŒØ±ÛŒ Ù…Ø¯Ù„ Ù…Ù†Ø§Ø³Ø¨**: Ú©ÙˆÚ†Ú©â€ŒØªØ±ÛŒÙ† Ù…Ø¯Ù„ÛŒ Ø±Ø§ Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ù†ÛŒØ¯ Ú©Ù‡ Ù†ÛŒØ§Ø²Ù‡Ø§ÛŒ Ø¯Ù‚Øª Ø´Ù…Ø§ Ø±Ø§ Ø¨Ø±Ø¢ÙˆØ±Ø¯Ù‡ Ú©Ù†Ø¯  
3. **Ø·Ø±Ø§Ø­ÛŒ Ø§Ø¨Ø²Ø§Ø±**: Ø§Ø¨Ø²Ø§Ø±Ù‡Ø§ÛŒ Ù…ØªÙ…Ø±Ú©Ø² Ùˆ ØªÚ©â€ŒÙ…Ù†Ø¸ÙˆØ±Ù‡ Ø§ÛŒØ¬Ø§Ø¯ Ú©Ù†ÛŒØ¯ Ø¨Ù‡ Ø¬Ø§ÛŒ Ø§Ø¨Ø²Ø§Ø±Ù‡Ø§ÛŒ Ú†Ù†Ø¯Ù…Ù†Ø¸ÙˆØ±Ù‡ Ù¾ÛŒÚ†ÛŒØ¯Ù‡  
4. **Ù…Ø¯ÛŒØ±ÛŒØª Ø®Ø·Ø§**: Ú©Ø§Ù‡Ø´ ØªØ¯Ø±ÛŒØ¬ÛŒ Ø¨Ø±Ø§ÛŒ Ø³Ù†Ø§Ø±ÛŒÙˆÙ‡Ø§ÛŒ Ø¢ÙÙ„Ø§ÛŒÙ† Ùˆ Ø®Ø±Ø§Ø¨ÛŒ Ù…Ø¯Ù„ Ù¾ÛŒØ§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ú©Ù†ÛŒØ¯  
5. **Ø¢Ø²Ù…Ø§ÛŒØ´**: Ø¹ÙˆØ§Ù…Ù„ Ø±Ø§ Ø¨Ù‡ Ø·ÙˆØ± Ú¯Ø³ØªØ±Ø¯Ù‡ Ø¯Ø± Ø´Ø±Ø§ÛŒØ· Ø¢ÙÙ„Ø§ÛŒÙ† Ùˆ Ù…Ø­ÛŒØ·â€ŒÙ‡Ø§ÛŒ Ù…Ø­Ø¯ÙˆØ¯ Ø¨Ù‡ Ù…Ù†Ø§Ø¨Ø¹ Ø¢Ø²Ù…Ø§ÛŒØ´ Ú©Ù†ÛŒØ¯  

#### Ø¨Ù‡ØªØ±ÛŒÙ† Ø±ÙˆØ´â€ŒÙ‡Ø§ÛŒ Ø§Ø³ØªÙ‚Ø±Ø§Ø±

1. **Ø§Ø³ØªÙ‚Ø±Ø§Ø± ØªØ¯Ø±ÛŒØ¬ÛŒ**: Ø§Ø¨ØªØ¯Ø§ Ø¨Ù‡ Ú¯Ø±ÙˆÙ‡â€ŒÙ‡Ø§ÛŒ Ú©ÙˆÚ†Ú© Ú©Ø§Ø±Ø¨Ø±Ø§Ù† Ø§Ø³ØªÙ‚Ø±Ø§Ø± Ø¯Ù‡ÛŒØ¯ØŒ Ù…Ø¹ÛŒØ§Ø±Ù‡Ø§ÛŒ Ø¹Ù…Ù„Ú©Ø±Ø¯ Ø±Ø§ Ø¨Ù‡ Ø¯Ù‚Øª Ù†Ø¸Ø§Ø±Øª Ú©Ù†ÛŒØ¯  
2. **Ù†Ø¸Ø§Ø±Øª Ø¨Ø± Ù…Ù†Ø§Ø¨Ø¹**: Ù‡Ø´Ø¯Ø§Ø±Ù‡Ø§ÛŒÛŒ Ø¨Ø±Ø§ÛŒ Ø¢Ø³ØªØ§Ù†Ù‡â€ŒÙ‡Ø§ÛŒ Ø­Ø§ÙØ¸Ù‡ØŒ CPUØŒ Ùˆ Ø²Ù…Ø§Ù† Ù¾Ø§Ø³Ø® ØªÙ†Ø¸ÛŒÙ… Ú©Ù†ÛŒØ¯  
3. **Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒâ€ŒÙ‡Ø§ÛŒ Ù¾Ø´ØªÛŒØ¨Ø§Ù†**: Ù‡Ù…ÛŒØ´Ù‡ Ø¨Ø±Ù†Ø§Ù…Ù‡â€ŒÙ‡Ø§ÛŒ Ù¾Ø´ØªÛŒØ¨Ø§Ù† Ø¨Ø±Ø§ÛŒ Ø®Ø±Ø§Ø¨ÛŒ Ù…Ø¯Ù„ ÛŒØ§ Ø®Ø³ØªÚ¯ÛŒ Ù…Ù†Ø§Ø¨Ø¹ Ø¯Ø§Ø´ØªÙ‡ Ø¨Ø§Ø´ÛŒØ¯  
4. **Ø§Ù…Ù†ÛŒØª Ø§ÙˆÙ„ÙˆÛŒØª Ø¯Ø§Ø±Ø¯**: Ú©Ù†ØªØ±Ù„â€ŒÙ‡Ø§ÛŒ Ø§Ù…Ù†ÛŒØªÛŒ Ø±Ø§ Ø§Ø² Ø§Ø¨ØªØ¯Ø§ Ù¾ÛŒØ§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ú©Ù†ÛŒØ¯ØŒ Ù†Ù‡ Ø¨Ù‡ Ø¹Ù†ÙˆØ§Ù† ÛŒÚ© ÙÚ©Ø± Ø¨Ø¹Ø¯ÛŒ  
5. **Ù…Ø³ØªÙ†Ø¯Ø³Ø§Ø²ÛŒ**: Ù…Ø³ØªÙ†Ø¯Ø§Øª ÙˆØ§Ø¶Ø­ÛŒ Ø§Ø² Ù‚Ø§Ø¨Ù„ÛŒØªâ€ŒÙ‡Ø§ Ùˆ Ù…Ø­Ø¯ÙˆØ¯ÛŒØªâ€ŒÙ‡Ø§ÛŒ Ø¹Ø§Ù…Ù„ Ø­ÙØ¸ Ú©Ù†ÛŒØ¯  

### Ù†Ù‚Ø´Ù‡ Ø±Ø§Ù‡ Ø¢ÛŒÙ†Ø¯Ù‡ Ùˆ ÛŒÚ©Ù¾Ø§Ø±Ú†Ú¯ÛŒ

Microsoft Agent Framework Ø¨Ù‡ ØªÚ©Ø§Ù…Ù„ Ø®ÙˆØ¯ Ø¨Ø§ Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ SLM Ù¾ÛŒØ´Ø±ÙØªÙ‡ØŒ Ø§Ø¨Ø²Ø§Ø±Ù‡Ø§ÛŒ Ø§Ø³ØªÙ‚Ø±Ø§Ø± Ù„Ø¨Ù‡ Ø¨Ù‡Ø¨ÙˆØ¯ ÛŒØ§ÙØªÙ‡ØŒ Ù…Ø¯ÛŒØ±ÛŒØª Ù…Ù†Ø§Ø¨Ø¹ Ø¨Ù‡ØªØ± Ø¨Ø±Ø§ÛŒ Ù…Ø­ÛŒØ·â€ŒÙ‡Ø§ÛŒ Ù…Ø­Ø¯ÙˆØ¯ Ø¨Ù‡ Ù…Ù†Ø§Ø¨Ø¹ØŒ Ùˆ Ø§Ú©ÙˆØ³ÛŒØ³ØªÙ… Ø§Ø¨Ø²Ø§Ø± Ú¯Ø³ØªØ±Ø´â€ŒÛŒØ§ÙØªÙ‡ Ø¨Ø±Ø§ÛŒ Ø³Ù†Ø§Ø±ÛŒÙˆÙ‡Ø§ÛŒ Ù…Ø¹Ù…ÙˆÙ„ Ø³Ø§Ø²Ù…Ø§Ù†ÛŒ Ø§Ø¯Ø§Ù…Ù‡ Ù…ÛŒâ€ŒØ¯Ù‡Ø¯.

**ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ø¢ÛŒÙ†Ø¯Ù‡**:
- **AutoML Ø¨Ø±Ø§ÛŒ Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø¹Ø§Ù…Ù„**: ØªÙ†Ø¸ÛŒÙ… Ø®ÙˆØ¯Ú©Ø§Ø± SLMÙ‡Ø§ Ø¨Ø±Ø§ÛŒ ÙˆØ¸Ø§ÛŒÙ Ø®Ø§Øµ Ø¹Ø§Ù…Ù„  
- **Ø´Ø¨Ú©Ù‡â€ŒØ³Ø§Ø²ÛŒ Ù…Ø´ Ù„Ø¨Ù‡**: Ù‡Ù…Ø§Ù‡Ù†Ú¯ÛŒ Ø¨ÛŒÙ† Ø§Ø³ØªÙ‚Ø±Ø§Ø±Ù‡Ø§ÛŒ Ù…ØªØ¹Ø¯Ø¯ Ø¹Ø§Ù…Ù„ Ù„Ø¨Ù‡  
- **ØªÙ„Ù‡â€ŒÙ…ØªØ±ÛŒ Ù¾ÛŒØ´Ø±ÙØªÙ‡**: Ù†Ø¸Ø§Ø±Øª Ùˆ ØªØ­Ù„ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ø¨Ù‡Ø¨ÙˆØ¯ ÛŒØ§ÙØªÙ‡ Ø¨Ø±Ø§ÛŒ Ø¹Ù…Ù„Ú©Ø±Ø¯ Ø¹Ø§Ù…Ù„  
- **Ø³Ø§Ø²Ù†Ø¯Ù‡ Ø¹Ø§Ù…Ù„ Ø¨ØµØ±ÛŒ**: Ø§Ø¨Ø²Ø§Ø±Ù‡Ø§ÛŒ ØªÙˆØ³Ø¹Ù‡ Ø¹Ø§Ù…Ù„ Ú©Ù…â€ŒÚ©Ø¯/Ø¨Ø¯ÙˆÙ† Ú©Ø¯  

## Ø¨Ù‡ØªØ±ÛŒÙ† Ø±ÙˆØ´â€ŒÙ‡Ø§ Ø¨Ø±Ø§ÛŒ Ù¾ÛŒØ§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø¹Ø§Ù…Ù„ SLM

### Ø¯Ø³ØªÙˆØ±Ø§Ù„Ø¹Ù…Ù„â€ŒÙ‡Ø§ÛŒ Ø§Ù†ØªØ®Ø§Ø¨ SLM Ø¨Ø±Ø§ÛŒ Ø¹ÙˆØ§Ù…Ù„

Ù‡Ù†Ú¯Ø§Ù… Ø§Ù†ØªØ®Ø§Ø¨ SLMÙ‡Ø§ Ø¨Ø±Ø§ÛŒ Ø§Ø³ØªÙ‚Ø±Ø§Ø± Ø¹Ø§Ù…Ù„ØŒ Ø¹ÙˆØ§Ù…Ù„ Ø²ÛŒØ± Ø±Ø§ Ø¯Ø± Ù†Ø¸Ø± Ø¨Ú¯ÛŒØ±ÛŒØ¯:

**Ù…Ù„Ø§Ø­Ø¸Ø§Øª Ø§Ù†Ø¯Ø§Ø²Ù‡ Ù…Ø¯Ù„**: Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ ÙÙˆÙ‚ ÙØ´Ø±Ø¯Ù‡ Ù…Ø§Ù†Ù†Ø¯ Q2_K Ø±Ø§ Ø¨Ø±Ø§ÛŒ Ø¨Ø±Ù†Ø§Ù…Ù‡â€ŒÙ‡Ø§ÛŒ Ø¹Ø§Ù…Ù„ Ù…ÙˆØ¨Ø§ÛŒÙ„ Ø¨Ø³ÛŒØ§Ø± Ù…Ø­Ø¯ÙˆØ¯ØŒ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ù…ØªØ¹Ø§Ø¯Ù„ Ù…Ø§Ù†Ù†Ø¯ Q4_K_M Ø±Ø§ Ø¨Ø±Ø§ÛŒ Ø³Ù†Ø§Ø±ÛŒÙˆÙ‡Ø§ÛŒ Ø¹Ù…ÙˆÙ…ÛŒ Ø¹Ø§Ù…Ù„ØŒ Ùˆ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ø¨Ø§ Ø¯Ù‚Øª Ø¨Ø§Ù„Ø§ØªØ± Ù…Ø§Ù†Ù†Ø¯ Q8_0 Ø±Ø§ Ø¨Ø±Ø§ÛŒ Ø¨Ø±Ù†Ø§Ù…Ù‡â€ŒÙ‡Ø§ÛŒ Ø¹Ø§Ù…Ù„ Ø­Ø³Ø§Ø³ Ø¨Ù‡ Ú©ÛŒÙÛŒØª Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ù†ÛŒØ¯.

**Ù‡Ù…â€ŒØ±Ø§Ø³ØªØ§ÛŒÛŒ Ù…ÙˆØ±Ø¯ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø¹Ø§Ù…Ù„**: Ù‚Ø§Ø¨Ù„ÛŒØªâ€ŒÙ‡Ø§ÛŒ SLM Ø±Ø§ Ø¨Ø§ Ù†ÛŒØ§Ø²Ù‡Ø§ÛŒ Ø®Ø§Øµ Ø¹Ø§Ù…Ù„ Ù…Ø·Ø§Ø¨Ù‚Øª Ø¯Ù‡ÛŒØ¯ØŒ Ø¨Ø§ Ø¯Ø± Ù†Ø¸Ø± Ú¯Ø±ÙØªÙ† Ø¹ÙˆØ§Ù…Ù„ÛŒ Ù…Ø§Ù†Ù†Ø¯ Ø­ÙØ¸ Ø¯Ù‚Øª Ø¨Ø±Ø§ÛŒ ØªØµÙ…ÛŒÙ…Ø§Øª Ø¹Ø§Ù…Ù„ØŒ Ø³Ø±Ø¹Øª Ø§Ø³ØªÙ†ØªØ§Ø¬ Ø¨Ø±Ø§ÛŒ ØªØ¹Ø§Ù…Ù„Ø§Øª Ø¹Ø§Ù…Ù„ Ø¯Ø± Ø²Ù…Ø§Ù† ÙˆØ§Ù‚Ø¹ÛŒØŒ Ù…Ø­Ø¯ÙˆØ¯ÛŒØªâ€ŒÙ‡Ø§ÛŒ Ø­Ø§ÙØ¸Ù‡ Ø¨Ø±Ø§ÛŒ Ø§Ø³ØªÙ‚Ø±Ø§Ø± Ø¹Ø§Ù…Ù„ Ù„Ø¨Ù‡ØŒ Ùˆ Ù†ÛŒØ§Ø²Ù‡Ø§ÛŒ Ø¹Ù…Ù„Ú©Ø±Ø¯ Ø¢ÙÙ„Ø§ÛŒÙ† Ø¨Ø±Ø§ÛŒ Ø¹ÙˆØ§Ù…Ù„ Ù…ØªÙ…Ø±Ú©Ø² Ø¨Ø± Ø­
**Ø§Ù†ØªØ®Ø§Ø¨ Ú†Ø§Ø±Ú†ÙˆØ¨ Ø¨Ø±Ø§ÛŒ Ø§Ø³ØªÙ‚Ø±Ø§Ø± Ø¹Ø§Ù…Ù„**: Ú†Ø§Ø±Ú†ÙˆØ¨â€ŒÙ‡Ø§ÛŒ Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø±Ø§ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø³Ø®Øªâ€ŒØ§ÙØ²Ø§Ø± Ù‡Ø¯Ù Ùˆ Ù†ÛŒØ§Ø²Ù‡Ø§ÛŒ Ø¹Ø§Ù…Ù„ Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ù†ÛŒØ¯. Ø§Ø² Llama.cpp Ø¨Ø±Ø§ÛŒ Ø§Ø³ØªÙ‚Ø±Ø§Ø± Ø¹Ø§Ù…Ù„ Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ´Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ CPUØŒ Apple MLX Ø¨Ø±Ø§ÛŒ Ø¨Ø±Ù†Ø§Ù…Ù‡â€ŒÙ‡Ø§ÛŒ Ø¹Ø§Ù…Ù„ Ø¯Ø± Apple Silicon Ùˆ ONNX Ø¨Ø±Ø§ÛŒ Ø³Ø§Ø²Ú¯Ø§Ø±ÛŒ Ø¹Ø§Ù…Ù„ Ø¯Ø± Ù¾Ù„ØªÙØ±Ù…â€ŒÙ‡Ø§ÛŒ Ù…Ø®ØªÙ„Ù Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯.

## ØªØ¨Ø¯ÛŒÙ„ Ø¹Ù…Ù„ÛŒ Ø¹Ø§Ù…Ù„ SLM Ùˆ Ù…ÙˆØ§Ø±Ø¯ Ø§Ø³ØªÙØ§Ø¯Ù‡

### Ø³Ù†Ø§Ø±ÛŒÙˆÙ‡Ø§ÛŒ ÙˆØ§Ù‚Ø¹ÛŒ Ø§Ø³ØªÙ‚Ø±Ø§Ø± Ø¹Ø§Ù…Ù„

**Ø¨Ø±Ù†Ø§Ù…Ù‡â€ŒÙ‡Ø§ÛŒ Ø¹Ø§Ù…Ù„ Ù…ÙˆØ¨Ø§ÛŒÙ„**: ÙØ±Ù…Øªâ€ŒÙ‡Ø§ÛŒ Q4_K Ø¯Ø± Ø¨Ø±Ù†Ø§Ù…Ù‡â€ŒÙ‡Ø§ÛŒ Ø¹Ø§Ù…Ù„ Ú¯ÙˆØ´ÛŒâ€ŒÙ‡Ø§ÛŒ Ù‡ÙˆØ´Ù…Ù†Ø¯ Ø¨Ø§ Ø­Ø¯Ø§Ù‚Ù„ Ù…ØµØ±Ù Ø­Ø§ÙØ¸Ù‡ Ø¹Ø§Ù„ÛŒ Ø¹Ù…Ù„ Ù…ÛŒâ€ŒÚ©Ù†Ù†Ø¯ØŒ Ø¯Ø± Ø­Ø§Ù„ÛŒ Ú©Ù‡ Q8_0 Ø¹Ù…Ù„Ú©Ø±Ø¯ Ù…ØªØ¹Ø§Ø¯Ù„ÛŒ Ø¨Ø±Ø§ÛŒ Ø³ÛŒØ³ØªÙ…â€ŒÙ‡Ø§ÛŒ Ø¹Ø§Ù…Ù„ Ù…Ø¨ØªÙ†ÛŒ Ø¨Ø± ØªØ¨Ù„Øª Ø§Ø±Ø§Ø¦Ù‡ Ù…ÛŒâ€ŒØ¯Ù‡Ø¯. ÙØ±Ù…Øªâ€ŒÙ‡Ø§ÛŒ Q5_K Ú©ÛŒÙÛŒØª Ø¨Ø±ØªØ±ÛŒ Ø¨Ø±Ø§ÛŒ Ø¹ÙˆØ§Ù…Ù„ Ø¨Ù‡Ø±Ù‡â€ŒÙˆØ±ÛŒ Ù…ÙˆØ¨Ø§ÛŒÙ„ Ø¯Ø§Ø±Ù†Ø¯.

**Ø±Ø§ÛŒØ§Ù†Ù‡â€ŒÙ‡Ø§ÛŒ Ø±ÙˆÙ…ÛŒØ²ÛŒ Ùˆ Ù…Ø­Ø§Ø³Ø¨Ø§Øª Ø¹Ø§Ù…Ù„ Ù„Ø¨Ù‡**: Q5_K Ø¹Ù…Ù„Ú©Ø±Ø¯ Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ§ÛŒ Ø¨Ø±Ø§ÛŒ Ø¨Ø±Ù†Ø§Ù…Ù‡â€ŒÙ‡Ø§ÛŒ Ø¹Ø§Ù…Ù„ Ø±Ø§ÛŒØ§Ù†Ù‡â€ŒÙ‡Ø§ÛŒ Ø±ÙˆÙ…ÛŒØ²ÛŒ Ø§Ø±Ø§Ø¦Ù‡ Ù…ÛŒâ€ŒØ¯Ù‡Ø¯ØŒ Q8_0 Ø§Ø³ØªÙ†ØªØ§Ø¬ Ø¨Ø§ Ú©ÛŒÙÛŒØª Ø¨Ø§Ù„Ø§ Ø±Ø§ Ø¨Ø±Ø§ÛŒ Ù…Ø­ÛŒØ·â€ŒÙ‡Ø§ÛŒ Ø¹Ø§Ù…Ù„ Ø§ÛŒØ³ØªÚ¯Ø§Ù‡ Ú©Ø§Ø±ÛŒ ÙØ±Ø§Ù‡Ù… Ù…ÛŒâ€ŒÚ©Ù†Ø¯ Ùˆ Q4_K Ù¾Ø±Ø¯Ø§Ø²Ø´ Ú©Ø§Ø±Ø¢Ù…Ø¯ÛŒ Ø±Ø§ Ø¯Ø± Ø¯Ø³ØªÚ¯Ø§Ù‡â€ŒÙ‡Ø§ÛŒ Ø¹Ø§Ù…Ù„ Ù„Ø¨Ù‡ Ø§Ù…Ú©Ø§Ù†â€ŒÙ¾Ø°ÛŒØ± Ù…ÛŒâ€ŒØ³Ø§Ø²Ø¯.

**Ø¹ÙˆØ§Ù…Ù„ ØªØ­Ù‚ÛŒÙ‚Ø§ØªÛŒ Ùˆ Ø¢Ø²Ù…Ø§ÛŒØ´ÛŒ**: ÙØ±Ù…Øªâ€ŒÙ‡Ø§ÛŒ Ù¾ÛŒØ´Ø±ÙØªÙ‡ Ú©ÙˆØ§Ù†ØªÛŒØ²Ø§Ø³ÛŒÙˆÙ† Ø§Ù…Ú©Ø§Ù† Ø¨Ø±Ø±Ø³ÛŒ Ø§Ø³ØªÙ†ØªØ§Ø¬ Ø¹Ø§Ù…Ù„ Ø¨Ø§ Ø¯Ù‚Øª ÙÙˆÙ‚â€ŒØ§Ù„Ø¹Ø§Ø¯Ù‡ Ù¾Ø§ÛŒÛŒÙ† Ø±Ø§ Ø¨Ø±Ø§ÛŒ ØªØ­Ù‚ÛŒÙ‚Ø§Øª Ø¢Ú©Ø§Ø¯Ù…ÛŒÚ© Ùˆ Ø¨Ø±Ù†Ø§Ù…Ù‡â€ŒÙ‡Ø§ÛŒ Ø¹Ø§Ù…Ù„ Ø§Ø«Ø¨Ø§Øª Ù…ÙÙ‡ÙˆÙ… Ú©Ù‡ Ù†ÛŒØ§Ø² Ø¨Ù‡ Ù…Ø­Ø¯ÙˆØ¯ÛŒØªâ€ŒÙ‡Ø§ÛŒ Ø´Ø¯ÛŒØ¯ Ù…Ù†Ø§Ø¨Ø¹ Ø¯Ø§Ø±Ù†Ø¯ØŒ ÙØ±Ø§Ù‡Ù… Ù…ÛŒâ€ŒÚ©Ù†Ù†Ø¯.

### Ù…Ø¹ÛŒØ§Ø±Ù‡Ø§ÛŒ Ø¹Ù…Ù„Ú©Ø±Ø¯ Ø¹Ø§Ù…Ù„ SLM

**Ø³Ø±Ø¹Øª Ø§Ø³ØªÙ†ØªØ§Ø¬ Ø¹Ø§Ù…Ù„**: Q4_K Ø³Ø±ÛŒØ¹â€ŒØªØ±ÛŒÙ† Ø²Ù…Ø§Ù† Ù¾Ø§Ø³Ø® Ø¹Ø§Ù…Ù„ Ø±Ø§ Ø¨Ø± Ø±ÙˆÛŒ CPUÙ‡Ø§ÛŒ Ù…ÙˆØ¨Ø§ÛŒÙ„ Ø§Ø±Ø§Ø¦Ù‡ Ù…ÛŒâ€ŒØ¯Ù‡Ø¯ØŒ Q5_K Ù†Ø³Ø¨Øª Ø³Ø±Ø¹Øª-Ú©ÛŒÙÛŒØª Ù…ØªØ¹Ø§Ø¯Ù„ÛŒ Ø±Ø§ Ø¨Ø±Ø§ÛŒ Ø¨Ø±Ù†Ø§Ù…Ù‡â€ŒÙ‡Ø§ÛŒ Ø¹Ø§Ù…Ù„ Ø¹Ù…ÙˆÙ…ÛŒ ÙØ±Ø§Ù‡Ù… Ù…ÛŒâ€ŒÚ©Ù†Ø¯ØŒ Q8_0 Ú©ÛŒÙÛŒØª Ø¨Ø±ØªØ±ÛŒ Ø±Ø§ Ø¨Ø±Ø§ÛŒ ÙˆØ¸Ø§ÛŒÙ Ù¾ÛŒÚ†ÛŒØ¯Ù‡ Ø¹Ø§Ù…Ù„ Ø§Ø±Ø§Ø¦Ù‡ Ù…ÛŒâ€ŒØ¯Ù‡Ø¯ Ùˆ ÙØ±Ù…Øªâ€ŒÙ‡Ø§ÛŒ Ø¢Ø²Ù…Ø§ÛŒØ´ÛŒ Ø­Ø¯Ø§Ú©Ø«Ø± ØªÙˆØ§Ù† Ø±Ø§ Ø¨Ø±Ø§ÛŒ Ø³Ø®Øªâ€ŒØ§ÙØ²Ø§Ø±Ù‡Ø§ÛŒ ØªØ®ØµØµÛŒ Ø¹Ø§Ù…Ù„ ÙØ±Ø§Ù‡Ù… Ù…ÛŒâ€ŒÚ©Ù†Ù†Ø¯.

**Ù†ÛŒØ§Ø²Ù‡Ø§ÛŒ Ø­Ø§ÙØ¸Ù‡ Ø¹Ø§Ù…Ù„**: Ø³Ø·ÙˆØ­ Ú©ÙˆØ§Ù†ØªÛŒØ²Ø§Ø³ÛŒÙˆÙ† Ø¨Ø±Ø§ÛŒ Ø¹ÙˆØ§Ù…Ù„ Ø§Ø² Q2_K (Ú©Ù…ØªØ± Ø§Ø² 500MB Ø¨Ø±Ø§ÛŒ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ø¹Ø§Ù…Ù„ Ú©ÙˆÚ†Ú©) ØªØ§ Q8_0 (ØªÙ‚Ø±ÛŒØ¨Ø§Ù‹ 50% Ø§Ù†Ø¯Ø§Ø²Ù‡ Ø§ØµÙ„ÛŒ) Ù…ØªØºÛŒØ± Ø§Ø³ØªØŒ Ø¨Ø§ Ù¾ÛŒÚ©Ø±Ø¨Ù†Ø¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ø¢Ø²Ù…Ø§ÛŒØ´ÛŒ Ú©Ù‡ Ø­Ø¯Ø§Ú©Ø«Ø± ÙØ´Ø±Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø±Ø§ Ø¨Ø±Ø§ÛŒ Ù…Ø­ÛŒØ·â€ŒÙ‡Ø§ÛŒ Ø¹Ø§Ù…Ù„ Ø¨Ø§ Ù…Ù†Ø§Ø¨Ø¹ Ù…Ø­Ø¯ÙˆØ¯ ÙØ±Ø§Ù‡Ù… Ù…ÛŒâ€ŒÚ©Ù†Ù†Ø¯.

## Ú†Ø§Ù„Ø´â€ŒÙ‡Ø§ Ùˆ Ù…Ù„Ø§Ø­Ø¸Ø§Øª Ø¨Ø±Ø§ÛŒ Ø¹ÙˆØ§Ù…Ù„ SLM

### Ù…ØµØ§Ù„Ø­Ù‡â€ŒÙ‡Ø§ÛŒ Ø¹Ù…Ù„Ú©Ø±Ø¯ Ø¯Ø± Ø³ÛŒØ³ØªÙ…â€ŒÙ‡Ø§ÛŒ Ø¹Ø§Ù…Ù„

Ø§Ø³ØªÙ‚Ø±Ø§Ø± Ø¹Ø§Ù…Ù„ SLM Ø´Ø§Ù…Ù„ Ø¨Ø±Ø±Ø³ÛŒ Ø¯Ù‚ÛŒÙ‚ Ù…ØµØ§Ù„Ø­Ù‡â€ŒÙ‡Ø§ Ø¨ÛŒÙ† Ø§Ù†Ø¯Ø§Ø²Ù‡ Ù…Ø¯Ù„ØŒ Ø³Ø±Ø¹Øª Ù¾Ø§Ø³Ø® Ø¹Ø§Ù…Ù„ Ùˆ Ú©ÛŒÙÛŒØª Ø®Ø±ÙˆØ¬ÛŒ Ø§Ø³Øª. Ø¯Ø± Ø­Ø§Ù„ÛŒ Ú©Ù‡ Q4_K Ø³Ø±Ø¹Øª Ùˆ Ú©Ø§Ø±Ø§ÛŒÛŒ Ø§Ø³ØªØ«Ù†Ø§ÛŒÛŒ Ø±Ø§ Ø¨Ø±Ø§ÛŒ Ø¹ÙˆØ§Ù…Ù„ Ù…ÙˆØ¨Ø§ÛŒÙ„ Ø§Ø±Ø§Ø¦Ù‡ Ù…ÛŒâ€ŒØ¯Ù‡Ø¯ØŒ Q8_0 Ú©ÛŒÙÛŒØª Ø¨Ø±ØªØ±ÛŒ Ø±Ø§ Ø¨Ø±Ø§ÛŒ ÙˆØ¸Ø§ÛŒÙ Ù¾ÛŒÚ†ÛŒØ¯Ù‡ Ø¹Ø§Ù…Ù„ ÙØ±Ø§Ù‡Ù… Ù…ÛŒâ€ŒÚ©Ù†Ø¯. Q5_K ØªØ¹Ø§Ø¯Ù„ Ù…Ù†Ø§Ø³Ø¨ÛŒ Ø±Ø§ Ø¨Ø±Ø§ÛŒ Ø§Ú©Ø«Ø± Ø¨Ø±Ù†Ø§Ù…Ù‡â€ŒÙ‡Ø§ÛŒ Ø¹Ø§Ù…Ù„ Ø¹Ù…ÙˆÙ…ÛŒ Ø§ÛŒØ¬Ø§Ø¯ Ù…ÛŒâ€ŒÚ©Ù†Ø¯.

### Ø³Ø§Ø²Ú¯Ø§Ø±ÛŒ Ø³Ø®Øªâ€ŒØ§ÙØ²Ø§Ø±ÛŒ Ø¨Ø±Ø§ÛŒ Ø¹ÙˆØ§Ù…Ù„ SLM

Ø¯Ø³ØªÚ¯Ø§Ù‡â€ŒÙ‡Ø§ÛŒ Ù„Ø¨Ù‡ Ù…Ø®ØªÙ„Ù Ù‚Ø§Ø¨Ù„ÛŒØªâ€ŒÙ‡Ø§ÛŒ Ù…ØªÙØ§ÙˆØªÛŒ Ø¨Ø±Ø§ÛŒ Ø§Ø³ØªÙ‚Ø±Ø§Ø± Ø¹Ø§Ù…Ù„ SLM Ø¯Ø§Ø±Ù†Ø¯. Q4_K Ø¨Ø± Ø±ÙˆÛŒ Ù¾Ø±Ø¯Ø§Ø²Ù†Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø³Ø§Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ Ø¹ÙˆØ§Ù…Ù„ Ø³Ø§Ø¯Ù‡ Ø¨Ù‡ Ø®ÙˆØ¨ÛŒ Ø§Ø¬Ø±Ø§ Ù…ÛŒâ€ŒØ´ÙˆØ¯ØŒ Q5_K Ù…Ù†Ø§Ø¨Ø¹ Ù…Ø­Ø§Ø³Ø¨Ø§ØªÛŒ Ù…ØªÙˆØ³Ø·ÛŒ Ø±Ø§ Ø¨Ø±Ø§ÛŒ Ø¹Ù…Ù„Ú©Ø±Ø¯ Ù…ØªØ¹Ø§Ø¯Ù„ Ø¹Ø§Ù…Ù„ Ù†ÛŒØ§Ø² Ø¯Ø§Ø±Ø¯ Ùˆ Q8_0 Ø§Ø² Ø³Ø®Øªâ€ŒØ§ÙØ²Ø§Ø±Ù‡Ø§ÛŒ Ù¾ÛŒØ´Ø±ÙØªÙ‡â€ŒØªØ± Ø¨Ø±Ø§ÛŒ Ù‚Ø§Ø¨Ù„ÛŒØªâ€ŒÙ‡Ø§ÛŒ Ù¾ÛŒØ´Ø±ÙØªÙ‡ Ø¹Ø§Ù…Ù„ Ø¨Ù‡Ø±Ù‡ Ù…ÛŒâ€ŒØ¨Ø±Ø¯.

### Ø§Ù…Ù†ÛŒØª Ùˆ Ø­Ø±ÛŒÙ… Ø®ØµÙˆØµÛŒ Ø¯Ø± Ø³ÛŒØ³ØªÙ…â€ŒÙ‡Ø§ÛŒ Ø¹Ø§Ù…Ù„ SLM

Ø¯Ø± Ø­Ø§Ù„ÛŒ Ú©Ù‡ Ø¹ÙˆØ§Ù…Ù„ SLM Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù…Ø­Ù„ÛŒ Ø±Ø§ Ø¨Ø±Ø§ÛŒ Ø§ÙØ²Ø§ÛŒØ´ Ø­Ø±ÛŒÙ… Ø®ØµÙˆØµÛŒ Ø§Ù…Ú©Ø§Ù†â€ŒÙ¾Ø°ÛŒØ± Ù…ÛŒâ€ŒØ³Ø§Ø²Ù†Ø¯ØŒ Ø¨Ø§ÛŒØ¯ Ø§Ù‚Ø¯Ø§Ù…Ø§Øª Ø§Ù…Ù†ÛŒØªÛŒ Ù…Ù†Ø§Ø³Ø¨ Ø¨Ø±Ø§ÛŒ Ø­ÙØ§Ø¸Øª Ø§Ø² Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ø¹Ø§Ù…Ù„ Ùˆ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø¯Ø± Ù…Ø­ÛŒØ·â€ŒÙ‡Ø§ÛŒ Ù„Ø¨Ù‡ Ø§Ø¬Ø±Ø§ Ø´ÙˆØ¯. Ø§ÛŒÙ† Ø§Ù…Ø± Ø¨Ù‡ ÙˆÛŒÚ˜Ù‡ Ù‡Ù†Ú¯Ø§Ù… Ø§Ø³ØªÙ‚Ø±Ø§Ø± ÙØ±Ù…Øªâ€ŒÙ‡Ø§ÛŒ Ø¹Ø§Ù…Ù„ Ø¨Ø§ Ø¯Ù‚Øª Ø¨Ø§Ù„Ø§ Ø¯Ø± Ù…Ø­ÛŒØ·â€ŒÙ‡Ø§ÛŒ Ø³Ø§Ø²Ù…Ø§Ù†ÛŒ ÛŒØ§ ÙØ±Ù…Øªâ€ŒÙ‡Ø§ÛŒ Ø¹Ø§Ù…Ù„ ÙØ´Ø±Ø¯Ù‡ Ø¯Ø± Ø¨Ø±Ù†Ø§Ù…Ù‡â€ŒÙ‡Ø§ÛŒÛŒ Ú©Ù‡ Ø¨Ø§ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø­Ø³Ø§Ø³ Ø³Ø±ÙˆÚ©Ø§Ø± Ø¯Ø§Ø±Ù†Ø¯ØŒ Ø§Ù‡Ù…ÛŒØª Ø¯Ø§Ø±Ø¯.

## Ø±ÙˆÙ†Ø¯Ù‡Ø§ÛŒ Ø¢ÛŒÙ†Ø¯Ù‡ Ø¯Ø± ØªÙˆØ³Ø¹Ù‡ Ø¹ÙˆØ§Ù…Ù„ SLM

Ú†Ø´Ù…â€ŒØ§Ù†Ø¯Ø§Ø² Ø¹ÙˆØ§Ù…Ù„ SLM Ø¨Ø§ Ù¾ÛŒØ´Ø±ÙØª Ø¯Ø± ØªÚ©Ù†ÛŒÚ©â€ŒÙ‡Ø§ÛŒ ÙØ´Ø±Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒØŒ Ø±ÙˆØ´â€ŒÙ‡Ø§ÛŒ Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ùˆ Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒâ€ŒÙ‡Ø§ÛŒ Ø§Ø³ØªÙ‚Ø±Ø§Ø± Ù„Ø¨Ù‡ Ù‡Ù…Ú†Ù†Ø§Ù† Ø¯Ø± Ø­Ø§Ù„ ØªØ­ÙˆÙ„ Ø§Ø³Øª. ØªÙˆØ³Ø¹Ù‡â€ŒÙ‡Ø§ÛŒ Ø¢ÛŒÙ†Ø¯Ù‡ Ø´Ø§Ù…Ù„ Ø§Ù„Ú¯ÙˆØ±ÛŒØªÙ…â€ŒÙ‡Ø§ÛŒ Ú©ÙˆØ§Ù†ØªÛŒØ²Ø§Ø³ÛŒÙˆÙ† Ú©Ø§Ø±Ø¢Ù…Ø¯ØªØ± Ø¨Ø±Ø§ÛŒ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ø¹Ø§Ù…Ù„ØŒ Ø±ÙˆØ´â€ŒÙ‡Ø§ÛŒ ÙØ´Ø±Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø¨Ù‡Ø¨ÙˆØ¯ ÛŒØ§ÙØªÙ‡ Ø¨Ø±Ø§ÛŒ Ø¬Ø±ÛŒØ§Ù†â€ŒÙ‡Ø§ÛŒ Ú©Ø§Ø±ÛŒ Ø¹Ø§Ù…Ù„ Ùˆ Ø§Ø¯ØºØ§Ù… Ø¨Ù‡ØªØ± Ø¨Ø§ Ø´ØªØ§Ø¨â€ŒØ¯Ù‡Ù†Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø³Ø®Øªâ€ŒØ§ÙØ²Ø§Ø±ÛŒ Ù„Ø¨Ù‡ Ø¨Ø±Ø§ÛŒ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø¹Ø§Ù…Ù„ Ø®ÙˆØ§Ù‡Ø¯ Ø¨ÙˆØ¯.

**Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒâ€ŒÙ‡Ø§ÛŒ Ø¨Ø§Ø²Ø§Ø± Ø¨Ø±Ø§ÛŒ Ø¹ÙˆØ§Ù…Ù„ SLM**: Ø¨Ø± Ø§Ø³Ø§Ø³ ØªØ­Ù‚ÛŒÙ‚Ø§Øª Ø§Ø®ÛŒØ±ØŒ Ø§ØªÙˆÙ…Ø§Ø³ÛŒÙˆÙ† Ù…Ø¨ØªÙ†ÛŒ Ø¨Ø± Ø¹Ø§Ù…Ù„ Ù…ÛŒâ€ŒØªÙˆØ§Ù†Ø¯ 40â€“60% Ø§Ø² ÙˆØ¸Ø§ÛŒÙ Ø´Ù†Ø§Ø®ØªÛŒ ØªÚ©Ø±Ø§Ø±ÛŒ Ø±Ø§ Ø¯Ø± Ø¬Ø±ÛŒØ§Ù†â€ŒÙ‡Ø§ÛŒ Ú©Ø§Ø±ÛŒ Ø³Ø§Ø²Ù…Ø§Ù†ÛŒ ØªØ§ Ø³Ø§Ù„ 2027 Ø­Ø°Ù Ú©Ù†Ø¯ØŒ Ø¨Ø§ SLMâ€ŒÙ‡Ø§ Ú©Ù‡ Ø§ÛŒÙ† ØªØ­ÙˆÙ„ Ø±Ø§ Ø¨Ù‡ Ø¯Ù„ÛŒÙ„ Ú©Ø§Ø±Ø§ÛŒÛŒ Ù‡Ø²ÛŒÙ†Ù‡ Ùˆ Ø§Ù†Ø¹Ø·Ø§Ùâ€ŒÙ¾Ø°ÛŒØ±ÛŒ Ø§Ø³ØªÙ‚Ø±Ø§Ø± Ù‡Ø¯Ø§ÛŒØª Ù…ÛŒâ€ŒÚ©Ù†Ù†Ø¯.

**Ø±ÙˆÙ†Ø¯Ù‡Ø§ÛŒ ÙÙ†Ø§ÙˆØ±ÛŒ Ø¯Ø± Ø¹ÙˆØ§Ù…Ù„ SLM**:
- **Ø¹ÙˆØ§Ù…Ù„ SLM ØªØ®ØµØµÛŒ**: Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ø®Ø§Øµ Ø¯Ø§Ù…Ù†Ù‡ Ú©Ù‡ Ø¨Ø±Ø§ÛŒ ÙˆØ¸Ø§ÛŒÙ Ùˆ ØµÙ†Ø§ÛŒØ¹ Ø®Ø§Øµ Ø¹Ø§Ù…Ù„ Ø¢Ù…ÙˆØ²Ø´ Ø¯ÛŒØ¯Ù‡â€ŒØ§Ù†Ø¯
- **Ù…Ø­Ø§Ø³Ø¨Ø§Øª Ø¹Ø§Ù…Ù„ Ù„Ø¨Ù‡**: Ù‚Ø§Ø¨Ù„ÛŒØªâ€ŒÙ‡Ø§ÛŒ Ø¹Ø§Ù…Ù„ Ø¨Ù‡Ø¨ÙˆØ¯ ÛŒØ§ÙØªÙ‡ Ø¯Ø± Ø¯Ø³ØªÚ¯Ø§Ù‡ Ø¨Ø§ Ø­Ø±ÛŒÙ… Ø®ØµÙˆØµÛŒ Ø¨Ù‡ØªØ± Ùˆ Ú©Ø§Ù‡Ø´ ØªØ£Ø®ÛŒØ±
- **Ù‡Ù…Ø§Ù‡Ù†Ú¯ÛŒ Ø¹Ø§Ù…Ù„**: Ù‡Ù…Ø§Ù‡Ù†Ú¯ÛŒ Ø¨Ù‡ØªØ± Ø¨ÛŒÙ† Ø¹ÙˆØ§Ù…Ù„ SLM Ù…ØªØ¹Ø¯Ø¯ Ø¨Ø§ Ù…Ø³ÛŒØ±ÛŒØ§Ø¨ÛŒ Ù¾ÙˆÛŒØ§ Ùˆ ØªØ¹Ø§Ø¯Ù„ Ø¨Ø§Ø±
- **Ø¯Ù…ÙˆÚ©Ø±Ø§ØªÛŒØ²Ù‡â€ŒØ³Ø§Ø²ÛŒ**: Ø§Ù†Ø¹Ø·Ø§Ùâ€ŒÙ¾Ø°ÛŒØ±ÛŒ SLM Ø§Ù…Ú©Ø§Ù† Ù…Ø´Ø§Ø±Ú©Øª Ú¯Ø³ØªØ±Ø¯Ù‡â€ŒØªØ± Ø¯Ø± ØªÙˆØ³Ø¹Ù‡ Ø¹Ø§Ù…Ù„ Ø±Ø§ Ø¯Ø± Ø³Ø±Ø§Ø³Ø± Ø³Ø§Ø²Ù…Ø§Ù†â€ŒÙ‡Ø§ ÙØ±Ø§Ù‡Ù… Ù…ÛŒâ€ŒÚ©Ù†Ø¯

## Ø´Ø±ÙˆØ¹ Ú©Ø§Ø± Ø¨Ø§ Ø¹ÙˆØ§Ù…Ù„ SLM

### Ù…Ø±Ø­Ù„Ù‡ 1: Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ Ù…Ø­ÛŒØ· Ú†Ø§Ø±Ú†ÙˆØ¨ Ø¹Ø§Ù…Ù„ Microsoft

**Ù†ØµØ¨ ÙˆØ§Ø¨Ø³ØªÚ¯ÛŒâ€ŒÙ‡Ø§**:
```bash
# Install Microsoft Agent Framework
pip install microsoft-agent-framework

# Install Foundry Local SDK for edge deployment
pip install foundry-local-sdk

# Install additional dependencies for edge agents
pip install openai asyncio
```

**Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ Foundry Local**:
```bash
# Start Foundry Local service
foundry service start

# Load default model for agent development
foundry model run phi-4-mini
```

### Ù…Ø±Ø­Ù„Ù‡ 2: Ø§Ù†ØªØ®Ø§Ø¨ SLM Ø¨Ø±Ø§ÛŒ Ø¨Ø±Ù†Ø§Ù…Ù‡â€ŒÙ‡Ø§ÛŒ Ø¹Ø§Ù…Ù„
Ú¯Ø²ÛŒÙ†Ù‡â€ŒÙ‡Ø§ÛŒ Ù…Ø­Ø¨ÙˆØ¨ Ø¨Ø±Ø§ÛŒ Ú†Ø§Ø±Ú†ÙˆØ¨ Ø¹Ø§Ù…Ù„ Microsoft:
- **Microsoft Phi-4 Mini (3.8B)**: Ø¹Ø§Ù„ÛŒ Ø¨Ø±Ø§ÛŒ ÙˆØ¸Ø§ÛŒÙ Ø¹Ù…ÙˆÙ…ÛŒ Ø¹Ø§Ù…Ù„ Ø¨Ø§ Ø¹Ù…Ù„Ú©Ø±Ø¯ Ù…ØªØ¹Ø§Ø¯Ù„
- **Qwen2.5-0.5B (0.5B)**: ÙÙˆÙ‚â€ŒØ§Ù„Ø¹Ø§Ø¯Ù‡ Ú©Ø§Ø±Ø¢Ù…Ø¯ Ø¨Ø±Ø§ÛŒ Ø¹ÙˆØ§Ù…Ù„ Ù…Ø³ÛŒØ±ÛŒØ§Ø¨ÛŒ Ùˆ Ø·Ø¨Ù‚Ù‡â€ŒØ¨Ù†Ø¯ÛŒ Ø³Ø§Ø¯Ù‡
- **Qwen2.5-Coder-0.5B (0.5B)**: ØªØ®ØµØµÛŒ Ø¨Ø±Ø§ÛŒ ÙˆØ¸Ø§ÛŒÙ Ø¹Ø§Ù…Ù„ Ù…Ø±ØªØ¨Ø· Ø¨Ø§ Ú©Ø¯Ù†ÙˆÛŒØ³ÛŒ
- **Phi-4 (7B)**: Ø§Ø³ØªØ¯Ù„Ø§Ù„ Ù¾ÛŒØ´Ø±ÙØªÙ‡ Ø¨Ø±Ø§ÛŒ Ø³Ù†Ø§Ø±ÛŒÙˆÙ‡Ø§ÛŒ Ù¾ÛŒÚ†ÛŒØ¯Ù‡ Ù„Ø¨Ù‡ Ø²Ù…Ø§Ù†ÛŒ Ú©Ù‡ Ù…Ù†Ø§Ø¨Ø¹ Ø§Ø¬Ø§Ø²Ù‡ Ù…ÛŒâ€ŒØ¯Ù‡Ù†Ø¯

### Ù…Ø±Ø­Ù„Ù‡ 3: Ø§ÛŒØ¬Ø§Ø¯ Ø§ÙˆÙ„ÛŒÙ† Ø¹Ø§Ù…Ù„ Ø®ÙˆØ¯ Ø¨Ø§ Ú†Ø§Ø±Ú†ÙˆØ¨ Ø¹Ø§Ù…Ù„ Microsoft

**Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ Ø§ÙˆÙ„ÛŒÙ‡ Ø¹Ø§Ù…Ù„**:
```python
from microsoft_agent_framework import Agent, Config
from foundry_local import FoundryLocalManager

# Initialize Foundry Local connection
foundry = FoundryLocalManager("phi-4-mini")

# Create agent configuration
config = Config(
    name="my-first-agent",
    model_provider="foundry-local",
    model_alias="phi-4-mini",
    offline_mode=True
)

# Create and configure agent
agent = Agent(
    config=config,
    model_endpoint=foundry.endpoint,
    api_key=foundry.api_key
)

# Define a simple tool
@agent.tool
def get_current_time() -> str:
    """Get the current time."""
    from datetime import datetime
    return datetime.now().strftime("%Y-%m-%d %H:%M:%S")

# Test the agent
response = agent.chat("What time is it?")
print(response)
```

### Ù…Ø±Ø­Ù„Ù‡ 4: ØªØ¹Ø±ÛŒÙ Ø¯Ø§Ù…Ù†Ù‡ Ùˆ Ù†ÛŒØ§Ø²Ù‡Ø§ÛŒ Ø¹Ø§Ù…Ù„
Ø¨Ø§ Ø¨Ø±Ù†Ø§Ù…Ù‡â€ŒÙ‡Ø§ÛŒ Ø¹Ø§Ù…Ù„ Ù…ØªÙ…Ø±Ú©Ø² Ùˆ Ø¨Ù‡ Ø®ÙˆØ¨ÛŒ ØªØ¹Ø±ÛŒÙ Ø´Ø¯Ù‡ Ø¨Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ú†Ø§Ø±Ú†ÙˆØ¨ Ø¹Ø§Ù…Ù„ Microsoft Ø´Ø±ÙˆØ¹ Ú©Ù†ÛŒØ¯:
- **Ø¹ÙˆØ§Ù…Ù„ Ø¯Ø§Ù…Ù†Ù‡ ÙˆØ§Ø­Ø¯**: Ø®Ø¯Ù…Ø§Øª Ù…Ø´ØªØ±ÛŒ ÛŒØ§ Ø²Ù…Ø§Ù†â€ŒØ¨Ù†Ø¯ÛŒ ÛŒØ§ ØªØ­Ù‚ÛŒÙ‚
- **Ø§Ù‡Ø¯Ø§Ù ÙˆØ§Ø¶Ø­ Ø¹Ø§Ù…Ù„**: Ø§Ù‡Ø¯Ø§Ù Ø®Ø§Øµ Ùˆ Ù‚Ø§Ø¨Ù„ Ø§Ù†Ø¯Ø§Ø²Ù‡â€ŒÚ¯ÛŒØ±ÛŒ Ø¨Ø±Ø§ÛŒ Ø¹Ù…Ù„Ú©Ø±Ø¯ Ø¹Ø§Ù…Ù„
- **Ø§Ø¯ØºØ§Ù… Ø§Ø¨Ø²Ø§Ø± Ù…Ø­Ø¯ÙˆØ¯**: Ø­Ø¯Ø§Ú©Ø«Ø± 3-5 Ø§Ø¨Ø²Ø§Ø± Ø¨Ø±Ø§ÛŒ Ø§Ø³ØªÙ‚Ø±Ø§Ø± Ø§ÙˆÙ„ÛŒÙ‡ Ø¹Ø§Ù…Ù„
- **Ù…Ø±Ø²Ù‡Ø§ÛŒ ØªØ¹Ø±ÛŒÙ Ø´Ø¯Ù‡ Ø¹Ø§Ù…Ù„**: Ù…Ø³ÛŒØ±Ù‡Ø§ÛŒ ØªØµØ§Ø¹Ø¯ÛŒ ÙˆØ§Ø¶Ø­ Ø¨Ø±Ø§ÛŒ Ø³Ù†Ø§Ø±ÛŒÙˆÙ‡Ø§ÛŒ Ù¾ÛŒÚ†ÛŒØ¯Ù‡
- **Ø·Ø±Ø§Ø­ÛŒ Ø§ÙˆÙ„ Ù„Ø¨Ù‡**: Ø§ÙˆÙ„ÙˆÛŒØªâ€ŒØ¨Ù†Ø¯ÛŒ Ø¹Ù…Ù„Ú©Ø±Ø¯ Ø¢ÙÙ„Ø§ÛŒÙ† Ùˆ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù…Ø­Ù„ÛŒ

### Ù…Ø±Ø­Ù„Ù‡ 5: Ø§Ø¬Ø±Ø§ÛŒ Ø§Ø³ØªÙ‚Ø±Ø§Ø± Ù„Ø¨Ù‡ Ø¨Ø§ Ú†Ø§Ø±Ú†ÙˆØ¨ Ø¹Ø§Ù…Ù„ Microsoft

**Ù¾ÛŒÚ©Ø±Ø¨Ù†Ø¯ÛŒ Ù…Ù†Ø§Ø¨Ø¹**:
```python
from microsoft_agent_framework import ResourceConfig

# Configure for edge deployment
resource_config = ResourceConfig(
    max_memory_usage="2GB",
    max_concurrent_agents=2,
    model_cache_size="1GB",
    auto_unload_idle_models=True,
    power_management=True
)

agent = Agent(
    config=config,
    resource_limits=resource_config
)
```

**Ø§Ø³ØªÙ‚Ø±Ø§Ø± Ø§Ù‚Ø¯Ø§Ù…Ø§Øª Ø§ÛŒÙ…Ù†ÛŒ Ø¨Ø±Ø§ÛŒ Ø¹ÙˆØ§Ù…Ù„ Ù„Ø¨Ù‡**:
- **Ø§Ø¹ØªØ¨Ø§Ø±Ø³Ù†Ø¬ÛŒ ÙˆØ±ÙˆØ¯ÛŒ Ù…Ø­Ù„ÛŒ**: Ø¨Ø±Ø±Ø³ÛŒ Ø¯Ø±Ø®ÙˆØ§Ø³Øªâ€ŒÙ‡Ø§ Ø¨Ø¯ÙˆÙ† ÙˆØ§Ø¨Ø³ØªÚ¯ÛŒ Ø¨Ù‡ Ø§Ø¨Ø±
- **ÙÛŒÙ„ØªØ± Ú©Ø±Ø¯Ù† Ø®Ø±ÙˆØ¬ÛŒ Ø¢ÙÙ„Ø§ÛŒÙ†**: Ø§Ø·Ù…ÛŒÙ†Ø§Ù† Ø§Ø² Ø§ÛŒÙ†Ú©Ù‡ Ù¾Ø§Ø³Ø®â€ŒÙ‡Ø§ Ø§Ø³ØªØ§Ù†Ø¯Ø§Ø±Ø¯Ù‡Ø§ÛŒ Ú©ÛŒÙÛŒØª Ø±Ø§ Ø¨Ù‡ ØµÙˆØ±Øª Ù…Ø­Ù„ÛŒ Ø¨Ø±Ø¢ÙˆØ±Ø¯Ù‡ Ù…ÛŒâ€ŒÚ©Ù†Ù†Ø¯
- **Ú©Ù†ØªØ±Ù„â€ŒÙ‡Ø§ÛŒ Ø§Ù…Ù†ÛŒØªÛŒ Ù„Ø¨Ù‡**: Ø§Ø¬Ø±Ø§ÛŒ Ø§Ù…Ù†ÛŒØª Ø¨Ø¯ÙˆÙ† Ù†ÛŒØ§Ø² Ø¨Ù‡ Ø§ØªØµØ§Ù„ Ø§ÛŒÙ†ØªØ±Ù†Øª
- **Ù†Ø¸Ø§Ø±Øª Ù…Ø­Ù„ÛŒ**: Ø±Ø¯ÛŒØ§Ø¨ÛŒ Ø¹Ù…Ù„Ú©Ø±Ø¯ Ùˆ Ø¹Ù„Ø§Ù…Øªâ€ŒÚ¯Ø°Ø§Ø±ÛŒ Ù…Ø´Ú©Ù„Ø§Øª Ø¨Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² ØªÙ„Ù‡â€ŒÙ…ØªØ±ÛŒ Ù„Ø¨Ù‡

### Ù…Ø±Ø­Ù„Ù‡ 6: Ø§Ù†Ø¯Ø§Ø²Ù‡â€ŒÚ¯ÛŒØ±ÛŒ Ùˆ Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø¹Ù…Ù„Ú©Ø±Ø¯ Ø¹Ø§Ù…Ù„ Ù„Ø¨Ù‡
- **Ù†Ø±Ø® ØªÚ©Ù…ÛŒÙ„ ÙˆØ¸Ø§ÛŒÙ Ø¹Ø§Ù…Ù„**: Ù†Ø¸Ø§Ø±Øª Ø¨Ø± Ù†Ø±Ø® Ù…ÙˆÙÙ‚ÛŒØª Ø¯Ø± Ø³Ù†Ø§Ø±ÛŒÙˆÙ‡Ø§ÛŒ Ø¢ÙÙ„Ø§ÛŒÙ†
- **Ø²Ù…Ø§Ù†â€ŒÙ‡Ø§ÛŒ Ù¾Ø§Ø³Ø® Ø¹Ø§Ù…Ù„**: Ø§Ø·Ù…ÛŒÙ†Ø§Ù† Ø§Ø² Ø²Ù…Ø§Ù†â€ŒÙ‡Ø§ÛŒ Ù¾Ø§Ø³Ø® Ø²ÛŒØ± ÛŒÚ© Ø«Ø§Ù†ÛŒÙ‡ Ø¨Ø±Ø§ÛŒ Ø§Ø³ØªÙ‚Ø±Ø§Ø± Ù„Ø¨Ù‡
- **Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ù…Ù†Ø§Ø¨Ø¹**: Ø±Ø¯ÛŒØ§Ø¨ÛŒ Ø­Ø§ÙØ¸Ù‡ØŒ CPU Ùˆ Ù…ØµØ±Ù Ø¨Ø§ØªØ±ÛŒ Ø¯Ø± Ø¯Ø³ØªÚ¯Ø§Ù‡â€ŒÙ‡Ø§ÛŒ Ù„Ø¨Ù‡
- **Ú©Ø§Ø±Ø§ÛŒÛŒ Ù‡Ø²ÛŒÙ†Ù‡**: Ù…Ù‚Ø§ÛŒØ³Ù‡ Ù‡Ø²ÛŒÙ†Ù‡â€ŒÙ‡Ø§ÛŒ Ø§Ø³ØªÙ‚Ø±Ø§Ø± Ù„Ø¨Ù‡ Ø¨Ø§ Ø¬Ø§ÛŒÚ¯Ø²ÛŒÙ†â€ŒÙ‡Ø§ÛŒ Ù…Ø¨ØªÙ†ÛŒ Ø¨Ø± Ø§Ø¨Ø±
- **Ù‚Ø§Ø¨Ù„ÛŒØª Ø§Ø·Ù…ÛŒÙ†Ø§Ù† Ø¢ÙÙ„Ø§ÛŒÙ†**: Ø§Ù†Ø¯Ø§Ø²Ù‡â€ŒÚ¯ÛŒØ±ÛŒ Ø¹Ù…Ù„Ú©Ø±Ø¯ Ø¹Ø§Ù…Ù„ Ø¯Ø± Ø·ÙˆÙ„ Ù‚Ø·Ø¹ÛŒâ€ŒÙ‡Ø§ÛŒ Ø´Ø¨Ú©Ù‡

## Ù†Ú©Ø§Øª Ú©Ù„ÛŒØ¯ÛŒ Ø¨Ø±Ø§ÛŒ Ø§Ø¬Ø±Ø§ÛŒ Ø¹Ø§Ù…Ù„ SLM

1. **SLMâ€ŒÙ‡Ø§ Ø¨Ø±Ø§ÛŒ Ø¹ÙˆØ§Ù…Ù„ Ú©Ø§ÙÛŒ Ù‡Ø³ØªÙ†Ø¯**: Ø¨Ø±Ø§ÛŒ Ø§Ú©Ø«Ø± ÙˆØ¸Ø§ÛŒÙ Ø¹Ø§Ù…Ù„ØŒ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ú©ÙˆÚ†Ú© Ø¨Ù‡ Ø§Ù†Ø¯Ø§Ø²Ù‡ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ø¨Ø²Ø±Ú¯ Ø¹Ù…Ù„ Ù…ÛŒâ€ŒÚ©Ù†Ù†Ø¯ Ùˆ Ø¯Ø± Ø¹ÛŒÙ† Ø­Ø§Ù„ Ù…Ø²Ø§ÛŒØ§ÛŒ Ù‚Ø§Ø¨Ù„ ØªÙˆØ¬Ù‡ÛŒ Ø§Ø±Ø§Ø¦Ù‡ Ù…ÛŒâ€ŒØ¯Ù‡Ù†Ø¯
2. **Ú©Ø§Ø±Ø§ÛŒÛŒ Ù‡Ø²ÛŒÙ†Ù‡ Ø¯Ø± Ø¹ÙˆØ§Ù…Ù„**: Ø§Ø¬Ø±Ø§ÛŒ Ø¹ÙˆØ§Ù…Ù„ SLM 10-30 Ø¨Ø±Ø§Ø¨Ø± Ø§Ø±Ø²Ø§Ù†â€ŒØªØ± Ø§Ø³ØªØŒ Ú©Ù‡ Ø¢Ù†Ù‡Ø§ Ø±Ø§ Ø§Ø² Ù†Ø¸Ø± Ø§Ù‚ØªØµØ§Ø¯ÛŒ Ø¨Ø±Ø§ÛŒ Ø§Ø³ØªÙ‚Ø±Ø§Ø± Ú¯Ø³ØªØ±Ø¯Ù‡ Ù‚Ø§Ø¨Ù„ Ø§Ø¬Ø±Ø§ Ù…ÛŒâ€ŒÚ©Ù†Ø¯
3. **ØªØ®ØµØµ Ø¯Ø± Ø¹ÙˆØ§Ù…Ù„ Ú©Ø§Ø± Ù…ÛŒâ€ŒÚ©Ù†Ø¯**: SLMâ€ŒÙ‡Ø§ÛŒ ØªÙ†Ø¸ÛŒÙ…â€ŒØ´Ø¯Ù‡ Ø§ØºÙ„Ø¨ Ø¯Ø± Ø¨Ø±Ù†Ø§Ù…Ù‡â€ŒÙ‡Ø§ÛŒ Ø®Ø§Øµ Ø¹Ø§Ù…Ù„ Ø§Ø² LLMâ€ŒÙ‡Ø§ÛŒ Ø¹Ù…ÙˆÙ…ÛŒ Ø¨Ù‡ØªØ± Ø¹Ù…Ù„ Ù…ÛŒâ€ŒÚ©Ù†Ù†Ø¯
4. **Ù…Ø¹Ù…Ø§Ø±ÛŒ Ø¹Ø§Ù…Ù„ ØªØ±Ú©ÛŒØ¨ÛŒ**: Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² SLMâ€ŒÙ‡Ø§ Ø¨Ø±Ø§ÛŒ ÙˆØ¸Ø§ÛŒÙ Ù…Ø¹Ù…ÙˆÙ„ Ø¹Ø§Ù…Ù„ØŒ LLMâ€ŒÙ‡Ø§ Ø¨Ø±Ø§ÛŒ Ø§Ø³ØªØ¯Ù„Ø§Ù„ Ù¾ÛŒÚ†ÛŒØ¯Ù‡ Ø¯Ø± ØµÙˆØ±Øª Ù„Ø²ÙˆÙ…
5. **Ú†Ø§Ø±Ú†ÙˆØ¨ Ø¹Ø§Ù…Ù„ Microsoft Ø§Ù…Ú©Ø§Ù† Ø§Ø³ØªÙ‚Ø±Ø§Ø± ØªÙˆÙ„ÛŒØ¯ Ø±Ø§ ÙØ±Ø§Ù‡Ù… Ù…ÛŒâ€ŒÚ©Ù†Ø¯**: Ø§Ø¨Ø²Ø§Ø±Ù‡Ø§ÛŒ Ø¯Ø±Ø¬Ù‡ Ø³Ø§Ø²Ù…Ø§Ù†ÛŒ Ø¨Ø±Ø§ÛŒ Ø³Ø§Ø®ØªØŒ Ø§Ø³ØªÙ‚Ø±Ø§Ø± Ùˆ Ù…Ø¯ÛŒØ±ÛŒØª Ø¹ÙˆØ§Ù…Ù„ Ù„Ø¨Ù‡ Ø§Ø±Ø§Ø¦Ù‡ Ù…ÛŒâ€ŒØ¯Ù‡Ø¯
6. **Ø§ØµÙˆÙ„ Ø·Ø±Ø§Ø­ÛŒ Ø§ÙˆÙ„ Ù„Ø¨Ù‡**: Ø¹ÙˆØ§Ù…Ù„ Ø¢ÙÙ„Ø§ÛŒÙ† Ø¨Ø§ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù…Ø­Ù„ÛŒ Ø­Ø±ÛŒÙ… Ø®ØµÙˆØµÛŒ Ùˆ Ù‚Ø§Ø¨Ù„ÛŒØª Ø§Ø·Ù…ÛŒÙ†Ø§Ù† Ø±Ø§ ØªØ¶Ù…ÛŒÙ† Ù…ÛŒâ€ŒÚ©Ù†Ù†Ø¯
7. **Ø§Ø¯ØºØ§Ù… Foundry Local**: Ø§ØªØµØ§Ù„ Ø¨Ø¯ÙˆÙ† Ø¯Ø±Ø² Ø¨ÛŒÙ† Ú†Ø§Ø±Ú†ÙˆØ¨ Ø¹Ø§Ù…Ù„ Microsoft Ùˆ Ø§Ø³ØªÙ†ØªØ§Ø¬ Ù…Ø¯Ù„ Ù…Ø­Ù„ÛŒ
8. **Ø¢ÛŒÙ†Ø¯Ù‡ Ø¹ÙˆØ§Ù…Ù„ SLM Ø§Ø³Øª**: Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ø²Ø¨Ø§Ù† Ú©ÙˆÚ†Ú© Ø¨Ø§ Ú†Ø§Ø±Ú†ÙˆØ¨â€ŒÙ‡Ø§ÛŒ ØªÙˆÙ„ÛŒØ¯ Ø¢ÛŒÙ†Ø¯Ù‡ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ Ø¹Ø§Ù…Ù„ Ù‡Ø³ØªÙ†Ø¯ØŒ Ú©Ù‡ Ø§Ø³ØªÙ‚Ø±Ø§Ø± Ø¹Ø§Ù…Ù„ Ø±Ø§ Ø¯Ù…ÙˆÚ©Ø±Ø§ØªÛŒØ²Ù‡ Ùˆ Ú©Ø§Ø±Ø¢Ù…Ø¯ Ù…ÛŒâ€ŒÚ©Ù†Ù†Ø¯

## Ù…Ù†Ø§Ø¨Ø¹ Ùˆ Ù…Ø·Ø§Ù„Ø¹Ø§Øª Ø¨ÛŒØ´ØªØ±

### Ù…Ù‚Ø§Ù„Ø§Øª ØªØ­Ù‚ÛŒÙ‚Ø§ØªÛŒ Ø§ØµÙ„ÛŒ Ùˆ Ø§Ù†ØªØ´Ø§Ø±Ø§Øª

#### Ø¹ÙˆØ§Ù…Ù„ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ Ùˆ Ø³ÛŒØ³ØªÙ…â€ŒÙ‡Ø§ÛŒ Ø¹Ø§Ù…Ù„
- **"Ø¹ÙˆØ§Ù…Ù„ Ø²Ø¨Ø§Ù† Ø¨Ù‡ Ø¹Ù†ÙˆØ§Ù† Ú¯Ø±Ø§Ùâ€ŒÙ‡Ø§ÛŒ Ø¨Ù‡ÛŒÙ†Ù‡â€ŒÙ¾Ø°ÛŒØ±"** (2024) - ØªØ­Ù‚ÛŒÙ‚ Ø¨Ù†ÛŒØ§Ø¯ÛŒ Ø¯Ø± Ù…ÙˆØ±Ø¯ Ù…Ø¹Ù…Ø§Ø±ÛŒ Ø¹Ø§Ù…Ù„ Ùˆ Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒâ€ŒÙ‡Ø§ÛŒ Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ
  - Ù†ÙˆÛŒØ³Ù†Ø¯Ú¯Ø§Ù†: Wenyue HuaØŒ Lishan Yang Ùˆ Ø¯ÛŒÚ¯Ø±Ø§Ù†
  - Ù„ÛŒÙ†Ú©: https://arxiv.org/abs/2402.16823
  - Ù†Ú©Ø§Øª Ú©Ù„ÛŒØ¯ÛŒ: Ø·Ø±Ø§Ø­ÛŒ Ø¹Ø§Ù…Ù„ Ù…Ø¨ØªÙ†ÛŒ Ø¨Ø± Ú¯Ø±Ø§Ù Ùˆ Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒâ€ŒÙ‡Ø§ÛŒ Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ

- **"Ø¸Ù‡ÙˆØ± Ùˆ Ù¾ØªØ§Ù†Ø³ÛŒÙ„ Ø¹ÙˆØ§Ù…Ù„ Ù…Ø¨ØªÙ†ÛŒ Ø¨Ø± Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ø²Ø¨Ø§Ù† Ø¨Ø²Ø±Ú¯"** (2023)
  - Ù†ÙˆÛŒØ³Ù†Ø¯Ú¯Ø§Ù†: Zhiheng XiØŒ Wenxiang Chen Ùˆ Ø¯ÛŒÚ¯Ø±Ø§Ù†
  - Ù„ÛŒÙ†Ú©: https://arxiv.org/abs/2309.07864
  - Ù†Ú©Ø§Øª Ú©Ù„ÛŒØ¯ÛŒ: Ø¨Ø±Ø±Ø³ÛŒ Ø¬Ø§Ù…Ø¹ Ù‚Ø§Ø¨Ù„ÛŒØªâ€ŒÙ‡Ø§ Ùˆ Ú©Ø§Ø±Ø¨Ø±Ø¯Ù‡Ø§ÛŒ Ø¹ÙˆØ§Ù…Ù„ Ù…Ø¨ØªÙ†ÛŒ Ø¨Ø± LLM

- **"Ù…Ø¹Ù…Ø§Ø±ÛŒâ€ŒÙ‡Ø§ÛŒ Ø´Ù†Ø§Ø®ØªÛŒ Ø¨Ø±Ø§ÛŒ Ø¹ÙˆØ§Ù…Ù„ Ø²Ø¨Ø§Ù†"** (2024)
  - Ù†ÙˆÛŒØ³Ù†Ø¯Ú¯Ø§Ù†: Theodore SumersØŒ Shunyu Yao Ùˆ Ø¯ÛŒÚ¯Ø±Ø§Ù†
  - Ù„ÛŒÙ†Ú©: https://arxiv.org/abs/2309.02427
  - Ù†Ú©Ø§Øª Ú©Ù„ÛŒØ¯ÛŒ: Ú†Ø§Ø±Ú†ÙˆØ¨â€ŒÙ‡Ø§ÛŒ Ø´Ù†Ø§Ø®ØªÛŒ Ø¨Ø±Ø§ÛŒ Ø·Ø±Ø§Ø­ÛŒ Ø¹ÙˆØ§Ù…Ù„ Ù‡ÙˆØ´Ù…Ù†Ø¯

#### Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ø²Ø¨Ø§Ù† Ú©ÙˆÚ†Ú© Ùˆ Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ
- **"Ú¯Ø²Ø§Ø±Ø´ ÙÙ†ÛŒ Phi-3: ÛŒÚ© Ù…Ø¯Ù„ Ø²Ø¨Ø§Ù† Ø¨Ø³ÛŒØ§Ø± ØªÙˆØ§Ù†Ù…Ù†Ø¯ Ø¨Ù‡ ØµÙˆØ±Øª Ù…Ø­Ù„ÛŒ Ø¨Ø± Ø±ÙˆÛŒ Ú¯ÙˆØ´ÛŒ Ø´Ù…Ø§"** (2024)
  - Ù†ÙˆÛŒØ³Ù†Ø¯Ú¯Ø§Ù†: ØªÛŒÙ… ØªØ­Ù‚ÛŒÙ‚Ø§ØªÛŒ Microsoft
  - Ù„ÛŒÙ†Ú©: https://arxiv.org/abs/2404.14219
  - Ù†Ú©Ø§Øª Ú©Ù„ÛŒØ¯ÛŒ: Ø§ØµÙˆÙ„ Ø·Ø±Ø§Ø­ÛŒ SLM Ùˆ Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒâ€ŒÙ‡Ø§ÛŒ Ø§Ø³ØªÙ‚Ø±Ø§Ø± Ù…ÙˆØ¨Ø§ÛŒÙ„

- **"Ú¯Ø²Ø§Ø±Ø´ ÙÙ†ÛŒ Qwen2.5"** (2024)
  - Ù†ÙˆÛŒØ³Ù†Ø¯Ú¯Ø§Ù†: ØªÛŒÙ… Alibaba Cloud
  - Ù„ÛŒÙ†Ú©: https://arxiv.org/abs/2407.10671
  - Ù†Ú©Ø§Øª Ú©Ù„ÛŒØ¯ÛŒ: ØªÚ©Ù†ÛŒÚ©â€ŒÙ‡Ø§ÛŒ Ù¾ÛŒØ´Ø±ÙØªÙ‡ Ø¢Ù…ÙˆØ²Ø´ SLM Ùˆ Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø¹Ù…Ù„Ú©Ø±Ø¯

- **"TinyLlama: ÛŒÚ© Ù…Ø¯Ù„ Ø²Ø¨Ø§Ù† Ú©ÙˆÚ†Ú© Ù…ØªÙ†â€ŒØ¨Ø§Ø²"** (2024)
  - Ù†ÙˆÛŒØ³Ù†Ø¯Ú¯Ø§Ù†: Peiyuan ZhangØŒ Guangtao Zeng Ùˆ Ø¯ÛŒÚ¯Ø±Ø§Ù†
  - Ù„ÛŒÙ†Ú©: https://arxiv.org/abs/2401.02385
  - Ù†Ú©Ø§Øª Ú©Ù„ÛŒØ¯ÛŒ: Ø·Ø±Ø§Ø­ÛŒ Ù…Ø¯Ù„ ÙÙˆÙ‚â€ŒØ§Ù„Ø¹Ø§Ø¯Ù‡ ÙØ´Ø±Ø¯Ù‡ Ùˆ Ú©Ø§Ø±Ø§ÛŒÛŒ Ø¢Ù…ÙˆØ²Ø´

### Ù…Ø³ØªÙ†Ø¯Ø§Øª Ø±Ø³Ù…ÛŒ Ùˆ Ú†Ø§Ø±Ú†ÙˆØ¨â€ŒÙ‡Ø§

#### Ú†Ø§Ø±Ú†ÙˆØ¨ Ø¹Ø§Ù…Ù„ Microsoft
- **Ù…Ø³ØªÙ†Ø¯Ø§Øª Ø±Ø³Ù…ÛŒ**: https://docs.microsoft.com/en-us/azure/ai-services/agents/
- **Ù…Ø®Ø²Ù† GitHub**: https://github.com/microsoft/agent-framework

#### Foundry Local
- **Ù…Ø®Ø²Ù† Ø§ØµÙ„ÛŒ**: https://github.com/microsoft/foundry-local
- **Ù…Ø³ØªÙ†Ø¯Ø§Øª**: https://github.com/microsoft/foundry-local/blob/main/docs/README.md


#### VLLM
- **Ù…Ø®Ø²Ù† Ø§ØµÙ„ÛŒ**: https://github.com/vllm-project/vllm
- **Ù…Ø³ØªÙ†Ø¯Ø§Øª**: https://docs.vllm.ai/


#### Ollama
- **ÙˆØ¨â€ŒØ³Ø§ÛŒØª Ø±Ø³Ù…ÛŒ**: https://ollama.ai/
- **Ù…Ø®Ø²Ù† GitHub**: https://github.com/ollama/ollama

### Ú†Ø§Ø±Ú†ÙˆØ¨â€ŒÙ‡Ø§ÛŒ Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ù…Ø¯Ù„

#### Llama.cpp
- **Ù…Ø®Ø²Ù†**: https://github.com/ggml-org/llama.cpp


#### Microsoft Olive
- **Ù…Ø³ØªÙ†Ø¯Ø§Øª**: https://microsoft.github.io/Olive/
- **Ù…Ø®Ø²Ù† GitHub**: https://github.com/microsoft/Olive

#### OpenVINO
- **Ø³Ø§ÛŒØª Ø±Ø³Ù…ÛŒ**: https://docs.openvino.ai/

#### Apple MLX
- **Ù…Ø®Ø²Ù†**: https://github.com/ml-explore/mlx

### Ú¯Ø²Ø§Ø±Ø´â€ŒÙ‡Ø§ÛŒ ØµÙ†Ø¹ØªÛŒ Ùˆ ØªØ­Ù„ÛŒÙ„ Ø¨Ø§Ø²Ø§Ø±

#### ØªØ­Ù‚ÛŒÙ‚Ø§Øª Ø¨Ø§Ø²Ø§Ø± Ø¹ÙˆØ§Ù…Ù„ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ
- **"ÙˆØ¶Ø¹ÛŒØª Ø¹ÙˆØ§Ù…Ù„ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ 2025"** - Ù…ÙˆØ³Ø³Ù‡ Ø¬Ù‡Ø§Ù†ÛŒ McKinsey
  - Ù„ÛŒÙ†Ú©: https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/ai-agents-2025
  - Ù†Ú©Ø§Øª Ú©Ù„ÛŒØ¯ÛŒ: Ø±ÙˆÙ†Ø¯Ù‡Ø§ÛŒ Ø¨Ø§Ø²Ø§Ø± Ùˆ Ø§Ù„Ú¯ÙˆÙ‡Ø§ÛŒ Ù¾Ø°ÛŒØ±Ø´ Ø³Ø§Ø²Ù…Ø§Ù†ÛŒ

#### Ù…Ø¹ÛŒØ§Ø±Ù‡Ø§ÛŒ ÙÙ†ÛŒ

- **"Ù…Ø¹ÛŒØ§Ø±Ù‡Ø§ÛŒ Ø§Ø³ØªÙ†ØªØ§Ø¬ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ Ù„Ø¨Ù‡"** - MLPerf
  - Ù„ÛŒÙ†Ú©: https://mlcommons.org/en/inference-edge/
  - Ù†Ú©Ø§Øª Ú©Ù„ÛŒØ¯ÛŒ: Ù…Ø¹ÛŒØ§Ø±Ù‡Ø§ÛŒ Ø¹Ù…Ù„Ú©Ø±Ø¯ Ø§Ø³ØªØ§Ù†Ø¯Ø§Ø±Ø¯ Ø¨Ø±Ø§ÛŒ Ø§Ø³ØªÙ‚Ø±Ø§Ø± Ù„Ø¨Ù‡

### Ø§Ø³ØªØ§Ù†Ø¯Ø§Ø±Ø¯Ù‡Ø§ Ùˆ Ù…Ø´Ø®ØµØ§Øª

#### ÙØ±Ù…Øªâ€ŒÙ‡Ø§ Ùˆ Ø§Ø³ØªØ§Ù†Ø¯Ø§Ø±Ø¯Ù‡Ø§ÛŒ Ù…Ø¯Ù„
- **ONNX (Open Neural Network Exchange)**: https://onnx.ai/
  - ÙØ±Ù…Øª Ù…Ø¯Ù„ Ú†Ù†Ø¯ Ù¾Ù„ØªÙØ±Ù…ÛŒ Ø¨Ø±Ø§ÛŒ Ù‚Ø§Ø¨Ù„ÛŒØª Ù‡Ù…Ú©Ø§Ø±ÛŒ
- **Ù…Ø´Ø®ØµØ§Øª GGUF**: https://github.com/ggerganov/ggml/blob/master/docs/gguf.md
  - ÙØ±Ù…Øª Ù…Ø¯Ù„ Ú©ÙˆØ§Ù†ØªÛŒØ²Ù‡ Ø¨Ø±Ø§ÛŒ Ø§Ø³ØªÙ†ØªØ§Ø¬ CPU
- **Ù…Ø´Ø®ØµØ§Øª API OpenAI**: https://platform.openai.com/docs/api-reference
  - ÙØ±Ù…Øª Ø§Ø³ØªØ§Ù†Ø¯Ø§Ø±Ø¯ API Ø¨Ø±Ø§ÛŒ Ø§Ø¯ØºØ§Ù… Ù…Ø¯Ù„ Ø²Ø¨Ø§Ù†

#### Ø§Ù…Ù†ÛŒØª Ùˆ Ø§Ù†Ø·Ø¨Ø§Ù‚
- **Ú†Ø§Ø±Ú†ÙˆØ¨ Ù…Ø¯ÛŒØ±ÛŒØª Ø±ÛŒØ³Ú© Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ NIST**: https://www.nist.gov/itl/ai-risk-management-framework
- **ISO/IEC 23053:2022 - Ø³ÛŒØ³ØªÙ…â€ŒÙ‡Ø§ÛŒ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ**: Ú†Ø§Ø±Ú†ÙˆØ¨ÛŒ Ø¨Ø±Ø§ÛŒ Ø³ÛŒØ³ØªÙ…â€ŒÙ‡Ø§ÛŒ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ Ùˆ Ø§ÛŒÙ…Ù†ÛŒ
- **Ø§Ø³ØªØ§Ù†Ø¯Ø§Ø±Ø¯Ù‡Ø§ÛŒ IEEE Ø¨Ø±Ø§ÛŒ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ**: https://standards.ieee.org/industry-connections/ai/

ØªØºÛŒÛŒØ± Ø¨Ù‡ Ø³Ù…Øª Ø¹ÙˆØ§Ù…Ù„ Ù…Ø¨ØªÙ†ÛŒ Ø¨Ø± SLM Ù†Ù…Ø§ÛŒØ§Ù†Ú¯Ø± ØªØºÛŒÛŒØ± Ø¨Ù†ÛŒØ§Ø¯ÛŒ Ø¯Ø± Ù†Ø­ÙˆÙ‡ Ø¨Ø±Ø®ÙˆØ±Ø¯ Ù…Ø§ Ø¨Ø§ Ø§Ø³ØªÙ‚Ø±Ø§Ø± Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ Ø§Ø³Øª. Ú†Ø§Ø±Ú†ÙˆØ¨ Ø¹Ø§Ù…Ù„ MicrosoftØŒ Ù‡Ù…Ø±Ø§Ù‡ Ø¨Ø§ Ù¾Ù„ØªÙØ±Ù…â€ŒÙ‡Ø§ÛŒ Ù…Ø­Ù„ÛŒ Ùˆ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ø²Ø¨Ø§Ù† Ú©ÙˆÚ†Ú© Ú©Ø§Ø±Ø¢Ù…Ø¯ØŒ Ø±Ø§Ù‡â€ŒØ­Ù„ Ú©Ø§Ù…Ù„ÛŒ Ø¨Ø±Ø§ÛŒ Ø³Ø§Ø®Øª Ø¹ÙˆØ§Ù…Ù„ Ø¢Ù…Ø§Ø¯Ù‡ ØªÙˆÙ„ÛŒØ¯ ÙØ±Ø§Ù‡Ù… Ù…ÛŒâ€ŒÚ©Ù†Ø¯ Ú©Ù‡ Ø¨Ù‡ Ø·ÙˆØ± Ù…Ø¤Ø«Ø± Ø¯Ø± Ù…Ø­ÛŒØ·â€ŒÙ‡Ø§ÛŒ Ù„Ø¨Ù‡ Ø¹Ù…Ù„ Ù…ÛŒâ€ŒÚ©Ù†Ù†Ø¯. Ø¨Ø§ ØªÙ…Ø±Ú©Ø² Ø¨Ø± Ú©Ø§Ø±Ø§ÛŒÛŒØŒ ØªØ®ØµØµ Ùˆ Ú©Ø§Ø±Ø¨Ø±Ø¯ Ø¹Ù…Ù„ÛŒØŒ Ø§ÛŒÙ† Ù…Ø¬Ù…ÙˆØ¹Ù‡ ÙÙ†Ø§ÙˆØ±ÛŒ Ø¹ÙˆØ§Ù…Ù„ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ Ø±Ø§ Ø¨Ø±Ø§ÛŒ Ø¨Ø±Ù†Ø§Ù…Ù‡â€ŒÙ‡Ø§ÛŒ ÙˆØ§Ù‚Ø¹ÛŒ Ø¯Ø± Ù‡Ø± ØµÙ†Ø¹Øª Ùˆ Ù…Ø­ÛŒØ· Ù…Ø­Ø§Ø³Ø¨Ø§Øª Ù„Ø¨Ù‡ Ù‚Ø§Ø¨Ù„ Ø¯Ø³ØªØ±Ø³â€ŒØªØ±ØŒ Ù…Ù‚Ø±ÙˆÙ†â€ŒØ¨Ù‡â€ŒØµØ±ÙÙ‡â€ŒØªØ± Ùˆ Ù…Ø¤Ø«Ø±ØªØ± Ù…ÛŒâ€ŒÚ©Ù†Ø¯.

Ù‡Ù…Ø§Ù†â€ŒØ·ÙˆØ± Ú©Ù‡ Ø¨Ù‡ Ø³Ø§Ù„ 2025 Ù¾ÛŒØ´ Ù…ÛŒâ€ŒØ±ÙˆÛŒÙ…ØŒ ØªØ±Ú©ÛŒØ¨ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ú©ÙˆÚ†Ú©â€ŒØªØ± Ùˆ ØªÙˆØ§Ù†Ù…Ù†Ø¯ØªØ±ØŒ Ú†Ø§Ø±Ú†ÙˆØ¨â€ŒÙ‡Ø§ÛŒ Ø¹Ø§Ù…Ù„ Ù¾ÛŒÚ†ÛŒØ¯Ù‡ Ù…Ø§Ù†Ù†Ø¯ Ú†Ø§Ø±Ú†ÙˆØ¨ Ø¹Ø§Ù…Ù„ Microsoft Ùˆ Ù¾Ù„ØªÙØ±Ù…â€ŒÙ‡Ø§ÛŒ Ø§Ø³ØªÙ‚Ø±Ø§Ø± Ù„Ø¨Ù‡ Ù‚ÙˆÛŒØŒ Ø§Ù…Ú©Ø§Ù†Ø§Øª Ø¬Ø¯ÛŒØ¯ÛŒ Ø±Ø§ Ø¨Ø±Ø§ÛŒ Ø³ÛŒØ³ØªÙ…â€ŒÙ‡Ø§ÛŒ Ø®ÙˆØ¯Ù…Ø®ØªØ§Ø± Ø¨Ø§Ø² Ø®ÙˆØ§Ù‡Ø¯ Ú©Ø±Ø¯ Ú©Ù‡ Ù…ÛŒâ€ŒØªÙˆØ§Ù†Ù†Ø¯ Ø¨Ù‡ Ø·ÙˆØ± Ù…Ø¤Ø«Ø± Ø¨Ø± Ø±ÙˆÛŒ Ø¯Ø³ØªÚ¯Ø§Ù‡â€ŒÙ‡Ø§ÛŒ Ù„Ø¨Ù‡ Ø¹Ù…Ù„ Ú©Ù†Ù†Ø¯ Ùˆ Ø¯Ø± Ø¹ÛŒÙ† Ø­Ø§Ù„ Ø­Ø±ÛŒÙ… Ø®ØµÙˆØµÛŒ Ø±Ø§ Ø­ÙØ¸ Ú©Ù†Ù†Ø¯ØŒ Ù‡Ø²ÛŒÙ†Ù‡â€ŒÙ‡Ø§ Ø±Ø§ Ú©Ø§Ù‡Ø´ Ø¯Ù‡Ù†Ø¯ Ùˆ ØªØ¬Ø±Ø¨Ù‡â€ŒÙ‡Ø§ÛŒ Ú©Ø§Ø±Ø¨Ø±ÛŒ Ø§Ø³ØªØ«Ù†Ø§ÛŒÛŒ Ø§Ø±Ø§Ø¦Ù‡ Ø¯Ù‡Ù†Ø¯.

**Ú¯Ø§Ù…â€ŒÙ‡Ø§ÛŒ Ø¨Ø¹Ø¯ÛŒ Ø¨Ø±Ø§ÛŒ Ø§Ø¬Ø±Ø§**:
1. **Ø¨Ø±Ø±Ø³ÛŒ ÙØ±Ø§Ø®ÙˆØ§Ù†ÛŒ Ø¹Ù…Ù„Ú©Ø±Ø¯**: ÛŒØ§Ø¯ Ø¨Ú¯ÛŒØ±ÛŒØ¯ Ú©Ù‡ Ú†Ú¯ÙˆÙ†Ù‡ SLMâ€ŒÙ‡Ø§ Ø§Ø¯ØºØ§Ù… Ø§Ø¨Ø²Ø§Ø± Ùˆ Ø®Ø±ÙˆØ¬ÛŒâ€ŒÙ‡Ø§ÛŒ Ø³Ø§Ø®ØªØ§Ø±ÛŒØ§ÙØªÙ‡ Ø±Ø§ Ù…Ø¯ÛŒØ±ÛŒØª Ù…ÛŒâ€ŒÚ©Ù†Ù†Ø¯
2. **ØªØ³Ù„Ø· Ø¨Ø± Ù¾Ø±ÙˆØªÚ©Ù„ Ø²Ù…ÛŒÙ†Ù‡ Ù…Ø¯Ù„ (MCP)**: Ø§Ù„Ú¯ÙˆÙ‡Ø§ÛŒ Ø§Ø±ØªØ¨Ø§Ø·ÛŒ Ù¾ÛŒØ´Ø±ÙØªÙ‡ Ø¹Ø§Ù…Ù„ Ø±Ø§ Ø¯Ø±Ú© Ú©Ù†ÛŒØ¯
3. **Ø³Ø§Ø®Øª Ø¹ÙˆØ§Ù…Ù„ ØªÙˆÙ„ÛŒØ¯ÛŒ**: Ø§Ø² Ú†Ø§Ø±Ú†ÙˆØ¨ Ø¹Ø§Ù…Ù„ Microsoft Ø¨Ø±Ø§ÛŒ Ø§Ø³ØªÙ‚Ø±Ø§Ø±Ù‡Ø§ÛŒ Ø¯Ø±Ø¬Ù‡ Ø³Ø§Ø²Ù…Ø§Ù†ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯
4. **Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø¨Ø±Ø§ÛŒ Ù„Ø¨Ù‡**: ØªÚ©Ù†ÛŒÚ©â€ŒÙ‡Ø§ÛŒ Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ù¾ÛŒØ´Ø±ÙØªÙ‡ Ø±Ø§ Ø¨Ø±Ø§ÛŒ Ù…Ø­ÛŒØ·â€ŒÙ‡Ø§ÛŒ Ø¨Ø§ Ù…Ù†Ø§Ø¨Ø¹ Ù…Ø­Ø¯ÙˆØ¯ Ø§Ø¹Ù…Ø§Ù„ Ú©Ù†ÛŒØ¯


## âž¡ï¸ Ù…Ø±Ø­Ù„Ù‡ Ø¨Ø¹Ø¯ÛŒ

- [02: ÙØ±Ø§Ø®ÙˆØ§Ù†ÛŒ Ø¹Ù…Ù„Ú©Ø±Ø¯ Ø¯Ø± Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ø²Ø¨Ø§Ù† Ú©ÙˆÚ†Ú© (SLMs)](./02.FunctionCalling.md)

---

**Ø³Ù„Ø¨ Ù…Ø³Ø¦ÙˆÙ„ÛŒØª**:  
Ø§ÛŒÙ† Ø³Ù†Ø¯ Ø¨Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø³Ø±ÙˆÛŒØ³ ØªØ±Ø¬Ù…Ù‡ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ [Co-op Translator](https://github.com/Azure/co-op-translator) ØªØ±Ø¬Ù…Ù‡ Ø´Ø¯Ù‡ Ø§Ø³Øª. Ø¯Ø± Ø­Ø§Ù„ÛŒ Ú©Ù‡ Ù…Ø§ ØªÙ„Ø§Ø´ Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ… Ø¯Ù‚Øª Ø±Ø§ Ø­ÙØ¸ Ú©Ù†ÛŒÙ…ØŒ Ù„Ø·ÙØ§Ù‹ ØªÙˆØ¬Ù‡ Ø¯Ø§Ø´ØªÙ‡ Ø¨Ø§Ø´ÛŒØ¯ Ú©Ù‡ ØªØ±Ø¬Ù…Ù‡â€ŒÙ‡Ø§ÛŒ Ø®ÙˆØ¯Ú©Ø§Ø± Ù…Ù…Ú©Ù† Ø§Ø³Øª Ø´Ø§Ù…Ù„ Ø®Ø·Ø§Ù‡Ø§ ÛŒØ§ Ù†Ø§Ø¯Ø±Ø³ØªÛŒâ€ŒÙ‡Ø§ Ø¨Ø§Ø´Ù†Ø¯. Ø³Ù†Ø¯ Ø§ØµÙ„ÛŒ Ø¨Ù‡ Ø²Ø¨Ø§Ù† Ø§ØµÙ„ÛŒ Ø¢Ù† Ø¨Ø§ÛŒØ¯ Ø¨Ù‡ Ø¹Ù†ÙˆØ§Ù† Ù…Ù†Ø¨Ø¹ Ù…Ø¹ØªØ¨Ø± Ø¯Ø± Ù†Ø¸Ø± Ú¯Ø±ÙØªÙ‡ Ø´ÙˆØ¯. Ø¨Ø±Ø§ÛŒ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø­ÛŒØ§ØªÛŒØŒ ØªØ±Ø¬Ù…Ù‡ Ø­Ø±ÙÙ‡â€ŒØ§ÛŒ Ø§Ù†Ø³Ø§Ù†ÛŒ ØªÙˆØµÛŒÙ‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯. Ù…Ø§ Ù…Ø³Ø¦ÙˆÙ„ÛŒØªÛŒ Ø¯Ø± Ù‚Ø¨Ø§Ù„ Ø³ÙˆØ¡ ØªÙØ§Ù‡Ù…â€ŒÙ‡Ø§ ÛŒØ§ ØªÙØ³ÛŒØ±Ù‡Ø§ÛŒ Ù†Ø§Ø¯Ø±Ø³Øª Ù†Ø§Ø´ÛŒ Ø§Ø² Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø§ÛŒÙ† ØªØ±Ø¬Ù…Ù‡ Ù†Ø¯Ø§Ø±ÛŒÙ….