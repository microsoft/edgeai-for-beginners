# بخش 03 - یکپارچه‌سازی پروتکل زمینه مدل (MCP)

## معرفی پروتکل زمینه مدل (MCP)

پروتکل زمینه مدل (MCP) یک استاندارد متن‌باز برای اتصال برنامه‌های هوش مصنوعی به سیستم‌های خارجی است. با استفاده از MCP، برنامه‌های هوش مصنوعی مانند Claude یا ChatGPT می‌توانند به منابع داده (مانند فایل‌های محلی، پایگاه‌های داده)، ابزارها (مانند موتورهای جستجو، ماشین‌حساب‌ها) و جریان‌های کاری (مانند درخواست‌های تخصصی) متصل شوند—و به این ترتیب به اطلاعات کلیدی دسترسی پیدا کرده و وظایف را انجام دهند.

MCP را مانند یک **پورت USB-C برای برنامه‌های هوش مصنوعی** تصور کنید. همانطور که USB-C یک روش استاندارد برای اتصال دستگاه‌های الکترونیکی فراهم می‌کند، MCP یک روش استاندارد برای اتصال برنامه‌های هوش مصنوعی به سیستم‌های خارجی ارائه می‌دهد.

### MCP چه قابلیت‌هایی را فراهم می‌کند؟

MCP قابلیت‌های قدرتمندی را برای برنامه‌های هوش مصنوعی باز می‌کند:

- **دستیارهای شخصی‌سازی‌شده هوش مصنوعی**: عوامل می‌توانند به Google Calendar و Notion شما دسترسی پیدا کنند و به عنوان یک دستیار هوش مصنوعی شخصی‌تر عمل کنند.
- **تولید کد پیشرفته**: Claude Code می‌تواند یک اپلیکیشن وب کامل را با استفاده از طراحی Figma ایجاد کند.
- **یکپارچه‌سازی داده‌های سازمانی**: چت‌بات‌های سازمانی می‌توانند به چندین پایگاه داده در سراسر سازمان متصل شوند و کاربران را قادر سازند تا داده‌ها را با استفاده از چت تحلیل کنند.
- **جریان‌های کاری خلاقانه**: مدل‌های هوش مصنوعی می‌توانند طراحی‌های سه‌بعدی در Blender ایجاد کرده و آنها را با استفاده از چاپگر سه‌بعدی چاپ کنند.
- **دسترسی به اطلاعات به‌روز**: اتصال به منابع داده خارجی برای اطلاعات به‌روز.
- **عملیات پیچیده چندمرحله‌ای**: انجام جریان‌های کاری پیچیده با ترکیب چندین ابزار و سیستم.

### چرا MCP اهمیت دارد؟

MCP مزایای گسترده‌ای در اکوسیستم فراهم می‌کند:

**برای توسعه‌دهندگان**: MCP زمان و پیچیدگی توسعه را هنگام ساخت یا یکپارچه‌سازی با یک برنامه یا عامل هوش مصنوعی کاهش می‌دهد.

**برای برنامه‌های هوش مصنوعی**: MCP دسترسی به اکوسیستم منابع داده، ابزارها و اپلیکیشن‌ها را فراهم می‌کند که قابلیت‌ها را افزایش داده و تجربه کاربر نهایی را بهبود می‌بخشد.

**برای کاربران نهایی**: MCP منجر به برنامه‌ها یا عوامل هوش مصنوعی توانمندتری می‌شود که می‌توانند به داده‌های شما دسترسی پیدا کرده و در صورت نیاز اقدامات لازم را انجام دهند.

## مدل‌های زبان کوچک (SLMs) در MCP

مدل‌های زبان کوچک یک رویکرد کارآمد برای استقرار هوش مصنوعی ارائه می‌دهند و چندین مزیت دارند:

### مزایای SLMs
- **کارایی منابع**: نیازهای محاسباتی کمتر
- **زمان پاسخ سریع‌تر**: کاهش تأخیر برای برنامه‌های بلادرنگ  
- **صرفه‌جویی در هزینه**: نیازهای زیرساختی حداقلی
- **حریم خصوصی**: امکان اجرا به صورت محلی بدون انتقال داده
- **سفارشی‌سازی**: آسان‌تر برای تنظیم دقیق برای حوزه‌های خاص

### چرا SLMs با MCP خوب کار می‌کنند؟

ترکیب SLMs با MCP یک ترکیب قدرتمند ایجاد می‌کند که قابلیت‌های استدلال مدل را با ابزارهای خارجی تقویت می‌کند و با وجود تعداد پارامترهای کمتر، عملکرد بهتری ارائه می‌دهد.

## نمای کلی Python MCP SDK

Python MCP SDK پایه‌ای برای ساخت برنامه‌های مجهز به MCP فراهم می‌کند. این SDK شامل موارد زیر است:

- **کتابخانه‌های کلاینت**: برای اتصال به سرورهای MCP
- **چارچوب سرور**: برای ایجاد سرورهای سفارشی MCP
- **مدیریت پروتکل**: برای مدیریت ارتباطات
- **یکپارچه‌سازی ابزارها**: برای اجرای عملکردهای خارجی

## پیاده‌سازی عملی: کلاینت MCP Phi-4

بیایید یک پیاده‌سازی واقعی را با استفاده از مدل کوچک Phi-4 مایکروسافت که با قابلیت‌های MCP یکپارچه شده است بررسی کنیم.

### نمای کلی معماری MCP

MCP از معماری **کلاینت-سرور** پیروی می‌کند که در آن یک میزبان MCP (یک برنامه هوش مصنوعی مانند Claude Code یا Claude Desktop) ارتباطاتی با یک یا چند سرور MCP برقرار می‌کند. میزبان MCP این کار را با ایجاد یک کلاینت MCP برای هر سرور MCP انجام می‌دهد.

#### شرکت‌کنندگان کلیدی

- **میزبان MCP**: برنامه هوش مصنوعی که یک یا چند کلاینت MCP را هماهنگ و مدیریت می‌کند.
- **کلاینت MCP**: بخشی که ارتباط با یک سرور MCP را حفظ کرده و زمینه را از سرور MCP برای استفاده میزبان MCP دریافت می‌کند.
- **سرور MCP**: برنامه‌ای که زمینه را برای کلاینت‌های MCP فراهم می‌کند.

#### معماری دو لایه

MCP شامل دو لایه مجزا است:

**لایه داده**: پروتکل مبتنی بر JSON-RPC برای ارتباط کلاینت-سرور را تعریف می‌کند، شامل:
- مدیریت چرخه عمر (راه‌اندازی ارتباط، مذاکره قابلیت‌ها)
- اصول اولیه (ابزارها، منابع، درخواست‌ها)
- ویژگی‌های کلاینت (نمونه‌گیری، استخراج اطلاعات، ثبت)
- ویژگی‌های کمکی (اعلان‌ها، پیگیری پیشرفت)

**لایه انتقال**: مکانیزم‌ها و کانال‌های ارتباطی را تعریف می‌کند:
- **انتقال STDIO**: از جریان‌های ورودی/خروجی استاندارد برای فرآیندهای محلی استفاده می‌کند (عملکرد بهینه، بدون سربار شبکه)
- **انتقال HTTP قابل جریان**: از HTTP POST با رویدادهای ارسال‌شده توسط سرور برای سرورهای راه دور استفاده می‌کند (پشتیبانی از احراز هویت استاندارد HTTP)

```
┌─────────────────────────────────────┐
│           MCP Host                  │
│     (AI Application)                │
└─────────────────┬───────────────────┘
                  │
┌─────────────────┴───────────────────┐
│         MCP Client 1                │
│  ┌─────────────────────────────────┐ │
│  │        Data Layer               │ │
│  │  ├── Lifecycle Management       │ │
│  │  ├── Primitives (Tools/Resources)│ │
│  │  └── Notifications              │ │
│  └─────────────────────────────────┘ │
│  ┌─────────────────────────────────┐ │
│  │      Transport Layer           │ │
│  │  ├── STDIO Transport           │ │
│  │  └── HTTP Transport            │ │
│  └─────────────────────────────────┘ │
└─────────────────┬───────────────────┘
                  │
┌─────────────────┴───────────────────┐
│         MCP Server 1                │
│    (Local/Remote Context Provider)  │
└─────────────────────────────────────┘
```

### اصول اولیه MCP

MCP اصولی را تعریف می‌کند که انواع اطلاعات زمینه‌ای قابل اشتراک با برنامه‌های هوش مصنوعی و دامنه اقدامات قابل انجام را مشخص می‌کند.

#### اصول سرور

MCP سه اصل اصلی را تعریف می‌کند که سرورها می‌توانند ارائه دهند:

**ابزارها**: عملکردهای قابل اجرا که برنامه‌های هوش مصنوعی می‌توانند برای انجام اقدامات فراخوانی کنند.
- مثال‌ها: عملیات فایل، فراخوانی API، پرس‌وجوهای پایگاه داده
- روش‌ها: `tools/list`, `tools/call`
- پشتیبانی از کشف و اجرای پویا

**منابع**: منابع داده که اطلاعات زمینه‌ای را برای برنامه‌های هوش مصنوعی فراهم می‌کنند.
- مثال‌ها: محتوای فایل‌ها، رکوردهای پایگاه داده، پاسخ‌های API
- روش‌ها: `resources/list`, `resources/read`
- امکان دسترسی به داده‌های ساختاریافته

**درخواست‌ها**: قالب‌های قابل استفاده مجدد که به ساختاردهی تعاملات با مدل‌های زبان کمک می‌کنند.
- مثال‌ها: درخواست‌های سیستم، نمونه‌های چندشات
- روش‌ها: `prompts/list`, `prompts/get`
- استانداردسازی الگوهای تعامل هوش مصنوعی

#### اصول کلاینت

MCP همچنین اصولی را تعریف می‌کند که کلاینت‌ها می‌توانند برای تعاملات غنی‌تر ارائه دهند:

**نمونه‌گیری**: به سرورها اجازه می‌دهد تا از برنامه هوش مصنوعی کلاینت درخواست تکمیل مدل زبان کنند.
- روش: `sampling/complete`
- امکان توسعه سرور مستقل از مدل
- دسترسی به مدل زبان میزبان را فراهم می‌کند

**استخراج اطلاعات**: به سرورها اجازه می‌دهد تا اطلاعات اضافی از کاربران درخواست کنند.
- روش: `elicitation/request`
- امکان تعامل و تأیید کاربر را فراهم می‌کند
- پشتیبانی از جمع‌آوری اطلاعات پویا

**ثبت**: به سرورها اجازه می‌دهد تا پیام‌های ثبت را به کلاینت‌ها ارسال کنند.
- برای اهداف اشکال‌زدایی و نظارت استفاده می‌شود.
- دید به عملیات سرور را فراهم می‌کند.

### چرخه عمر پروتکل MCP

#### راه‌اندازی و مذاکره قابلیت‌ها

MCP یک پروتکل حالت‌دار است که نیاز به مدیریت چرخه عمر دارد. فرآیند راه‌اندازی چندین اهداف حیاتی را دنبال می‌کند:

1. **مذاکره نسخه پروتکل**: اطمینان حاصل می‌کند که کلاینت و سرور از نسخه‌های سازگار پروتکل استفاده می‌کنند (مانند "2025-06-18").
2. **کشف قابلیت‌ها**: هر طرف ویژگی‌ها و اصول پشتیبانی‌شده را اعلام می‌کند.
3. **تبادل هویت**: اطلاعات شناسایی و نسخه‌بندی را فراهم می‌کند.

```python
# Example initialization request
{
  "jsonrpc": "2.0",
  "id": 1,
  "method": "initialize",
  "params": {
    "protocolVersion": "2025-06-18",
    "capabilities": {
      "elicitation": {},  # Client supports user interaction
      "sampling": {}      # Client can provide LLM completions
    },
    "clientInfo": {
      "name": "edge-ai-client",
      "version": "1.0.0"
    }
  }
}
```

#### کشف و اجرای ابزارها

پس از راه‌اندازی، کلاینت‌ها می‌توانند ابزارها را کشف کرده و اجرا کنند:

```python
# Discover available tools
tools_response = await session.list_tools()

# Execute a tool
result = await session.call_tool(
    "weather_current",
    {
        "location": "San Francisco",
        "units": "imperial"
    }
)
```

#### اعلان‌های بلادرنگ

MCP از اعلان‌های بلادرنگ برای به‌روزرسانی‌های پویا پشتیبانی می‌کند:

```python
# Server sends notification when tools change
{
  "jsonrpc": "2.0",
  "method": "notifications/tools/list_changed"
}

# Client responds by refreshing tool list
await session.list_tools()  # Get updated tools
```

## شروع به کار: راهنمای گام‌به‌گام

### گام 1: تنظیم محیط

وابستگی‌های مورد نیاز را نصب کنید:
```bash
pip install fastmcp mcp-python-client openai requests pyautogui Pillow
```

### گام 2: پیکربندی اولیه

متغیرهای محیطی خود را تنظیم کنید:
```python
# System Configuration
SYSTEM_PROMPT = "You are an AI assistant with some tools."

# Ollama Configuration (Local)
OLLAMA_URL = "http://localhost:11434/api/chat"
OLLAMA_MODEL_ID = "phi4-mini:3.8b-fp16"

# vLLM Configuration (Server)
VLLM_URL = "http://localhost:8000/v1"
VLLM_MODEL_ID = "microsoft/Phi-4-mini-instruct"
```

### گام 3: اجرای اولین کلاینت MCP

**تنظیمات اولیه Ollama:**
```bash
python ghmodel_mcp_demo.py
```

**استفاده از Backend vLLM:**
```bash
python ghmodel_mcp_demo.py --env vllm
```

**اتصال رویدادهای ارسال‌شده توسط سرور:**
```bash
python ghmodel_mcp_demo.py --run sse
```

**سرور MCP سفارشی:**
```bash
python ghmodel_mcp_demo.py --server /path/to/server.py
```

### گام 4: استفاده برنامه‌ریزی‌شده

```python
import asyncio
from ghmodel_mcp_demo import OllamaClient, Phi4MiniMCPClient

async def automated_interaction():
    # Configure MCP server parameters
    server_params = StdioServerParameters(
        command="npx",
        args=["@playwright/mcp@latest"],
        env=None,
    )
    
    # Create MCP client and process tools
    async with Phi4MiniMCPClient(server_params) as mcp_client:
        tools = await process_mcp_tools(mcp_client)
        llm_client = OllamaClient()
        
        # Generate response with tool capabilities
        response, messages = await llm_client.generate_response(
            "Help me automate a web task",
            tools
        )
        return response

# Execute the automation
result = asyncio.run(automated_interaction())
print(result)
```

## ویژگی‌های پیشرفته

### پشتیبانی از چندین Backend

پیاده‌سازی از هر دو Backend Ollama و vLLM پشتیبانی می‌کند و به شما امکان می‌دهد بر اساس نیازهای خود انتخاب کنید:

- **Ollama**: مناسب برای توسعه و آزمایش محلی
- **vLLM**: بهینه‌شده برای تولید و سناریوهای با توان بالا

### پروتکل‌های اتصال انعطاف‌پذیر

دو حالت اتصال پشتیبانی می‌شوند:

**حالت STDIO**: ارتباط مستقیم فرآیند
- تأخیر کمتر
- مناسب برای ابزارهای محلی
- تنظیمات ساده

**حالت SSE**: جریان مبتنی بر HTTP
- قابلیت شبکه
- مناسب برای سیستم‌های توزیع‌شده
- به‌روزرسانی‌های بلادرنگ

### قابلیت‌های یکپارچه‌سازی ابزارها

سیستم می‌تواند با ابزارهای مختلف یکپارچه شود:
- اتوماسیون وب (Playwright)
- عملیات فایل
- تعاملات API
- دستورات سیستم
- عملکردهای سفارشی

## مدیریت خطا و بهترین روش‌ها

### مدیریت جامع خطا

پیاده‌سازی شامل مدیریت خطای قوی برای موارد زیر است:

**خطاهای اتصال:**
- خرابی سرور MCP
- زمان‌های انتظار شبکه
- مشکلات اتصال

**خطاهای اجرای ابزار:**
- ابزارهای گم‌شده
- اعتبارسنجی پارامترها
- خرابی‌های اجرا

**خطاهای پردازش پاسخ:**
- مشکلات تجزیه JSON
- ناسازگاری‌های فرمت
- ناهنجاری‌های پاسخ LLM

### بهترین روش‌ها

1. **مدیریت منابع**: از مدیران زمینه غیرهمزمان استفاده کنید.
2. **مدیریت خطا**: بلوک‌های try-catch جامع پیاده‌سازی کنید.
3. **ثبت**: سطوح ثبت مناسب را فعال کنید.
4. **امنیت**: ورودی‌ها را اعتبارسنجی کرده و خروجی‌ها را پاکسازی کنید.
5. **عملکرد**: از اتصال‌های مشترک و کش استفاده کنید.

## کاربردهای واقعی

### اتوماسیون وب
```python
# Example: Automated web testing
async def web_automation_example():
    tools = await setup_playwright_tools()
    response = await llm_client.generate_response(
        "Navigate to example.com and take a screenshot",
        tools
    )
```

### پردازش داده
```python
# Example: File analysis
async def data_processing_example():
    tools = await setup_file_tools()
    response = await llm_client.generate_response(
        "Analyze the CSV file and generate a summary report",
        tools
    )
```

### یکپارچه‌سازی API
```python
# Example: API interactions
async def api_integration_example():
    tools = await setup_api_tools()
    response = await llm_client.generate_response(
        "Fetch weather data and create a forecast summary",
        tools
    )
```

## بهینه‌سازی عملکرد

### مدیریت حافظه
- مدیریت کارآمد تاریخچه پیام‌ها
- پاکسازی مناسب منابع
- اتصال‌های مشترک

### بهینه‌سازی شبکه
- عملیات HTTP غیرهمزمان
- زمان‌های انتظار قابل تنظیم
- بازیابی خطای مناسب

### پردازش همزمان
- I/O غیرمسدودکننده
- اجرای موازی ابزارها
- الگوهای غیرهمزمان کارآمد

## ملاحظات امنیتی

### حفاظت از داده‌ها
- مدیریت امن کلیدهای API
- اعتبارسنجی ورودی‌ها
- پاکسازی خروجی‌ها

### امنیت شبکه
- پشتیبانی از HTTPS
- پیش‌فرض‌های نقطه پایانی محلی
- مدیریت امن توکن‌ها

### ایمنی اجرا
- فیلتر کردن ابزارها
- محیط‌های ایزوله‌شده
- ثبت حسابرسی

## اکوسیستم و توسعه MCP

### دامنه پروژه MCP

اکوسیستم پروتکل زمینه مدل شامل چندین مؤلفه کلیدی است:

- **[مشخصات MCP](https://modelcontextprotocol.io/specification/latest)**: مشخصات رسمی که الزامات پیاده‌سازی برای کلاینت‌ها و سرورها را شرح می‌دهد.
- **[SDKهای MCP](https://modelcontextprotocol.io/docs/sdk)**: SDKهایی برای زبان‌های برنامه‌نویسی مختلف که MCP را پیاده‌سازی می‌کنند.
- **ابزارهای توسعه MCP**: ابزارهایی برای توسعه سرورها و کلاینت‌های MCP، شامل [بازرس MCP](https://github.com/modelcontextprotocol/inspector)
- **[پیاده‌سازی‌های مرجع سرور MCP](https://github.com/modelcontextprotocol/servers)**: پیاده‌سازی‌های مرجع سرورهای MCP

### شروع به کار با توسعه MCP

برای شروع ساخت با MCP:

**ساخت سرورها**: [سرورهای MCP ایجاد کنید](https://modelcontextprotocol.io/docs/develop/build-server) تا داده‌ها و ابزارهای خود را ارائه دهید.

**ساخت کلاینت‌ها**: [برنامه‌هایی توسعه دهید](https://modelcontextprotocol.io/docs/develop/build-client) که به سرورهای MCP متصل شوند.

**مفاهیم را بیاموزید**: [مفاهیم اصلی](https://modelcontextprotocol.io/docs/learn/architecture) و معماری MCP را درک کنید.

## نتیجه‌گیری

مدل‌های زبان کوچک که با MCP یکپارچه شده‌اند، یک تغییر پارادایم در توسعه برنامه‌های هوش مصنوعی را نشان می‌دهند. با ترکیب کارایی مدل‌های کوچک با قدرت ابزارهای خارجی، توسعه‌دهندگان می‌توانند سیستم‌های هوشمندی ایجاد کنند که هم از نظر منابع کارآمد و هم بسیار توانمند باشند.

پروتکل زمینه مدل یک روش استاندارد برای اتصال برنامه‌های هوش مصنوعی به سیستم‌های خارجی فراهم می‌کند، همانطور که USB-C یک استاندارد اتصال جهانی برای دستگاه‌های الکترونیکی ارائه می‌دهد. این استانداردسازی امکان:

- **یکپارچه‌سازی بدون دردسر**: اتصال مدل‌های هوش مصنوعی به منابع داده و ابزارهای متنوع
- **رشد اکوسیستم**: یک بار بسازید، در چندین برنامه هوش مصنوعی استفاده کنید
- **قابلیت‌های پیشرفته**: تقویت مدل‌های کوچک با عملکردهای خارجی
- **به‌روزرسانی‌های بلادرنگ**: پشتیبانی از برنامه‌های هوش مصنوعی پویا و پاسخگو

نکات کلیدی:
- MCP یک استاندارد باز است که برنامه‌های هوش مصنوعی و سیستم‌های خارجی را به هم متصل می‌کند.
- پروتکل از ابزارها، منابع و درخواست‌ها به عنوان اصول اصلی پشتیبانی می‌کند.
- اعلان‌های بلادرنگ امکان برنامه‌های پویا و پاسخگو را فراهم می‌کنند.
- مدیریت چرخه عمر و مدیریت خطا برای استفاده در تولید ضروری است.
- اکوسیستم ابزارها و SDKهای جامع برای توسعه فراهم می‌کند.

## منابع و مطالعه بیشتر

### مستندات رسمی MCP

- **[سایت رسمی پروتکل زمینه مدل](https://modelcontextprotocol.io/)** - مستندات و مشخصات کامل
- **[راهنمای شروع MCP](https://modelcontextprotocol.io/docs/getting-started/intro)** - معرفی و مفاهیم اصلی
- **[نمای کلی معماری MCP](https://modelcontextprotocol.io/docs/learn/architecture)** - معماری فنی دقیق
- **[مشخصات MCP](https://modelcontextprotocol.io/specification/latest)** - مشخصات رسمی پروتکل
- **[مستندات SDKهای MCP](https://modelcontextprotocol.io/docs/sdk)** - راهنماهای SDK زبان‌محور

### منابع توسعه

- **[MCP برای مبتدیان](https://aka.ms/mcp-for-beginners)** - راهنمای جامع مبتدیان برای پروتکل زمینه مدل
- **[سازمان GitHub MCP](https://github.com/modelcontextprotocol)** - مخازن و مثال‌های رسمی
- **[مخزن سرور MCP](https://github.com/modelcontextprotocol/servers)** - پیاده‌سازی‌های مرجع سرور
- **[بازرس MCP](https://github.com/modelcontextprotocol/inspector)** - ابزار توسعه و اشکال‌زدایی
- **[راهنمای ساخت سرورهای MCP](https://modelcontextprotocol.io/docs/develop/build-server)** - آموزش توسعه سرور
- **[راهنمای ساخت کلاینت‌های MCP](https://modelcontextprotocol.io/docs/develop/build-client)** - آموزش توسعه کلاینت

### مدل‌های زبان کوچک و هوش مصنوعی لبه

- **[مدل‌های Phi مایکروسافت](https://aka.ms/phicookbook)** - خانواده مدل‌های Phi
- **[مستندات Foundry Local](https://github.com/microsoft/Foundry-Local)** - محیط اجرایی هوش مصنوعی لبه مایکروسافت
- **[مستندات Ollama](https://ollama.ai/docs)** - پلتفرم استقرار LLM محلی  
- **[مستندات vLLM](https://docs.vllm.ai/)** - سرویس‌دهی LLM با عملکرد بالا  

### استانداردها و پروتکل‌های فنی  

- **[مشخصات JSON-RPC 2.0](https://www.jsonrpc.org/)** - پروتکل RPC پایه مورد استفاده توسط MCP  
- **[JSON Schema](https://json-schema.org/)** - استاندارد تعریف اسکیمای ابزارهای MCP  
- **[مشخصات OpenAPI](https://swagger.io/specification/)** - استاندارد مستندسازی API  
- **[رویدادهای ارسال‌شده توسط سرور (SSE)](https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events)** - استاندارد وب برای به‌روزرسانی‌های بلادرنگ  

### توسعه عامل‌های هوش مصنوعی  

- **[Microsoft Agent Framework](https://github.com/microsoft/agent-framework)** - توسعه عامل‌های آماده تولید  
- **[مستندات LangChain](https://docs.langchain.com/)** - چارچوب یکپارچه‌سازی عامل‌ها و ابزارها  
- **[Semantic Kernel](https://learn.microsoft.com/en-us/semantic-kernel/)** - SDK ارکستراسیون هوش مصنوعی مایکروسافت  

### گزارش‌ها و تحقیقات صنعتی  

- **[اعلامیه پروتکل زمینه مدل Anthropic](https://www.anthropic.com/news/model-context-protocol)** - معرفی اولیه MCP  
- **[بررسی مدل‌های زبان کوچک](https://arxiv.org/abs/2410.20011)** - بررسی آکادمیک تحقیقات SLM  
- **[تحلیل بازار هوش مصنوعی لبه](https://www.marketsandmarkets.com/Market-Reports/edge-ai-software-market-74385617.html)** - روندها و پیش‌بینی‌های صنعتی  
- **[بهترین روش‌های توسعه عامل‌های هوش مصنوعی](https://arxiv.org/abs/2309.02427)** - تحقیق در مورد معماری‌های عامل  

این بخش پایه‌ای برای ساخت برنامه‌های MCP مبتنی بر SLM شما فراهم می‌کند و امکان خودکارسازی، پردازش داده‌ها و یکپارچه‌سازی سیستم‌های هوشمند را باز می‌کند.  

## ➡️ مرحله بعد  

- [ماژول 7. نمونه‌های هوش مصنوعی لبه](../Module07/README.md)  

---

**سلب مسئولیت**:  
این سند با استفاده از سرویس ترجمه هوش مصنوعی [Co-op Translator](https://github.com/Azure/co-op-translator) ترجمه شده است. در حالی که ما تلاش می‌کنیم دقت را حفظ کنیم، لطفاً توجه داشته باشید که ترجمه‌های خودکار ممکن است شامل خطاها یا نادرستی‌ها باشند. سند اصلی به زبان اصلی آن باید به عنوان منبع معتبر در نظر گرفته شود. برای اطلاعات حیاتی، ترجمه حرفه‌ای انسانی توصیه می‌شود. ما مسئولیتی در قبال سوء تفاهم‌ها یا تفسیرهای نادرست ناشی از استفاده از این ترجمه نداریم.