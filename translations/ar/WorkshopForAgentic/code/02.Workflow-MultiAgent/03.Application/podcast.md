<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "f3f51b3c0edfef19d0ef4a9da47667d0",
  "translation_date": "2026-01-05T13:34:49+00:00",
  "source_file": "WorkshopForAgentic/code/02.Workflow-MultiAgent/03.Application/podcast.md",
  "language_code": "ar"
}
-->
المتحدث 1: مرحبًا بكم في هذه الحلقة من البودكاست! أنا المُقدمة لوسي، واليوم لدينا شرف استضافة خبير في مجال الذكاء الاصطناعي كين، لنتحدث عن أولا ما الذي يُثير الانتباه مؤخرًا وهو Ollama. كين، هل يمكنك أن تقدّم لنا تعريفًا موجزًا عن Ollama؟  
المتحدث 2: بالطبع! Ollama هو أداة تتيح للمستخدمين تشغيل وإدارة نماذج اللغة الكبيرة (LLM) على أجهزتهم المحلية. لا يعتمد على خدمات السحابة، ويركز على الخصوصية، التحكم، والتخصيص. للمطورين والشركات، يوفر بديلاً مرنًا وصديقًا للخصوصية بدلًا من خدمات السحابة مثل ChatGPT.  
المتحدث 1: يبدو ذلك جذابًا جدًا. فما هي المزايا الأساسية لـ Ollama؟  
المتحدث 2: هناك ثلاث مزايا رئيسية. أولًا الخصوصية والأمان. تبقى بيانات المستخدم دائمًا على الجهاز المحلي، مما يمنع تسريب البيانات عبر خدمات السحابة التابعة لأطراف خارجية، وهو أمر مهم جدًا في قطاعات حساسة مثل الرعاية الصحية والمالية. ثانيًا الوصول دون اتصال، حيث يمكن استخدامه حتى بدون شبكة، مناسب للمناطق ذات الاتصال غير المستقر. وأخيرًا التخصيص، حيث يمكن للمستخدم تعديل معلمات النموذج عبر نظام Modelfile، وحتى إجراء ضبط دقيق للنموذج ليناسب مهام أو احتياجات صناعية محددة.  
المتحدث 1: بالفعل هذه الميزات عملية جدًا. فما هي السيناريوهات التطبيقية الفعلية لـ Ollama؟  
المتحدث 2: مثلاً يمكن للشركات تطوير روبوتات دردشة محلية تقلل من زمن التأخير وتتكيف مع مصطلحات صناعية محددة؛ يمكن للمؤسسات البحثية إجراء تجارب بيانات في بيئات حساسة للخصوصية؛ كما يمكن للقطاعات القانونية والطبية بناء أدوات ذكاء اصطناعي مثل تحليل العقود أو مراجعة الامتثال دون تعريض المعلومات الحساسة. بالإضافة إلى ذلك، يمكن دمجه بسلاسة مع الأنظمة القائمة مثل CMS أو CRM دون الحاجة إلى إعادة هيكلة البنية التحتية.  
المتحدث 1: بالمقارنة مع ChatGPT، ما الذي يميز Ollama؟  
المتحدث 2: يتفوق ChatGPT في قابلية التوسع وخدمة السحابة وبيانات التدريب العالمية، بينما يركز Ollama أكثر على الخصوصية والتحكم المحلي. إذا كانت هناك حاجة صارمة لحماية البيانات أو للعمل دون اتصال، فـ Ollama هو الخيار الأفضل؛ أما إذا كانت الحاجة للنشر على نطاق واسع ودعم لغوي عالمي، فقد يكون ChatGPT أنسب.  
المتحدث 1: فهمت. ماذا عن المستخدم العادي، هل عتبة الدخول لـ Ollama مرتفعة؟  
المتحدث 2: في الواقع ليست مرتفعة جدًا. تثبيت وإعداد Ollama يشبه استخدام Docker، وهو مناسب للمستخدمين ذوي الخلفية التقنية بعض الشيء. كما أنه يوفر وثائق مفصلة ودعمًا مجتمعيًا، مما يسمح حتى للمبتدئين بالتعلم والتعامل معه تدريجيًا. ومع ذلك، قد يحتاج من ليس لهم معرفة بالنماذج الذكية إلى بعض الوقت للتعلم.  
المتحدث 1: شكرًا جزيلًا على مشاركتك! وأخيرًا، هل لديك نصائح للمستمعين؟  
المتحدث 2: إذا كان مشروعكم يتعامل مع بيانات حساسة أو يحتاج إلى العمل دون اتصال، أنصحكم بتجربة Ollama. وابدأوا بمهمات بسيطة مثل التوليد النصي المحلي، لتستكشفوا إمكانياته في التخصيص تدريجيًا. تذكروا أن الخصوصية والمرونة هما القيمة الجوهرية لـ Ollama، ولكن اختاروا الأداة حسب الاحتياجات الفعلية.  
المتحدث 1: شكرًا لك كين على الشرح الرائع! جعلتنا هذه الحلقة نفهم إمكانيات Ollama بشكل أفضل. إذا كنتم مهتمين بأدوات الذكاء الاصطناعي، لا تنسوا متابعة قناتنا، سنتحدث في الحلقة القادمة عن كيفية تحسين كفاءة العمل اليومي باستخدام الذكاء الاصطناعي. أنا لوسي، إلى اللقاء في الحلقة القادمة!

---

<!-- CO-OP TRANSLATOR DISCLAIMER START -->
**إخلاء المسؤولية**:  
تمت ترجمة هذا المستند باستخدام خدمة الترجمة الآلية [Co-op Translator](https://github.com/Azure/co-op-translator). على الرغم من أننا نسعى لتحقيق الدقة، يرجى العلم بأن الترجمات الآلية قد تحتوي على أخطاء أو عدم دقة. يجب اعتبار المستند الأصلي بلغته الأصلية هو المصدر الموثوق به. بالنسبة للمعلومات الحساسة، يوصى بالاستعانة بترجمة بشرية محترفة. نحن غير مسؤولين عن أي سوء فهم أو تفسير خاطئ ناتج عن استخدام هذه الترجمة.
<!-- CO-OP TRANSLATOR DISCLAIMER END -->