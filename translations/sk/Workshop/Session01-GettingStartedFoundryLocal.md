<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "8c30436578b1bd604c48233ecdd39701",
  "translation_date": "2025-11-12T00:13:36+00:00",
  "source_file": "Workshop/Session01-GettingStartedFoundryLocal.md",
  "language_code": "sk"
}
-->
# Session 1: Zaƒç√≠name s Foundry Local

## Abstrakt

Nauƒçte sa nain≈°talova≈•, nakonfigurova≈• a spusti≈• svoje prv√© AI modely pomocou Microsoft Foundry Local. T√°to praktick√° rel√°cia poskytuje krok za krokom √∫vod do lok√°lnej inferencie, od in≈°tal√°cie a≈æ po vytvorenie va≈°ej prvej chatovacej aplik√°cie s modelmi ako Phi-4, Qwen a DeepSeek.

## Ciele uƒçenia

Na konci tejto rel√°cie budete schopn√≠:

- **In≈°talova≈• a konfigurova≈•**: Nastavi≈• Foundry Local s overen√≠m spr√°vnej in≈°tal√°cie
- **Ovl√°dnu≈• CLI oper√°cie**: Pou≈æ√≠va≈• Foundry Local CLI na spr√°vu a nasadenie modelov
- **Spusti≈• svoj prv√Ω model**: √öspe≈°ne nasadi≈• a interagova≈• s lok√°lnym AI modelom
- **Vytvori≈• chatovaciu aplik√°ciu**: Vytvori≈• z√°kladn√∫ chatovaciu aplik√°ciu pomocou Foundry Local Python SDK
- **Pochopi≈• lok√°lne AI**: Z√≠ska≈• z√°klady lok√°lnej inferencie a spr√°vy modelov

## Predpoklady

### Po≈æiadavky na syst√©m

- **Windows**: Windows 11 (22H2 alebo nov≈°√≠) ALEBO **macOS**: macOS 11+ (obmedzen√° podpora)
- **RAM**: Minim√°lne 8GB, odpor√∫ƒçan√© 16GB+
- **√ölo≈æisko**: 10GB+ voƒæn√©ho miesta pre modely
- **Python**: Nain≈°talovan√Ω vo verzii 3.10 alebo nov≈°ej
- **Admin pr√≠stup**: Administr√°torsk√© opr√°vnenia na in≈°tal√°ciu

### V√Ωvojov√© prostredie

- Visual Studio Code s roz≈°√≠ren√≠m pre Python (odpor√∫ƒçan√©)
- Pr√≠stup k pr√≠kazov√©mu riadku (PowerShell na Windows, Terminal na macOS)
- Git na klonovanie repozit√°rov (voliteƒæn√©)

## Priebeh workshopu (30 min√∫t)

### Krok 1: In≈°tal√°cia Foundry Local (5 min√∫t)

#### In≈°tal√°cia na Windows

Nain≈°talujte Foundry Local pomocou bal√≠kov√©ho mana≈æ√©ra pre Windows:

```powershell
# Install via winget (recommended)
winget install Microsoft.FoundryLocal
```

Alternat√≠va: Stiahnite priamo z [Microsoft Learn](https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/install)

#### In≈°tal√°cia na macOS (obmedzen√° podpora)

> [!NOTE] 
> Podpora pre macOS je moment√°lne v n√°hƒæade. Skontrolujte ofici√°lnu dokument√°ciu pre najnov≈°iu dostupnos≈•.

Ak je dostupn√°, nain≈°talujte pomocou Homebrew:

```bash
# If Homebrew formula is available
brew update
brew install foundry-local

# Or manual download (check official docs for latest)
curl -L -o foundry-local.tar.gz "https://download.microsoft.com/foundry-local/latest/macos/foundry-local.tar.gz"
tar -xzf foundry-local.tar.gz
sudo ./install.sh
```

**Alternat√≠va pre pou≈æ√≠vateƒæov macOS:**
- Pou≈æite Windows 11 VM (Parallels/UTM) a postupujte podƒæa krokov pre Windows
- Spustite cez kontajner, ak je dostupn√Ω, a nakonfigurujte `FOUNDRY_LOCAL_ENDPOINT`

### Krok 2: Overenie in≈°tal√°cie (3 min√∫ty)

Po in≈°tal√°cii re≈°tartujte svoj termin√°l a overte, ƒçi Foundry Local funguje:

```powershell
# Check if Foundry Local is installed correctly
foundry --version

# View available commands
foundry --help
```

Oƒçak√°van√Ω v√Ωstup by mal uk√°za≈• inform√°cie o verzii a dostupn√© pr√≠kazy.

### Krok 3: Nastavenie Python prostredia (5 min√∫t)

Vytvorte dedikovan√© Python prostredie pre tento workshop:

**Windows:**
```powershell
# Create virtual environment
py -m venv .venv

# Activate environment
.\.venv\Scripts\Activate.ps1

# Upgrade pip and install dependencies
python -m pip install --upgrade pip
pip install foundry-local-sdk openai
```

**macOS/Linux:**
```bash
# Create virtual environment
python3 -m venv .venv

# Activate environment
source .venv/bin/activate

# Upgrade pip and install dependencies
python -m pip install --upgrade pip
pip install foundry-local-sdk openai
```

### Krok 4: Spustenie v√°≈°ho prv√©ho modelu (7 min√∫t)

Teraz spust√≠me n√°≈° prv√Ω AI model lok√°lne!

#### Zaƒçnite s Phi-4 Mini (Odpor√∫ƒçan√Ω prv√Ω model)

```powershell
# Download and start phi-4-mini (lightweight, fast)
foundry model run phi-4-mini

# Test the model with a simple prompt
foundry model run phi-4-mini --prompt "Hello, introduce yourself in one sentence"
```

> [!TIP]
> Tento pr√≠kaz stiahne model (prv√Ωkr√°t) a automaticky spust√≠ slu≈æbu Foundry Local.

#### Skontrolujte, ƒço be≈æ√≠

```powershell
# List available models (shows downloaded models)
foundry model list

# Check service status
foundry service status

# See what models are cached locally
foundry cache list
```

#### Vysk√∫≈°ajte r√¥zne modely

Keƒè phi-4-mini funguje, experimentujte s in√Ωmi modelmi:

```powershell
# Larger model with better capabilities
foundry model run gpt-oss-20b --prompt "Explain edge AI in simple terms"

# Fast, efficient model
foundry model run qwen2.5-0.5b --prompt "What are the benefits of local AI inference?"
```

### Krok 5: Vytvorenie va≈°ej prvej chatovacej aplik√°cie (10 min√∫t)

Teraz vytvor√≠me Python aplik√°ciu, ktor√° pou≈æ√≠va modely, ktor√© sme pr√°ve spustili.

#### Vytvorenie chatovacieho skriptu

Vytvorte nov√Ω s√∫bor s n√°zvom `my_first_chat.py` (alebo pou≈æite poskytnut√Ω vzor):

```python
#!/usr/bin/env python3
"""
My First Foundry Local Chat Application
Using FoundryLocalManager for automatic service management
"""

import os
from foundry_local import FoundryLocalManager
from openai import OpenAI

def main():
    # Get model alias from environment or use default
    alias = os.getenv("FOUNDRY_LOCAL_ALIAS", "phi-4-mini")
    
    try:
        # Initialize Foundry Local Manager (auto-starts service, downloads model)
        manager = FoundryLocalManager(alias)
        
        # Create OpenAI client pointing to local endpoint
        client = OpenAI(
            base_url=manager.endpoint,
            api_key=manager.api_key or "not-needed"
        )
        
        # Get the actual model ID for this alias
        model_id = manager.get_model_info(alias).id
        
        print("ü§ñ Welcome to your first local AI chat!")
        print(f"ÔøΩ Using model: {alias} -> {model_id}")
        print(f"üåê Endpoint: {manager.endpoint}")
        print("ÔøΩüí° Type 'quit' to exit\n")
        
    except Exception as e:
        print(f"‚ùå Failed to initialize Foundry Local: {e}")
        print("üí° Make sure Foundry Local is installed: foundry --version")
        return
    
    while True:
        # Get user input
        user_message = input("You: ").strip()
        
        if user_message.lower() in ['quit', 'exit', 'bye']:
            print("üëã Goodbye!")
            break
            
        if not user_message:
            continue
            
        try:
            # Send message to local AI model
            response = client.chat.completions.create(
                model=model_id,
                messages=[
                    {"role": "system", "content": "You are a helpful AI assistant running locally."},
                    {"role": "user", "content": user_message}
                ],
                max_tokens=200,
                temperature=0.7
            )
            
            # Display the response
            ai_response = response.choices[0].message.content
            print(f"ü§ñ AI: {ai_response}\n")
            
        except Exception as e:
            print(f"‚ùå Error: {e}")
            print("üí° Check service status: foundry service status\n")

if __name__ == "__main__":
    main()
```

> [!TIP]
> **S√∫visiace pr√≠klady**: Pre pokroƒçilej≈°ie pou≈æitie pozrite:
>
> - **Python vzor**: `Workshop/samples/session01/chat_bootstrap.py` - Zah≈ï≈àa streamovanie odpoved√≠ a spracovanie ch√Ωb
> - **Jupyter Notebook**: `Workshop/notebooks/session01_chat_bootstrap.ipynb` - Interakt√≠vna verzia s podrobn√Ωmi vysvetleniami

#### Testovanie va≈°ej chatovacej aplik√°cie

```powershell
# No need to manually start models - FoundryLocalManager handles this!
# Just run your chat application
python my_first_chat.py
```

Alternat√≠va: Pou≈æite priamo poskytnut√© vzory

```powershell
# Try the complete sample with streaming support
cd Workshop/samples
python -m session01.chat_bootstrap "Your question here"
```

Alebo presk√∫majte interakt√≠vny notebook
Otvorte Workshop/notebooks/session01_chat_bootstrap.ipynb vo VS Code

Vysk√∫≈°ajte tieto pr√≠klady konverz√°ci√≠:

- "ƒåo je Microsoft Foundry Local?"
- "Vymenuj 3 v√Ωhody sp√∫≈°≈•ania AI modelov lok√°lne"
- "Pom√¥≈æ mi pochopi≈• edge AI"

## ƒåo ste dosiahli

Gratulujeme! √öspe≈°ne ste:

1. ‚úÖ **Nain≈°talovali Foundry Local** a overili jeho funkƒçnos≈•
2. ‚úÖ **Spustili svoj prv√Ω AI model** (phi-4-mini) lok√°lne
3. ‚úÖ **Otestovali r√¥zne modely** cez pr√≠kazov√Ω riadok
4. ‚úÖ **Vytvorili chatovaciu aplik√°ciu**, ktor√° sa prip√°ja k v√°≈°mu lok√°lnemu AI
5. ‚úÖ **Za≈æili lok√°lnu AI inferenciu** bez z√°vislosti na cloude

## Pochopenie, ƒço sa stalo

### Lok√°lna AI inferencia

- Va≈°e AI modely be≈æia √∫plne na va≈°om poƒç√≠taƒçi
- ≈Ωiadne d√°ta sa neposielaj√∫ do cloudu
- Odpovede s√∫ generovan√© lok√°lne pomocou v√°≈°ho CPU/GPU
- Ochrana s√∫kromia a bezpeƒçnos≈• s√∫ zachovan√©

### Spr√°va modelov

- `foundry model run` s≈•ahuje a sp√∫≈°≈•a modely
- **FoundryLocalManager SDK** automaticky spravuje spustenie slu≈æby a naƒç√≠tanie modelov
- Modely s√∫ ulo≈æen√© lok√°lne pre bud√∫ce pou≈æitie
- Viacero modelov m√¥≈æe by≈• stiahnut√Ωch, ale zvyƒçajne be≈æ√≠ iba jeden naraz
- Slu≈æba automaticky spravuje ≈æivotn√Ω cyklus modelu

### SDK vs CLI pr√≠stupy

- **CLI pr√≠stup**: Manu√°lna spr√°va modelov pomocou `foundry model run <model>`
- **SDK pr√≠stup**: Automatick√° spr√°va slu≈æby + modelov pomocou `FoundryLocalManager(alias)`
- **Odpor√∫ƒçanie**: Pou≈æ√≠vajte SDK pre aplik√°cie, CLI na testovanie a prieskum

## Referencia be≈æn√Ωch pr√≠kazov

### Z√°kladn√© CLI pr√≠kazy

```powershell
# Installation & Setup
foundry --version              # Check installation
foundry --help                 # View all commands

# Model Management
foundry model list             # List available models
foundry model run <model>      # Download and start a model
foundry model run <model> --prompt "text"  # One-shot prompt
foundry cache list             # Show downloaded models

# Service Management
foundry service status         # Check if service is running
foundry service start          # Start the service manually
foundry service stop           # Stop the service
```

### Odpor√∫ƒçania modelov

- **phi-4-mini**: Najlep≈°√≠ model na zaƒçiatok - r√Ωchly, nen√°roƒçn√Ω, dobr√° kvalita
- **qwen2.5-0.5b**: Najr√Ωchlej≈°ia inferencia, minim√°lne vyu≈æitie pam√§te
- **gpt-oss-20b**: Kvalitnej≈°ie odpovede, vy≈æaduje viac zdrojov
- **deepseek-coder-1.3b**: Optimalizovan√Ω na programovanie a √∫lohy s k√≥dom

## Rie≈°enie probl√©mov

### "Foundry command not found"

**Rie≈°enie:**

```powershell
# Restart your terminal after installation
# Or manually add to PATH (Windows)
$env:PATH += ";C:\Program Files\Microsoft\FoundryLocal"
```

### "Model sa nepodarilo naƒç√≠ta≈•"

**Rie≈°enie:**

```powershell
# Check available system memory
foundry service status

# Try a smaller model first
foundry model run phi-4-mini

# Check disk space for model downloads
# Models are stored in: %USERPROFILE%\.foundry\models (Windows)
```

### "Spojenie odmietnut√© na localhost"

**Rie≈°enie:**

```powershell
# Check if service is running
foundry service status

# Start service if needed
foundry service start

# Verify the port (default is 5273)
# Check for port conflicts with: netstat -an | findstr 5273
```

## ƒéal≈°ie kroky

### Okam≈æit√© ƒèal≈°ie akcie

1. **Experimentujte** s r√¥znymi modelmi a ot√°zkami
2. **Upravte** svoju chatovaciu aplik√°ciu na vysk√∫≈°anie r√¥znych modelov
3. **Vytvorte** vlastn√© ot√°zky a testujte odpovede
4. **Presk√∫majte** Session 2: Vytv√°ranie RAG aplik√°ci√≠

### Pokroƒçil√° cesta uƒçenia

1. **Session 2**: Vytv√°ranie AI rie≈°en√≠ s RAG (Retrieval-Augmented Generation)
2. **Session 3**: Porovnanie r√¥znych open-source modelov
3. **Session 4**: Pr√°ca s najmodernej≈°√≠mi modelmi
4. **Session 5**: Vytv√°ranie multi-agentov√Ωch AI syst√©mov

## Premenn√© prostredia (voliteƒæn√©)

Pre pokroƒçilej≈°ie pou≈æitie m√¥≈æete nastavi≈• tieto premenn√© prostredia:

| Premenn√° | √öƒçel | Pr√≠klad |
|----------|---------|---------|
| `FOUNDRY_LOCAL_ALIAS` | Predvolen√Ω model na pou≈æitie | `phi-4-mini` |
| `FOUNDRY_LOCAL_ENDPOINT` | Prekrytie URL adresy endpointu | `http://localhost:5273/v1` |

Vytvorte s√∫bor `.env` vo va≈°om projektovom adres√°ri:
```
FOUNDRY_LOCAL_ALIAS=phi-4-mini
FOUNDRY_LOCAL_ENDPOINT=auto
```

## ƒéal≈°ie zdroje

### Dokument√°cia

- [Foundry Local Python SDK Reference](https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/reference/reference-sdk?pivots=programming-language-python)
- [Foundry Local Installation Guide](https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/install)
- [Model Catalog](https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/models)

### Uk√°≈ækov√Ω k√≥d

- **Session01 Python Sample**: `Workshop/samples/session01/chat_bootstrap.py` - Kompletn√° chatovacia aplik√°cia so streamovan√≠m
- **Session01 Notebook**: `Workshop/notebooks/session01_chat_bootstrap.ipynb` - Interakt√≠vny tutori√°l  
- [Module08 Sample 01](../Module08/samples/01/README.md) - REST Chat Quickstart
- [Module08 Sample 02](../Module08/samples/02/README.md) - Integr√°cia OpenAI SDK
- [Module08 Sample 03](../Module08/samples/03/README.md) - Objavovanie modelov a benchmarking

### Komunita

- [Foundry Local GitHub Discussions](https://github.com/microsoft/Foundry-Local/discussions)
- [Azure AI Community](https://techcommunity.microsoft.com/category/artificialintelligence)

---

**Trvanie rel√°cie**: 30 min√∫t prakticky + 15 min√∫t ot√°zky a odpovede  
**√örove≈à obtia≈ænosti**: Zaƒçiatoƒçn√≠k  
**Predpoklady**: Windows 11/macOS 11+, Python 3.10+, Admin pr√≠stup

## Pr√≠klad scen√°ra workshopu

### Kontext z re√°lneho sveta

**Scen√°r**: T√≠m IT v podniku potrebuje vyhodnoti≈• inferenciu AI na zariaden√≠ na spracovanie citlivej sp√§tnej v√§zby zamestnancov bez odosielania √∫dajov do extern√Ωch slu≈æieb.

**V√°≈° cieƒæ**: Uk√°za≈•, ≈æe lok√°lne AI modely dok√°≈æu poskytova≈• kvalitn√© odpovede s latenciou pod jednu sekundu pri zachovan√≠ √∫plnej ochrany √∫dajov.

### Testovacie ot√°zky

Pou≈æite tieto ot√°zky na overenie v√°≈°ho nastavenia:

```json
[
    "List two benefits of local inference.",
    "Summarize why keeping data on device improves privacy.",
    "Give one trade-off when choosing a small model over a large model."
]
```

### Krit√©ri√° √∫spechu

- ‚úÖ V≈°etky ot√°zky dostan√∫ odpovede do 2 sek√∫nd
- ‚úÖ ≈Ωiadne √∫daje neopustia v√°≈° lok√°lny poƒç√≠taƒç
- ‚úÖ Odpovede s√∫ relevantn√© a u≈æitoƒçn√©
- ‚úÖ Va≈°a chatovacia aplik√°cia funguje bez probl√©mov

T√°to valid√°cia zabezpeƒç√≠, ≈æe va≈°e nastavenie Foundry Local je pripraven√© na pokroƒçil√© workshopy v rel√°ci√°ch 2-6.

---

<!-- CO-OP TRANSLATOR DISCLAIMER START -->
**Zrieknutie sa zodpovednosti**:  
Tento dokument bol prelo≈æen√Ω pomocou slu≈æby AI prekladu [Co-op Translator](https://github.com/Azure/co-op-translator). Hoci sa sna≈æ√≠me o presnos≈•, pros√≠m, berte na vedomie, ≈æe automatizovan√© preklady m√¥≈æu obsahova≈• chyby alebo nepresnosti. P√¥vodn√Ω dokument v jeho rodnom jazyku by mal by≈• pova≈æovan√Ω za autoritat√≠vny zdroj. Pre kritick√© inform√°cie sa odpor√∫ƒça profesion√°lny ƒæudsk√Ω preklad. Nenesieme zodpovednos≈• za ak√©koƒævek nedorozumenia alebo nespr√°vne interpret√°cie vypl√Ωvaj√∫ce z pou≈æitia tohto prekladu.
<!-- CO-OP TRANSLATOR DISCLAIMER END -->