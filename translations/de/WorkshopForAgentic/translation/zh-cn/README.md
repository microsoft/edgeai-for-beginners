<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "aa775a734bda4590ecbe3a94a3b62197",
  "translation_date": "2026-01-05T17:22:37+00:00",
  "source_file": "WorkshopForAgentic/translation/zh-cn/README.md",
  "language_code": "de"
}
-->
# ğŸ™ï¸ KI-Podcast-Studio Workshop

![logo](../../../../../translated_images/de/logo.8711e39dc8257d7b.webp)

## Deine Aufgabe

Willkommen im **KI-Podcast-Studio**! Du wirst deinen eigenen Tech-Podcast â€Future Bytesâ€œ starten â€“ aber hier kommt die Wendung: Du baust ein KI-gesteuertes Produktionsteam auf, das dir bei der Erstellung hilft. Kein endloses Recherchieren, Skripte schreiben und Audio bearbeiten mehr. Stattdessen wirst du zum Podcaster mit KI-SuperkrÃ¤ften durch Programmierung.

## Hintergrundgeschichte

Stell dir vor: Du und deine Freunde wollt einen Podcast Ã¼ber die coolsten Technologietrends starten, aber jeder ist mit Studium, Arbeit oder Alltag beschÃ¤ftigt. Was, wenn du ein Team von KI-Agenten aufbauen kÃ¶nntest, die die schwere Arbeit erledigen? Ein Agent recherchiert das Thema, ein anderer schreibt spannende Skripte, ein dritter wandelt Text in einen natÃ¼rlich klingenden Dialog um. Klingt wie Science-Fiction? Lass uns das zur RealitÃ¤t machen.

## Was du lernen wirst

Am Ende dieses Workshops wirst du wissen, wie du:
- ğŸ¤– Dein eigenes lokales KI-Modell bereitstellst (keine API-Kosten, keine Cloud-AbhÃ¤ngigkeit!)
- ğŸ”§ Professionelle, kollaborierende KI-Agenten baust
- ğŸ¬ Einen kompletten Podcast-Produktionsablauf von der Idee bis zum Audio erstellst

## Deine Reise: Drei Akte

Wie jede gute Geschichte haben wir drei Akte. Jeder Akt baut schrittweise dein KI-Podcast-Studio auf:

| Kapitel | Deine Aufgabe | Was passiert | FÃ¤higkeiten, die du freischaltest |
|---------|---------------|--------------|-------------------------------|
| **Akt 1** | [Lerne deine KI-Assistenten kennen](01.BuildAIAgentWithSLM.md) | Du entdeckst, wie du KI-Agenten baust, die chatten, im Web suchen und Probleme lÃ¶sen kÃ¶nnen. Stell sie dir als nie schlafende Recherche-Praktikanten vor. | ğŸ¯ Deinen ersten Agenten bauen<br>ğŸ› ï¸ SuperkrÃ¤fte verleihen (Tools!)<br>ğŸ§  Lehren zu denken<br>ğŸŒ Mit dem Internet verbinden |
| **Akt 2** | [Baue dein Produktionsteam auf](02.AIAgentOrchestrationAndWorkflows.md) | Jetzt wird es spannend! Du orchestrierst mehrere KI-Agenten, die wie ein echtes Podcast-Team zusammenarbeiten. Einer recherchiert, einer schreibt, du gibst das Okay â€“ Teamwork machtâ€™s mÃ¶glich. | ğŸ­ Mehrere Agenten koordinieren<br>ğŸ”„ Genehmigungs-Workflows bauen<br>ğŸ–¥ï¸ DevUI-OberflÃ¤che zum Testen nutzen<br>âœ‹ Menschliche Kontrolle bewahren |
| **Akt 3** | [Bring deinen Podcast zum Leben](03.Multi-SpeakerPodcastGenerationWithVibeVoice.md) | Das Finale! Wandle dein Textskript in echten Podcast-Content mit realistischen Stimmen und natÃ¼rlichem Dialog um. Dein â€Future Bytesâ€œ-Podcast ist bereit zur VerÃ¶ffentlichung! | ğŸ¤ Text-zu-Sprache-Magie<br>ğŸ‘¥ Multi-Sprecher-Stimmen<br>â±ï¸ Langformat-Audio<br>ğŸš€ Vollautomatisiert |

Jeder Akt schaltet neue FÃ¤higkeiten frei. Wenn du mutig bist, kannst du Ã¼berspringen, aber wir empfehlen die Reihenfolge!

## Systemanforderungen

Dieser Workshop unterstÃ¼tzt verschiedene Hardwareumgebungen:
- **CPU**: FÃ¼r Tests und kleine EinsÃ¤tze geeignet
- **GPU**: Empfohlen fÃ¼r Produktion, deutlich schnellere Inferenz
- **NPU**: UnterstÃ¼tzung fÃ¼r next-gen neuronale Prozessorbeschleunigung

## Was du brauchst

### Softwareliste âœ…
- **Python 3.10+** (deine Programmiersprache)
- **Ollama** (KI-Modell-Runner auf deinem GerÃ¤t)
- **VS Code** (dein Code-Editor)
- **Python-Erweiterung** (macht VS Code smarter)
- **Git** (zum Code holen)

### Hardware-Check ğŸ’»
- **LÃ¤uft es bei mir?**: 8 GB RAM, 10 GB freier Speicher (geht, kÃ¶nnte aber langsam sein)
- **Ideale Ausstattung**: 16 GB+ RAM, eine gute GPU (lÃ¤uft flÃ¼ssig!)
- **NPU vorhanden?**: Umso besser! Next-Gen Performance ğŸš€

## Baue dein Studio auf ğŸ¬

### Schritt 1: Python aktualisieren

Stelle sicher, dass du Python 3.10 oder neuer hast:

```bash
python --version
# Python 3.10.x oder hÃ¶her sollte angezeigt werden
```

Kein Python? Holâ€™s dir von [python.org](https://python.org) â€“ es ist kostenlos!

### Schritt 2: Ollama herunterladen (dein KI-Modell-Runner)

Gehe zu [ollama.ai](https://ollama.ai) und lade Ollama passend zu deinem Betriebssystem herunter. Stell es dir als die Engine vor, die KI-Modelle lokal ausfÃ¼hrt.

PrÃ¼fe, ob alles bereit ist:

```bash
ollama --version
```

### Schritt 3: Lade dein KI-Hirn herunter ğŸ§ 

Zeit, das Qwen-3-8B Modell zu holen (wie deinen ersten KI-Assistenten anstellen):

```bash
ollama pull qwen3:8b
```

*Das kann ein paar Minuten dauern. Perfekte Zeit fÃ¼r einen Kaffee! â˜•*

### Schritt 4: VS Code einrichten

Falls noch nicht installiert, besorge dir [Visual Studio Code](https://code.visualstudio.com/). Der beste Code-Editor (Ãœberzeug dich selbst ğŸ˜„).

### Schritt 5: Python-Erweiterung

In VS Code:
1. DrÃ¼cke `Ctrl+Shift+X` (auf Mac `Cmd+Shift+X`)
2. Suche nach "Python"
3. Installiere die offizielle Python-Erweiterung von Microsoft

### Schritt 6: Fertig! ğŸ‰

Ehrlich, du bist startklar. Lass uns KI-Magie bauen!

### Schritt 7: Microsoft Agent Framework und weitere Pakete installieren ğŸ“¦

Installiere alle benÃ¶tigten AbhÃ¤ngigkeiten fÃ¼r den Workshop:

```bash
pip install -r ./Installations/requirements.txt -U
```

*Das installiert das Microsoft Agent Framework und alle notwendigen Pakete. GenieÃŸe einen Kaffee â€“ die erste Installation kann ein paar Minuten dauern! â˜•*

## Workshop-Hinweise

Detaillierte Projektstruktur, Setup-Schritte und AusfÃ¼hrung werden im Workshop schrittweise erklÃ¤rt.

## Fehlerbehebung (wenn etwas schiefgeht) ğŸ”§

### â€Oh nein, der Modell-Download ist zu langsam!â€œ
**LÃ¶sung**: VPN nutzen oder Ollama Mirror konfigurieren. Manchmal hakt das Netz einfach.

### â€Mein Rechner hÃ¤ngt! Nicht genug Speicher!â€œ
**LÃ¶sung**: Kleinere Modelle nutzen oder `num_ctx` so anpassen, dass weniger RAM verwendet wird. Stell dir vor, deine KI macht DiÃ¤t.

### â€Kann ich GPU nutzen, um es schneller zu machen?â€œ
**LÃ¶sung**: Ollama erkennt GPUs automatisch! Achte nur darauf, dass deine GPU-Treiber aktuell sind. Kostenloser Geschwindigkeitsschub! ğŸï¸

## Extra Ressourcen (fÃ¼r die Neugierigen) ğŸ“š

- [Ollama Dokumentation](https://github.com/ollama/ollama) â€“ tiefere Einblicke in lokale KI-Modelle
- [Microsoft Agent Framework](https://microsoft.github.io/autogen/) â€“ mehr zum Aufbau von Agententeams
- [Qwen Modell Info](https://qwenlm.github.io/) â€“ lerne das Hirn deiner KI-Assistenten kennen

## Lizenz

MIT-Lizenz â€“ baue coole Sachen, teile sie und mach die Welt besser! ğŸŒ

## Willst du mitmachen?

Bug gefunden? Idee? Ã–ffne ein Issue oder Pull Request! Wir lieben die Community. âœ¨

---

<!-- CO-OP TRANSLATOR DISCLAIMER START -->
**Haftungsausschluss**:  
Dieses Dokument wurde mit dem KI-Ãœbersetzungsdienst [Co-op Translator](https://github.com/Azure/co-op-translator) Ã¼bersetzt. Obwohl wir auf Genauigkeit achten, kÃ¶nnen automatisierte Ãœbersetzungen Fehler oder Ungenauigkeiten enthalten. Das Originaldokument in seiner Ursprungssprache gilt als maÃŸgebliche Quelle. FÃ¼r kritische Informationen wird eine professionelle menschliche Ãœbersetzung empfohlen. Wir Ã¼bernehmen keine Haftung fÃ¼r MissverstÃ¤ndnisse oder Fehlinterpretationen, die sich aus der Nutzung dieser Ãœbersetzung ergeben.
<!-- CO-OP TRANSLATOR DISCLAIMER END -->