<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "f94e745264597bc5d8df967ead2eff97",
  "translation_date": "2026-01-05T10:20:26+00:00",
  "source_file": "WorkshopForAgentic/README.md",
  "language_code": "de"
}
-->
# ğŸ™ï¸ Der AI Podcast Studio Workshop

> ğŸŒ [ä¸­æ–‡ç‰ˆ (Chinesische Version)](translation/zh-cn/README.md)

![logo](../../../translated_images/de/logo.8711e39dc8257d7b.png)

## Deine Mission

Willkommen bei **The AI Podcast Studio**! Du bist dabei, deinen eigenen Tech-Podcast namens "Future Bytes" zu starten â€” aber hier kommt der Clou: Du baust ein KI-gestÃ¼tztes Produktionsteam, das dir bei der Erstellung hilft. Keine endlosen Stunden mehr mit Recherche, Skripterstellung und Audiobearbeitung. Stattdessen programmierst du dich zum Podcast-Produzenten mit KI-SuperkrÃ¤ften.

## Die Geschichte

Stell dir vor: Du und deine Freunde wollt einen Podcast Ã¼ber die coolsten Tech-Trends starten, aber jeder ist mit Schule, Arbeit oder dem Leben beschÃ¤ftigt. Was, wenn du ein Team von KI-Agenten zusammenstellen kÃ¶nntest, die die schwere Arbeit Ã¼bernehmen? Ein Agent recherchiert Themen, der nÃ¤chste schreibt spannende Skripte, und ein dritter verwandelt Text in natÃ¼rlich klingende GesprÃ¤che. Klingt nach Sci-Fi? Lass es uns Wirklichkeit werden lassen.

## Was Du Lernen Wirst

Am Ende dieses Workshops weiÃŸt du, wie du:
- ğŸ¤– Dein eigenes lokales KI-Modell einsetzt (keine API-Kosten, keine Cloud-AbhÃ¤ngigkeit!)
- ğŸ”§ Spezialisierte KI-Agenten baust, die wirklich zusammenarbeiten
- ğŸ¬ Eine komplette Podcast-Produktionspipeline von der Idee bis zum Audio erstellst

## Deine Reise: Drei Akte

![arch](../../../translated_images/de/arch.5965fe504e4a3a93.png)

Wie jede gute Geschichte besteht sie aus drei Akten. Jeder baut dein KI-Podcast-Studio StÃ¼ck fÃ¼r StÃ¼ck auf:

| Episode | Deine Aufgabe | Was passiert | Freigeschaltete FÃ¤higkeiten |
|---------|---------------|--------------|-----------------------------|
| **Akt 1** | [Lerne deine KI-Assistenten kennen](md/01.BuildAIAgentWithSLM.md) | Du entdeckst, wie du KI-Agenten erschaffst, die chatten, im Web suchen und sogar Probleme lÃ¶sen kÃ¶nnen. Denk an sie als deine unermÃ¼dlichen Recherche-Praktikanten. | ğŸ¯ Baue deinen ersten Agenten<br>ğŸ› ï¸ Verleihe ihm SuperkrÃ¤fte (Werkzeuge!)<br>ğŸ§  Bringe ihm Denken bei<br>ğŸŒ Verbinde ihn mit dem Internet |
| **Akt 2** | [Stelle dein Produktionsteam zusammen](md/02.AIAgentOrchestrationAndWorkflows.md) | Jetzt wird es spannend! Du orchestrierst mehrere KI-Agenten, damit sie zusammenarbeiten wie ein echtes Podcast-Team. Einer recherchiert, einer schreibt, du gibst die Freigabe â€“ Teamwork macht den Traum wahr. | ğŸ­ Koordiniere mehrere Agenten<br>ğŸ”„ Baue Freigabeworkflows<br>ğŸ–¥ï¸ Teste mit DevUI-OberflÃ¤che<br>âœ‹ Halte Menschen in der Kontrolle |
| **Akt 3** | [Bring deinen Podcast zum Leben](md/03.Multi-SpeakerPodcastGenerationWithVibeVoice.md) | Das Finale! Verwandle deine Textskripte in echten Podcast-Audio mit realistischen Stimmen und natÃ¼rlichen GesprÃ¤chen. Dein "Future Bytes"-Podcast ist versandbereit! | ğŸ¤ Text-zu-Sprache-Magie<br>ğŸ‘¥ Mehrere Sprecherstimmen<br>â±ï¸ Langform-Audio<br>ğŸš€ Vollautomatisierung |

Jeder Akt schaltet neue FÃ¤higkeiten frei. Spring gerne vor, wenn du mutig bist, aber wir empfehlen, die Geschichte zu verfolgen!

## Systemanforderungen

Dieser Workshop unterstÃ¼tzt verschiedene Hardware-Umgebungen:
- **CPU**: Geeignet fÃ¼r Tests und kleine Nutzungen
- **GPU**: Empfohlen fÃ¼r Produktionsumgebungen, verbessert die Inferenzgeschwindigkeit erheblich
- **NPU**: UnterstÃ¼tzt Beschleunigung durch die nÃ¤chste Generation neuronaler Verarbeitungseinheiten

## Was Du Brauchst

### Software-Checkliste âœ…
- **Python 3.10+** (Deine Programmiersprache)
- **Ollama** (FÃ¼hrt KI-Modelle auf deinem Rechner aus)
- **VS Code** (Dein Code-Editor)
- **Python Extension** (Macht VS Code schlauer)
- **Git** (Um Code zu holen)

### Hardware-Check ğŸ’»
- **Kann ich das ausfÃ¼hren?**: 8GB RAM, 10GB freier Speicher (funktioniert, kÃ¶nnte aber langsam sein)
- **Ideale Ausstattung**: 16GB+ RAM, eine anstÃ¤ndige GPU (lÃ¤uft geschmeidig!)
- **NPU vorhanden?**: Noch besser! Leistung der nÃ¤chsten Generation freigeschaltet ğŸš€

## Richte Dein Studio Ein ğŸ¬

### Schritt 1: Python Power-Up

Stelle sicher, dass du Python 3.10 oder neuer installiert hast:

```bash
python --version
# Sollte Python 3.10.x oder hÃ¶her anzeigen
```

Kein Python? Hol es dir kostenlos von [python.org](https://python.org)!

### Schritt 2: Hol dir Ollama (Deinen KI-Modell-Runner)

Gehe zu [ollama.ai](https://ollama.ai) und lade Ollama fÃ¼r dein Betriebssystem herunter. Stell es dir als Motor vor, der deine KI-Modelle lokal ausfÃ¼hrt.

PrÃ¼fe, ob alles bereit ist:

```bash
ollama --version
```

### Schritt 3: Lade Dein KI-Gehirn herunter ğŸ§ 

Zeit, das Modell Qwen-3-8B zu holen (wie deinen ersten KI-Assistenten einstellen):

```bash
ollama pull qwen3:8b
```

*Das kann ein paar Minuten dauern. Perfekte Zeit fÃ¼r eine Kaffeepause! â˜•*

### Schritt 4: Richte VS Code ein

Lade [Visual Studio Code](https://code.visualstudio.com/) herunter, wenn du es noch nicht hast. Es ist der beste Code-Editor (beweis mir das Gegenteil ğŸ˜„).

### Schritt 5: Python Extension

In VS Code:
1. DrÃ¼cke `Ctrl+Shift+X` (oder `Cmd+Shift+X` auf dem Mac)
2. Suche nach "Python"
3. Installiere die offizielle Python-Erweiterung von Microsoft

### Schritt 6: Du bist bereit! ğŸ‰

Ernsthaft, jetzt kannst du loslegen. Lass uns AI-Magie bauen!

### Schritt 7: Installiere Microsoft Agent Framework und benÃ¶tigte Pakete ğŸ“¦

Installiere alle benÃ¶tigten AbhÃ¤ngigkeiten fÃ¼r den Workshop:

```bash
pip install -r ./Installations/requirements.txt -U
```

*Dadurch werden Microsoft Agent Framework und alle nÃ¶tigen Pakete installiert. Hol dir einen Kaffee â€“ die Erstinstallation kann einige Minuten dauern! â˜•*

## Workshop-Anleitung

Detaillierte Projektstruktur, Konfigurationsschritte und AusfÃ¼hrungsanweisungen werden wÃ¤hrend des Workshops Schritt fÃ¼r Schritt erlÃ¤utert.

## Fehlerbehebung (Wenn mal was schiefgeht) ğŸ”§

### "Ugh, der Modell-Download dauert ewig!"
**LÃ¶sung**: Nutze ein VPN oder konfiguriere Ollama mit einem Mirror-Server. Manchmal hat das Internet einfach keinen SpaÃŸ mit uns.

### "Mein Computer steigt aus! Kein Speicher mehr!"
**LÃ¶sung**: Wechsle zu einem kleineren Modell oder passe die `num_ctx`-Einstellung an, um weniger Speicher zu verwenden. Denk daran, deine KI auf DiÃ¤t zu setzen.

### "Kann ich das mit meiner GPU schneller machen?"
**LÃ¶sung**: Ollama erkennt GPUs automatisch! Stelle nur sicher, dass deine GPU-Treiber aktuell sind. Kostenloses Turbo-Upgrade! ğŸï¸

## Zusatzressourcen (FÃ¼r Neugierige) ğŸ“š

- [Ollama Docs](https://github.com/ollama/ollama) â€” Tiefer Einblick in lokale KI-Modelle
- [Microsoft Agent Framework](https://microsoft.github.io/autogen/) â€” Erfahre mehr Ã¼ber den Aufbau von Agententeams
- [Qwen Modell Info](https://qwenlm.github.io/) â€” Lerne das Gehirn deines KI-Assistenten kennen

## Lizenz

MIT Lizenz â€” Baue coole Sachen, teile sie, mach die Welt besser! ğŸŒ

## Willst Du Mitwirken?

Bug gefunden? Idee? Erstelle ein Issue oder PR! Wir lieben die Community-Vibes. âœ¨

---

<!-- CO-OP TRANSLATOR DISCLAIMER START -->
**Haftungsausschluss**:  
Dieses Dokument wurde mithilfe des KI-Ãœbersetzungsdienstes [Co-op Translator](https://github.com/Azure/co-op-translator) Ã¼bersetzt. Obwohl wir auf Genauigkeit achten, kÃ¶nnen automatisierte Ãœbersetzungen Fehler oder Ungenauigkeiten enthalten. Das Originaldokument in seiner ursprÃ¼nglichen Sprache ist als maÃŸgebliche Quelle zu betrachten. FÃ¼r wichtige Informationen wird eine professionelle menschliche Ãœbersetzung empfohlen. Wir Ã¼bernehmen keine Haftung fÃ¼r MissverstÃ¤ndnisse oder Fehlinterpretationen, die aus der Verwendung dieser Ãœbersetzung entstehen.
<!-- CO-OP TRANSLATOR DISCLAIMER END -->