<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "8c30436578b1bd604c48233ecdd39701",
  "translation_date": "2025-11-12T00:04:31+00:00",
  "source_file": "Workshop/Session01-GettingStartedFoundryLocal.md",
  "language_code": "hu"
}
-->
# 1. szekci√≥: Els≈ë l√©p√©sek a Foundry Local haszn√°lat√°val

## √ñsszefoglal√≥

Tanulja meg, hogyan telep√≠tse, konfigur√°lja √©s futtassa els≈ë AI modelljeit a Microsoft Foundry Local seg√≠ts√©g√©vel. Ez a gyakorlati szekci√≥ l√©p√©sr≈ël l√©p√©sre bemutatja a helyi inferencia folyamat√°t, a telep√≠t√©st≈ël kezdve az els≈ë chat alkalmaz√°s fel√©p√≠t√©s√©ig, olyan modellek haszn√°lat√°val, mint a Phi-4, Qwen √©s DeepSeek.

## Tanul√°si c√©lok

A szekci√≥ v√©g√©re k√©pes lesz:

- **Telep√≠t√©s √©s konfigur√°ci√≥**: A Foundry Local be√°ll√≠t√°sa √©s a telep√≠t√©s ellen≈ërz√©se
- **CLI m≈±veletek elsaj√°t√≠t√°sa**: A Foundry Local CLI haszn√°lata modellek kezel√©s√©re √©s telep√≠t√©s√©re
- **Els≈ë modell futtat√°sa**: Helyi AI modell sikeres telep√≠t√©se √©s interakci√≥ja
- **Chat alkalmaz√°s k√©sz√≠t√©se**: Alapvet≈ë chat alkalmaz√°s l√©trehoz√°sa a Foundry Local Python SDK seg√≠ts√©g√©vel
- **Helyi AI meg√©rt√©se**: A helyi inferencia √©s modellkezel√©s alapjainak elsaj√°t√≠t√°sa

## El≈ëfelt√©telek

### Rendszerk√∂vetelm√©nyek

- **Windows**: Windows 11 (22H2 vagy √∫jabb) VAGY **macOS**: macOS 11+ (korl√°tozott t√°mogat√°s)
- **RAM**: Minimum 8GB, aj√°nlott 16GB+
- **T√°rhely**: Legal√°bb 10GB szabad hely a modellek sz√°m√°ra
- **Python**: Telep√≠tett 3.10 vagy √∫jabb verzi√≥
- **Adminisztr√°tori hozz√°f√©r√©s**: Telep√≠t√©shez sz√ºks√©ges jogosults√°g

### Fejleszt≈ëi k√∂rnyezet

- Visual Studio Code Python kiterjeszt√©ssel (aj√°nlott)
- Parancssori hozz√°f√©r√©s (PowerShell Windows-on, Terminal macOS-en)
- Git a repozit√≥riumok kl√≥noz√°s√°hoz (opcion√°lis)

## Workshop menete (30 perc)

### 1. l√©p√©s: Foundry Local telep√≠t√©se (5 perc)

#### Windows telep√≠t√©s

Telep√≠tse a Foundry Local-t a Windows csomagkezel≈ë seg√≠ts√©g√©vel:

```powershell
# Install via winget (recommended)
winget install Microsoft.FoundryLocal
```

Alternat√≠va: T√∂ltse le k√∂zvetlen√ºl a [Microsoft Learn](https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/install) oldalr√≥l.

#### macOS telep√≠t√©s (korl√°tozott t√°mogat√°s)

> [!NOTE] 
> A macOS t√°mogat√°s jelenleg el≈ëzetes verzi√≥ban √©rhet≈ë el. Ellen≈ërizze a hivatalos dokument√°ci√≥t a legfrissebb inform√°ci√≥k√©rt.

Ha el√©rhet≈ë, telep√≠tse a Homebrew seg√≠ts√©g√©vel:

```bash
# If Homebrew formula is available
brew update
brew install foundry-local

# Or manual download (check official docs for latest)
curl -L -o foundry-local.tar.gz "https://download.microsoft.com/foundry-local/latest/macos/foundry-local.tar.gz"
tar -xzf foundry-local.tar.gz
sudo ./install.sh
```

**Alternat√≠va macOS felhaszn√°l√≥k sz√°m√°ra:**
- Haszn√°ljon Windows 11 virtu√°lis g√©pet (Parallels/UTM) √©s k√∂vesse a Windows l√©p√©seit
- Futtassa kont√©neren kereszt√ºl, ha el√©rhet≈ë, √©s konfigur√°lja a `FOUNDRY_LOCAL_ENDPOINT`-t

### 2. l√©p√©s: Telep√≠t√©s ellen≈ërz√©se (3 perc)

A telep√≠t√©s ut√°n ind√≠tsa √∫jra a termin√°lt, √©s ellen≈ërizze, hogy a Foundry Local m≈±k√∂dik:

```powershell
# Check if Foundry Local is installed correctly
foundry --version

# View available commands
foundry --help
```

A v√°rt kimenetnek tartalmaznia kell a verzi√≥inform√°ci√≥kat √©s az el√©rhet≈ë parancsokat.

### 3. l√©p√©s: Python k√∂rnyezet be√°ll√≠t√°sa (5 perc)

Hozzon l√©tre egy dedik√°lt Python k√∂rnyezetet ehhez a workshophoz:

**Windows:**
```powershell
# Create virtual environment
py -m venv .venv

# Activate environment
.\.venv\Scripts\Activate.ps1

# Upgrade pip and install dependencies
python -m pip install --upgrade pip
pip install foundry-local-sdk openai
```

**macOS/Linux:**
```bash
# Create virtual environment
python3 -m venv .venv

# Activate environment
source .venv/bin/activate

# Upgrade pip and install dependencies
python -m pip install --upgrade pip
pip install foundry-local-sdk openai
```

### 4. l√©p√©s: Els≈ë modell futtat√°sa (7 perc)

Most futtassuk az els≈ë AI modellt helyben!

#### Kezdje a Phi-4 Mini modellel (aj√°nlott els≈ë modell)

```powershell
# Download and start phi-4-mini (lightweight, fast)
foundry model run phi-4-mini

# Test the model with a simple prompt
foundry model run phi-4-mini --prompt "Hello, introduce yourself in one sentence"
```

> [!TIP]
> Ez a parancs let√∂lti a modellt (els≈ë alkalommal) √©s automatikusan elind√≠tja a Foundry Local szolg√°ltat√°st.

#### Ellen≈ërizze, mi fut

```powershell
# List available models (shows downloaded models)
foundry model list

# Check service status
foundry service status

# See what models are cached locally
foundry cache list
```

#### Pr√≥b√°ljon ki m√°s modelleket

Miut√°n a phi-4-mini m≈±k√∂dik, k√≠s√©rletezzen m√°s modellekkel:

```powershell
# Larger model with better capabilities
foundry model run gpt-oss-20b --prompt "Explain edge AI in simple terms"

# Fast, efficient model
foundry model run qwen2.5-0.5b --prompt "What are the benefits of local AI inference?"
```

### 5. l√©p√©s: Els≈ë chat alkalmaz√°s k√©sz√≠t√©se (10 perc)

Most hozzunk l√©tre egy Python alkalmaz√°st, amely haszn√°lja az √©ppen elind√≠tott modelleket.

#### Chat script l√©trehoz√°sa

Hozzon l√©tre egy √∫j f√°jlt `my_first_chat.py` n√©ven (vagy haszn√°lja a mell√©kelt mint√°t):

```python
#!/usr/bin/env python3
"""
My First Foundry Local Chat Application
Using FoundryLocalManager for automatic service management
"""

import os
from foundry_local import FoundryLocalManager
from openai import OpenAI

def main():
    # Get model alias from environment or use default
    alias = os.getenv("FOUNDRY_LOCAL_ALIAS", "phi-4-mini")
    
    try:
        # Initialize Foundry Local Manager (auto-starts service, downloads model)
        manager = FoundryLocalManager(alias)
        
        # Create OpenAI client pointing to local endpoint
        client = OpenAI(
            base_url=manager.endpoint,
            api_key=manager.api_key or "not-needed"
        )
        
        # Get the actual model ID for this alias
        model_id = manager.get_model_info(alias).id
        
        print("ü§ñ Welcome to your first local AI chat!")
        print(f"ÔøΩ Using model: {alias} -> {model_id}")
        print(f"üåê Endpoint: {manager.endpoint}")
        print("ÔøΩüí° Type 'quit' to exit\n")
        
    except Exception as e:
        print(f"‚ùå Failed to initialize Foundry Local: {e}")
        print("üí° Make sure Foundry Local is installed: foundry --version")
        return
    
    while True:
        # Get user input
        user_message = input("You: ").strip()
        
        if user_message.lower() in ['quit', 'exit', 'bye']:
            print("üëã Goodbye!")
            break
            
        if not user_message:
            continue
            
        try:
            # Send message to local AI model
            response = client.chat.completions.create(
                model=model_id,
                messages=[
                    {"role": "system", "content": "You are a helpful AI assistant running locally."},
                    {"role": "user", "content": user_message}
                ],
                max_tokens=200,
                temperature=0.7
            )
            
            # Display the response
            ai_response = response.choices[0].message.content
            print(f"ü§ñ AI: {ai_response}\n")
            
        except Exception as e:
            print(f"‚ùå Error: {e}")
            print("üí° Check service status: foundry service status\n")

if __name__ == "__main__":
    main()
```

> [!TIP]
> **Kapcsol√≥d√≥ p√©ld√°k**: Tov√°bbi fejlett haszn√°lathoz l√°sd:
>
> - **Python p√©lda**: `Workshop/samples/session01/chat_bootstrap.py` - Streaming v√°laszokkal √©s hibakezel√©ssel
> - **Jupyter Notebook**: `Workshop/notebooks/session01_chat_bootstrap.ipynb` - Interakt√≠v verzi√≥ r√©szletes magyar√°zatokkal

#### Chat alkalmaz√°s tesztel√©se

```powershell
# No need to manually start models - FoundryLocalManager handles this!
# Just run your chat application
python my_first_chat.py
```

Alternat√≠va: Haszn√°lja k√∂zvetlen√ºl a mell√©kelt mint√°kat

```powershell
# Try the complete sample with streaming support
cd Workshop/samples
python -m session01.chat_bootstrap "Your question here"
```

Vagy fedezze fel az interakt√≠v notebookot
Nyissa meg a Workshop/notebooks/session01_chat_bootstrap.ipynb f√°jlt a VS Code-ban

Pr√≥b√°lja ki ezeket a p√©ldabesz√©lget√©seket:

- "Mi az a Microsoft Foundry Local?"
- "Sorolj fel 3 el≈ënyt a helyi AI modellek futtat√°s√°val kapcsolatban"
- "Seg√≠ts meg√©rteni az edge AI-t"

## Amit el√©rt

Gratul√°lunk! Sikeresen:

1. ‚úÖ **Telep√≠tette a Foundry Local-t** √©s ellen≈ërizte a m≈±k√∂d√©s√©t
2. ‚úÖ **Elind√≠totta az els≈ë AI modellt** (phi-4-mini) helyben
3. ‚úÖ **Tesztelte k√ºl√∂nb√∂z≈ë modelleket** parancssoron kereszt√ºl
4. ‚úÖ **K√©sz√≠tett egy chat alkalmaz√°st**, amely csatlakozik a helyi AI-hoz
5. ‚úÖ **Tapasztalatot szerzett a helyi AI inferenci√°ban** felh≈ëf√ºgg≈ës√©g n√©lk√ºl

## Mi t√∂rt√©nt?

### Helyi AI inferencia

- Az AI modellek teljes m√©rt√©kben az √ñn sz√°m√≠t√≥g√©p√©n futnak
- Nem ker√ºl adat a felh≈ëbe
- A v√°laszok helyben, a CPU/GPU seg√≠ts√©g√©vel gener√°l√≥dnak
- A mag√°n√©let √©s a biztons√°g meg≈ërz√©se biztos√≠tott

### Modellkezel√©s

- A `foundry model run` let√∂lti √©s elind√≠tja a modelleket
- A **FoundryLocalManager SDK** automatikusan kezeli a szolg√°ltat√°s ind√≠t√°s√°t √©s a modellek bet√∂lt√©s√©t
- A modellek helyben t√°rol√≥dnak a k√©s≈ëbbi haszn√°latra
- T√∂bb modell is let√∂lthet≈ë, de √°ltal√°ban egyszerre csak egy fut
- A szolg√°ltat√°s automatikusan kezeli a modellek √©letciklus√°t

### SDK vs CLI megk√∂zel√≠t√©sek

- **CLI megk√∂zel√≠t√©s**: Manu√°lis modellkezel√©s a `foundry model run <model>` parancs seg√≠ts√©g√©vel
- **SDK megk√∂zel√≠t√©s**: Automatikus szolg√°ltat√°s- √©s modellkezel√©s a `FoundryLocalManager(alias)` haszn√°lat√°val
- **Aj√°nl√°s**: Haszn√°lja az SDK-t alkalmaz√°sokhoz, a CLI-t tesztel√©shez √©s felfedez√©shez

## Gyakori parancsok referenci√°ja

### Alapvet≈ë CLI parancsok

```powershell
# Installation & Setup
foundry --version              # Check installation
foundry --help                 # View all commands

# Model Management
foundry model list             # List available models
foundry model run <model>      # Download and start a model
foundry model run <model> --prompt "text"  # One-shot prompt
foundry cache list             # Show downloaded models

# Service Management
foundry service status         # Check if service is running
foundry service start          # Start the service manually
foundry service stop           # Stop the service
```

### Modellaj√°nl√°sok

- **phi-4-mini**: Legjobb kezd≈ë modell - gyors, k√∂nny≈±, j√≥ min≈ës√©g≈±
- **qwen2.5-0.5b**: Leggyorsabb inferencia, minim√°lis mem√≥riahaszn√°lat
- **gpt-oss-20b**: Magasabb min≈ës√©g≈± v√°laszok, t√∂bb er≈ëforr√°st ig√©nyel
- **deepseek-coder-1.3b**: Programoz√°sra √©s k√≥dol√°si feladatokra optimaliz√°lt

## Hibakeres√©s

### "Foundry parancs nem tal√°lhat√≥"

**Megold√°s:**

```powershell
# Restart your terminal after installation
# Or manually add to PATH (Windows)
$env:PATH += ";C:\Program Files\Microsoft\FoundryLocal"
```

### "A modell bet√∂lt√©se sikertelen"

**Megold√°s:**

```powershell
# Check available system memory
foundry service status

# Try a smaller model first
foundry model run phi-4-mini

# Check disk space for model downloads
# Models are stored in: %USERPROFILE%\.foundry\models (Windows)
```

### "Kapcsolat megtagadva a localhoston"

**Megold√°s:**

```powershell
# Check if service is running
foundry service status

# Start service if needed
foundry service start

# Verify the port (default is 5273)
# Check for port conflicts with: netstat -an | findstr 5273
```

## K√∂vetkez≈ë l√©p√©sek

### Azonnali teend≈ëk

1. **K√≠s√©rletezzen** k√ºl√∂nb√∂z≈ë modellekkel √©s k√©rd√©sekkel
2. **M√≥dos√≠tsa** a chat alkalmaz√°s√°t, hogy k√ºl√∂nb√∂z≈ë modelleket pr√≥b√°ljon ki
3. **Hozzon l√©tre** saj√°t k√©rd√©seket √©s tesztelje a v√°laszokat
4. **Fedezze fel** a 2. szekci√≥t: RAG alkalmaz√°sok √©p√≠t√©se

### Halad√≥ tanul√°si √∫tvonal

1. **2. szekci√≥**: AI megold√°sok √©p√≠t√©se RAG (Retrieval-Augmented Generation) seg√≠ts√©g√©vel
2. **3. szekci√≥**: K√ºl√∂nb√∂z≈ë ny√≠lt forr√°sk√≥d√∫ modellek √∂sszehasonl√≠t√°sa
3. **4. szekci√≥**: Legmodernebb modellek haszn√°lata
4. **5. szekci√≥**: T√∂bb√ºgyn√∂k√∂s AI rendszerek √©p√≠t√©se

## K√∂rnyezeti v√°ltoz√≥k (opcion√°lis)

Halad√≥ haszn√°lathoz be√°ll√≠thatja ezeket a k√∂rnyezeti v√°ltoz√≥kat:

| V√°ltoz√≥ | C√©l | P√©lda |
|----------|---------|---------|
| `FOUNDRY_LOCAL_ALIAS` | Alap√©rtelmezett modell haszn√°lata | `phi-4-mini` |
| `FOUNDRY_LOCAL_ENDPOINT` | V√©gpont URL fel√ºl√≠r√°sa | `http://localhost:5273/v1` |

Hozzon l√©tre egy `.env` f√°jlt a projekt k√∂nyvt√°r√°ban:
```
FOUNDRY_LOCAL_ALIAS=phi-4-mini
FOUNDRY_LOCAL_ENDPOINT=auto
```

## Tov√°bbi forr√°sok

### Dokument√°ci√≥

- [Foundry Local Python SDK Referencia](https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/reference/reference-sdk?pivots=programming-language-python)
- [Foundry Local Telep√≠t√©si √ötmutat√≥](https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/install)
- [Modellkatal√≥gus](https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/models)

### P√©ldak√≥dok

- **Session01 Python Minta**: `Workshop/samples/session01/chat_bootstrap.py` - Teljes chat alkalmaz√°s streaminggel
- **Session01 Notebook**: `Workshop/notebooks/session01_chat_bootstrap.ipynb` - Interakt√≠v oktat√≥anyag  
- [Module08 Sample 01](../Module08/samples/01/README.md) - REST Chat Gyorsind√≠t√≥
- [Module08 Sample 02](../Module08/samples/02/README.md) - OpenAI SDK Integr√°ci√≥
- [Module08 Sample 03](../Module08/samples/03/README.md) - Modell felfedez√©s √©s teljes√≠tm√©nytesztel√©s

### K√∂z√∂ss√©g

- [Foundry Local GitHub Discussions](https://github.com/microsoft/Foundry-Local/discussions)
- [Azure AI K√∂z√∂ss√©g](https://techcommunity.microsoft.com/category/artificialintelligence)

---

**Szekci√≥ id≈ëtartama**: 30 perc gyakorlati r√©sz + 15 perc k√©rd√©sek √©s v√°laszok  
**Neh√©zs√©gi szint**: Kezd≈ë  
**El≈ëfelt√©telek**: Windows 11/macOS 11+, Python 3.10+, Adminisztr√°tori hozz√°f√©r√©s

## Workshop p√©lda szcen√°ri√≥

### Val√≥s √©letbeli kontextus

**Szcen√°ri√≥**: Egy v√°llalati IT csapatnak √©rt√©kelnie kell az eszk√∂z√∂n fut√≥ AI inferenci√°t, hogy √©rz√©keny munkav√°llal√≥i visszajelz√©seket dolgozzon fel an√©lk√ºl, hogy adatokat k√ºldene k√ºls≈ë szolg√°ltat√°soknak.

**C√©lja**: Bizony√≠tsa be, hogy a helyi AI modellek min≈ës√©gi v√°laszokat tudnak ny√∫jtani m√°sodpercek alatti k√©sleltet√©ssel, mik√∂zben teljes adatv√©delmet biztos√≠tanak.

### Tesztk√©rd√©sek

Haszn√°lja ezeket a k√©rd√©seket a be√°ll√≠t√°s ellen≈ërz√©s√©hez:

```json
[
    "List two benefits of local inference.",
    "Summarize why keeping data on device improves privacy.",
    "Give one trade-off when choosing a small model over a large model."
]
```

### Sikeress√©gi krit√©riumok

- ‚úÖ Minden k√©rd√©sre 2 m√°sodpercen bel√ºl √©rkezik v√°lasz
- ‚úÖ Nem ker√ºl adat ki a helyi g√©pr≈ël
- ‚úÖ A v√°laszok relev√°nsak √©s hasznosak
- ‚úÖ A chat alkalmaz√°s z√∂kken≈ëmentesen m≈±k√∂dik

Ez az ellen≈ërz√©s biztos√≠tja, hogy a Foundry Local be√°ll√≠t√°sa k√©szen √°ll a 2-6. szekci√≥k halad√≥ workshopjaira.

---

<!-- CO-OP TRANSLATOR DISCLAIMER START -->
**Felel≈ëss√©g kiz√°r√°sa**:  
Ez a dokumentum az [Co-op Translator](https://github.com/Azure/co-op-translator) AI ford√≠t√°si szolg√°ltat√°s seg√≠ts√©g√©vel lett leford√≠tva. B√°r t√∂reksz√ºnk a pontoss√°gra, k√©rj√ºk, vegye figyelembe, hogy az automatikus ford√≠t√°sok hib√°kat vagy pontatlans√°gokat tartalmazhatnak. Az eredeti dokumentum az eredeti nyelv√©n tekintend≈ë hiteles forr√°snak. Kritikus inform√°ci√≥k eset√©n javasolt professzion√°lis emberi ford√≠t√°st ig√©nybe venni. Nem v√°llalunk felel≈ëss√©get semmilyen f√©lre√©rt√©s√©rt vagy t√©ves √©rtelmez√©s√©rt, amely a ford√≠t√°s haszn√°lat√°b√≥l eredhet.
<!-- CO-OP TRANSLATOR DISCLAIMER END -->