# 03. szakasz - Model Context Protocol (MCP) integráció

## Bevezetés az MCP-be (Model Context Protocol)

A Model Context Protocol (MCP) egy nyílt forráskódú szabvány, amely lehetővé teszi az AI alkalmazások számára, hogy külső rendszerekhez csatlakozzanak. Az MCP segítségével az olyan AI alkalmazások, mint Claude vagy ChatGPT, hozzáférhetnek adatforrásokhoz (pl. helyi fájlok, adatbázisok), eszközökhöz (pl. keresőmotorok, számológépek) és munkafolyamatokhoz (pl. speciális promptok), így kulcsfontosságú információkhoz juthatnak és feladatokat végezhetnek el.

Gondolj az MCP-re úgy, mint egy **USB-C port az AI alkalmazások számára**. Ahogy az USB-C szabványos módot biztosít az elektronikai eszközök csatlakoztatására, az MCP szabványos módot kínál az AI alkalmazások külső rendszerekhez való csatlakoztatására.

### Mit tesz lehetővé az MCP?

Az MCP erőteljes képességeket nyit meg az AI alkalmazások számára:

- **Személyre szabott AI asszisztensek**: Az ügynökök hozzáférhetnek a Google Naptáradhoz és a Notionhoz, így személyre szabottabb AI asszisztensként működhetnek
- **Fejlett kódgenerálás**: A Claude Code képes egy teljes webalkalmazást létrehozni egy Figma terv alapján
- **Vállalati adatintegráció**: A vállalati chatbotok több adatbázishoz csatlakozhatnak egy szervezeten belül, lehetővé téve a felhasználók számára, hogy csevegésen keresztül elemezzék az adatokat
- **Kreatív munkafolyamatok**: Az AI modellek 3D terveket hozhatnak létre Blenderben, majd kinyomtathatják azokat egy 3D nyomtatóval
- **Valós idejű információhozzáférés**: Külső adatforrásokhoz való csatlakozás az aktuális információkért
- **Komplex, több lépésből álló műveletek**: Összetett munkafolyamatok végrehajtása, amelyek több eszközt és rendszert kombinálnak

### Miért fontos az MCP?

Az MCP előnyöket kínál az egész ökoszisztéma számára:

**Fejlesztők számára**: Az MCP csökkenti a fejlesztési időt és komplexitást az AI alkalmazások vagy ügynökök építése és integrálása során.

**AI alkalmazások számára**: Az MCP hozzáférést biztosít egy adatforrásokból, eszközökből és alkalmazásokból álló ökoszisztémához, amely növeli a képességeket és javítja a végfelhasználói élményt.

**Végfelhasználók számára**: Az MCP eredményeként az AI alkalmazások vagy ügynökök képesebbek lesznek hozzáférni az adataidhoz és szükség esetén cselekedni helyetted.

## Kis nyelvi modellek (SLM-ek) az MCP-ben

A kis nyelvi modellek hatékony megközelítést képviselnek az AI telepítésében, számos előnnyel:

### Az SLM-ek előnyei
- **Erőforrás-hatékonyság**: Alacsonyabb számítási igények
- **Gyorsabb válaszidők**: Csökkentett késleltetés valós idejű alkalmazásokhoz  
- **Költséghatékonyság**: Minimális infrastruktúraigény
- **Adatvédelem**: Helyben futtatható adatátvitel nélkül
- **Testreszabhatóság**: Könnyebben finomhangolható specifikus területekre

### Miért működnek jól az SLM-ek az MCP-vel?

Az SLM-ek és az MCP kombinációja erőteljes megoldást kínál, ahol a modell érvelési képességeit külső eszközök egészítik ki, ellensúlyozva a kisebb paraméterszámot a kibővített funkcionalitás révén.

## Python MCP SDK áttekintés

A Python MCP SDK alapot biztosít az MCP-kompatibilis alkalmazások építéséhez. Az SDK tartalmazza:

- **Klienskönyvtárak**: MCP szerverekhez való csatlakozáshoz
- **Szerverkeretrendszer**: Egyedi MCP szerverek létrehozásához
- **Protokollkezelők**: A kommunikáció kezeléséhez
- **Eszközintegráció**: Külső funkciók végrehajtásához

## Gyakorlati megvalósítás: Phi-4 MCP kliens

Nézzünk meg egy valós példát a Microsoft Phi-4 mini modelljének MCP képességekkel való integrációjára.

### MCP architektúra áttekintés

Az MCP **kliens-szerver architektúrát** követ, ahol egy MCP gazda (egy AI alkalmazás, mint például Claude Code vagy Claude Desktop) kapcsolatokat hoz létre egy vagy több MCP szerverrel. Az MCP gazda ezt úgy valósítja meg, hogy minden MCP szerverhez létrehoz egy MCP klienst.

#### Fő résztvevők

- **MCP gazda**: Az AI alkalmazás, amely koordinálja és kezeli az MCP klienseket
- **MCP kliens**: Egy komponens, amely fenntartja a kapcsolatot egy MCP szerverrel, és kontextust szerez az MCP gazda számára
- **MCP szerver**: Egy program, amely kontextust biztosít az MCP kliensek számára

#### Két rétegű architektúra

Az MCP két különálló rétegből áll:

**Adatréteg**: Meghatározza a JSON-RPC alapú protokollt a kliens-szerver kommunikációhoz, beleértve:
- Életciklus-kezelés (kapcsolat inicializálása, képességek egyeztetése)
- Alapvető elemek (eszközök, erőforrások, promptok)
- Kliens funkciók (mintavétel, információgyűjtés, naplózás)
- Segédfunkciók (értesítések, előrehaladás követése)

**Átvitel réteg**: Meghatározza a kommunikációs mechanizmusokat és csatornákat:
- **STDIO átvitel**: Helyi folyamatok standard bemeneti/kimeneti adatfolyamait használja (optimális teljesítmény, nincs hálózati terhelés)
- **Streamelhető HTTP átvitel**: HTTP POST-ot használ opcionális szerver által küldött eseményekkel távoli szerverekhez (támogatja a szabványos HTTP hitelesítést)

```
┌─────────────────────────────────────┐
│           MCP Host                  │
│     (AI Application)                │
└─────────────────┬───────────────────┘
                  │
┌─────────────────┴───────────────────┐
│         MCP Client 1                │
│  ┌─────────────────────────────────┐ │
│  │        Data Layer               │ │
│  │  ├── Lifecycle Management       │ │
│  │  ├── Primitives (Tools/Resources)│ │
│  │  └── Notifications              │ │
│  └─────────────────────────────────┘ │
│  ┌─────────────────────────────────┐ │
│  │      Transport Layer           │ │
│  │  ├── STDIO Transport           │ │
│  │  └── HTTP Transport            │ │
│  └─────────────────────────────────┘ │
└─────────────────┬───────────────────┘
                  │
┌─────────────────┴───────────────────┐
│         MCP Server 1                │
│    (Local/Remote Context Provider)  │
└─────────────────────────────────────┘
```

### MCP alapvető elemek

Az MCP meghatározza azokat az elemeket, amelyek specifikálják a megosztható kontextuális információk típusait az AI alkalmazásokkal, valamint az elvégezhető műveletek körét.

#### Szerverelemek

Az MCP három alapvető elemet határoz meg, amelyeket a szerverek elérhetővé tehetnek:

**Eszközök**: Végrehajtható funkciók, amelyeket az AI alkalmazások hívhatnak meg műveletek végrehajtására
- Példák: fájlműveletek, API hívások, adatbázis-lekérdezések
- Módszerek: `tools/list`, `tools/call`
- Támogatja a dinamikus felfedezést és végrehajtást

**Erőforrások**: Adatforrások, amelyek kontextuális információt nyújtanak az AI alkalmazásoknak
- Példák: fájltartalom, adatbázis-rekordok, API válaszok
- Módszerek: `resources/list`, `resources/read`
- Strukturált adatokhoz való hozzáférést tesz lehetővé

**Promptok**: Újrahasználható sablonok, amelyek segítenek az interakciók strukturálásában a nyelvi modellekkel
- Példák: rendszerpromptok, néhány példás promptok
- Módszerek: `prompts/list`, `prompts/get`
- Standardizálja az AI interakciós mintákat

#### Klienselemek

Az MCP olyan elemeket is meghatároz, amelyeket a kliensek elérhetővé tehetnek a gazdagabb interakciók érdekében:

**Mintavétel**: Lehetővé teszi a szerverek számára, hogy nyelvi modell kimeneteket kérjenek a kliens AI alkalmazásától
- Módszer: `sampling/complete`
- Modellfüggetlen szerverfejlesztést tesz lehetővé
- Hozzáférést biztosít a gazda nyelvi modelljéhez

**Információgyűjtés**: Lehetővé teszi a szerverek számára, hogy további információkat kérjenek a felhasználóktól
- Módszer: `elicitation/request`
- Felhasználói interakciót és megerősítést tesz lehetővé
- Támogatja a dinamikus információgyűjtést

**Naplózás**: Lehetővé teszi a szerverek számára, hogy naplóüzeneteket küldjenek a klienseknek
- Hibakeresési és monitorozási célokra használható
- Láthatóságot biztosít a szerver műveleteiben

### MCP protokoll életciklusa

#### Inicializálás és képességek egyeztetése

Az MCP egy állapotfüggő protokoll, amely életciklus-kezelést igényel. Az inicializálási folyamat több kritikus célt szolgál:

1. **Protokoll verzió egyeztetése**: Biztosítja, hogy a kliens és a szerver kompatibilis protokoll verziókat használjon (pl. "2025-06-18")
2. **Képességek felfedezése**: Mindkét fél deklarálja a támogatott funkciókat és elemeket
3. **Azonosítási információcsere**: Azonosítási és verzióinformációkat biztosít

```python
# Example initialization request
{
  "jsonrpc": "2.0",
  "id": 1,
  "method": "initialize",
  "params": {
    "protocolVersion": "2025-06-18",
    "capabilities": {
      "elicitation": {},  # Client supports user interaction
      "sampling": {}      # Client can provide LLM completions
    },
    "clientInfo": {
      "name": "edge-ai-client",
      "version": "1.0.0"
    }
  }
}
```

#### Eszközök felfedezése és végrehajtása

Az inicializálás után a kliensek felfedezhetik és végrehajthatják az eszközöket:

```python
# Discover available tools
tools_response = await session.list_tools()

# Execute a tool
result = await session.call_tool(
    "weather_current",
    {
        "location": "San Francisco",
        "units": "imperial"
    }
)
```

#### Valós idejű értesítések

Az MCP támogatja a valós idejű értesítéseket a dinamikus frissítésekhez:

```python
# Server sends notification when tools change
{
  "jsonrpc": "2.0",
  "method": "notifications/tools/list_changed"
}

# Client responds by refreshing tool list
await session.list_tools()  # Get updated tools
```

## Első lépések: Lépésről lépésre útmutató

### 1. lépés: Környezet beállítása

Telepítsd a szükséges függőségeket:
```bash
pip install fastmcp mcp-python-client openai requests pyautogui Pillow
```

### 2. lépés: Alapkonfiguráció

Állítsd be a környezeti változókat:
```python
# System Configuration
SYSTEM_PROMPT = "You are an AI assistant with some tools."

# Ollama Configuration (Local)
OLLAMA_URL = "http://localhost:11434/api/chat"
OLLAMA_MODEL_ID = "phi4-mini:3.8b-fp16"

# vLLM Configuration (Server)
VLLM_URL = "http://localhost:8000/v1"
VLLM_MODEL_ID = "microsoft/Phi-4-mini-instruct"
```

### 3. lépés: Az első MCP kliens futtatása

**Alap Ollama beállítás:**
```bash
python ghmodel_mcp_demo.py
```

**vLLM háttér használata:**
```bash
python ghmodel_mcp_demo.py --env vllm
```

**Szerver által küldött események kapcsolata:**
```bash
python ghmodel_mcp_demo.py --run sse
```

**Egyedi MCP szerver:**
```bash
python ghmodel_mcp_demo.py --server /path/to/server.py
```

### 4. lépés: Programozott használat

```python
import asyncio
from ghmodel_mcp_demo import OllamaClient, Phi4MiniMCPClient

async def automated_interaction():
    # Configure MCP server parameters
    server_params = StdioServerParameters(
        command="npx",
        args=["@playwright/mcp@latest"],
        env=None,
    )
    
    # Create MCP client and process tools
    async with Phi4MiniMCPClient(server_params) as mcp_client:
        tools = await process_mcp_tools(mcp_client)
        llm_client = OllamaClient()
        
        # Generate response with tool capabilities
        response, messages = await llm_client.generate_response(
            "Help me automate a web task",
            tools
        )
        return response

# Execute the automation
result = asyncio.run(automated_interaction())
print(result)
```

## Fejlett funkciók

### Több háttér támogatása

A megvalósítás támogatja az Ollama és vLLM háttereket, lehetővé téve, hogy az igényeid alapján válassz:

- **Ollama**: Jobb helyi fejlesztéshez és teszteléshez
- **vLLM**: Optimalizált produkciós és nagy áteresztőképességű forgatókönyvekhez

### Rugalmas kapcsolódási protokollok

Két kapcsolódási mód támogatott:

**STDIO mód**: Közvetlen folyamatkommunikáció
- Alacsonyabb késleltetés
- Helyi eszközökhöz alkalmas
- Egyszerű beállítás

**SSE mód**: HTTP-alapú adatfolyam
- Hálózatképes
- Jobb elosztott rendszerekhez
- Valós idejű frissítések

### Eszközintegrációs képességek

A rendszer különféle eszközökkel integrálható:
- Webautomatizálás (Playwright)
- Fájlműveletek
- API interakciók
- Rendszerparancsok
- Egyedi funkciók

## Hibakezelés és legjobb gyakorlatok

### Átfogó hibakezelés

A megvalósítás robusztus hibakezelést tartalmaz:

**Kapcsolódási hibák:**
- MCP szerver meghibásodások
- Hálózati időtúllépések
- Kapcsolódási problémák

**Eszközvégrehajtási hibák:**
- Hiányzó eszközök
- Paraméterellenőrzés
- Végrehajtási hibák

**Válaszfeldolgozási hibák:**
- JSON elemzési problémák
- Formátumeltérések
- LLM válasz anomáliák

### Legjobb gyakorlatok

1. **Erőforrás-kezelés**: Használj aszinkron kontextuskezelőket
2. **Hibakezelés**: Valósíts meg átfogó try-catch blokkokat
3. **Naplózás**: Állítsd be a megfelelő naplózási szinteket
4. **Biztonság**: Ellenőrizd a bemeneteket és tisztítsd meg a kimeneteket
5. **Teljesítmény**: Használj kapcsolatpoolingot és gyorsítótárazást

## Valós alkalmazások

### Webautomatizálás
```python
# Example: Automated web testing
async def web_automation_example():
    tools = await setup_playwright_tools()
    response = await llm_client.generate_response(
        "Navigate to example.com and take a screenshot",
        tools
    )
```

### Adatfeldolgozás
```python
# Example: File analysis
async def data_processing_example():
    tools = await setup_file_tools()
    response = await llm_client.generate_response(
        "Analyze the CSV file and generate a summary report",
        tools
    )
```

### API integráció
```python
# Example: API interactions
async def api_integration_example():
    tools = await setup_api_tools()
    response = await llm_client.generate_response(
        "Fetch weather data and create a forecast summary",
        tools
    )
```

## Teljesítményoptimalizálás

### Memóriakezelés
- Hatékony üzenetelőzmény-kezelés
- Megfelelő erőforrás-tisztítás
- Kapcsolatpooling

### Hálózati optimalizálás
- Aszinkron HTTP műveletek
- Konfigurálható időtúllépések
- Kegyelmes hibajavítás

### Egyidejű feldolgozás
- Nem blokkoló I/O
- Párhuzamos eszközvégrehajtás
- Hatékony aszinkron minták

## Biztonsági megfontolások

### Adatvédelem
- API kulcsok biztonságos kezelése
- Bemenetellenőrzés
- Kimenettisztítás

### Hálózati biztonság
- HTTPS támogatás
- Helyi végpont alapértelmezések
- Biztonságos tokenkezelés

### Végrehajtási biztonság
- Eszközszűrés
- Homokozott környezetek
- Auditnaplózás

## MCP ökoszisztéma és fejlesztés

### MCP projekt hatóköre

A Model Context Protocol ökoszisztéma több kulcsfontosságú komponenst tartalmaz:

- **[MCP Specifikáció](https://modelcontextprotocol.io/specification/latest)**: Hivatalos specifikáció, amely meghatározza a kliens és szerver implementációs követelményeket
- **[MCP SDK-k](https://modelcontextprotocol.io/docs/sdk)**: Különböző programozási nyelvekhez készült SDK-k, amelyek megvalósítják az MCP-t
- **MCP fejlesztői eszközök**: Eszközök MCP szerverek és kliensek fejlesztéséhez, beleértve az [MCP Inspector](https://github.com/modelcontextprotocol/inspector)-t
- **[MCP Referencia Szerver Implementációk](https://github.com/modelcontextprotocol/servers)**: MCP szerverek referencia implementációi

### MCP fejlesztés kezdése

Az MCP-vel való építés megkezdéséhez:

**Szerverek építése**: [Hozz létre MCP szervereket](https://modelcontextprotocol.io/docs/develop/build-server), hogy elérhetővé tedd az adataidat és eszközeidet

**Kliensek építése**: [Fejlessz alkalmazásokat](https://modelcontextprotocol.io/docs/develop/build-client), amelyek csatlakoznak MCP szerverekhez

**Fogalmak megértése**: [Ismerd meg az alapfogalmakat](https://modelcontextprotocol.io/docs/learn/architecture) és az MCP architektúráját

## Összegzés

Az MCP-vel integrált SLM-ek paradigmaváltást jelentenek az AI alkalmazások fejlesztésében. A kis modellek hatékonyságát külső eszközök erejével kombinálva a fejlesztők olyan intelligens rendszereket hozhat
- **[Ollama Dokumentáció](https://ollama.ai/docs)** - Helyi LLM telepítési platform
- **[vLLM Dokumentáció](https://docs.vllm.ai/)** - Nagy teljesítményű LLM kiszolgálás

### Technikai szabványok és protokollok

- **[JSON-RPC 2.0 Specifikáció](https://www.jsonrpc.org/)** - Az MCP által használt alapvető RPC protokoll
- **[JSON Schema](https://json-schema.org/)** - MCP eszközök séma meghatározási szabványa
- **[OpenAPI Specifikáció](https://swagger.io/specification/)** - API dokumentációs szabvány
- **[Server-Sent Events (SSE)](https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events)** - Valós idejű frissítések webes szabványa

### AI ügynök fejlesztés

- **[Microsoft Agent Framework](https://github.com/microsoft/agent-framework)** - Gyártásra kész ügynökfejlesztés
- **[LangChain Dokumentáció](https://docs.langchain.com/)** - Ügynök és eszköz integrációs keretrendszer
- **[Semantic Kernel](https://learn.microsoft.com/en-us/semantic-kernel/)** - A Microsoft AI orchestration SDK-ja

### Iparági jelentések és kutatások

- **[Anthropic Model Context Protocol Bejelentés](https://www.anthropic.com/news/model-context-protocol)** - Az MCP eredeti bemutatása
- **[Kis Nyelvi Modellek Felmérése](https://arxiv.org/abs/2410.20011)** - Tudományos felmérés az SLM kutatásról
- **[Edge AI Piacelemzés](https://www.marketsandmarkets.com/Market-Reports/edge-ai-software-market-74385617.html)** - Iparági trendek és előrejelzések
- **[AI Ügynök Fejlesztési Legjobb Gyakorlatok](https://arxiv.org/abs/2309.02427)** - Kutatás az ügynök architektúrákról

Ez a szekció alapot nyújt saját SLM-alapú MCP alkalmazások fejlesztéséhez, megnyitva az automatizálás, adatfeldolgozás és intelligens rendszerintegráció lehetőségeit.

## ➡️ Mi következik

- [7. modul. Edge AI minták](../Module07/README.md)

---

**Felelősség kizárása**:  
Ez a dokumentum az [Co-op Translator](https://github.com/Azure/co-op-translator) AI fordítási szolgáltatás segítségével lett lefordítva. Bár törekszünk a pontosságra, kérjük, vegye figyelembe, hogy az automatikus fordítások hibákat vagy pontatlanságokat tartalmazhatnak. Az eredeti dokumentum az eredeti nyelvén tekintendő hiteles forrásnak. Fontos információk esetén javasolt professzionális emberi fordítást igénybe venni. Nem vállalunk felelősséget semmilyen félreértésért vagy téves értelmezésért, amely a fordítás használatából eredhet.