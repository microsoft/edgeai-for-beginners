<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "f94e745264597bc5d8df967ead2eff97",
  "translation_date": "2026-01-05T10:41:35+00:00",
  "source_file": "WorkshopForAgentic/README.md",
  "language_code": "no"
}
-->
# ğŸ™ï¸ The AI Podcast Studio Workshop

> ğŸŒ [ä¸­æ–‡ç‰ˆ (Chinese Version)](translation/zh-cn/README.md)

![logo](../../../translated_images/no/logo.8711e39dc8257d7b.png)

## Din oppgave

Velkommen til **The AI Podcast Studio**! Du skal lansere din egen teknologipodcast kalt "Future Bytes" â€” men her er vri: du skal bygge et produksjonsteam drevet av AI som hjelper deg Ã¥ lage den. Ikke mer uendelige timer med research, manusarbeid og lydredigering. I stedet skal du kode deg frem til Ã¥ bli en podkast-produsent med AI-krefter.

## Historien

Tenk deg dette: Du og vennene dine vil starte en podcast om de kuleste teknologitrendene, men alle er opptatt med skole, jobb eller bare livet. Hva om du kunne bygge et team av AI-agenter som gjorde det tunge lÃ¸ftet? En agent forsker pÃ¥ emner, en annen skriver engasjerende manus, og en tredje gjÃ¸r tekst om til naturlige samtaler. HÃ¸res ut som sci-fi? La oss gjÃ¸re det til virkelighet.

## Hva du vil lÃ¦re

Ved slutten av denne workshopen vil du kunne:
- ğŸ¤– DeplÃ¸yere din egen lokale AI-modell (ingen API-kostnader, ingen skyavhengighet!)
- ğŸ”§ Bygge spesialiserte AI-agenter som faktisk samarbeider
- ğŸ¬ Lage en komplett podkastproduksjonslinje fra idÃ© til lyd

## Din reise: Tre akter

![arch](../../../translated_images/no/arch.5965fe504e4a3a93.png)

Som i enhver god historie har vi tre akter. Hver bygger AI-podcaststudioet ditt bit for bit:

| Episode | Din oppgave | Hva skjer | Ferdigheter lÃ¥st opp |
|---------|-------------|-----------|---------------------|
| **Akt 1** | [MÃ¸t dine AI-assistenter](md/01.BuildAIAgentWithSLM.md) | Du oppdager hvordan du lager AI-agenter som kan chatte, sÃ¸ke pÃ¥ nettet og til og med lÃ¸se problemer. Tenk pÃ¥ dem som forskningspraktikanter som aldri sover. | ğŸ¯ Bygg din fÃ¸rste agent<br>ğŸ› ï¸ Gi den superkrefter (verktÃ¸y!)<br>ğŸ§  LÃ¦r den Ã¥ tenke<br>ğŸŒ Kople den til internett |
| **Akt 2** | [Sett sammen ditt produksjonsteam](md/02.AIAgentOrchestrationAndWorkflows.md) | NÃ¥ blir det spennende! Du skal orkestrere flere AI-agenter til Ã¥ jobbe sammen som et ekte podkastteam. En forsker, en skriver, du godkjenner â€” lagarbeid fÃ¥r drÃ¸mmen til Ã¥ fungere. | ğŸ­ Koordinere flere agenter<br>ğŸ”„ Bygge godkjenningsflyter<br>ğŸ–¥ï¸ Teste med DevUI-grensesnitt<br>âœ‹ Hold menneskene i kontroll |
| **Akt 3** | [Gi liv til din podcast](md/03.Multi-SpeakerPodcastGenerationWithVibeVoice.md) | Finale! Forvandle dine tekstmanus til ekte podkastlyd med realistiske stemmer og naturlige samtaler. Din "Future Bytes"-podcast er klar for lansering! | ğŸ¤ Tekst-til-tale-magien<br>ğŸ‘¥ Flere hÃ¸yttalerstemmer<br>â±ï¸ Langformet lyd<br>ğŸš€ Full automatisering |

Hver akt lÃ¥ser opp nye evner. Hopp fremover hvis du er modig, men vi anbefaler Ã¥ fÃ¸lge historien!

## MiljÃ¸krav

Denne workshopen stÃ¸tter forskjellige maskinvarermiljÃ¸er:
- **CPU**: Egnet for testing og liten skala bruk
- **GPU**: Anbefalt for produksjonsmiljÃ¸er, forbedrer betydelig inferenshastighet
- **NPU**: StÃ¸tter neste generasjons akselerasjon med nevrale prosesseringsenheter

## Hva du trenger

### Programvare-sjekkliste âœ…
- **Python 3.10+** (Ditt programmeringssprÃ¥k)
- **Ollama** (KjÃ¸rer AI-modeller pÃ¥ maskinen din)
- **VS Code** (Din kodeeditor)
- **Python-utvidelse** (GjÃ¸r VS Code smartere)
- **Git** (For Ã¥ hente kode)

### Maskinvare-sjekk ğŸ’»
- **Kan jeg kjÃ¸re dette?**: 8GB RAM, 10GB ledig plass (fungerer, men kan vÃ¦re tregt)
- **Ideelt oppsett**: 16GB+ RAM, et anstendig GPU (problemfri kjÃ¸ring!)
- **Har du NPU?**: Enda bedre! Neste generasjons ytelse lÃ¥st opp ğŸš€

## Sett opp studioet ditt ğŸ¬

### Steg 1: Python Power-Up

SÃ¸rg for at du har Python 3.10 eller nyere:

```bash
python --version
# Skal vise Python 3.10.x eller hÃ¸yere
```

Ingen Python? Last det ned fra [python.org](https://python.org) â€” det er gratis!

### Steg 2: Skaff Ollama (Din AI-modell-kjÃ¸rer)

GÃ¥ til [ollama.ai](https://ollama.ai) og last ned Ollama for ditt operativsystem. Tenk pÃ¥ det som motoren som kjÃ¸rer AI-modellene dine lokalt.

Sjekk om det er klart:

```bash
ollama --version
```

### Steg 3: Last ned din AI-hjerne ğŸ§ 

Tid for Ã¥ hente Qwen-3-8B-modellen (det er som Ã¥ ansette din fÃ¸rste AI-assistent):

```bash
ollama pull qwen3:8b
```

*Dette kan ta noen minutter. Perfekt tid for en kaffepause! â˜•*

### Steg 4: Sett opp VS Code

Last ned [Visual Studio Code](https://code.visualstudio.com/) hvis du ikke har det. Det er den beste kodeeditoren der ute (prÃ¸v meg ğŸ˜„).

### Steg 5: Python-utvidelsen

I VS Code:  
1. Trykk `Ctrl+Shift+X` (eller `Cmd+Shift+X` pÃ¥ Mac)  
2. SÃ¸k etter "Python"  
3. Installer den offisielle Microsoft Python-utvidelsen  

### Steg 6: Du er klar! ğŸ‰

Alvorlig talt, nÃ¥ er du klar til Ã¥ rocke. La oss bygge litt AI-magi!

### Steg 7: Installer Microsoft Agent Framework og relaterte pakker ğŸ“¦

Installer alle nÃ¸dvendige avhengigheter for workshopen:

```bash
pip install -r ./Installations/requirements.txt -U
```

*Dette vil installere Microsoft Agent Framework og alle nÃ¸dvendige pakker. Ta en kaffe â€” fÃ¸rste gangs oppsett kan ta noen minutter! â˜•*

## Workshop-instruksjoner

Detaljert prosjektstruktur, konfigurasjonssteg og kjÃ¸reanvisninger forklares steg-for-steg under workshopen.

## FeilsÃ¸king (nÃ¥r ting gÃ¥r galt) ğŸ”§

### "Ugh, modellnedlastingen tar evigheter!"  
**LÃ¸sning**: Bruk en VPN eller konfigurer Ollama med en mirrorkilde. Noen ganger hater bare internett oss.

### "Maskinen min dÃ¸r! Slutt pÃ¥ minne!"  
**LÃ¸sning**: Bytt til en mindre modell eller juster `num_ctx` innstillingen for Ã¥ bruke mindre minne. Tenk pÃ¥ det som Ã¥ sette AI-en pÃ¥ diett.

### "Kan jeg fÃ¥ det raskere med GPU-en min?"  
**LÃ¸sning**: Ollama oppdager GPU-er automatisk! Bare sÃ¸rg for at GPU-driverne dine er oppdaterte. Gratis hastighetsboost! ğŸï¸

## Ekstra ressurser (for nysgjerrige) ğŸ“š

- [Ollama Docs](https://github.com/ollama/ollama) â€” Dypdykk i lokale AI-modeller  
- [Microsoft Agent Framework](https://microsoft.github.io/autogen/) â€” LÃ¦r mer om Ã¥ bygge agentteam  
- [Qwen Model Info](https://qwenlm.github.io/) â€” MÃ¸t hjernen til AI-assistenten din  

## Lisens

MIT-lisens â€” Bygg kule ting, del dem, gjÃ¸r verden bedre! ğŸŒ

## Vil du bidra?

Fant en feil? Har en idÃ©? Legg inn en Issue eller PR! Vi digger fellesskapsvibber. âœ¨

---

<!-- CO-OP TRANSLATOR DISCLAIMER START -->
**Ansvarsfraskrivelse**:  
Dette dokumentet er oversatt ved hjelp av AI-oversettelsestjenesten [Co-op Translator](https://github.com/Azure/co-op-translator). Selv om vi streber etter nÃ¸yaktighet, vennligst vÃ¦r oppmerksom pÃ¥ at automatiserte oversettelser kan inneholde feil eller unÃ¸yaktigheter. Det opprinnelige dokumentet pÃ¥ originalsprÃ¥ket skal betraktes som den autoritative kilden. For kritisk informasjon anbefales profesjonell menneskelig oversettelse. Vi er ikke ansvarlige for eventuelle misforstÃ¥elser eller feiltolkninger som oppstÃ¥r ved bruk av denne oversettelsen.
<!-- CO-OP TRANSLATOR DISCLAIMER END -->