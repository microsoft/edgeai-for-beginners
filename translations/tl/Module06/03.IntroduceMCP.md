# Seksyon 03 - Integrasyon ng Model Context Protocol (MCP)

## Panimula sa MCP (Model Context Protocol)

Ang Model Context Protocol (MCP) ay isang open-source na pamantayan para sa pagkonekta ng mga AI application sa mga panlabas na sistema. Sa pamamagitan ng MCP, ang mga AI application tulad ng Claude o ChatGPT ay maaaring kumonekta sa mga pinagmumulan ng data (hal. mga lokal na file, database), mga tool (hal. search engines, calculators), at mga workflow (hal. mga espesyal na prompt)—na nagbibigay-daan sa kanila na ma-access ang mahalagang impormasyon at maisagawa ang mga gawain.

Isipin ang MCP na parang **USB-C port para sa mga AI application**. Katulad ng USB-C na nagbibigay ng pamantayan para sa pagkonekta ng mga elektronikong device, ang MCP ay nagbibigay ng pamantayan para sa pagkonekta ng mga AI application sa mga panlabas na sistema.

### Ano ang Maaaring Paganahin ng MCP?

Binubuksan ng MCP ang makapangyarihang kakayahan para sa mga AI application:

- **Personalized na AI Assistants**: Maaaring ma-access ng mga agent ang iyong Google Calendar at Notion, na nagiging mas personal na AI assistant
- **Advanced Code Generation**: Ang Claude Code ay maaaring bumuo ng buong web app gamit ang isang Figma design
- **Enterprise Data Integration**: Ang mga enterprise chatbot ay maaaring kumonekta sa maraming database sa isang organisasyon, na nagbibigay-kapangyarihan sa mga user na mag-analyze ng data gamit ang chat
- **Creative Workflows**: Ang mga AI model ay maaaring lumikha ng 3D designs sa Blender at i-print ito gamit ang 3D printer
- **Real-time Information Access**: Kumonekta sa mga panlabas na pinagmumulan ng data para sa napapanahong impormasyon
- **Komplikadong Multi-step Operations**: Magsagawa ng mga sopistikadong workflow na pinagsasama ang maraming tool at sistema

### Bakit Mahalaga ang MCP?

Nagbibigay ang MCP ng benepisyo sa buong ecosystem:

**Para sa mga Developer**: Binabawasan ng MCP ang oras at pagiging kumplikado ng pag-develop kapag gumagawa o nag-iintegrate ng AI application o agent.

**Para sa mga AI Application**: Nagbibigay ang MCP ng access sa ecosystem ng mga pinagmumulan ng data, tool, at apps na nagpapahusay sa kakayahan at karanasan ng end-user.

**Para sa mga End-user**: Nagreresulta ang MCP sa mas may kakayahang AI application o agent na maaaring ma-access ang iyong data at kumilos sa iyong ngalan kung kinakailangan.

## Small Language Models (SLMs) sa MCP

Ang Small Language Models ay kumakatawan sa isang mahusay na paraan ng AI deployment, na nag-aalok ng ilang benepisyo:

### Mga Benepisyo ng SLMs
- **Resource Efficiency**: Mas mababang computational requirements
- **Mas Mabilis na Tugon**: Nabawasan ang latency para sa real-time applications  
- **Cost Effectiveness**: Minimal na pangangailangan sa infrastructure
- **Privacy**: Maaaring patakbuhin nang lokal nang walang data transmission
- **Customization**: Mas madaling i-fine-tune para sa mga partikular na domain

### Bakit Maganda ang SLMs sa MCP

Ang SLMs na ipinares sa MCP ay lumilikha ng makapangyarihang kombinasyon kung saan ang kakayahan ng modelo sa pangangatwiran ay pinapalakas ng mga panlabas na tool, na binabawi ang mas maliit na parameter count sa pamamagitan ng pinahusay na functionality.

## Python MCP SDK Overview

Ang Python MCP SDK ay nagbibigay ng pundasyon para sa paggawa ng mga MCP-enabled na application. Kasama sa SDK ang:

- **Client Libraries**: Para sa pagkonekta sa MCP servers
- **Server Framework**: Para sa paggawa ng custom na MCP servers
- **Protocol Handlers**: Para sa pamamahala ng komunikasyon
- **Tool Integration**: Para sa pagsasagawa ng mga panlabas na function

## Praktikal na Implementasyon: Phi-4 MCP Client

Tingnan natin ang isang real-world na implementasyon gamit ang Phi-4 mini model ng Microsoft na may integrasyon ng MCP capabilities.

### MCP Architecture Overview

Ang MCP ay sumusunod sa **client-server architecture** kung saan ang isang MCP host (isang AI application tulad ng Claude Code o Claude Desktop) ay nagtatatag ng koneksyon sa isa o higit pang MCP servers. Ang MCP host ay ginagawa ito sa pamamagitan ng paglikha ng isang MCP client para sa bawat MCP server.

#### Mga Pangunahing Kalahok

- **MCP Host**: Ang AI application na nagko-coordinate at namamahala sa isa o maraming MCP clients
- **MCP Client**: Isang component na nagpapanatili ng koneksyon sa isang MCP server at kumukuha ng context mula sa MCP server para magamit ng MCP host
- **MCP Server**: Isang programa na nagbibigay ng context sa MCP clients

#### Two-Layer Architecture

Ang MCP ay binubuo ng dalawang natatanging layer:

**Data Layer**: Tinutukoy ang JSON-RPC based protocol para sa client-server communication, kabilang ang:
- Pamamahala ng lifecycle (connection initialization, capability negotiation)
- Core primitives (tools, resources, prompts)
- Mga feature ng client (sampling, elicitation, logging)
- Mga utility feature (notifications, progress tracking)

**Transport Layer**: Tinutukoy ang mga mekanismo at channel ng komunikasyon:
- **STDIO Transport**: Gumagamit ng standard input/output streams para sa mga lokal na proseso (optimal na performance, walang network overhead)
- **Streamable HTTP Transport**: Gumagamit ng HTTP POST na may optional Server-Sent Events para sa mga remote servers (sumusuporta sa standard HTTP authentication)

```
┌─────────────────────────────────────┐
│           MCP Host                  │
│     (AI Application)                │
└─────────────────┬───────────────────┘
                  │
┌─────────────────┴───────────────────┐
│         MCP Client 1                │
│  ┌─────────────────────────────────┐ │
│  │        Data Layer               │ │
│  │  ├── Lifecycle Management       │ │
│  │  ├── Primitives (Tools/Resources)│ │
│  │  └── Notifications              │ │
│  └─────────────────────────────────┘ │
│  ┌─────────────────────────────────┐ │
│  │      Transport Layer           │ │
│  │  ├── STDIO Transport           │ │
│  │  └── HTTP Transport            │ │
│  └─────────────────────────────────┘ │
└─────────────────┬───────────────────┘
                  │
┌─────────────────┴───────────────────┐
│         MCP Server 1                │
│    (Local/Remote Context Provider)  │
└─────────────────────────────────────┘
```

### MCP Core Primitives

Tinutukoy ng MCP ang mga primitives na naglalarawan sa mga uri ng contextual information na maaaring ibahagi sa mga AI application at ang saklaw ng mga aksyon na maaaring isagawa.

#### Server Primitives

Tinutukoy ng MCP ang tatlong core primitives na maaaring i-expose ng mga server:

**Tools**: Mga executable function na maaaring i-invoke ng mga AI application para magsagawa ng mga aksyon
- Halimbawa: file operations, API calls, database queries
- Mga Method: `tools/list`, `tools/call`
- Sumusuporta sa dynamic discovery at execution

**Resources**: Mga pinagmumulan ng data na nagbibigay ng contextual information sa mga AI application
- Halimbawa: nilalaman ng file, mga record sa database, mga tugon ng API
- Mga Method: `resources/list`, `resources/read`
- Nagbibigay-daan sa access sa structured data

**Prompts**: Mga reusable template na tumutulong sa pag-structure ng interaksyon sa mga language model
- Halimbawa: system prompts, few-shot examples
- Mga Method: `prompts/list`, `prompts/get`
- Nag-standardize ng AI interaction patterns

#### Client Primitives

Tinutukoy din ng MCP ang mga primitives na maaaring i-expose ng mga client para sa mas mayamang interaksyon:

**Sampling**: Pinapayagan ang mga server na humiling ng language model completions mula sa AI application ng client
- Method: `sampling/complete`
- Nagbibigay-daan sa model-independent server development
- Nagbibigay ng access sa language model ng host

**Elicitation**: Pinapayagan ang mga server na humiling ng karagdagang impormasyon mula sa mga user
- Method: `elicitation/request`
- Nagbibigay-daan sa user interaction at confirmation
- Sumusuporta sa dynamic information gathering

**Logging**: Pinapayagan ang mga server na magpadala ng log messages sa mga client
- Ginagamit para sa debugging at monitoring purposes
- Nagbibigay ng visibility sa mga operasyon ng server

### MCP Protocol Lifecycle

#### Initialization at Capability Negotiation

Ang MCP ay isang stateful protocol na nangangailangan ng lifecycle management. Ang proseso ng initialization ay may ilang mahahalagang layunin:

1. **Protocol Version Negotiation**: Tinitiyak na parehong client at server ay gumagamit ng compatible protocol versions (hal. "2025-06-18")
2. **Capability Discovery**: Ang bawat partido ay nagdedeklara ng mga suportadong feature at primitives
3. **Identity Exchange**: Nagbibigay ng identification at versioning information

```python
# Example initialization request
{
  "jsonrpc": "2.0",
  "id": 1,
  "method": "initialize",
  "params": {
    "protocolVersion": "2025-06-18",
    "capabilities": {
      "elicitation": {},  # Client supports user interaction
      "sampling": {}      # Client can provide LLM completions
    },
    "clientInfo": {
      "name": "edge-ai-client",
      "version": "1.0.0"
    }
  }
}
```

#### Tool Discovery at Execution

Pagkatapos ng initialization, maaaring matuklasan at maisagawa ng mga client ang mga tool:

```python
# Discover available tools
tools_response = await session.list_tools()

# Execute a tool
result = await session.call_tool(
    "weather_current",
    {
        "location": "San Francisco",
        "units": "imperial"
    }
)
```

#### Real-time Notifications

Sinusuportahan ng MCP ang real-time notifications para sa dynamic updates:

```python
# Server sends notification when tools change
{
  "jsonrpc": "2.0",
  "method": "notifications/tools/list_changed"
}

# Client responds by refreshing tool list
await session.list_tools()  # Get updated tools
```

## Pagsisimula: Step-by-Step Guide

### Hakbang 1: Environment Setup

I-install ang mga kinakailangang dependencies:
```bash
pip install fastmcp mcp-python-client openai requests pyautogui Pillow
```

### Hakbang 2: Basic Configuration

I-set up ang iyong environment variables:
```python
# System Configuration
SYSTEM_PROMPT = "You are an AI assistant with some tools."

# Ollama Configuration (Local)
OLLAMA_URL = "http://localhost:11434/api/chat"
OLLAMA_MODEL_ID = "phi4-mini:3.8b-fp16"

# vLLM Configuration (Server)
VLLM_URL = "http://localhost:8000/v1"
VLLM_MODEL_ID = "microsoft/Phi-4-mini-instruct"
```

### Hakbang 3: Pagpapatakbo ng Iyong Unang MCP Client

**Basic Ollama Setup:**
```bash
python ghmodel_mcp_demo.py
```

**Gamit ang vLLM Backend:**
```bash
python ghmodel_mcp_demo.py --env vllm
```

**Server-Sent Events Connection:**
```bash
python ghmodel_mcp_demo.py --run sse
```

**Custom MCP Server:**
```bash
python ghmodel_mcp_demo.py --server /path/to/server.py
```

### Hakbang 4: Programmatic Usage

```python
import asyncio
from ghmodel_mcp_demo import OllamaClient, Phi4MiniMCPClient

async def automated_interaction():
    # Configure MCP server parameters
    server_params = StdioServerParameters(
        command="npx",
        args=["@playwright/mcp@latest"],
        env=None,
    )
    
    # Create MCP client and process tools
    async with Phi4MiniMCPClient(server_params) as mcp_client:
        tools = await process_mcp_tools(mcp_client)
        llm_client = OllamaClient()
        
        # Generate response with tool capabilities
        response, messages = await llm_client.generate_response(
            "Help me automate a web task",
            tools
        )
        return response

# Execute the automation
result = asyncio.run(automated_interaction())
print(result)
```

## Advanced Features

### Multi-Backend Support

Ang implementasyon ay sumusuporta sa parehong Ollama at vLLM backends, na nagbibigay-daan sa iyo na pumili batay sa iyong mga pangangailangan:

- **Ollama**: Mas maganda para sa lokal na development at testing
- **vLLM**: Optimized para sa production at high-throughput scenarios

### Flexible Connection Protocols

Dalawang connection modes ang sinusuportahan:

**STDIO Mode**: Direktang komunikasyon ng proseso
- Mas mababang latency
- Angkop para sa lokal na tools
- Simpleng setup

**SSE Mode**: HTTP-based streaming
- Network-capable
- Mas maganda para sa distributed systems
- Real-time updates

### Tool Integration Capabilities

Ang sistema ay maaaring mag-integrate sa iba't ibang tools:
- Web automation (Playwright)
- File operations
- API interactions
- System commands
- Custom functions

## Error Handling at Best Practices

### Comprehensive Error Management

Ang implementasyon ay may kasamang robust error handling para sa:

**Connection Errors:**
- MCP server failures
- Network timeouts
- Connectivity issues

**Tool Execution Errors:**
- Nawawalang tools
- Parameter validation
- Execution failures

**Response Processing Errors:**
- JSON parsing issues
- Format inconsistencies
- LLM response anomalies

### Best Practices

1. **Resource Management**: Gumamit ng async context managers
2. **Error Handling**: Mag-implement ng comprehensive try-catch blocks
3. **Logging**: I-enable ang tamang logging levels
4. **Security**: I-validate ang inputs at i-sanitize ang outputs
5. **Performance**: Gumamit ng connection pooling at caching

## Real-World Applications

### Web Automation
```python
# Example: Automated web testing
async def web_automation_example():
    tools = await setup_playwright_tools()
    response = await llm_client.generate_response(
        "Navigate to example.com and take a screenshot",
        tools
    )
```

### Data Processing
```python
# Example: File analysis
async def data_processing_example():
    tools = await setup_file_tools()
    response = await llm_client.generate_response(
        "Analyze the CSV file and generate a summary report",
        tools
    )
```

### API Integration
```python
# Example: API interactions
async def api_integration_example():
    tools = await setup_api_tools()
    response = await llm_client.generate_response(
        "Fetch weather data and create a forecast summary",
        tools
    )
```

## Performance Optimization

### Memory Management
- Mahusay na paghawak ng message history
- Tamang resource cleanup
- Connection pooling

### Network Optimization
- Async HTTP operations
- Configurable timeouts
- Graceful error recovery

### Concurrent Processing
- Non-blocking I/O
- Parallel tool execution
- Efficient async patterns

## Security Considerations

### Data Protection
- Secure API key management
- Input validation
- Output sanitization

### Network Security
- HTTPS support
- Local endpoint defaults
- Secure token handling

### Execution Safety
- Tool filtering
- Sandboxed environments
- Audit logging

## MCP Ecosystem at Development

### Saklaw ng MCP Project

Kasama sa Model Context Protocol ecosystem ang ilang mahahalagang bahagi:

- **[MCP Specification](https://modelcontextprotocol.io/specification/latest)**: Opisyal na specification na naglalarawan ng mga kinakailangan sa implementasyon para sa mga client at server
- **[MCP SDKs](https://modelcontextprotocol.io/docs/sdk)**: Mga SDK para sa iba't ibang programming languages na nag-iimplement ng MCP
- **MCP Development Tools**: Mga tool para sa pag-develop ng MCP servers at clients, kabilang ang [MCP Inspector](https://github.com/modelcontextprotocol/inspector)
- **[MCP Reference Server Implementations](https://github.com/modelcontextprotocol/servers)**: Mga reference implementation ng MCP servers

### Pagsisimula sa MCP Development

Para simulan ang paggawa gamit ang MCP:

**Gumawa ng Servers**: [Lumikha ng MCP servers](https://modelcontextprotocol.io/docs/develop/build-server) para i-expose ang iyong data at tools

**Gumawa ng Clients**: [Mag-develop ng applications](https://modelcontextprotocol.io/docs/develop/build-client) na kumokonekta sa MCP servers

**Alamin ang Mga Konsepto**: [Unawain ang mga pangunahing konsepto](https://modelcontextprotocol.io/docs/learn/architecture) at arkitektura ng MCP

## Konklusyon

Ang SLMs na may integrasyon ng MCP ay kumakatawan sa isang makabagong pagbabago sa pag-develop ng AI application. Sa pamamagitan ng pagsasama ng kahusayan ng maliliit na modelo sa kapangyarihan ng mga panlabas na tool, maaaring lumikha ang mga developer ng mga intelligent na sistema na parehong resource-efficient at may mataas na kakayahan.

Ang Model Context Protocol ay nagbibigay ng pamantayan para sa pagkonekta ng mga AI application sa mga panlabas na sistema, katulad ng USB-C na nagbibigay ng universal connection standard para sa mga elektronikong device. Ang standardization na ito ay nagbibigay-daan sa:

- **Seamless Integration**: Ikonekta ang mga AI model sa iba't ibang pinagmumulan ng data at tools
- **Ecosystem Growth**: Gumawa ng isang beses, gamitin sa maraming AI application
- **Enhanced Capabilities**: Palakasin ang SLMs gamit ang panlabas na functionality
- **Real-time Updates**: Suportahan ang dynamic, responsive na AI applications

Mga pangunahing aral:
- Ang MCP ay isang open standard na nag-uugnay sa mga AI application at panlabas na sistema
- Sinusuportahan ng protocol ang tools, resources, at prompts bilang core primitives
- Ang real-time notifications ay nagbibigay-daan sa dynamic, responsive na applications
- Ang tamang lifecycle management at error handling ay mahalaga para sa production use
- Ang ecosystem ay nagbibigay ng komprehensibong SDKs at development tools

## Mga Sanggunian at Karagdagang Pagbabasa

### Opisyal na Dokumentasyon ng MCP

- **[Model Context Protocol Official Site](https://modelcontextprotocol.io/)** - Kumpletong dokumentasyon at mga specification
- **[MCP Getting Started Guide](https://modelcontextprotocol.io/docs/getting-started/intro)** - Panimula at mga pangunahing konsepto
- **[MCP Architecture Overview](https://modelcontextprotocol.io/docs/learn/architecture)** - Detalyadong teknikal na arkitektura
- **[MCP Specification](https://modelcontextprotocol.io/specification/latest)** - Opisyal na protocol specification
- **[MCP SDKs Documentation](https://modelcontextprotocol.io/docs/sdk)** - Mga gabay sa language-specific SDK

### Mga Resource sa Development

- **[MCP for Beginners](https://aka.ms/mcp-for-beginners)** - Komprehensibong gabay para sa mga baguhan sa Model Context Protocol
- **[MCP GitHub Organization](https://github.com/modelcontextprotocol)** - Opisyal na repositories at mga halimbawa
- **[MCP Server Repository](https://github.com/modelcontextprotocol/servers)** - Mga reference server implementations
- **[MCP Inspector](https://github.com/modelcontextprotocol/inspector)** - Tool para sa pag-develop at debugging
- **[Build MCP Servers Guide](https://modelcontextprotocol.io/docs/develop/build-server)** - Tutorial sa paggawa ng server
- **[Build MCP Clients Guide](https://modelcontextprotocol.io/docs/develop/build-client)** - Tutorial sa paggawa ng client

### Small Language Models at Edge AI

- **[Microsoft Phi Models](https://aka.ms/phicookbook)** - Phi model family 
- **[Foundry Local Documentation](https://github.com/microsoft/Foundry-Local)** - Microsoft's edge AI runtime
- **[Ollama Documentation](https://ollama.ai/docs)** - Plataporma para sa lokal na LLM deployment
- **[vLLM Documentation](https://docs.vllm.ai/)** - Mataas na performance na LLM serving

### Mga Pamantayan at Protocol sa Teknolohiya

- **[JSON-RPC 2.0 Specification](https://www.jsonrpc.org/)** - Pangunahing RPC protocol na ginagamit ng MCP
- **[JSON Schema](https://json-schema.org/)** - Pamantayan sa schema definition para sa mga MCP tools
- **[OpenAPI Specification](https://swagger.io/specification/)** - Pamantayan sa dokumentasyon ng API
- **[Server-Sent Events (SSE)](https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events)** - Web standard para sa real-time na mga update

### Pag-develop ng AI Agent

- **[Microsoft Agent Framework](https://github.com/microsoft/agent-framework)** - Pang-produksyon na framework para sa pag-develop ng agent
- **[LangChain Documentation](https://docs.langchain.com/)** - Framework para sa integration ng agent at tools
- **[Semantic Kernel](https://learn.microsoft.com/en-us/semantic-kernel/)** - AI orchestration SDK ng Microsoft

### Mga Ulat sa Industriya at Pananaliksik

- **[Anthropic's Model Context Protocol Announcement](https://www.anthropic.com/news/model-context-protocol)** - Orihinal na pagpapakilala sa MCP
- **[Small Language Models Survey](https://arxiv.org/abs/2410.20011)** - Akademikong survey sa pananaliksik ng SLM
- **[Edge AI Market Analysis](https://www.marketsandmarkets.com/Market-Reports/edge-ai-software-market-74385617.html)** - Mga trend at forecast sa industriya
- **[AI Agent Development Best Practices](https://arxiv.org/abs/2309.02427)** - Pananaliksik sa mga arkitektura ng agent

Ang seksyong ito ay nagbibigay ng pundasyon para sa pagbuo ng sarili mong mga MCP application na pinapagana ng SLM, na nagbubukas ng mga posibilidad para sa awtomasyon, pagproseso ng datos, at integrasyon ng matatalinong sistema.

## ➡️ Ano ang susunod

- [Module 7. Mga halimbawa ng Edge AI](../Module07/README.md)

---

**Paunawa**:  
Ang dokumentong ito ay isinalin gamit ang AI translation service na [Co-op Translator](https://github.com/Azure/co-op-translator). Bagama't sinisikap naming maging tumpak, mangyaring tandaan na ang mga awtomatikong pagsasalin ay maaaring maglaman ng mga pagkakamali o hindi pagkakatugma. Ang orihinal na dokumento sa kanyang katutubong wika ang dapat ituring na mapagkakatiwalaang pinagmulan. Para sa mahalagang impormasyon, inirerekomenda ang propesyonal na pagsasalin ng tao. Hindi kami mananagot sa anumang hindi pagkakaunawaan o maling interpretasyon na dulot ng paggamit ng pagsasaling ito.