<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "e8d157e0a282083a1e1c7bb5dda28646",
  "translation_date": "2025-10-30T12:41:19+00:00",
  "source_file": "Module04/README.md",
  "language_code": "tr"
}
-->
# BÃ¶lÃ¼m 04: Model Format DÃ¶nÃ¼ÅŸÃ¼mÃ¼ ve Kuantizasyon - BÃ¶lÃ¼m Genel BakÄ±ÅŸ

EdgeAI'nin yÃ¼kseliÅŸi, kaynaklarÄ± sÄ±nÄ±rlÄ± cihazlarda geliÅŸmiÅŸ makine Ã¶ÄŸrenimi yeteneklerini daÄŸÄ±tmak iÃ§in model format dÃ¶nÃ¼ÅŸÃ¼mÃ¼ ve kuantizasyonu Ã¶nemli teknolojiler haline getirdi. Bu kapsamlÄ± bÃ¶lÃ¼m, kenar daÄŸÄ±tÄ±m senaryolarÄ± iÃ§in modelleri anlamak, uygulamak ve optimize etmek konusunda eksiksiz bir rehber sunar.

## ğŸ“š BÃ¶lÃ¼m YapÄ±sÄ± ve Ã–ÄŸrenme Yolu

Bu bÃ¶lÃ¼m, kenar biliÅŸim iÃ§in model optimizasyonunu anlamak iÃ§in birbiri Ã¼zerine inÅŸa edilen yedi bÃ¶lÃ¼mden oluÅŸmaktadÄ±r:

---

## [BÃ¶lÃ¼m 1: Model Format DÃ¶nÃ¼ÅŸÃ¼mÃ¼ ve Kuantizasyon Temelleri](./01.Introduce.md)

### ğŸ¯ Genel BakÄ±ÅŸ
Bu temel bÃ¶lÃ¼m, kenar biliÅŸim ortamlarÄ±nda model optimizasyonu iÃ§in teorik Ã§erÃ§eveyi oluÅŸturur ve 1-bit ile 8-bit hassasiyet seviyeleri arasÄ±ndaki kuantizasyon sÄ±nÄ±rlarÄ±nÄ± ve ana format dÃ¶nÃ¼ÅŸÃ¼m stratejilerini kapsar.

**Ana Konular:**
- Hassasiyet sÄ±nÄ±flandÄ±rma Ã§erÃ§evesi (ultra dÃ¼ÅŸÃ¼k, dÃ¼ÅŸÃ¼k, orta hassasiyet)
- GGUF ve ONNX formatlarÄ±nÄ±n avantajlarÄ± ve kullanÄ±m alanlarÄ±
- Operasyonel verimlilik ve daÄŸÄ±tÄ±m esnekliÄŸi iÃ§in kuantizasyonun faydalarÄ±
- Performans karÅŸÄ±laÅŸtÄ±rmalarÄ± ve bellek kullanÄ±m analizleri

**Ã–ÄŸrenme Ã‡Ä±ktÄ±larÄ±:**
- Kuantizasyon sÄ±nÄ±rlarÄ±nÄ± ve sÄ±nÄ±flandÄ±rmalarÄ±nÄ± anlamak
- Uygun format dÃ¶nÃ¼ÅŸÃ¼m tekniklerini belirlemek
- Kenar daÄŸÄ±tÄ±mÄ± iÃ§in geliÅŸmiÅŸ optimizasyon stratejilerini Ã¶ÄŸrenmek

---

## [BÃ¶lÃ¼m 2: Llama.cpp Uygulama Rehberi](./02.Llamacpp.md)

### ğŸ¯ Genel BakÄ±ÅŸ
Llama.cpp'nin uygulanmasÄ± iÃ§in kapsamlÄ± bir rehber; bu gÃ¼Ã§lÃ¼ C++ Ã§erÃ§evesi, Ã§eÅŸitli donanÄ±m yapÄ±landÄ±rmalarÄ±nda minimal kurulumla verimli BÃ¼yÃ¼k Dil Modeli Ã§Ä±karÄ±mÄ± saÄŸlar.

**Ana Konular:**
- Windows, macOS ve Linux platformlarÄ±nda kurulum
- GGUF format dÃ¶nÃ¼ÅŸÃ¼mÃ¼ ve Ã§eÅŸitli kuantizasyon seviyeleri (Q2_K'den Q8_0'a)
- CUDA, Metal, OpenCL ve Vulkan ile donanÄ±m hÄ±zlandÄ±rma
- Python entegrasyonu ve Ã¼retim daÄŸÄ±tÄ±m stratejileri

**Ã–ÄŸrenme Ã‡Ä±ktÄ±larÄ±:**
- Ã‡apraz platform kurulumunu ve kaynak koddan derlemeyi Ã¶ÄŸrenmek
- Model kuantizasyonu ve optimizasyon tekniklerini uygulamak
- REST API entegrasyonu ile sunucu modunda modelleri daÄŸÄ±tmak

---

## [BÃ¶lÃ¼m 3: Microsoft Olive Optimizasyon Paketi](./03.MicrosoftOlive.md)

### ğŸ¯ Genel BakÄ±ÅŸ
Microsoft Olive'nin keÅŸfi; bu donanÄ±m odaklÄ± model optimizasyon aracÄ±, Ã§eÅŸitli donanÄ±m platformlarÄ±nda kurumsal dÃ¼zeyde model daÄŸÄ±tÄ±mÄ± iÃ§in tasarlanmÄ±ÅŸ 40'tan fazla yerleÅŸik optimizasyon bileÅŸeni sunar.

**Ana Konular:**
- Dinamik ve statik kuantizasyon ile otomatik optimizasyon Ã¶zellikleri
- CPU, GPU ve NPU daÄŸÄ±tÄ±mÄ± iÃ§in donanÄ±m odaklÄ± zeka
- PopÃ¼ler model desteÄŸi (Llama, Phi, Qwen, Gemma) kutudan Ã§Ä±ktÄ±ÄŸÄ± gibi
- Azure ML ile kurumsal entegrasyon ve Ã¼retim iÅŸ akÄ±ÅŸlarÄ±

**Ã–ÄŸrenme Ã‡Ä±ktÄ±larÄ±:**
- Ã‡eÅŸitli model mimarileri iÃ§in otomatik optimizasyonu kullanmak
- Ã‡apraz platform daÄŸÄ±tÄ±m stratejilerini uygulamak
- Kurumsal dÃ¼zeyde optimizasyon iÅŸ akÄ±ÅŸlarÄ± oluÅŸturmak

---

## [BÃ¶lÃ¼m 4: OpenVINO AraÃ§ TakÄ±mÄ± Optimizasyon Paketi](./04.openvino.md)

### ğŸ¯ Genel BakÄ±ÅŸ
Intel'in OpenVINO araÃ§ takÄ±mÄ±, bulut, ÅŸirket iÃ§i ve kenar ortamlarÄ±nda performanslÄ± AI Ã§Ã¶zÃ¼mleri daÄŸÄ±tmak iÃ§in geliÅŸmiÅŸ Sinir AÄŸÄ± SÄ±kÄ±ÅŸtÄ±rma Ã‡erÃ§evesi (NNCF) yetenekleriyle aÃ§Ä±k kaynaklÄ± bir platform olarak kapsamlÄ± bir ÅŸekilde incelenir.

**Ana Konular:**
- DonanÄ±m hÄ±zlandÄ±rma ile Ã§apraz platform daÄŸÄ±tÄ±mÄ± (CPU, GPU, VPU, AI hÄ±zlandÄ±rÄ±cÄ±lar)
- GeliÅŸmiÅŸ kuantizasyon ve budama iÃ§in Sinir AÄŸÄ± SÄ±kÄ±ÅŸtÄ±rma Ã‡erÃ§evesi (NNCF)
- OpenVINO GenAI ile bÃ¼yÃ¼k dil modeli optimizasyonu ve daÄŸÄ±tÄ±mÄ±
- Kurumsal dÃ¼zeyde model sunucu yetenekleri ve Ã¶lÃ§eklenebilir daÄŸÄ±tÄ±m stratejileri

**Ã–ÄŸrenme Ã‡Ä±ktÄ±larÄ±:**
- OpenVINO model dÃ¶nÃ¼ÅŸÃ¼mÃ¼ ve optimizasyon iÅŸ akÄ±ÅŸlarÄ±nÄ± Ã¶ÄŸrenmek
- NNCF ile geliÅŸmiÅŸ kuantizasyon tekniklerini uygulamak
- Model sunucu ile optimize edilmiÅŸ modelleri Ã§eÅŸitli donanÄ±m platformlarÄ±nda daÄŸÄ±tmak

---

## [BÃ¶lÃ¼m 5: Apple MLX Ã‡erÃ§evesi Derinlemesine Ä°nceleme](./05.AppleMLX.md)

### ğŸ¯ Genel BakÄ±ÅŸ
Apple MLX'in kapsamlÄ± bir ÅŸekilde ele alÄ±nmasÄ±; bu devrim niteliÄŸindeki Ã§erÃ§eve, Apple Silicon Ã¼zerinde verimli makine Ã¶ÄŸrenimi iÃ§in Ã¶zel olarak tasarlanmÄ±ÅŸtÄ±r ve BÃ¼yÃ¼k Dil Modeli yetenekleri ve yerel daÄŸÄ±tÄ±m Ã¼zerine odaklanÄ±r.

**Ana Konular:**
- BirleÅŸik bellek mimarisi avantajlarÄ± ve Metal Performans Shader'larÄ±
- LLaMA, Mistral, Phi-3, Qwen ve Code Llama modelleri desteÄŸi
- Verimli model Ã¶zelleÅŸtirme iÃ§in LoRA ince ayarÄ±
- Hugging Face entegrasyonu ve kuantizasyon desteÄŸi (4-bit ve 8-bit)

**Ã–ÄŸrenme Ã‡Ä±ktÄ±larÄ±:**
- Apple Silicon optimizasyonunu LLM daÄŸÄ±tÄ±mÄ± iÃ§in Ã¶ÄŸrenmek
- Ä°nce ayar ve model Ã¶zelleÅŸtirme tekniklerini uygulamak
- GeliÅŸmiÅŸ gizlilik Ã¶zellikleriyle kurumsal AI uygulamalarÄ± oluÅŸturmak

---

## [BÃ¶lÃ¼m 6: Edge AI GeliÅŸtirme Ä°ÅŸ AkÄ±ÅŸÄ± Sentezi](./06.workflow-synthesis.md)

### ğŸ¯ Genel BakÄ±ÅŸ
TÃ¼m optimizasyon Ã§erÃ§evelerinin birleÅŸik iÅŸ akÄ±ÅŸlarÄ±na, karar matrislerine ve mobil, masaÃ¼stÃ¼ ve bulut ortamlarÄ± dahil olmak Ã¼zere Ã§eÅŸitli platformlar ve kullanÄ±m durumlarÄ± iÃ§in Ã¼retime hazÄ±r Edge AI daÄŸÄ±tÄ±mÄ±na yÃ¶nelik en iyi uygulamalara kapsamlÄ± bir sentezi.

**Ana Konular:**
- Birden fazla optimizasyon Ã§erÃ§evesini entegre eden birleÅŸik iÅŸ akÄ±ÅŸÄ± mimarisi
- Ã‡erÃ§eve seÃ§imi karar aÄŸaÃ§larÄ± ve performans Ã¶dÃ¼nleÅŸimi analizi
- Ãœretim hazÄ±r doÄŸrulama ve kapsamlÄ± daÄŸÄ±tÄ±m stratejileri
- GeliÅŸen donanÄ±m ve model mimarileri iÃ§in geleceÄŸe yÃ¶nelik stratejiler

**Ã–ÄŸrenme Ã‡Ä±ktÄ±larÄ±:**
- Gereksinimler ve kÄ±sÄ±tlamalara dayalÄ± sistematik Ã§erÃ§eve seÃ§imini Ã¶ÄŸrenmek
- KapsamlÄ± izleme ile Ã¼retim dÃ¼zeyinde Edge AI iÅŸ akÄ±ÅŸlarÄ± uygulamak
- GeliÅŸen teknolojiler ve gereksinimlerle uyumlu iÅŸ akÄ±ÅŸlarÄ± tasarlamak

---

## [BÃ¶lÃ¼m 7: Qualcomm QNN Optimizasyon Paketi](./07.QualcommQNN.md)

### ğŸ¯ Genel BakÄ±ÅŸ
Qualcomm QNN'nin kapsamlÄ± bir ÅŸekilde incelenmesi; bu birleÅŸik AI Ã§Ä±karÄ±m Ã§erÃ§evesi, Qualcomm'un heterojen hesaplama mimarisinden maksimum performans ve enerji verimliliÄŸi saÄŸlamak iÃ§in Hexagon NPU, Adreno GPU ve Kryo CPU'yu kullanÄ±r.

**Ana Konular:**
- NPU, GPU ve CPU'ya birleÅŸik eriÅŸim ile heterojen hesaplama
- Snapdragon platformlarÄ± iÃ§in akÄ±llÄ± iÅŸ yÃ¼kÃ¼ daÄŸÄ±tÄ±mÄ± ile donanÄ±m odaklÄ± optimizasyon
- Mobil daÄŸÄ±tÄ±m iÃ§in geliÅŸmiÅŸ kuantizasyon teknikleri (INT8, INT16, karma hassasiyet)
- Pil gÃ¼cÃ¼yle Ã§alÄ±ÅŸan cihazlar ve gerÃ§ek zamanlÄ± uygulamalar iÃ§in enerji verimli Ã§Ä±karÄ±m

**Ã–ÄŸrenme Ã‡Ä±ktÄ±larÄ±:**
- Mobil AI daÄŸÄ±tÄ±mÄ± iÃ§in Qualcomm donanÄ±m hÄ±zlandÄ±rmayÄ± Ã¶ÄŸrenmek
- Kenar biliÅŸim iÃ§in enerji verimli optimizasyon stratejilerini uygulamak
- Qualcomm ekosisteminde Ã¼retime hazÄ±r modelleri optimal performansla daÄŸÄ±tmak

---

## ğŸ¯ BÃ¶lÃ¼m Ã–ÄŸrenme Ã‡Ä±ktÄ±larÄ±

Bu kapsamlÄ± bÃ¶lÃ¼mÃ¼ tamamladÄ±ktan sonra okuyucular ÅŸunlarÄ± baÅŸaracaktÄ±r:

### **Teknik UzmanlÄ±k**
- Kuantizasyon sÄ±nÄ±rlarÄ±nÄ± ve pratik uygulamalarÄ±nÄ± derinlemesine anlamak
- Birden fazla optimizasyon Ã§erÃ§evesiyle uygulamalÄ± deneyim
- Kenar biliÅŸim ortamlarÄ± iÃ§in Ã¼retim daÄŸÄ±tÄ±m becerileri

### **Stratejik AnlayÄ±ÅŸ**
- DonanÄ±m odaklÄ± optimizasyon seÃ§imi yetenekleri
- Performans Ã¶dÃ¼nleÅŸimleri hakkÄ±nda bilinÃ§li karar verme
- Kurumsal dÃ¼zeyde daÄŸÄ±tÄ±m ve izleme stratejileri

### **Performans KarÅŸÄ±laÅŸtÄ±rmalarÄ±**

| Ã‡erÃ§eve    | Kuantizasyon | Bellek KullanÄ±mÄ± | HÄ±z ArtÄ±ÅŸÄ± | KullanÄ±m Durumu                |
|------------|--------------|------------------|------------|--------------------------------|
| Llama.cpp  | Q4_K_M       | ~4GB            | 2-3x       | Ã‡apraz platform daÄŸÄ±tÄ±mÄ±       |
| Olive      | INT4         | %60-75 azalma   | 2-6x       | Kurumsal iÅŸ akÄ±ÅŸlarÄ±           |
| OpenVINO   | INT8/INT4    | %50-75 azalma   | 2-5x       | Intel donanÄ±m optimizasyonu    |
| QNN        | INT8/INT4    | %50-80 azalma   | 5-15x      | Qualcomm mobil/kenar          |
| MLX        | 4-bit        | ~4GB            | 2-4x       | Apple Silicon optimizasyonu    |

## ğŸš€ Sonraki AdÄ±mlar ve Ä°leri Uygulamalar

Bu bÃ¶lÃ¼m, aÅŸaÄŸÄ±daki konular iÃ§in eksiksiz bir temel saÄŸlar:
- Belirli alanlar iÃ§in Ã¶zel model geliÅŸtirme
- Kenar AI optimizasyonunda araÅŸtÄ±rma
- Ticari AI uygulama geliÅŸtirme
- BÃ¼yÃ¼k Ã¶lÃ§ekli kurumsal kenar AI daÄŸÄ±tÄ±mlarÄ±

Bu yedi bÃ¶lÃ¼mden elde edilen bilgiler, hÄ±zla geliÅŸen kenar AI model optimizasyonu ve daÄŸÄ±tÄ±mÄ± alanÄ±nda gezinmek iÃ§in kapsamlÄ± bir araÃ§ seti sunar.

---

**Feragatname**:  
Bu belge, AI Ã§eviri hizmeti [Co-op Translator](https://github.com/Azure/co-op-translator) kullanÄ±larak Ã§evrilmiÅŸtir. DoÄŸruluk iÃ§in Ã§aba gÃ¶stersek de, otomatik Ã§evirilerin hata veya yanlÄ±ÅŸlÄ±k iÃ§erebileceÄŸini lÃ¼tfen unutmayÄ±n. Belgenin orijinal dili, yetkili kaynak olarak kabul edilmelidir. Kritik bilgiler iÃ§in profesyonel insan Ã§evirisi Ã¶nerilir. Bu Ã§evirinin kullanÄ±mÄ±ndan kaynaklanan yanlÄ±ÅŸ anlamalar veya yanlÄ±ÅŸ yorumlamalar iÃ§in sorumluluk kabul etmiyoruz.