# Oturum 1: Foundry Local ile BaÅŸlangÄ±Ã§

## Ã–zet

Microsoft Foundry Local kullanarak ilk yapay zeka modellerinizi nasÄ±l kuracaÄŸÄ±nÄ±zÄ±, yapÄ±landÄ±racaÄŸÄ±nÄ±zÄ± ve Ã§alÄ±ÅŸtÄ±racaÄŸÄ±nÄ±zÄ± Ã¶ÄŸrenin. Bu uygulamalÄ± oturum, kurulumdan Phi-4, Qwen ve DeepSeek gibi modellerle ilk sohbet uygulamanÄ±zÄ± oluÅŸturmaya kadar yerel Ã§Ä±karÄ±m iÃ§in adÄ±m adÄ±m bir giriÅŸ sunar.

## Ã–ÄŸrenme Hedefleri

Bu oturumun sonunda:

- **Kurulum ve YapÄ±landÄ±rma**: Foundry Local'Ä± doÄŸru bir ÅŸekilde kurup doÄŸrulama yapmayÄ± Ã¶ÄŸrenin
- **CLI Ä°ÅŸlemlerinde UstalaÅŸma**: Foundry Local CLI'yi model yÃ¶netimi ve daÄŸÄ±tÄ±mÄ± iÃ§in kullanÄ±n
- **Ä°lk Modelinizi Ã‡alÄ±ÅŸtÄ±rÄ±n**: Yerel bir yapay zeka modelini baÅŸarÄ±yla daÄŸÄ±tÄ±n ve etkileÅŸimde bulunun
- **Sohbet UygulamasÄ± OluÅŸturun**: Foundry Local Python SDK kullanarak temel bir sohbet uygulamasÄ± oluÅŸturun
- **Yerel Yapay ZekayÄ± AnlayÄ±n**: Yerel Ã§Ä±karÄ±m ve model yÃ¶netiminin temellerini kavrayÄ±n

## Ã–n KoÅŸullar

### Sistem Gereksinimleri

- **Windows**: Windows 11 (22H2 veya Ã¼stÃ¼) VEYA **macOS**: macOS 11+ (sÄ±nÄ±rlÄ± destek)
- **RAM**: Minimum 8GB, Ã¶nerilen 16GB+
- **Depolama**: Modeller iÃ§in 10GB+ boÅŸ alan
- **Python**: 3.10 veya Ã¼stÃ¼ kurulu
- **YÃ¶netici EriÅŸimi**: Kurulum iÃ§in yÃ¶netici yetkileri

### GeliÅŸtirme OrtamÄ±

- Python uzantÄ±sÄ± ile Visual Studio Code (Ã¶nerilir)
- Komut satÄ±rÄ± eriÅŸimi (Windows'ta PowerShell, macOS'ta Terminal)
- DepolarÄ± klonlamak iÃ§in Git (isteÄŸe baÄŸlÄ±)

## AtÃ¶lye AkÄ±ÅŸÄ± (30 dakika)

### AdÄ±m 1: Foundry Local'Ä± Kurun (5 dakika)

#### Windows Kurulumu

Foundry Local'Ä± Windows paket yÃ¶neticisi kullanarak kurun:

```powershell
# Install via winget (recommended)
winget install Microsoft.FoundryLocal
```

Alternatif: [Microsoft Learn](https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/install) Ã¼zerinden doÄŸrudan indirin

#### macOS Kurulumu (SÄ±nÄ±rlÄ± Destek)

> [!NOTE] 
> macOS desteÄŸi ÅŸu anda Ã¶nizleme aÅŸamasÄ±ndadÄ±r. En son kullanÄ±labilirlik iÃ§in resmi belgeleri kontrol edin.

Homebrew kullanarak kurulum yapÄ±n:

```bash
# If Homebrew formula is available
brew update
brew install foundry-local

# Or manual download (check official docs for latest)
curl -L -o foundry-local.tar.gz "https://download.microsoft.com/foundry-local/latest/macos/foundry-local.tar.gz"
tar -xzf foundry-local.tar.gz
sudo ./install.sh
```

**macOS kullanÄ±cÄ±larÄ± iÃ§in alternatif:**
- Windows 11 VM (Parallels/UTM) kullanarak Windows adÄ±mlarÄ±nÄ± takip edin
- Mevcutsa bir konteyner Ã¼zerinden Ã§alÄ±ÅŸtÄ±rÄ±n ve `FOUNDRY_LOCAL_ENDPOINT` yapÄ±landÄ±rmasÄ±nÄ± yapÄ±n

### AdÄ±m 2: Kurulumu DoÄŸrulayÄ±n (3 dakika)

Kurulumdan sonra terminalinizi yeniden baÅŸlatÄ±n ve Foundry Local'Ä±n Ã§alÄ±ÅŸtÄ±ÄŸÄ±nÄ± doÄŸrulayÄ±n:

```powershell
# Check if Foundry Local is installed correctly
foundry --version

# View available commands
foundry --help
```

Beklenen Ã§Ä±ktÄ±, sÃ¼rÃ¼m bilgilerini ve mevcut komutlarÄ± gÃ¶stermelidir.

### AdÄ±m 3: Python OrtamÄ±nÄ± AyarlayÄ±n (5 dakika)

Bu atÃ¶lye iÃ§in Ã¶zel bir Python ortamÄ± oluÅŸturun:

**Windows:**
```powershell
# Create virtual environment
py -m venv .venv

# Activate environment
.\.venv\Scripts\Activate.ps1

# Upgrade pip and install dependencies
python -m pip install --upgrade pip
pip install foundry-local-sdk openai
```

**macOS/Linux:**
```bash
# Create virtual environment
python3 -m venv .venv

# Activate environment
source .venv/bin/activate

# Upgrade pip and install dependencies
python -m pip install --upgrade pip
pip install foundry-local-sdk openai
```

### AdÄ±m 4: Ä°lk Modelinizi Ã‡alÄ±ÅŸtÄ±rÄ±n (7 dakika)

Åimdi ilk yapay zeka modelimizi yerel olarak Ã§alÄ±ÅŸtÄ±ralÄ±m!

#### Phi-4 Mini ile BaÅŸlayÄ±n (Ã–nerilen Ä°lk Model)

```powershell
# Download and start phi-4-mini (lightweight, fast)
foundry model run phi-4-mini

# Test the model with a simple prompt
foundry model run phi-4-mini --prompt "Hello, introduce yourself in one sentence"
```

> [!TIP]
> Bu komut modeli indirir (ilk kez) ve Foundry Local hizmetini otomatik olarak baÅŸlatÄ±r.

#### Ã‡alÄ±ÅŸanlarÄ± Kontrol Edin

```powershell
# List available models (shows downloaded models)
foundry model list

# Check service status
foundry service status

# See what models are cached locally
foundry cache list
```

#### FarklÄ± Modelleri Deneyin

Phi-4-mini Ã§alÄ±ÅŸtÄ±ktan sonra diÄŸer modelleri deneyin:

```powershell
# Larger model with better capabilities
foundry model run gpt-oss-20b --prompt "Explain edge AI in simple terms"

# Fast, efficient model
foundry model run qwen2.5-0.5b --prompt "What are the benefits of local AI inference?"
```

### AdÄ±m 5: Ä°lk Sohbet UygulamanÄ±zÄ± OluÅŸturun (10 dakika)

Åimdi baÅŸlattÄ±ÄŸÄ±mÄ±z modelleri kullanan bir Python uygulamasÄ± oluÅŸturalÄ±m.

#### Sohbet Scriptini OluÅŸturun

`my_first_chat.py` adlÄ± yeni bir dosya oluÅŸturun (veya saÄŸlanan Ã¶rneÄŸi kullanÄ±n):

```python
#!/usr/bin/env python3
"""
My First Foundry Local Chat Application
Using FoundryLocalManager for automatic service management
"""

import os
from foundry_local import FoundryLocalManager
from openai import OpenAI

def main():
    # Get model alias from environment or use default
    alias = os.getenv("FOUNDRY_LOCAL_ALIAS", "phi-4-mini")
    
    try:
        # Initialize Foundry Local Manager (auto-starts service, downloads model)
        manager = FoundryLocalManager(alias)
        
        # Create OpenAI client pointing to local endpoint
        client = OpenAI(
            base_url=manager.endpoint,
            api_key=manager.api_key or "not-needed"
        )
        
        # Get the actual model ID for this alias
        model_id = manager.get_model_info(alias).id
        
        print("ğŸ¤– Welcome to your first local AI chat!")
        print(f"ï¿½ Using model: {alias} -> {model_id}")
        print(f"ğŸŒ Endpoint: {manager.endpoint}")
        print("ï¿½ğŸ’¡ Type 'quit' to exit\n")
        
    except Exception as e:
        print(f"âŒ Failed to initialize Foundry Local: {e}")
        print("ğŸ’¡ Make sure Foundry Local is installed: foundry --version")
        return
    
    while True:
        # Get user input
        user_message = input("You: ").strip()
        
        if user_message.lower() in ['quit', 'exit', 'bye']:
            print("ğŸ‘‹ Goodbye!")
            break
            
        if not user_message:
            continue
            
        try:
            # Send message to local AI model
            response = client.chat.completions.create(
                model=model_id,
                messages=[
                    {"role": "system", "content": "You are a helpful AI assistant running locally."},
                    {"role": "user", "content": user_message}
                ],
                max_tokens=200,
                temperature=0.7
            )
            
            # Display the response
            ai_response = response.choices[0].message.content
            print(f"ğŸ¤– AI: {ai_response}\n")
            
        except Exception as e:
            print(f"âŒ Error: {e}")
            print("ğŸ’¡ Check service status: foundry service status\n")

if __name__ == "__main__":
    main()
```

> [!TIP]
> **Ä°lgili Ã–rnekler**: Daha geliÅŸmiÅŸ kullanÄ±m iÃ§in ÅŸunlara bakÄ±n:
>
> - **Python Ã–rneÄŸi**: `Workshop/samples/session01/chat_bootstrap.py` - AkÄ±ÅŸ yanÄ±tlarÄ± ve hata yÃ¶netimi iÃ§erir
> - **Jupyter Notebook**: `Workshop/notebooks/session01_chat_bootstrap.ipynb` - AyrÄ±ntÄ±lÄ± aÃ§Ä±klamalarla interaktif versiyon

#### Sohbet UygulamanÄ±zÄ± Test Edin

```powershell
# No need to manually start models - FoundryLocalManager handles this!
# Just run your chat application
python my_first_chat.py
```

Alternatif: SaÄŸlanan Ã¶rnekleri doÄŸrudan kullanÄ±n

```powershell
# Try the complete sample with streaming support
cd Workshop/samples
python -m session01.chat_bootstrap "Your question here"
```

Veya interaktif notebook'u keÅŸfedin  
Workshop/notebooks/session01_chat_bootstrap.ipynb dosyasÄ±nÄ± VS Code'da aÃ§Ä±n

Bu Ã¶rnek konuÅŸmalarÄ± deneyin:

- "Microsoft Foundry Local nedir?"
- "Yerel yapay zeka modellerini Ã§alÄ±ÅŸtÄ±rmanÄ±n 3 faydasÄ±nÄ± listele"
- "Edge AI'yi anlamama yardÄ±mcÄ± ol"

## BaÅŸardÄ±klarÄ±nÄ±z

Tebrikler! BaÅŸarÄ±yla:

1. âœ… **Foundry Local'Ä± kurdunuz** ve Ã§alÄ±ÅŸtÄ±ÄŸÄ±nÄ± doÄŸruladÄ±nÄ±z
2. âœ… **Ä°lk yapay zeka modelinizi** (phi-4-mini) yerel olarak baÅŸlattÄ±nÄ±z
3. âœ… **FarklÄ± modelleri** komut satÄ±rÄ± Ã¼zerinden test ettiniz
4. âœ… **Bir sohbet uygulamasÄ± oluÅŸturdunuz** ve yerel yapay zekaya baÄŸlandÄ±nÄ±z
5. âœ… **Yerel yapay zeka Ã§Ä±karÄ±mÄ±nÄ±** bulut baÄŸÄ±mlÄ±lÄ±ÄŸÄ± olmadan deneyimlediniz

## Ne OlduÄŸunu Anlama

### Yerel Yapay Zeka Ã‡Ä±karÄ±mÄ±

- Yapay zeka modelleriniz tamamen bilgisayarÄ±nÄ±zda Ã§alÄ±ÅŸÄ±r
- HiÃ§bir veri buluta gÃ¶nderilmez
- YanÄ±tlar CPU/GPU'nuz kullanÄ±larak yerel olarak Ã¼retilir
- Gizlilik ve gÃ¼venlik korunur

### Model YÃ¶netimi

- `foundry model run` modelleri indirir ve baÅŸlatÄ±r
- **FoundryLocalManager SDK** hizmet baÅŸlatma ve model yÃ¼klemeyi otomatik olarak yÃ¶netir
- Modeller gelecekteki kullanÄ±m iÃ§in yerel olarak Ã¶nbelleÄŸe alÄ±nÄ±r
- Birden fazla model indirilebilir ancak genellikle bir model Ã§alÄ±ÅŸÄ±r
- Hizmet model yaÅŸam dÃ¶ngÃ¼sÃ¼nÃ¼ otomatik olarak yÃ¶netir

### SDK ve CLI YaklaÅŸÄ±mlarÄ±

- **CLI YaklaÅŸÄ±mÄ±**: `foundry model run <model>` ile manuel model yÃ¶netimi
- **SDK YaklaÅŸÄ±mÄ±**: `FoundryLocalManager(alias)` ile otomatik hizmet + model yÃ¶netimi
- **Ã–neri**: Uygulamalar iÃ§in SDK, test ve keÅŸif iÃ§in CLI kullanÄ±n

## SÄ±k KullanÄ±lan Komutlar ReferansÄ±

### Temel CLI KomutlarÄ±

```powershell
# Installation & Setup
foundry --version              # Check installation
foundry --help                 # View all commands

# Model Management
foundry model list             # List available models
foundry model run <model>      # Download and start a model
foundry model run <model> --prompt "text"  # One-shot prompt
foundry cache list             # Show downloaded models

# Service Management
foundry service status         # Check if service is running
foundry service start          # Start the service manually
foundry service stop           # Stop the service
```

### Model Ã–nerileri

- **phi-4-mini**: En iyi baÅŸlangÄ±Ã§ modeli - hÄ±zlÄ±, hafif, kaliteli
- **qwen2.5-0.5b**: En hÄ±zlÄ± Ã§Ä±karÄ±m, minimum bellek kullanÄ±mÄ±
- **gpt-oss-20b**: Daha kaliteli yanÄ±tlar, daha fazla kaynak gerektirir
- **deepseek-coder-1.3b**: Programlama ve kod gÃ¶revleri iÃ§in optimize edilmiÅŸ

## Sorun Giderme

### "Foundry komutu bulunamadÄ±"

**Ã‡Ã¶zÃ¼m:**

```powershell
# Restart your terminal after installation
# Or manually add to PATH (Windows)
$env:PATH += ";C:\Program Files\Microsoft\FoundryLocal"
```

### "Model yÃ¼klenemedi"

**Ã‡Ã¶zÃ¼m:**

```powershell
# Check available system memory
foundry service status

# Try a smaller model first
foundry model run phi-4-mini

# Check disk space for model downloads
# Models are stored in: %USERPROFILE%\.foundry\models (Windows)
```

### "Localhost'ta baÄŸlantÄ± reddedildi"

**Ã‡Ã¶zÃ¼m:**

```powershell
# Check if service is running
foundry service status

# Start service if needed
foundry service start

# Verify the port (default is 5273)
# Check for port conflicts with: netstat -an | findstr 5273
```

## Sonraki AdÄ±mlar

### Hemen YapÄ±lacaklar

1. **FarklÄ± modeller ve istemlerle** deney yapÄ±n
2. Sohbet uygulamanÄ±zÄ± **deÄŸiÅŸtirerek** farklÄ± modelleri deneyin
3. **Kendi istemlerinizi oluÅŸturun** ve yanÄ±tlarÄ± test edin
4. **Oturum 2'yi keÅŸfedin**: RAG uygulamalarÄ± oluÅŸturma

### Ä°leri DÃ¼zey Ã–ÄŸrenme Yolu

1. **Oturum 2**: RAG (Retrieval-Augmented Generation) ile yapay zeka Ã§Ã¶zÃ¼mleri oluÅŸturma
2. **Oturum 3**: FarklÄ± aÃ§Ä±k kaynak modelleri karÅŸÄ±laÅŸtÄ±rma
3. **Oturum 4**: En son modellerle Ã§alÄ±ÅŸma
4. **Oturum 5**: Ã‡oklu ajan yapay zeka sistemleri oluÅŸturma

## Ortam DeÄŸiÅŸkenleri (Ä°steÄŸe BaÄŸlÄ±)

Daha geliÅŸmiÅŸ kullanÄ±m iÃ§in ÅŸu ortam deÄŸiÅŸkenlerini ayarlayabilirsiniz:

| DeÄŸiÅŸken | AmaÃ§ | Ã–rnek |
|----------|---------|---------|
| `FOUNDRY_LOCAL_ALIAS` | KullanÄ±lacak varsayÄ±lan model | `phi-4-mini` |
| `FOUNDRY_LOCAL_ENDPOINT` | Endpoint URL'sini geÃ§ersiz kÄ±l | `http://localhost:5273/v1` |

Proje dizininizde bir `.env` dosyasÄ± oluÅŸturun:
```
FOUNDRY_LOCAL_ALIAS=phi-4-mini
FOUNDRY_LOCAL_ENDPOINT=auto
```

## Ek Kaynaklar

### Belgeler

- [Foundry Local Python SDK ReferansÄ±](https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/reference/reference-sdk?pivots=programming-language-python)
- [Foundry Local Kurulum KÄ±lavuzu](https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/install)
- [Model KataloÄŸu](https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/models)

### Ã–rnek Kod

- **Session01 Python Ã–rneÄŸi**: `Workshop/samples/session01/chat_bootstrap.py` - AkÄ±ÅŸlÄ± tam sohbet uygulamasÄ±
- **Session01 Notebook**: `Workshop/notebooks/session01_chat_bootstrap.ipynb` - Ä°nteraktif eÄŸitim  
- [Module08 Ã–rnek 01](../Module08/samples/01/README.md) - REST Sohbet HÄ±zlÄ± BaÅŸlangÄ±Ã§
- [Module08 Ã–rnek 02](../Module08/samples/02/README.md) - OpenAI SDK Entegrasyonu
- [Module08 Ã–rnek 03](../Module08/samples/03/README.md) - Model KeÅŸfi ve KarÅŸÄ±laÅŸtÄ±rma

### Topluluk

- [Foundry Local GitHub TartÄ±ÅŸmalarÄ±](https://github.com/microsoft/Foundry-Local/discussions)
- [Azure AI TopluluÄŸu](https://techcommunity.microsoft.com/category/artificialintelligence)

---

**Oturum SÃ¼resi**: 30 dakika uygulamalÄ± + 15 dakika Soru-Cevap  
**Zorluk Seviyesi**: BaÅŸlangÄ±Ã§  
**Ã–n KoÅŸullar**: Windows 11/macOS 11+, Python 3.10+, YÃ¶netici eriÅŸimi

## AtÃ¶lye Ã–rnek Senaryosu

### GerÃ§ek DÃ¼nya BaÄŸlamÄ±

**Senaryo**: Bir kurumsal BT ekibi, hassas Ã§alÄ±ÅŸan geri bildirimlerini dÄ±ÅŸ hizmetlere gÃ¶ndermeden iÅŸlemek iÃ§in cihaz Ã¼zerinde yapay zeka Ã§Ä±karÄ±mÄ±nÄ± deÄŸerlendirmek istiyor.

**Hedefiniz**: Yerel yapay zeka modellerinin, tam veri gizliliÄŸi saÄŸlarken alt saniye gecikme ile kaliteli yanÄ±tlar verebileceÄŸini gÃ¶sterin.

### Test Ä°stemleri

Kurulumunuzu doÄŸrulamak iÃ§in bu istemleri kullanÄ±n:

```json
[
    "List two benefits of local inference.",
    "Summarize why keeping data on device improves privacy.",
    "Give one trade-off when choosing a small model over a large model."
]
```

### BaÅŸarÄ± Kriterleri

- âœ… TÃ¼m istemler 2 saniyeden kÄ±sa sÃ¼rede yanÄ±t alÄ±r
- âœ… HiÃ§bir veri yerel makinenizden dÄ±ÅŸarÄ± Ã§Ä±kmaz
- âœ… YanÄ±tlar alakalÄ± ve yardÄ±mcÄ±dÄ±r
- âœ… Sohbet uygulamanÄ±z sorunsuz Ã§alÄ±ÅŸÄ±r

Bu doÄŸrulama, Foundry Local kurulumunuzun Oturum 2-6'daki ileri dÃ¼zey atÃ¶lyeler iÃ§in hazÄ±r olduÄŸunu garanti eder.

---

<!-- CO-OP TRANSLATOR DISCLAIMER START -->
**Feragatname**:  
Bu belge, AI Ã§eviri hizmeti [Co-op Translator](https://github.com/Azure/co-op-translator) kullanÄ±larak Ã§evrilmiÅŸtir. DoÄŸruluk iÃ§in Ã§aba gÃ¶stersek de, otomatik Ã§eviriler hata veya yanlÄ±ÅŸlÄ±klar iÃ§erebilir. Belgenin orijinal dili, yetkili kaynak olarak kabul edilmelidir. Kritik bilgiler iÃ§in profesyonel insan Ã§evirisi Ã¶nerilir. Bu Ã§evirinin kullanÄ±mÄ±ndan kaynaklanan yanlÄ±ÅŸ anlamalar veya yanlÄ±ÅŸ yorumlamalar iÃ§in sorumluluk kabul edilmez.
<!-- CO-OP TRANSLATOR DISCLAIMER END -->