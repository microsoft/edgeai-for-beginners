<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "f4b84b08208b791e7822f88127e498f5",
  "translation_date": "2025-11-11T23:01:55+00:00",
  "source_file": "Workshop/QUICK_REFERENCE.md",
  "language_code": "tr"
}
-->
# AtÃ¶lye Ã–rnekleri - HÄ±zlÄ± Referans KartÄ±

**Son GÃ¼ncelleme**: 8 Ekim 2025

---

## ğŸš€ HÄ±zlÄ± BaÅŸlangÄ±Ã§

```bash
# 1. Ensure Foundry Local is running
foundry service status
foundry model run phi-4-mini

# 2. Install dependencies
pip install -r Workshop/requirements.txt

# 3. Run a sample
cd Workshop/samples
python -m session01.chat_bootstrap "What is edge AI?"
```

---

## ğŸ“‚ Ã–rnek Genel BakÄ±ÅŸ

| Oturum | Ã–rnek | AmaÃ§ | SÃ¼re |
|--------|-------|------|------|
| 01 | `chat_bootstrap.py` | Temel sohbet + akÄ±ÅŸ | ~30s |
| 02 | `rag_pipeline.py` | Embedding ile RAG | ~45s |
| 02 | `rag_eval_ragas.py` | RAG deÄŸerlendirme | ~60s |
| 03 | `benchmark_oss_models.py` | Model karÅŸÄ±laÅŸtÄ±rma | ~2m |
| 04 | `model_compare.py` | SLM vs LLM | ~45s |
| 05 | `agents_orchestrator.py` | Ã‡oklu ajan sistemi | ~60s |
| 06 | `models_router.py` | Niyet yÃ¶nlendirme | ~45s |
| 06 | `models_pipeline.py` | Ã‡ok adÄ±mlÄ± iÅŸlem hattÄ± | ~60s |

---

## ğŸ› ï¸ Ortam DeÄŸiÅŸkenleri

### Temel
```bash
# Choose model
set FOUNDRY_LOCAL_ALIAS=phi-4-mini

# Override endpoint (optional)
set FOUNDRY_LOCAL_ENDPOINT=http://localhost:8000

# Show token usage
set SHOW_USAGE=1
```

### Oturuma Ã–zel
```bash
# Session 02: RAG
set RAG_QUESTION="What is local inference?"
set EMBED_MODEL=sentence-transformers/all-MiniLM-L6-v2

# Session 03: Benchmarking
set BENCH_MODELS=phi-4-mini,qwen2.5-0.5b
set BENCH_ROUNDS=3
set BENCH_STREAM=1

# Session 04: Comparison
set SLM_ALIAS=phi-4-mini
set LLM_ALIAS=qwen2.5-7b

# Session 05: Agents
set AGENT_MODEL_PRIMARY=phi-4-mini
set AGENT_QUESTION="Why use edge AI?"

# Session 06: Pipeline
set PIPELINE_TASK="Your task here"
```

---

## âœ… DoÄŸrulama ve Test

```bash
# Validate syntax and imports
python scripts/validate_samples.py

# Validate specific session
python scripts/validate_samples.py --session 01

# Run smoke tests
python scripts/test_samples.py --quick

# Verbose testing
python scripts/test_samples.py --verbose
```

---

## ğŸ› Sorun Giderme

### BaÄŸlantÄ± HatasÄ±
```bash
# Check Foundry Local
foundry service status

# Start if needed
foundry service start
foundry model run phi-4-mini
```

### Ä°Ã§e Aktarma HatasÄ±
```bash
# Install missing dependencies
pip install sentence-transformers ragas datasets

# Or install all
pip install -r Workshop/requirements.txt
```

### Model BulunamadÄ±
```bash
# List available models
foundry model ls

# Download model
foundry model download phi-4-mini
```

### YavaÅŸ Performans
```bash
# Use smaller model
set FOUNDRY_LOCAL_ALIAS=qwen2.5-0.5b

# Reduce benchmark rounds
set BENCH_ROUNDS=1
```

---

## ğŸ“– YaygÄ±n KalÄ±plar

### Temel Sohbet
```python
from workshop_utils import chat_once

text, usage = chat_once(
    'phi-4-mini',
    messages=[{"role": "user", "content": "Hello"}],
    max_tokens=100,
    temperature=0.7
)
```

### Ä°stemci Alma
```python
from workshop_utils import get_client

manager, client, model_id = get_client(
    alias='phi-4-mini',
    endpoint=None  # Auto-detect
)
```

### Hata YÃ¶netimi
```python
try:
    manager, client, model_id = get_client(alias)
except Exception as e:
    print(f"[ERROR] Failed: {e}")
    print("[INFO] Check: foundry service status")
    sys.exit(1)
```

### AkÄ±ÅŸ
```python
stream = client.chat.completions.create(
    model=model_id,
    messages=messages,
    stream=True
)

for chunk in stream:
    if chunk.choices[0].delta.content:
        print(chunk.choices[0].delta.content, end="", flush=True)
```

---

## ğŸ“Š Model SeÃ§imi

| Model | Boyut | En Ä°yi KullanÄ±m AlanÄ± | HÄ±z |
|-------|-------|------------------------|-----|
| `qwen2.5-0.5b` | 0.5B | HÄ±zlÄ± sÄ±nÄ±flandÄ±rma | âš¡âš¡âš¡ |
| `qwen2.5-coder-0.5b` | 0.5B | HÄ±zlÄ± kod Ã¼retimi | âš¡âš¡âš¡ |
| `gemma-2-2b` | 2B | YaratÄ±cÄ± yazÄ±m | âš¡âš¡ |
| `phi-3.5-mini` | 3.5B | Kod, yeniden dÃ¼zenleme | âš¡âš¡ |
| `phi-4-mini` | 4B | Genel, Ã¶zetleme | âš¡âš¡ |
| `qwen2.5-7b` | 7B | KarmaÅŸÄ±k akÄ±l yÃ¼rÃ¼tme | âš¡ |

---

## ğŸ”— Kaynaklar

- **SDK Belgeleri**: https://github.com/microsoft/Foundry-Local/tree/main/sdk/python
- **HÄ±zlÄ± Referans**: `Workshop/FOUNDRY_SDK_QUICKREF.md`

---

## ğŸ’¡ Ä°puÃ§larÄ±

1. **Ä°stemcileri Ã¶nbelleÄŸe alÄ±n**: `workshop_utils` sizin iÃ§in Ã¶nbelleÄŸe alÄ±r
2. **Daha kÃ¼Ã§Ã¼k modeller kullanÄ±n**: Test iÃ§in `qwen2.5-0.5b` ile baÅŸlayÄ±n
3. **KullanÄ±m istatistiklerini etkinleÅŸtirin**: Token takibi iÃ§in `SHOW_USAGE=1` ayarÄ±nÄ± yapÄ±n
4. **Toplu iÅŸlem yapÄ±n**: Birden fazla istemi sÄ±rayla iÅŸleyin
5. **max_tokens deÄŸerini dÃ¼ÅŸÃ¼rÃ¼n**: HÄ±zlÄ± yanÄ±tlar iÃ§in gecikmeyi azaltÄ±r

---

## ğŸ¯ Ã–rnek Ä°ÅŸ AkÄ±ÅŸlarÄ±

### Her Åeyi Test Et
```bash
python scripts/validate_samples.py
python scripts/test_samples.py --quick
```

### Modelleri KarÅŸÄ±laÅŸtÄ±r
```bash
cd samples
set BENCH_MODELS=phi-4-mini,qwen2.5-0.5b
set BENCH_ROUNDS=3
python -m session03.benchmark_oss_models
```

### RAG Ä°ÅŸlem HattÄ±
```bash
cd samples
set RAG_QUESTION="What is RAG?"
python -m session02.rag_pipeline
```

### Ã‡oklu Ajan Sistemi
```bash
cd samples
set AGENT_QUESTION="Why edge AI for healthcare?"
python -m session05.agents_orchestrator
```

---

**HÄ±zlÄ± YardÄ±m**: `samples` dizininden herhangi bir Ã¶rneÄŸi `--help` ile Ã§alÄ±ÅŸtÄ±rÄ±n veya docstring'e gÃ¶z atÄ±n:
```bash
python -c "import session01.chat_bootstrap; help(session01.chat_bootstrap)"
```

---

**TÃ¼m Ã¶rnekler Ekim 2025'te Foundry Local SDK en iyi uygulamalarÄ±yla gÃ¼ncellendi** âœ¨

---

<!-- CO-OP TRANSLATOR DISCLAIMER START -->
**Feragatname**:  
Bu belge, AI Ã§eviri hizmeti [Co-op Translator](https://github.com/Azure/co-op-translator) kullanÄ±larak Ã§evrilmiÅŸtir. DoÄŸruluk iÃ§in Ã§aba gÃ¶stersek de, otomatik Ã§evirilerin hata veya yanlÄ±ÅŸlÄ±klar iÃ§erebileceÄŸini lÃ¼tfen unutmayÄ±n. Belgenin orijinal dili, yetkili kaynak olarak kabul edilmelidir. Kritik bilgiler iÃ§in profesyonel insan Ã§evirisi Ã¶nerilir. Bu Ã§evirinin kullanÄ±mÄ±ndan kaynaklanan yanlÄ±ÅŸ anlamalar veya yanlÄ±ÅŸ yorumlamalar iÃ§in sorumluluk kabul etmiyoruz.
<!-- CO-OP TRANSLATOR DISCLAIMER END -->