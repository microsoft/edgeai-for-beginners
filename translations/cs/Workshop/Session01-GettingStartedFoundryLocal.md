# Sezen√≠ 1: Zaƒç√≠n√°me s Foundry Local

## Abstrakt

Nauƒçte se instalovat, konfigurovat a spou≈°tƒõt sv√© prvn√≠ AI modely pomoc√≠ Microsoft Foundry Local. Toto praktick√© sezen√≠ poskytuje krok za krokem √∫vod do lok√°ln√≠ inference, od instalace a≈æ po vytvo≈ôen√≠ va≈°√≠ prvn√≠ chatovac√≠ aplikace s modely jako Phi-4, Qwen a DeepSeek.

## C√≠le uƒçen√≠

Na konci tohoto sezen√≠ budete schopni:

- **Instalovat a konfigurovat**: Nastavit Foundry Local s ovƒõ≈ôen√≠m spr√°vn√© instalace
- **Ovl√°dnout CLI operace**: Pou≈æ√≠vat Foundry Local CLI pro spr√°vu a nasazen√≠ model≈Ø
- **Spustit sv≈Øj prvn√≠ model**: √öspƒõ≈°nƒõ nasadit a interagovat s lok√°ln√≠m AI modelem
- **Vytvo≈ôit chatovac√≠ aplikaci**: Vytvo≈ôit z√°kladn√≠ chatovac√≠ aplikaci pomoc√≠ Foundry Local Python SDK
- **Porozumƒõt lok√°ln√≠mu AI**: Pochopit z√°klady lok√°ln√≠ inference a spr√°vy model≈Ø

## Po≈æadavky

### Syst√©mov√© po≈æadavky

- **Windows**: Windows 11 (22H2 nebo novƒõj≈°√≠) NEBO **macOS**: macOS 11+ (omezen√° podpora)
- **RAM**: Minim√°lnƒõ 8GB, doporuƒçeno 16GB+
- **√ölo≈æi≈°tƒõ**: 10GB+ voln√©ho m√≠sta pro modely
- **Python**: Verze 3.10 nebo novƒõj≈°√≠
- **Administr√°torsk√Ω p≈ô√≠stup**: Pr√°va administr√°tora pro instalaci

### V√Ωvojov√© prost≈ôed√≠

- Visual Studio Code s roz≈°√≠≈ôen√≠m pro Python (doporuƒçeno)
- P≈ô√≠stup k p≈ô√≠kazov√©mu ≈ô√°dku (PowerShell na Windows, Terminal na macOS)
- Git pro klonov√°n√≠ repozit√°≈ô≈Ø (voliteln√©)

## Pr≈Øbƒõh workshopu (30 minut)

### Krok 1: Instalace Foundry Local (5 minut)

#### Instalace na Windows

Nainstalujte Foundry Local pomoc√≠ spr√°vce bal√≠ƒçk≈Ø pro Windows:

```powershell
# Install via winget (recommended)
winget install Microsoft.FoundryLocal
```

Alternativa: St√°hnƒõte p≈ô√≠mo z [Microsoft Learn](https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/install)

#### Instalace na macOS (omezen√° podpora)

> [!NOTE] 
> Podpora macOS je aktu√°lnƒõ v preview. Zkontrolujte ofici√°ln√≠ dokumentaci pro nejnovƒõj≈°√≠ dostupnost.

Pokud je dostupn√°, nainstalujte pomoc√≠ Homebrew:

```bash
# If Homebrew formula is available
brew update
brew install foundry-local

# Or manual download (check official docs for latest)
curl -L -o foundry-local.tar.gz "https://download.microsoft.com/foundry-local/latest/macos/foundry-local.tar.gz"
tar -xzf foundry-local.tar.gz
sudo ./install.sh
```

**Alternativa pro u≈æivatele macOS:**
- Pou≈æijte Windows 11 VM (Parallels/UTM) a postupujte podle krok≈Ø pro Windows
- Spus≈•te p≈ôes kontejner, pokud je dostupn√Ω, a nakonfigurujte `FOUNDRY_LOCAL_ENDPOINT`

### Krok 2: Ovƒõ≈ôen√≠ instalace (3 minuty)

Po instalaci restartujte sv≈Øj termin√°l a ovƒõ≈ôte, ≈æe Foundry Local funguje:

```powershell
# Check if Foundry Local is installed correctly
foundry --version

# View available commands
foundry --help
```

Oƒçek√°van√Ω v√Ωstup by mƒõl zobrazit informace o verzi a dostupn√© p≈ô√≠kazy.

### Krok 3: Nastaven√≠ Python prost≈ôed√≠ (5 minut)

Vytvo≈ôte dedikovan√© Python prost≈ôed√≠ pro tento workshop:

**Windows:**
```powershell
# Create virtual environment
py -m venv .venv

# Activate environment
.\.venv\Scripts\Activate.ps1

# Upgrade pip and install dependencies
python -m pip install --upgrade pip
pip install foundry-local-sdk openai
```

**macOS/Linux:**
```bash
# Create virtual environment
python3 -m venv .venv

# Activate environment
source .venv/bin/activate

# Upgrade pip and install dependencies
python -m pip install --upgrade pip
pip install foundry-local-sdk openai
```

### Krok 4: Spu≈°tƒõn√≠ va≈°eho prvn√≠ho modelu (7 minut)

Nyn√≠ spust√≠me n√°≈° prvn√≠ AI model lok√°lnƒõ!

#### Zaƒçnƒõte s Phi-4 Mini (doporuƒçen√Ω prvn√≠ model)

```powershell
# Download and start phi-4-mini (lightweight, fast)
foundry model run phi-4-mini

# Test the model with a simple prompt
foundry model run phi-4-mini --prompt "Hello, introduce yourself in one sentence"
```

> [!TIP]
> Tento p≈ô√≠kaz st√°hne model (poprv√©) a automaticky spust√≠ slu≈æbu Foundry Local.

#### Zkontrolujte, co bƒõ≈æ√≠

```powershell
# List available models (shows downloaded models)
foundry model list

# Check service status
foundry service status

# See what models are cached locally
foundry cache list
```

#### Vyzkou≈°ejte r≈Øzn√© modely

Jakmile phi-4-mini funguje, experimentujte s dal≈°√≠mi modely:

```powershell
# Larger model with better capabilities
foundry model run gpt-oss-20b --prompt "Explain edge AI in simple terms"

# Fast, efficient model
foundry model run qwen2.5-0.5b --prompt "What are the benefits of local AI inference?"
```

### Krok 5: Vytvo≈ôen√≠ va≈°√≠ prvn√≠ chatovac√≠ aplikace (10 minut)

Nyn√≠ vytvo≈ô√≠me Python aplikaci, kter√° vyu≈æ√≠v√° modely, kter√© jsme pr√°vƒõ spustili.

#### Vytvo≈ôen√≠ chatovac√≠ho skriptu

Vytvo≈ôte nov√Ω soubor nazvan√Ω `my_first_chat.py` (nebo pou≈æijte poskytnut√Ω vzorek):

```python
#!/usr/bin/env python3
"""
My First Foundry Local Chat Application
Using FoundryLocalManager for automatic service management
"""

import os
from foundry_local import FoundryLocalManager
from openai import OpenAI

def main():
    # Get model alias from environment or use default
    alias = os.getenv("FOUNDRY_LOCAL_ALIAS", "phi-4-mini")
    
    try:
        # Initialize Foundry Local Manager (auto-starts service, downloads model)
        manager = FoundryLocalManager(alias)
        
        # Create OpenAI client pointing to local endpoint
        client = OpenAI(
            base_url=manager.endpoint,
            api_key=manager.api_key or "not-needed"
        )
        
        # Get the actual model ID for this alias
        model_id = manager.get_model_info(alias).id
        
        print("ü§ñ Welcome to your first local AI chat!")
        print(f"ÔøΩ Using model: {alias} -> {model_id}")
        print(f"üåê Endpoint: {manager.endpoint}")
        print("ÔøΩüí° Type 'quit' to exit\n")
        
    except Exception as e:
        print(f"‚ùå Failed to initialize Foundry Local: {e}")
        print("üí° Make sure Foundry Local is installed: foundry --version")
        return
    
    while True:
        # Get user input
        user_message = input("You: ").strip()
        
        if user_message.lower() in ['quit', 'exit', 'bye']:
            print("üëã Goodbye!")
            break
            
        if not user_message:
            continue
            
        try:
            # Send message to local AI model
            response = client.chat.completions.create(
                model=model_id,
                messages=[
                    {"role": "system", "content": "You are a helpful AI assistant running locally."},
                    {"role": "user", "content": user_message}
                ],
                max_tokens=200,
                temperature=0.7
            )
            
            # Display the response
            ai_response = response.choices[0].message.content
            print(f"ü§ñ AI: {ai_response}\n")
            
        except Exception as e:
            print(f"‚ùå Error: {e}")
            print("üí° Check service status: foundry service status\n")

if __name__ == "__main__":
    main()
```

> [!TIP]
> **Souvisej√≠c√≠ p≈ô√≠klady**: Pro pokroƒçilej≈°√≠ pou≈æit√≠ viz:
>
> - **Python vzorek**: `Workshop/samples/session01/chat_bootstrap.py` - Zahrnuje streamov√°n√≠ odpovƒõd√≠ a zpracov√°n√≠ chyb
> - **Jupyter Notebook**: `Workshop/notebooks/session01_chat_bootstrap.ipynb` - Interaktivn√≠ verze s podrobn√Ωmi vysvƒõtlen√≠mi

#### Testov√°n√≠ va≈°√≠ chatovac√≠ aplikace

```powershell
# No need to manually start models - FoundryLocalManager handles this!
# Just run your chat application
python my_first_chat.py
```

Alternativa: Pou≈æijte p≈ô√≠mo poskytnut√© vzorky

```powershell
# Try the complete sample with streaming support
cd Workshop/samples
python -m session01.chat_bootstrap "Your question here"
```

Nebo prozkoumejte interaktivn√≠ notebook
Otev≈ôete Workshop/notebooks/session01_chat_bootstrap.ipynb ve VS Code

Vyzkou≈°ejte tyto p≈ô√≠klady konverzac√≠:

- "Co je Microsoft Foundry Local?"
- "Vyjmenuj 3 v√Ωhody provozov√°n√≠ AI model≈Ø lok√°lnƒõ"
- "Pomoz mi pochopit edge AI"

## Co jste dos√°hli

Gratulujeme! √öspƒõ≈°nƒõ jste:

1. ‚úÖ **Nainstalovali Foundry Local** a ovƒõ≈ôili jeho funkƒçnost
2. ‚úÖ **Spustili sv≈Øj prvn√≠ AI model** (phi-4-mini) lok√°lnƒõ
3. ‚úÖ **Otestovali r≈Øzn√© modely** p≈ôes p≈ô√≠kazov√Ω ≈ô√°dek
4. ‚úÖ **Vytvo≈ôili chatovac√≠ aplikaci**, kter√° se p≈ôipojuje k va≈°emu lok√°ln√≠mu AI
5. ‚úÖ **Za≈æili lok√°ln√≠ AI inference** bez z√°vislosti na cloudu

## Porozumƒõn√≠ tomu, co se stalo

### Lok√°ln√≠ AI inference

- Va≈°e AI modely bƒõ≈æ√≠ zcela na va≈°em poƒç√≠taƒçi
- ≈Ω√°dn√° data nejsou odes√≠l√°na do cloudu
- Odpovƒõdi jsou generov√°ny lok√°lnƒõ pomoc√≠ va≈°eho CPU/GPU
- Soukrom√≠ a bezpeƒçnost jsou zachov√°ny

### Spr√°va model≈Ø

- `foundry model run` stahuje a spou≈°t√≠ modely
- **FoundryLocalManager SDK** automaticky spravuje spu≈°tƒõn√≠ slu≈æby a naƒç√≠t√°n√≠ model≈Ø
- Modely jsou ukl√°d√°ny lok√°lnƒõ pro budouc√≠ pou≈æit√≠
- M≈Ø≈æe b√Ωt sta≈æeno v√≠ce model≈Ø, ale obvykle bƒõ≈æ√≠ jeden najednou
- Slu≈æba automaticky spravuje ≈æivotn√≠ cyklus model≈Ø

### SDK vs CLI p≈ô√≠stupy

- **CLI p≈ô√≠stup**: Manu√°ln√≠ spr√°va model≈Ø pomoc√≠ `foundry model run <model>`
- **SDK p≈ô√≠stup**: Automatick√° spr√°va slu≈æby + model≈Ø pomoc√≠ `FoundryLocalManager(alias)`
- **Doporuƒçen√≠**: Pou≈æ√≠vejte SDK pro aplikace, CLI pro testov√°n√≠ a pr≈Øzkum

## Referenƒçn√≠ p≈ô√≠kazy

### Z√°kladn√≠ CLI p≈ô√≠kazy

```powershell
# Installation & Setup
foundry --version              # Check installation
foundry --help                 # View all commands

# Model Management
foundry model list             # List available models
foundry model run <model>      # Download and start a model
foundry model run <model> --prompt "text"  # One-shot prompt
foundry cache list             # Show downloaded models

# Service Management
foundry service status         # Check if service is running
foundry service start          # Start the service manually
foundry service stop           # Stop the service
```

### Doporuƒçen√≠ model≈Ø

- **phi-4-mini**: Nejlep≈°√≠ startovac√≠ model - rychl√Ω, lehk√Ω, dobr√° kvalita
- **qwen2.5-0.5b**: Nejrychlej≈°√≠ inference, minim√°ln√≠ vyu≈æit√≠ pamƒõti
- **gpt-oss-20b**: Vy≈°≈°√≠ kvalita odpovƒõd√≠, vy≈æaduje v√≠ce zdroj≈Ø
- **deepseek-coder-1.3b**: Optimalizov√°no pro programov√°n√≠ a √∫koly s k√≥dem

## ≈òe≈°en√≠ probl√©m≈Ø

### "Foundry command not found"

**≈òe≈°en√≠:**

```powershell
# Restart your terminal after installation
# Or manually add to PATH (Windows)
$env:PATH += ";C:\Program Files\Microsoft\FoundryLocal"
```

### "Model failed to load"

**≈òe≈°en√≠:**

```powershell
# Check available system memory
foundry service status

# Try a smaller model first
foundry model run phi-4-mini

# Check disk space for model downloads
# Models are stored in: %USERPROFILE%\.foundry\models (Windows)
```

### "Connection refused on localhost"

**≈òe≈°en√≠:**

```powershell
# Check if service is running
foundry service status

# Start service if needed
foundry service start

# Verify the port (default is 5273)
# Check for port conflicts with: netstat -an | findstr 5273
```

## Dal≈°√≠ kroky

### Okam≈æit√© dal≈°√≠ akce

1. **Experimentujte** s r≈Øzn√Ωmi modely a dotazy
2. **Upravte** svou chatovac√≠ aplikaci a vyzkou≈°ejte r≈Øzn√© modely
3. **Vytvo≈ôte** vlastn√≠ dotazy a testujte odpovƒõdi
4. **Prozkoumejte** Sezen√≠ 2: Vytv√°≈ôen√≠ RAG aplikac√≠

### Pokroƒçil√° vzdƒõl√°vac√≠ cesta

1. **Sezen√≠ 2**: Vytv√°≈ôen√≠ AI ≈ôe≈°en√≠ s RAG (Retrieval-Augmented Generation)
2. **Sezen√≠ 3**: Porovn√°n√≠ r≈Øzn√Ωch open-source model≈Ø
3. **Sezen√≠ 4**: Pr√°ce s nejmodernƒõj≈°√≠mi modely
4. **Sezen√≠ 5**: Vytv√°≈ôen√≠ multi-agentn√≠ch AI syst√©m≈Ø

## Promƒõnn√© prost≈ôed√≠ (voliteln√©)

Pro pokroƒçilej≈°√≠ pou≈æit√≠ m≈Ø≈æete nastavit tyto promƒõnn√© prost≈ôed√≠:

| Promƒõnn√° | √öƒçel | P≈ô√≠klad |
|----------|---------|---------|
| `FOUNDRY_LOCAL_ALIAS` | V√Ωchoz√≠ model k pou≈æit√≠ | `phi-4-mini` |
| `FOUNDRY_LOCAL_ENDPOINT` | P≈ôeps√°n√≠ URL endpointu | `http://localhost:5273/v1` |

Vytvo≈ôte soubor `.env` ve va≈°em projektov√©m adres√°≈ôi:
```
FOUNDRY_LOCAL_ALIAS=phi-4-mini
FOUNDRY_LOCAL_ENDPOINT=auto
```

## Dal≈°√≠ zdroje

### Dokumentace

- [Foundry Local Python SDK Reference](https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/reference/reference-sdk?pivots=programming-language-python)
- [Foundry Local Installation Guide](https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/install)
- [Model Catalog](https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/models)

### Uk√°zkov√Ω k√≥d

- **Session01 Python Sample**: `Workshop/samples/session01/chat_bootstrap.py` - Kompletn√≠ chatovac√≠ aplikace se streamov√°n√≠m
- **Session01 Notebook**: `Workshop/notebooks/session01_chat_bootstrap.ipynb` - Interaktivn√≠ tutori√°l  
- [Module08 Sample 01](../Module08/samples/01/README.md) - REST Chat Quickstart
- [Module08 Sample 02](../Module08/samples/02/README.md) - Integrace OpenAI SDK
- [Module08 Sample 03](../Module08/samples/03/README.md) - Objevov√°n√≠ model≈Ø a benchmarking

### Komunita

- [Foundry Local GitHub Discussions](https://github.com/microsoft/Foundry-Local/discussions)
- [Azure AI Community](https://techcommunity.microsoft.com/category/artificialintelligence)

---

**D√©lka sezen√≠**: 30 minut prakticky + 15 minut Q&A  
**√örove≈à obt√≠≈ænosti**: Zaƒç√°teƒçn√≠k  
**Po≈æadavky**: Windows 11/macOS 11+, Python 3.10+, administr√°torsk√Ω p≈ô√≠stup

## P≈ô√≠klad sc√©n√°≈ôe workshopu

### Kontext z re√°ln√©ho svƒõta

**Sc√©n√°≈ô**: IT t√Ωm v podniku pot≈ôebuje vyhodnotit inference AI na za≈ô√≠zen√≠ pro zpracov√°n√≠ citliv√© zpƒõtn√© vazby zamƒõstnanc≈Ø bez odes√≠l√°n√≠ dat do extern√≠ch slu≈æeb.

**V√°≈° c√≠l**: Demonstrovat, ≈æe lok√°ln√≠ AI modely mohou poskytovat kvalitn√≠ odpovƒõdi s latenc√≠ pod jednu sekundu p≈ôi zachov√°n√≠ √∫pln√©ho soukrom√≠ dat.

### Testovac√≠ dotazy

Pou≈æijte tyto dotazy k ovƒõ≈ôen√≠ va≈°eho nastaven√≠:

```json
[
    "List two benefits of local inference.",
    "Summarize why keeping data on device improves privacy.",
    "Give one trade-off when choosing a small model over a large model."
]
```

### Krit√©ria √∫spƒõchu

- ‚úÖ V≈°echny dotazy obdr≈æ√≠ odpovƒõdi do 2 sekund
- ‚úÖ ≈Ω√°dn√° data neopust√≠ v√°≈° lok√°ln√≠ poƒç√≠taƒç
- ‚úÖ Odpovƒõdi jsou relevantn√≠ a u≈æiteƒçn√©
- ‚úÖ Va≈°e chatovac√≠ aplikace funguje hladce

Toto ovƒõ≈ôen√≠ zajist√≠, ≈æe va≈°e nastaven√≠ Foundry Local je p≈ôipraveno na pokroƒçil√© workshopy v sezen√≠ch 2-6.

---

<!-- CO-OP TRANSLATOR DISCLAIMER START -->
**Prohl√°≈°en√≠**:  
Tento dokument byl p≈ôelo≈æen pomoc√≠ slu≈æby AI pro p≈ôeklady [Co-op Translator](https://github.com/Azure/co-op-translator). Aƒçkoli se sna≈æ√≠me o p≈ôesnost, mƒõjte pros√≠m na pamƒõti, ≈æe automatizovan√© p≈ôeklady mohou obsahovat chyby nebo nep≈ôesnosti. P≈Øvodn√≠ dokument v jeho p≈Øvodn√≠m jazyce by mƒõl b√Ωt pova≈æov√°n za autoritativn√≠ zdroj. Pro d≈Øle≈æit√© informace se doporuƒçuje profesion√°ln√≠ lidsk√Ω p≈ôeklad. Neodpov√≠d√°me za ≈æ√°dn√° nedorozumƒõn√≠ nebo nespr√°vn√© interpretace vypl√Ωvaj√≠c√≠ z pou≈æit√≠ tohoto p≈ôekladu.
<!-- CO-OP TRANSLATOR DISCLAIMER END -->