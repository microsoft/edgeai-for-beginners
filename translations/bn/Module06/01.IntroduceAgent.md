<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "44bc28c27b993c5fb988791b7a115705",
  "translation_date": "2025-10-30T11:44:50+00:00",
  "source_file": "Module06/01.IntroduceAgent.md",
  "language_code": "bn"
}
-->
# à¦à¦†à¦‡ à¦à¦œà§‡à¦¨à§à¦Ÿ à¦à¦¬à¦‚ à¦›à§‹à¦Ÿ à¦­à¦¾à¦·à¦¾ à¦®à¦¡à§‡à¦²: à¦à¦•à¦Ÿà¦¿ à¦¬à¦¿à¦¸à§à¦¤à§ƒà¦¤ à¦—à¦¾à¦‡à¦¡

## à¦­à§‚à¦®à¦¿à¦•à¦¾

à¦à¦‡ à¦Ÿà¦¿à¦‰à¦Ÿà§‹à¦°à¦¿à¦¯à¦¼à¦¾à¦²à§‡, à¦†à¦®à¦°à¦¾ à¦à¦†à¦‡ à¦à¦œà§‡à¦¨à§à¦Ÿ à¦à¦¬à¦‚ à¦›à§‹à¦Ÿ à¦­à¦¾à¦·à¦¾ à¦®à¦¡à§‡à¦² (SLMs) à¦à¦¬à¦‚ à¦¤à¦¾à¦¦à§‡à¦° à¦‰à¦¨à§à¦¨à¦¤ à¦¬à¦¾à¦¸à§à¦¤à¦¬à¦¾à¦¯à¦¼à¦¨ à¦•à§Œà¦¶à¦²à¦—à§à¦²à¦¿ à¦ªà§à¦°à¦¾à¦¨à§à¦¤ à¦•à¦®à§à¦ªà¦¿à¦‰à¦Ÿà¦¿à¦‚ à¦ªà¦°à¦¿à¦¬à§‡à¦¶à§‡à¦° à¦œà¦¨à§à¦¯ à¦…à¦¨à§à¦¬à§‡à¦·à¦£ à¦•à¦°à¦¬à¥¤ à¦†à¦®à¦°à¦¾ à¦à¦œà§‡à¦¨à§à¦Ÿà¦¿à¦• à¦à¦†à¦‡-à¦à¦° à¦®à§Œà¦²à¦¿à¦• à¦§à¦¾à¦°à¦£à¦¾, SLM à¦…à¦ªà§à¦Ÿà¦¿à¦®à¦¾à¦‡à¦œà§‡à¦¶à¦¨ à¦•à§Œà¦¶à¦², à¦¸à§€à¦®à¦¿à¦¤ à¦¸à¦®à§à¦ªà¦¦à¦¯à§à¦•à§à¦¤ à¦¡à¦¿à¦­à¦¾à¦‡à¦¸à§‡à¦° à¦œà¦¨à§à¦¯ à¦¬à§à¦¯à¦¬à¦¹à¦¾à¦°à¦¿à¦• à¦¸à§à¦¥à¦¾à¦ªà¦¨à¦¾à¦° à¦•à§Œà¦¶à¦² à¦à¦¬à¦‚ à¦ªà§à¦°à§‹à¦¡à¦¾à¦•à¦¶à¦¨-à¦°à§‡à¦¡à¦¿ à¦à¦œà§‡à¦¨à§à¦Ÿ à¦¸à¦¿à¦¸à§à¦Ÿà§‡à¦® à¦¤à§ˆà¦°à¦¿à¦° à¦œà¦¨à§à¦¯ Microsoft Agent Framework à¦¨à¦¿à¦¯à¦¼à§‡ à¦†à¦²à§‹à¦šà¦¨à¦¾ à¦•à¦°à¦¬à¥¤

à¦•à§ƒà¦¤à§à¦°à¦¿à¦® à¦¬à§à¦¦à§à¦§à¦¿à¦®à¦¤à§à¦¤à¦¾à¦° à¦•à§à¦·à§‡à¦¤à§à¦°à¦Ÿà¦¿ à§¨à§¦à§¨à§« à¦¸à¦¾à¦²à§‡ à¦à¦•à¦Ÿà¦¿ à¦®à§Œà¦²à¦¿à¦• à¦ªà¦°à¦¿à¦¬à¦°à§à¦¤à¦¨à§‡à¦° à¦®à¦§à§à¦¯ à¦¦à¦¿à¦¯à¦¼à§‡ à¦¯à¦¾à¦šà§à¦›à§‡à¥¤ à§¨à§¦à§¨à§© à¦›à¦¿à¦² à¦šà§à¦¯à¦¾à¦Ÿà¦¬à¦Ÿà§‡à¦° à¦¬à¦›à¦° à¦à¦¬à¦‚ à§¨à§¦à§¨à§ª-à¦ à¦•à§‹-à¦ªà¦¾à¦‡à¦²à¦Ÿà§‡à¦° à¦‰à¦¤à§à¦¥à¦¾à¦¨ à¦¦à§‡à¦–à¦¾ à¦—à§‡à¦›à§‡, à§¨à§¦à§¨à§« à¦à¦†à¦‡ à¦à¦œà§‡à¦¨à§à¦Ÿà§‡à¦° â€” à¦¬à§à¦¦à§à¦§à¦¿à¦®à¦¾à¦¨ à¦¸à¦¿à¦¸à§à¦Ÿà§‡à¦® à¦¯à¦¾ à¦šà¦¿à¦¨à§à¦¤à¦¾ à¦•à¦°à§‡, à¦¯à§à¦•à§à¦¤à¦¿ à¦•à¦°à§‡, à¦ªà¦°à¦¿à¦•à¦²à§à¦ªà¦¨à¦¾ à¦•à¦°à§‡, à¦¸à¦°à¦žà§à¦œà¦¾à¦® à¦¬à§à¦¯à¦¬à¦¹à¦¾à¦° à¦•à¦°à§‡ à¦à¦¬à¦‚ à¦¨à§à¦¯à§‚à¦¨à¦¤à¦® à¦®à¦¾à¦¨à¦¬ à¦‡à¦¨à¦ªà§à¦Ÿ à¦¦à¦¿à¦¯à¦¼à§‡ à¦•à¦¾à¦œ à¦¸à¦®à§à¦ªà¦¾à¦¦à¦¨ à¦•à¦°à§‡, à¦¯à¦¾ à¦•à§à¦°à¦®à¦¬à¦°à§à¦§à¦®à¦¾à¦¨à¦­à¦¾à¦¬à§‡ à¦¦à¦•à§à¦· à¦›à§‹à¦Ÿ à¦­à¦¾à¦·à¦¾ à¦®à¦¡à§‡à¦² à¦¦à§à¦¬à¦¾à¦°à¦¾ à¦šà¦¾à¦²à¦¿à¦¤à¥¤ Microsoft Agent Framework à¦…à¦«à¦²à¦¾à¦‡à¦¨ à¦ªà§à¦°à¦¾à¦¨à§à¦¤-à¦­à¦¿à¦¤à§à¦¤à¦¿à¦• à¦¸à¦•à§à¦·à¦®à¦¤à¦¾à¦° à¦¸à¦¾à¦¥à§‡ à¦à¦‡ à¦¬à§à¦¦à§à¦§à¦¿à¦®à¦¾à¦¨ à¦¸à¦¿à¦¸à§à¦Ÿà§‡à¦®à¦—à§à¦²à¦¿ à¦¤à§ˆà¦°à¦¿à¦° à¦œà¦¨à§à¦¯ à¦à¦•à¦Ÿà¦¿ à¦¶à§€à¦°à§à¦·à¦¸à§à¦¥à¦¾à¦¨à§€à¦¯à¦¼ à¦¸à¦®à¦¾à¦§à¦¾à¦¨ à¦¹à¦¿à¦¸à¦¾à¦¬à§‡ à¦†à¦¬à¦¿à¦°à§à¦­à§‚à¦¤ à¦¹à¦¯à¦¼à§‡à¦›à§‡à¥¤

## à¦¶à§‡à¦–à¦¾à¦° à¦²à¦•à§à¦·à§à¦¯

à¦à¦‡ à¦Ÿà¦¿à¦‰à¦Ÿà§‹à¦°à¦¿à¦¯à¦¼à¦¾à¦² à¦¶à§‡à¦·à§‡, à¦†à¦ªà¦¨à¦¿ à¦¸à¦•à§à¦·à¦® à¦¹à¦¬à§‡à¦¨:

- ðŸ¤– à¦à¦†à¦‡ à¦à¦œà§‡à¦¨à§à¦Ÿ à¦à¦¬à¦‚ à¦à¦œà§‡à¦¨à§à¦Ÿà¦¿à¦• à¦¸à¦¿à¦¸à§à¦Ÿà§‡à¦®à§‡à¦° à¦®à§Œà¦²à¦¿à¦• à¦§à¦¾à¦°à¦£à¦¾ à¦¬à§à¦à¦¤à§‡
- ðŸ”¬ à¦à¦œà§‡à¦¨à§à¦Ÿà¦¿à¦• à¦…à§à¦¯à¦¾à¦ªà§à¦²à¦¿à¦•à§‡à¦¶à¦¨à§‡ à¦¬à¦¡à¦¼ à¦­à¦¾à¦·à¦¾ à¦®à¦¡à§‡à¦²à§‡à¦° à¦¤à§à¦²à¦¨à¦¾à¦¯à¦¼ à¦›à§‹à¦Ÿ à¦­à¦¾à¦·à¦¾ à¦®à¦¡à§‡à¦²à§‡à¦° à¦¸à§à¦¬à¦¿à¦§à¦¾ à¦šà¦¿à¦¹à§à¦¨à¦¿à¦¤ à¦•à¦°à¦¤à§‡
- ðŸš€ à¦ªà§à¦°à¦¾à¦¨à§à¦¤ à¦•à¦®à§à¦ªà¦¿à¦‰à¦Ÿà¦¿à¦‚ à¦ªà¦°à¦¿à¦¬à§‡à¦¶à§‡à¦° à¦œà¦¨à§à¦¯ à¦‰à¦¨à§à¦¨à¦¤ SLM à¦¸à§à¦¥à¦¾à¦ªà¦¨à¦¾à¦° à¦•à§Œà¦¶à¦² à¦¶à¦¿à¦–à¦¤à§‡
- ðŸ“± à¦¬à¦¾à¦¸à§à¦¤à¦¬-à¦œà¦—à¦¤à§‡à¦° à¦…à§à¦¯à¦¾à¦ªà§à¦²à¦¿à¦•à§‡à¦¶à¦¨à§‡à¦° à¦œà¦¨à§à¦¯ à¦¬à§à¦¯à¦¬à¦¹à¦¾à¦°à¦¿à¦• SLM-à¦šà¦¾à¦²à¦¿à¦¤ à¦à¦œà§‡à¦¨à§à¦Ÿ à¦¬à¦¾à¦¸à§à¦¤à¦¬à¦¾à¦¯à¦¼à¦¨ à¦•à¦°à¦¤à§‡
- ðŸ—ï¸ Microsoft Agent Framework à¦¬à§à¦¯à¦¬à¦¹à¦¾à¦° à¦•à¦°à§‡ à¦ªà§à¦°à§‹à¦¡à¦¾à¦•à¦¶à¦¨-à¦°à§‡à¦¡à¦¿ à¦à¦œà§‡à¦¨à§à¦Ÿ à¦¤à§ˆà¦°à¦¿ à¦•à¦°à¦¤à§‡
- ðŸŒ à¦¸à§à¦¥à¦¾à¦¨à§€à¦¯à¦¼ LLM à¦à¦¬à¦‚ SLM à¦‡à¦¨à§à¦Ÿà¦¿à¦—à§à¦°à§‡à¦¶à¦¨à§‡à¦° à¦¸à¦¾à¦¥à§‡ à¦…à¦«à¦²à¦¾à¦‡à¦¨ à¦ªà§à¦°à¦¾à¦¨à§à¦¤-à¦­à¦¿à¦¤à§à¦¤à¦¿à¦• à¦à¦œà§‡à¦¨à§à¦Ÿ à¦¸à§à¦¥à¦¾à¦ªà¦¨ à¦•à¦°à¦¤à§‡
- ðŸ”§ à¦ªà§à¦°à¦¾à¦¨à§à¦¤ à¦¸à§à¦¥à¦¾à¦ªà¦¨à¦¾à¦° à¦œà¦¨à§à¦¯ Foundry Local-à¦à¦° à¦¸à¦¾à¦¥à§‡ Microsoft Agent Framework à¦‡à¦¨à§à¦Ÿà¦¿à¦—à§à¦°à§‡à¦Ÿ à¦•à¦°à¦¤à§‡

## à¦à¦†à¦‡ à¦à¦œà§‡à¦¨à§à¦Ÿ à¦¬à§‹à¦à¦¾: à¦­à¦¿à¦¤à§à¦¤à¦¿ à¦à¦¬à¦‚ à¦¶à§à¦°à§‡à¦£à§€à¦¬à¦¿à¦­à¦¾à¦—

### à¦¸à¦‚à¦œà§à¦žà¦¾ à¦à¦¬à¦‚ à¦®à§‚à¦² à¦§à¦¾à¦°à¦£à¦¾

à¦à¦•à¦Ÿà¦¿ à¦•à§ƒà¦¤à§à¦°à¦¿à¦® à¦¬à§à¦¦à§à¦§à¦¿à¦®à¦¤à§à¦¤à¦¾ (AI) à¦à¦œà§‡à¦¨à§à¦Ÿ à¦à¦®à¦¨ à¦à¦•à¦Ÿà¦¿ à¦¸à¦¿à¦¸à§à¦Ÿà§‡à¦® à¦¬à¦¾ à¦ªà§à¦°à§‹à¦—à§à¦°à¦¾à¦®à¦•à§‡ à¦¬à§‹à¦à¦¾à¦¯à¦¼ à¦¯à¦¾ à¦¬à§à¦¯à¦¬à¦¹à¦¾à¦°à¦•à¦¾à¦°à§€ à¦¬à¦¾ à¦…à¦¨à§à¦¯ à¦¸à¦¿à¦¸à§à¦Ÿà§‡à¦®à§‡à¦° à¦ªà¦•à§à¦· à¦¥à§‡à¦•à§‡ à¦¸à§à¦¬à¦¯à¦¼à¦‚à¦•à§à¦°à¦¿à¦¯à¦¼à¦­à¦¾à¦¬à§‡ à¦•à¦¾à¦œ à¦¸à¦®à§à¦ªà¦¾à¦¦à¦¨ à¦•à¦°à¦¤à§‡ à¦¸à¦•à§à¦·à¦® à¦¹à¦¯à¦¼, à¦¤à¦¾à¦° à¦•à¦°à§à¦®à¦ªà§à¦°à¦¬à¦¾à¦¹ à¦¡à¦¿à¦œà¦¾à¦‡à¦¨ à¦•à¦°à§‡ à¦à¦¬à¦‚ à¦‰à¦ªà¦²à¦¬à§à¦§ à¦¸à¦°à¦žà§à¦œà¦¾à¦®à¦—à§à¦²à¦¿ à¦¬à§à¦¯à¦¬à¦¹à¦¾à¦° à¦•à¦°à§‡à¥¤ à¦à¦¤à¦¿à¦¹à§à¦¯à¦¬à¦¾à¦¹à§€ à¦à¦†à¦‡-à¦à¦° à¦¬à¦¿à¦ªà¦°à§€à¦¤à§‡, à¦¯à¦¾ à¦¶à§à¦§à§à¦®à¦¾à¦¤à§à¦° à¦†à¦ªà¦¨à¦¾à¦° à¦ªà§à¦°à¦¶à§à¦¨à§‡à¦° à¦‰à¦¤à§à¦¤à¦° à¦¦à§‡à¦¯à¦¼, à¦à¦•à¦Ÿà¦¿ à¦à¦œà§‡à¦¨à§à¦Ÿ à¦¸à§à¦¬à¦¾à¦§à§€à¦¨à¦­à¦¾à¦¬à§‡ à¦•à¦¾à¦œ à¦•à¦°à¦¤à§‡ à¦ªà¦¾à¦°à§‡ à¦à¦¬à¦‚ à¦²à¦•à§à¦·à§à¦¯ à¦…à¦°à§à¦œà¦¨ à¦•à¦°à¦¤à§‡ à¦ªà¦¾à¦°à§‡à¥¤

### à¦à¦œà§‡à¦¨à§à¦Ÿ à¦¶à§à¦°à§‡à¦£à§€à¦¬à¦¿à¦­à¦¾à¦— à¦•à¦¾à¦ à¦¾à¦®à§‹

à¦à¦œà§‡à¦¨à§à¦Ÿà§‡à¦° à¦¸à§€à¦®à¦¾à¦¨à¦¾ à¦¬à§‹à¦à¦¾ à¦¬à¦¿à¦­à¦¿à¦¨à§à¦¨ à¦•à¦®à§à¦ªà¦¿à¦‰à¦Ÿà¦¿à¦‚ à¦ªà¦°à¦¿à¦¸à§à¦¥à¦¿à¦¤à¦¿à¦° à¦œà¦¨à§à¦¯ à¦‰à¦ªà¦¯à§à¦•à§à¦¤ à¦à¦œà§‡à¦¨à§à¦Ÿà§‡à¦° à¦§à¦°à¦¨ à¦¨à¦¿à¦°à§à¦¬à¦¾à¦šà¦¨ à¦•à¦°à¦¤à§‡ à¦¸à¦¾à¦¹à¦¾à¦¯à§à¦¯ à¦•à¦°à§‡:

- **ðŸ”¬ à¦¸à¦¾à¦§à¦¾à¦°à¦£ à¦°à¦¿à¦«à§à¦²à§‡à¦•à§à¦¸ à¦à¦œà§‡à¦¨à§à¦Ÿ**: à¦¨à¦¿à¦¯à¦¼à¦®-à¦­à¦¿à¦¤à§à¦¤à¦¿à¦• à¦¸à¦¿à¦¸à§à¦Ÿà§‡à¦® à¦¯à¦¾ à¦¤à¦¾à§Žà¦•à§à¦·à¦£à¦¿à¦• à¦‰à¦ªà¦²à¦¬à§à¦§à¦¿à¦¤à§‡ à¦¸à¦¾à¦¡à¦¼à¦¾ à¦¦à§‡à¦¯à¦¼ (à¦¥à¦¾à¦°à§à¦®à§‹à¦¸à§à¦Ÿà§à¦¯à¦¾à¦Ÿ, à¦®à§Œà¦²à¦¿à¦• à¦…à¦Ÿà§‹à¦®à§‡à¦¶à¦¨)
- **ðŸ“± à¦®à¦¡à§‡à¦²-à¦­à¦¿à¦¤à§à¦¤à¦¿à¦• à¦à¦œà§‡à¦¨à§à¦Ÿ**: à¦¸à¦¿à¦¸à§à¦Ÿà§‡à¦® à¦¯à¦¾ à¦…à¦­à§à¦¯à¦¨à§à¦¤à¦°à§€à¦£ à¦…à¦¬à¦¸à§à¦¥à¦¾ à¦à¦¬à¦‚ à¦¸à§à¦®à§ƒà¦¤à¦¿ à¦¬à¦œà¦¾à¦¯à¦¼ à¦°à¦¾à¦–à§‡ (à¦°à§‹à¦¬à¦Ÿ à¦­à§à¦¯à¦¾à¦•à§à¦¯à¦¼à¦¾à¦®, à¦¨à§‡à¦­à¦¿à¦—à§‡à¦¶à¦¨ à¦¸à¦¿à¦¸à§à¦Ÿà§‡à¦®)
- **âš–ï¸ à¦²à¦•à§à¦·à§à¦¯-à¦­à¦¿à¦¤à§à¦¤à¦¿à¦• à¦à¦œà§‡à¦¨à§à¦Ÿ**: à¦¸à¦¿à¦¸à§à¦Ÿà§‡à¦® à¦¯à¦¾ à¦²à¦•à§à¦·à§à¦¯ à¦…à¦°à§à¦œà¦¨à§‡à¦° à¦œà¦¨à§à¦¯ à¦•à§à¦°à¦® à¦ªà¦°à¦¿à¦•à¦²à§à¦ªà¦¨à¦¾ à¦à¦¬à¦‚ à¦¸à¦®à§à¦ªà¦¾à¦¦à¦¨ à¦•à¦°à§‡ (à¦°à§à¦Ÿ à¦ªà§à¦²à§à¦¯à¦¾à¦¨à¦¾à¦°, à¦Ÿà¦¾à¦¸à§à¦• à¦¶à¦¿à¦¡à¦¿à¦‰à¦²à¦¾à¦°)
- **ðŸ§  à¦¶à§‡à¦–à¦¾à¦° à¦à¦œà§‡à¦¨à§à¦Ÿ**: à¦…à¦­à¦¿à¦¯à§‹à¦œà¦¿à¦¤ à¦¸à¦¿à¦¸à§à¦Ÿà§‡à¦® à¦¯à¦¾ à¦¸à¦®à¦¯à¦¼à§‡à¦° à¦¸à¦¾à¦¥à§‡ à¦•à¦°à§à¦®à¦•à§à¦·à¦®à¦¤à¦¾ à¦‰à¦¨à§à¦¨à¦¤ à¦•à¦°à§‡ (à¦ªà§à¦°à¦¸à§à¦¤à¦¾à¦¬à¦¨à¦¾ à¦¸à¦¿à¦¸à§à¦Ÿà§‡à¦®, à¦¬à§à¦¯à¦•à§à¦¤à¦¿à¦—à¦¤ à¦¸à¦¹à¦•à¦¾à¦°à§€)

### à¦à¦†à¦‡ à¦à¦œà§‡à¦¨à§à¦Ÿà§‡à¦° à¦®à§‚à¦² à¦¸à§à¦¬à¦¿à¦§à¦¾

à¦à¦†à¦‡ à¦à¦œà§‡à¦¨à§à¦Ÿà¦—à§à¦²à¦¿ à¦¬à§‡à¦¶ à¦•à¦¯à¦¼à§‡à¦•à¦Ÿà¦¿ à¦®à§Œà¦²à¦¿à¦• à¦¸à§à¦¬à¦¿à¦§à¦¾ à¦ªà§à¦°à¦¦à¦¾à¦¨ à¦•à¦°à§‡ à¦¯à¦¾ à¦¤à¦¾à¦¦à§‡à¦° à¦ªà§à¦°à¦¾à¦¨à§à¦¤ à¦•à¦®à§à¦ªà¦¿à¦‰à¦Ÿà¦¿à¦‚ à¦…à§à¦¯à¦¾à¦ªà§à¦²à¦¿à¦•à§‡à¦¶à¦¨à§‡à¦° à¦œà¦¨à§à¦¯ à¦†à¦¦à¦°à§à¦¶ à¦•à¦°à§‡ à¦¤à§‹à¦²à§‡:

**à¦…à¦ªà¦¾à¦°à§‡à¦¶à¦¨à¦¾à¦² à¦¸à§à¦¬à¦¾à¦¯à¦¼à¦¤à§à¦¤à¦¶à¦¾à¦¸à¦¨**: à¦à¦œà§‡à¦¨à§à¦Ÿà¦—à§à¦²à¦¿ à¦¸à§à¦¬à¦¾à¦§à§€à¦¨à¦­à¦¾à¦¬à§‡ à¦•à¦¾à¦œ à¦¸à¦®à§à¦ªà¦¾à¦¦à¦¨ à¦•à¦°à§‡, à¦¯à¦¾ à¦¤à¦¾à¦¦à§‡à¦° à¦°à¦¿à¦¯à¦¼à§‡à¦²-à¦Ÿà¦¾à¦‡à¦® à¦…à§à¦¯à¦¾à¦ªà§à¦²à¦¿à¦•à§‡à¦¶à¦¨à§‡à¦° à¦œà¦¨à§à¦¯ à¦†à¦¦à¦°à§à¦¶ à¦•à¦°à§‡ à¦¤à§‹à¦²à§‡à¥¤ à¦¤à¦¾à¦°à¦¾ à¦¨à§à¦¯à§‚à¦¨à¦¤à¦® à¦¤à¦¤à§à¦¤à§à¦¬à¦¾à¦¬à¦§à¦¾à¦¨à§‡à¦° à¦ªà§à¦°à¦¯à¦¼à§‹à¦œà¦¨ à¦¹à¦¯à¦¼ à¦à¦¬à¦‚ à¦…à¦­à¦¿à¦¯à§‹à¦œà¦¿à¦¤ à¦†à¦šà¦°à¦£ à¦¬à¦œà¦¾à¦¯à¦¼ à¦°à¦¾à¦–à§‡, à¦¯à¦¾ à¦¸à§€à¦®à¦¿à¦¤ à¦¸à¦®à§à¦ªà¦¦à¦¯à§à¦•à§à¦¤ à¦¡à¦¿à¦­à¦¾à¦‡à¦¸à§‡ à¦•à¦® à¦…à¦ªà¦¾à¦°à§‡à¦¶à¦¨à¦¾à¦² à¦“à¦­à¦¾à¦°à¦¹à§‡à¦¡ à¦¸à¦¹ à¦¸à§à¦¥à¦¾à¦ªà¦¨ à¦¸à¦•à§à¦·à¦® à¦•à¦°à§‡à¥¤

**à¦¸à§à¦¥à¦¾à¦ªà¦¨à¦¾à¦° à¦¨à¦®à¦¨à§€à¦¯à¦¼à¦¤à¦¾**: à¦à¦‡ à¦¸à¦¿à¦¸à§à¦Ÿà§‡à¦®à¦—à§à¦²à¦¿ à¦‡à¦¨à§à¦Ÿà¦¾à¦°à¦¨à§‡à¦Ÿ à¦¸à¦‚à¦¯à§‹à¦—à§‡à¦° à¦ªà§à¦°à¦¯à¦¼à§‹à¦œà¦¨ à¦›à¦¾à¦¡à¦¼à¦¾à¦‡ à¦…à¦¨-à¦¡à¦¿à¦­à¦¾à¦‡à¦¸ à¦à¦†à¦‡ à¦¸à¦•à§à¦·à¦®à¦¤à¦¾ à¦ªà§à¦°à¦¦à¦¾à¦¨ à¦•à¦°à§‡, à¦¸à§à¦¥à¦¾à¦¨à§€à¦¯à¦¼ à¦ªà§à¦°à¦•à§à¦°à¦¿à¦¯à¦¼à¦¾à¦•à¦°à¦£à§‡à¦° à¦®à¦¾à¦§à§à¦¯à¦®à§‡ à¦—à§‹à¦ªà¦¨à§€à¦¯à¦¼à¦¤à¦¾ à¦à¦¬à¦‚ à¦¨à¦¿à¦°à¦¾à¦ªà¦¤à§à¦¤à¦¾ à¦‰à¦¨à§à¦¨à¦¤ à¦•à¦°à§‡, à¦¡à§‹à¦®à§‡à¦¨-à¦¨à¦¿à¦°à§à¦¦à¦¿à¦·à§à¦Ÿ à¦…à§à¦¯à¦¾à¦ªà§à¦²à¦¿à¦•à§‡à¦¶à¦¨à§‡à¦° à¦œà¦¨à§à¦¯ à¦•à¦¾à¦¸à§à¦Ÿà¦®à¦¾à¦‡à¦œ à¦•à¦°à¦¾ à¦¯à¦¾à¦¯à¦¼ à¦à¦¬à¦‚ à¦¬à¦¿à¦­à¦¿à¦¨à§à¦¨ à¦ªà§à¦°à¦¾à¦¨à§à¦¤ à¦•à¦®à§à¦ªà¦¿à¦‰à¦Ÿà¦¿à¦‚ à¦ªà¦°à¦¿à¦¬à§‡à¦¶à§‡à¦° à¦œà¦¨à§à¦¯ à¦‰à¦ªà¦¯à§à¦•à§à¦¤à¥¤

**à¦–à¦°à¦š à¦•à¦¾à¦°à§à¦¯à¦•à¦¾à¦°à¦¿à¦¤à¦¾**: à¦à¦œà§‡à¦¨à§à¦Ÿ à¦¸à¦¿à¦¸à§à¦Ÿà§‡à¦®à¦—à§à¦²à¦¿ à¦•à§à¦²à¦¾à¦‰à¦¡-à¦­à¦¿à¦¤à§à¦¤à¦¿à¦• à¦¸à¦®à¦¾à¦§à¦¾à¦¨à§‡à¦° à¦¤à§à¦²à¦¨à¦¾à¦¯à¦¼ à¦–à¦°à¦š-à¦•à¦¾à¦°à§à¦¯à¦•à¦° à¦¸à§à¦¥à¦¾à¦ªà¦¨ à¦ªà§à¦°à¦¦à¦¾à¦¨ à¦•à¦°à§‡, à¦ªà§à¦°à¦¾à¦¨à§à¦¤ à¦…à§à¦¯à¦¾à¦ªà§à¦²à¦¿à¦•à§‡à¦¶à¦¨à§‡à¦° à¦œà¦¨à§à¦¯ à¦•à¦® à¦…à¦ªà¦¾à¦°à§‡à¦¶à¦¨à¦¾à¦² à¦–à¦°à¦š à¦à¦¬à¦‚ à¦•à¦® à¦¬à§à¦¯à¦¾à¦¨à§à¦¡à¦‰à¦‡à¦¥ à¦ªà§à¦°à¦¯à¦¼à§‹à¦œà¦¨à§€à¦¯à¦¼à¦¤à¦¾ à¦¸à¦¹à¥¤

## à¦‰à¦¨à§à¦¨à¦¤ à¦›à§‹à¦Ÿ à¦­à¦¾à¦·à¦¾ à¦®à¦¡à§‡à¦² à¦•à§Œà¦¶à¦²

### SLM (à¦›à§‹à¦Ÿ à¦­à¦¾à¦·à¦¾ à¦®à¦¡à§‡à¦²) à¦®à§Œà¦²à¦¿à¦• à¦¬à¦¿à¦·à¦¯à¦¼

à¦à¦•à¦Ÿà¦¿ à¦›à§‹à¦Ÿ à¦­à¦¾à¦·à¦¾ à¦®à¦¡à§‡à¦² (SLM) à¦à¦•à¦Ÿà¦¿ à¦­à¦¾à¦·à¦¾ à¦®à¦¡à§‡à¦² à¦¯à¦¾ à¦à¦•à¦Ÿà¦¿ à¦¸à¦¾à¦§à¦¾à¦°à¦£ à¦­à§‹à¦•à§à¦¤à¦¾ à¦‡à¦²à§‡à¦•à¦Ÿà§à¦°à¦¨à¦¿à¦• à¦¡à¦¿à¦­à¦¾à¦‡à¦¸à§‡ à¦«à¦¿à¦Ÿ à¦•à¦°à¦¤à§‡ à¦ªà¦¾à¦°à§‡ à¦à¦¬à¦‚ à¦à¦•à¦Ÿà¦¿ à¦¬à§à¦¯à¦¬à¦¹à¦¾à¦°à¦•à¦¾à¦°à§€à¦° à¦à¦œà§‡à¦¨à§à¦Ÿà¦¿à¦• à¦…à¦¨à§à¦°à§‹à¦§ à¦ªà¦°à¦¿à¦¬à§‡à¦¶à¦¨ à¦•à¦°à¦¾à¦° à¦¸à¦®à¦¯à¦¼ à¦¯à¦¥à§‡à¦·à§à¦Ÿ à¦•à¦® à¦¬à¦¿à¦²à¦®à§à¦¬ à¦¸à¦¹ à¦…à¦¨à§à¦®à¦¾à¦¨ à¦•à¦°à¦¤à§‡ à¦ªà¦¾à¦°à§‡à¥¤ à¦¬à§à¦¯à¦¬à¦¹à¦¾à¦°à¦¿à¦•à¦­à¦¾à¦¬à§‡, SLM à¦¸à¦¾à¦§à¦¾à¦°à¦£à¦¤ à§§à§¦ à¦¬à¦¿à¦²à¦¿à¦¯à¦¼à¦¨à§‡à¦° à¦•à¦® à¦ªà§à¦¯à¦¾à¦°à¦¾à¦®à¦¿à¦Ÿà¦¾à¦° à¦¸à¦¹ à¦®à¦¡à§‡à¦²à¥¤

**à¦«à¦°à¦®à§à¦¯à¦¾à¦Ÿ à¦†à¦¬à¦¿à¦·à§à¦•à¦¾à¦° à¦¬à§ˆà¦¶à¦¿à¦·à§à¦Ÿà§à¦¯**: SLM à¦¬à¦¿à¦­à¦¿à¦¨à§à¦¨ à¦•à§‹à¦¯à¦¼à¦¾à¦¨à§à¦Ÿà¦¾à¦‡à¦œà§‡à¦¶à¦¨ à¦¸à§à¦¤à¦°, à¦•à§à¦°à¦¸-à¦ªà§à¦²à§à¦¯à¦¾à¦Ÿà¦«à¦°à§à¦® à¦¸à¦¾à¦®à¦žà§à¦œà¦¸à§à¦¯, à¦°à¦¿à¦¯à¦¼à§‡à¦²-à¦Ÿà¦¾à¦‡à¦® à¦•à¦°à§à¦®à¦•à§à¦·à¦®à¦¤à¦¾ à¦…à¦ªà§à¦Ÿà¦¿à¦®à¦¾à¦‡à¦œà§‡à¦¶à¦¨ à¦à¦¬à¦‚ à¦ªà§à¦°à¦¾à¦¨à§à¦¤ à¦¸à§à¦¥à¦¾à¦ªà¦¨ à¦¸à¦•à§à¦·à¦®à¦¤à¦¾à¦° à¦œà¦¨à§à¦¯ à¦‰à¦¨à§à¦¨à¦¤ à¦¸à¦®à¦°à§à¦¥à¦¨ à¦ªà§à¦°à¦¦à¦¾à¦¨ à¦•à¦°à§‡à¥¤ à¦¬à§à¦¯à¦¬à¦¹à¦¾à¦°à¦•à¦¾à¦°à§€à¦°à¦¾ à¦¸à§à¦¥à¦¾à¦¨à§€à¦¯à¦¼ à¦ªà§à¦°à¦•à§à¦°à¦¿à¦¯à¦¼à¦¾à¦•à¦°à¦£ à¦à¦¬à¦‚ à¦¬à§à¦°à¦¾à¦‰à¦œà¦¾à¦°-à¦­à¦¿à¦¤à§à¦¤à¦¿à¦• à¦¸à§à¦¥à¦¾à¦ªà¦¨à¦¾à¦° à¦œà¦¨à§à¦¯ WebGPU à¦¸à¦®à¦°à§à¦¥à¦¨à§‡à¦° à¦®à¦¾à¦§à§à¦¯à¦®à§‡ à¦‰à¦¨à§à¦¨à¦¤ à¦—à§‹à¦ªà¦¨à§€à¦¯à¦¼à¦¤à¦¾ à¦…à§à¦¯à¦¾à¦•à§à¦¸à§‡à¦¸ à¦•à¦°à¦¤à§‡ à¦ªà¦¾à¦°à§‡à¦¨à¥¤

**à¦•à§‹à¦¯à¦¼à¦¾à¦¨à§à¦Ÿà¦¾à¦‡à¦œà§‡à¦¶à¦¨ à¦¸à§à¦¤à¦° à¦¸à¦‚à¦—à§à¦°à¦¹**: à¦œà¦¨à¦ªà§à¦°à¦¿à¦¯à¦¼ SLM à¦«à¦°à¦®à§à¦¯à¦¾à¦Ÿà¦—à§à¦²à¦¿à¦° à¦®à¦§à§à¦¯à§‡ à¦°à¦¯à¦¼à§‡à¦›à§‡ Q4_K_M à¦®à§‹à¦¬à¦¾à¦‡à¦² à¦…à§à¦¯à¦¾à¦ªà§à¦²à¦¿à¦•à§‡à¦¶à¦¨à§‡ à¦­à¦¾à¦°à¦¸à¦¾à¦®à§à¦¯à¦ªà§‚à¦°à§à¦£ à¦•à¦®à§à¦ªà§à¦°à§‡à¦¶à¦¨à§‡à¦° à¦œà¦¨à§à¦¯, Q5_K_S à¦¸à¦¿à¦°à¦¿à¦œ à¦—à§à¦£à¦®à¦¾à¦¨-à¦•à§‡à¦¨à§à¦¦à§à¦°à¦¿à¦• à¦ªà§à¦°à¦¾à¦¨à§à¦¤ à¦¸à§à¦¥à¦¾à¦ªà¦¨à¦¾à¦° à¦œà¦¨à§à¦¯, Q8_0 à¦¶à¦•à§à¦¤à¦¿à¦¶à¦¾à¦²à§€ à¦ªà§à¦°à¦¾à¦¨à§à¦¤ à¦¡à¦¿à¦­à¦¾à¦‡à¦¸à§‡ à¦ªà§à¦°à¦¾à¦¯à¦¼-à¦†à¦¸à¦² à¦¨à¦¿à¦°à§à¦­à§à¦²à¦¤à¦¾à¦° à¦œà¦¨à§à¦¯ à¦à¦¬à¦‚ Q2_K-à¦à¦° à¦®à¦¤à§‹ à¦ªà¦°à§€à¦•à§à¦·à¦¾à¦®à§‚à¦²à¦• à¦«à¦°à¦®à§à¦¯à¦¾à¦Ÿà¦—à§à¦²à¦¿ à¦…à¦¤à¦¿-à¦•à¦® à¦¸à¦®à§à¦ªà¦¦ à¦ªà¦°à¦¿à¦¸à§à¦¥à¦¿à¦¤à¦¿à¦° à¦œà¦¨à§à¦¯à¥¤

### GGUF (à¦œà§‡à¦¨à¦¾à¦°à§‡à¦² GGML à¦‡à¦‰à¦¨à¦¿à¦­à¦¾à¦°à§à¦¸à¦¾à¦² à¦«à¦°à¦®à§à¦¯à¦¾à¦Ÿ) SLM à¦¸à§à¦¥à¦¾à¦ªà¦¨à¦¾à¦° à¦œà¦¨à§à¦¯

GGUF CPU à¦à¦¬à¦‚ à¦ªà§à¦°à¦¾à¦¨à§à¦¤ à¦¡à¦¿à¦­à¦¾à¦‡à¦¸à§‡ à¦•à§‹à¦¯à¦¼à¦¾à¦¨à§à¦Ÿà¦¾à¦‡à¦œà¦¡ SLM à¦¸à§à¦¥à¦¾à¦ªà¦¨à§‡à¦° à¦œà¦¨à§à¦¯ à¦ªà§à¦°à¦¾à¦¥à¦®à¦¿à¦• à¦«à¦°à¦®à§à¦¯à¦¾à¦Ÿ à¦¹à¦¿à¦¸à¦¾à¦¬à§‡ à¦•à¦¾à¦œ à¦•à¦°à§‡, à¦¬à¦¿à¦¶à§‡à¦·à¦­à¦¾à¦¬à§‡ à¦à¦œà§‡à¦¨à§à¦Ÿà¦¿à¦• à¦…à§à¦¯à¦¾à¦ªà§à¦²à¦¿à¦•à§‡à¦¶à¦¨à§‡à¦° à¦œà¦¨à§à¦¯ à¦…à¦ªà§à¦Ÿà¦¿à¦®à¦¾à¦‡à¦œ à¦•à¦°à¦¾ à¦¹à¦¯à¦¼à§‡à¦›à§‡:

**à¦à¦œà§‡à¦¨à§à¦Ÿ-à¦…à¦ªà§à¦Ÿà¦¿à¦®à¦¾à¦‡à¦œà¦¡ à¦¬à§ˆà¦¶à¦¿à¦·à§à¦Ÿà§à¦¯**: à¦«à¦°à¦®à§à¦¯à¦¾à¦Ÿà¦Ÿà¦¿ SLM à¦°à§‚à¦ªà¦¾à¦¨à§à¦¤à¦° à¦à¦¬à¦‚ à¦¸à§à¦¥à¦¾à¦ªà¦¨à¦¾à¦° à¦œà¦¨à§à¦¯ à¦¬à§à¦¯à¦¾à¦ªà¦• à¦¸à¦‚à¦¸à§à¦¥à¦¾à¦¨ à¦ªà§à¦°à¦¦à¦¾à¦¨ à¦•à¦°à§‡, à¦‰à¦¨à§à¦¨à¦¤ à¦¸à¦°à¦žà§à¦œà¦¾à¦® à¦•à¦²à¦¿à¦‚, à¦•à¦¾à¦ à¦¾à¦®à§‹à¦—à¦¤ à¦†à¦‰à¦Ÿà¦ªà§à¦Ÿ à¦ªà§à¦°à¦œà¦¨à§à¦® à¦à¦¬à¦‚ à¦®à¦¾à¦²à§à¦Ÿà¦¿-à¦Ÿà¦¾à¦°à§à¦¨ à¦•à¦¥à§‹à¦ªà¦•à¦¥à¦¨à§‡à¦° à¦œà¦¨à§à¦¯ à¦¸à¦®à¦°à§à¦¥à¦¨ à¦¸à¦¹à¥¤ à¦•à§à¦°à¦¸-à¦ªà§à¦²à§à¦¯à¦¾à¦Ÿà¦«à¦°à§à¦® à¦¸à¦¾à¦®à¦žà§à¦œà¦¸à§à¦¯ à¦¬à¦¿à¦­à¦¿à¦¨à§à¦¨ à¦ªà§à¦°à¦¾à¦¨à§à¦¤ à¦¡à¦¿à¦­à¦¾à¦‡à¦¸à§‡ à¦§à¦¾à¦°à¦¾à¦¬à¦¾à¦¹à¦¿à¦• à¦à¦œà§‡à¦¨à§à¦Ÿ à¦†à¦šà¦°à¦£ à¦¨à¦¿à¦¶à§à¦šà¦¿à¦¤ à¦•à¦°à§‡à¥¤

**à¦•à¦°à§à¦®à¦•à§à¦·à¦®à¦¤à¦¾ à¦…à¦ªà§à¦Ÿà¦¿à¦®à¦¾à¦‡à¦œà§‡à¦¶à¦¨**: GGUF à¦à¦œà§‡à¦¨à§à¦Ÿ à¦•à¦°à§à¦®à¦ªà§à¦°à¦¬à¦¾à¦¹à§‡à¦° à¦œà¦¨à§à¦¯ à¦¦à¦•à§à¦· à¦®à§‡à¦®à¦°à¦¿ à¦¬à§à¦¯à¦¬à¦¹à¦¾à¦° à¦¸à¦•à§à¦·à¦® à¦•à¦°à§‡, à¦®à¦¾à¦²à§à¦Ÿà¦¿-à¦à¦œà§‡à¦¨à§à¦Ÿ à¦¸à¦¿à¦¸à§à¦Ÿà§‡à¦®à§‡à¦° à¦œà¦¨à§à¦¯ à¦—à¦¤à¦¿à¦¶à§€à¦² à¦®à¦¡à§‡à¦² à¦²à§‹à¦¡à¦¿à¦‚ à¦¸à¦®à¦°à§à¦¥à¦¨ à¦•à¦°à§‡ à¦à¦¬à¦‚ à¦°à¦¿à¦¯à¦¼à§‡à¦²-à¦Ÿà¦¾à¦‡à¦® à¦à¦œà§‡à¦¨à§à¦Ÿ à¦‡à¦¨à§à¦Ÿà¦¾à¦°à¦…à§à¦¯à¦¾à¦•à¦¶à¦¨à§‡à¦° à¦œà¦¨à§à¦¯ à¦…à¦ªà§à¦Ÿà¦¿à¦®à¦¾à¦‡à¦œà¦¡ à¦…à¦¨à§à¦®à¦¾à¦¨ à¦ªà§à¦°à¦¦à¦¾à¦¨ à¦•à¦°à§‡à¥¤

### à¦ªà§à¦°à¦¾à¦¨à§à¦¤-à¦…à¦ªà§à¦Ÿà¦¿à¦®à¦¾à¦‡à¦œà¦¡ SLM à¦«à§à¦°à§‡à¦®à¦“à¦¯à¦¼à¦¾à¦°à§à¦•

#### à¦à¦œà§‡à¦¨à§à¦Ÿà§‡à¦° à¦œà¦¨à§à¦¯ Llama.cpp à¦…à¦ªà§à¦Ÿà¦¿à¦®à¦¾à¦‡à¦œà§‡à¦¶à¦¨

Llama.cpp à¦à¦œà§‡à¦¨à§à¦Ÿà¦¿à¦• SLM à¦¸à§à¦¥à¦¾à¦ªà¦¨à¦¾à¦° à¦œà¦¨à§à¦¯ à¦¬à¦¿à¦¶à§‡à¦·à¦­à¦¾à¦¬à§‡ à¦…à¦ªà§à¦Ÿà¦¿à¦®à¦¾à¦‡à¦œà¦¡ à¦•à§‹à¦¯à¦¼à¦¾à¦¨à§à¦Ÿà¦¾à¦‡à¦œà§‡à¦¶à¦¨ à¦•à§Œà¦¶à¦² à¦ªà§à¦°à¦¦à¦¾à¦¨ à¦•à¦°à§‡:

**à¦à¦œà§‡à¦¨à§à¦Ÿ-à¦¨à¦¿à¦°à§à¦¦à¦¿à¦·à§à¦Ÿ à¦•à§‹à¦¯à¦¼à¦¾à¦¨à§à¦Ÿà¦¾à¦‡à¦œà§‡à¦¶à¦¨**: à¦«à§à¦°à§‡à¦®à¦“à¦¯à¦¼à¦¾à¦°à§à¦• Q4_0 (à¦®à§‹à¦¬à¦¾à¦‡à¦² à¦à¦œà§‡à¦¨à§à¦Ÿ à¦¸à§à¦¥à¦¾à¦ªà¦¨à¦¾à¦° à¦œà¦¨à§à¦¯ à§­à§«% à¦†à¦•à¦¾à¦° à¦¹à§à¦°à¦¾à¦¸ à¦¸à¦¹ à¦…à¦ªà§à¦Ÿà¦¿à¦®à¦¾à¦²), Q5_1 (à¦ªà§à¦°à¦¾à¦¨à§à¦¤ à¦…à¦¨à§à¦®à¦¾à¦¨à§‡à¦° à¦à¦œà§‡à¦¨à§à¦Ÿà§‡à¦° à¦œà¦¨à§à¦¯ à¦—à§à¦£à¦®à¦¾à¦¨-à¦•à¦®à§à¦ªà§à¦°à§‡à¦¶à¦¨ à¦­à¦¾à¦°à¦¸à¦¾à¦®à§à¦¯) à¦à¦¬à¦‚ Q8_0 (à¦ªà§à¦°à§‹à¦¡à¦¾à¦•à¦¶à¦¨ à¦à¦œà§‡à¦¨à§à¦Ÿ à¦¸à¦¿à¦¸à§à¦Ÿà§‡à¦®à§‡à¦° à¦œà¦¨à§à¦¯ à¦ªà§à¦°à¦¾à¦¯à¦¼-à¦†à¦¸à¦² à¦—à§à¦£à¦®à¦¾à¦¨) à¦¸à¦®à¦°à§à¦¥à¦¨ à¦•à¦°à§‡à¥¤ à¦‰à¦¨à§à¦¨à¦¤ à¦«à¦°à¦®à§à¦¯à¦¾à¦Ÿà¦—à§à¦²à¦¿ à¦šà¦°à¦® à¦ªà§à¦°à¦¾à¦¨à§à¦¤ à¦ªà¦°à¦¿à¦¸à§à¦¥à¦¿à¦¤à¦¿à¦° à¦œà¦¨à§à¦¯ à¦…à¦¤à¦¿-à¦¸à¦‚à¦•à§à¦šà¦¿à¦¤ à¦à¦œà§‡à¦¨à§à¦Ÿ à¦¸à¦•à§à¦·à¦® à¦•à¦°à§‡à¥¤

**à¦¬à¦¾à¦¸à§à¦¤à¦¬à¦¾à¦¯à¦¼à¦¨ à¦¸à§à¦¬à¦¿à¦§à¦¾**: SIMD à¦¤à§à¦¬à¦°à¦£ à¦¸à¦¹ CPU-à¦…à¦ªà§à¦Ÿà¦¿à¦®à¦¾à¦‡à¦œà¦¡ à¦…à¦¨à§à¦®à¦¾à¦¨ à¦®à§‡à¦®à¦°à¦¿-à¦¦à¦•à§à¦· à¦à¦œà§‡à¦¨à§à¦Ÿ à¦•à¦¾à¦°à§à¦¯à¦•à¦°à§€à¦¤à¦¾ à¦ªà§à¦°à¦¦à¦¾à¦¨ à¦•à¦°à§‡à¥¤ x86, ARM à¦à¦¬à¦‚ Apple Silicon à¦†à¦°à§à¦•à¦¿à¦Ÿà§‡à¦•à¦šà¦¾à¦°à§‡à¦° à¦œà§à¦¡à¦¼à§‡ à¦•à§à¦°à¦¸-à¦ªà§à¦²à§à¦¯à¦¾à¦Ÿà¦«à¦°à§à¦® à¦¸à¦¾à¦®à¦žà§à¦œà¦¸à§à¦¯ à¦¸à¦¾à¦°à§à¦¬à¦œà¦¨à§€à¦¨ à¦à¦œà§‡à¦¨à§à¦Ÿ à¦¸à§à¦¥à¦¾à¦ªà¦¨à¦¾à¦° à¦¸à¦•à§à¦·à¦®à¦¤à¦¾ à¦¸à¦•à§à¦·à¦® à¦•à¦°à§‡à¥¤

#### Apple MLX à¦«à§à¦°à§‡à¦®à¦“à¦¯à¦¼à¦¾à¦°à§à¦• SLM à¦à¦œà§‡à¦¨à§à¦Ÿà§‡à¦° à¦œà¦¨à§à¦¯

Apple MLX Apple Silicon à¦¡à¦¿à¦­à¦¾à¦‡à¦¸à§‡ SLM-à¦šà¦¾à¦²à¦¿à¦¤ à¦à¦œà§‡à¦¨à§à¦Ÿà§‡à¦° à¦œà¦¨à§à¦¯ à¦¬à¦¿à¦¶à§‡à¦·à¦­à¦¾à¦¬à§‡ à¦¡à¦¿à¦œà¦¾à¦‡à¦¨ à¦•à¦°à¦¾ à¦¨à§‡à¦Ÿà¦¿à¦­ à¦…à¦ªà§à¦Ÿà¦¿à¦®à¦¾à¦‡à¦œà§‡à¦¶à¦¨ à¦ªà§à¦°à¦¦à¦¾à¦¨ à¦•à¦°à§‡:

**Apple Silicon à¦à¦œà§‡à¦¨à§à¦Ÿ à¦…à¦ªà§à¦Ÿà¦¿à¦®à¦¾à¦‡à¦œà§‡à¦¶à¦¨**: à¦«à§à¦°à§‡à¦®à¦“à¦¯à¦¼à¦¾à¦°à§à¦•à¦Ÿà¦¿ à¦®à§‡à¦Ÿà¦¾à¦² à¦ªà¦¾à¦°à¦«à¦°à¦®à§à¦¯à¦¾à¦¨à§à¦¸ à¦¶à§‡à¦¡à¦¾à¦° à¦‡à¦¨à§à¦Ÿà¦¿à¦—à§à¦°à§‡à¦¶à¦¨ à¦¸à¦¹ à¦‡à¦‰à¦¨à¦¿à¦«à¦¾à¦‡à¦¡ à¦®à§‡à¦®à¦°à¦¿ à¦†à¦°à§à¦•à¦¿à¦Ÿà§‡à¦•à¦šà¦¾à¦°, à¦à¦œà§‡à¦¨à§à¦Ÿ à¦…à¦¨à§à¦®à¦¾à¦¨à§‡à¦° à¦œà¦¨à§à¦¯ à¦¸à§à¦¬à¦¯à¦¼à¦‚à¦•à§à¦°à¦¿à¦¯à¦¼ à¦®à¦¿à¦¶à§à¦°à¦¿à¦¤ à¦¨à¦¿à¦°à§à¦­à§à¦²à¦¤à¦¾ à¦à¦¬à¦‚ à¦®à¦¾à¦²à§à¦Ÿà¦¿-à¦à¦œà§‡à¦¨à§à¦Ÿ à¦¸à¦¿à¦¸à§à¦Ÿà§‡à¦®à§‡à¦° à¦œà¦¨à§à¦¯ à¦…à¦ªà§à¦Ÿà¦¿à¦®à¦¾à¦‡à¦œà¦¡ à¦®à§‡à¦®à¦°à¦¿ à¦¬à§à¦¯à¦¾à¦¨à§à¦¡à¦‰à¦‡à¦¥ à¦¬à§à¦¯à¦¬à¦¹à¦¾à¦° à¦•à¦°à§‡à¥¤ M-à¦¸à¦¿à¦°à¦¿à¦œ à¦šà¦¿à¦ªà§‡ SLM à¦à¦œà§‡à¦¨à§à¦Ÿà¦—à§à¦²à¦¿ à¦…à¦¸à¦¾à¦§à¦¾à¦°à¦£ à¦•à¦°à§à¦®à¦•à§à¦·à¦®à¦¤à¦¾ à¦¦à§‡à¦–à¦¾à¦¯à¦¼à¥¤

**à¦‰à¦¨à§à¦¨à¦¯à¦¼à¦¨ à¦¬à§ˆà¦¶à¦¿à¦·à§à¦Ÿà§à¦¯**: Python à¦à¦¬à¦‚ Swift API à¦¸à¦®à¦°à§à¦¥à¦¨ à¦¸à¦¹ à¦à¦œà§‡à¦¨à§à¦Ÿ-à¦¨à¦¿à¦°à§à¦¦à¦¿à¦·à§à¦Ÿ à¦…à¦ªà§à¦Ÿà¦¿à¦®à¦¾à¦‡à¦œà§‡à¦¶à¦¨, à¦à¦œà§‡à¦¨à§à¦Ÿ à¦¶à§‡à¦–à¦¾à¦° à¦œà¦¨à§à¦¯ à¦¸à§à¦¬à¦¯à¦¼à¦‚à¦•à§à¦°à¦¿à¦¯à¦¼ à¦ªà¦¾à¦°à§à¦¥à¦•à§à¦¯ à¦à¦¬à¦‚ Apple à¦¡à§‡à¦­à§‡à¦²à¦ªà¦®à§‡à¦¨à§à¦Ÿ à¦Ÿà§à¦²à¦—à§à¦²à¦¿à¦° à¦¸à¦¾à¦¥à§‡ à¦¨à¦¿à¦°à§à¦¬à¦¿à¦˜à§à¦¨ à¦‡à¦¨à§à¦Ÿà¦¿à¦—à§à¦°à§‡à¦¶à¦¨ à¦¬à§à¦¯à¦¾à¦ªà¦• à¦à¦œà§‡à¦¨à§à¦Ÿ à¦‰à¦¨à§à¦¨à¦¯à¦¼à¦¨ à¦ªà¦°à¦¿à¦¬à§‡à¦¶ à¦ªà§à¦°à¦¦à¦¾à¦¨ à¦•à¦°à§‡à¥¤

#### ONNX Runtime à¦•à§à¦°à¦¸-à¦ªà§à¦²à§à¦¯à¦¾à¦Ÿà¦«à¦°à§à¦® SLM à¦à¦œà§‡à¦¨à§à¦Ÿà§‡à¦° à¦œà¦¨à§à¦¯

ONNX Runtime à¦à¦•à¦Ÿà¦¿ à¦¸à¦¾à¦°à§à¦¬à¦œà¦¨à§€à¦¨ à¦…à¦¨à§à¦®à¦¾à¦¨ à¦‡à¦žà§à¦œà¦¿à¦¨ à¦ªà§à¦°à¦¦à¦¾à¦¨ à¦•à¦°à§‡ à¦¯à¦¾ SLM à¦à¦œà§‡à¦¨à§à¦Ÿà¦—à§à¦²à¦¿à¦•à§‡ à¦¬à¦¿à¦­à¦¿à¦¨à§à¦¨ à¦¹à¦¾à¦°à§à¦¡à¦“à¦¯à¦¼à§à¦¯à¦¾à¦° à¦ªà§à¦²à§à¦¯à¦¾à¦Ÿà¦«à¦°à§à¦® à¦à¦¬à¦‚ à¦…à¦ªà¦¾à¦°à§‡à¦Ÿà¦¿à¦‚ à¦¸à¦¿à¦¸à§à¦Ÿà§‡à¦® à¦œà§à¦¡à¦¼à§‡ à¦§à¦¾à¦°à¦¾à¦¬à¦¾à¦¹à¦¿à¦•à¦­à¦¾à¦¬à§‡ à¦šà¦¾à¦²à¦¾à¦¤à§‡ à¦¸à¦•à§à¦·à¦® à¦•à¦°à§‡:

**à¦¸à¦¾à¦°à§à¦¬à¦œà¦¨à§€à¦¨ à¦¸à§à¦¥à¦¾à¦ªà¦¨**: ONNX Runtime Windows, Linux, macOS, iOS à¦à¦¬à¦‚ Android à¦ªà§à¦²à§à¦¯à¦¾à¦Ÿà¦«à¦°à§à¦® à¦œà§à¦¡à¦¼à§‡ à¦§à¦¾à¦°à¦¾à¦¬à¦¾à¦¹à¦¿à¦• SLM à¦à¦œà§‡à¦¨à§à¦Ÿ à¦†à¦šà¦°à¦£ à¦¨à¦¿à¦¶à§à¦šà¦¿à¦¤ à¦•à¦°à§‡à¥¤ à¦à¦‡ à¦•à§à¦°à¦¸-à¦ªà§à¦²à§à¦¯à¦¾à¦Ÿà¦«à¦°à§à¦® à¦¸à¦¾à¦®à¦žà§à¦œà¦¸à§à¦¯ à¦¡à§‡à¦­à§‡à¦²à¦ªà¦¾à¦°à¦¦à§‡à¦° à¦à¦•à¦¬à¦¾à¦° à¦²à¦¿à¦–à¦¤à§‡ à¦à¦¬à¦‚ à¦¸à¦°à§à¦¬à¦¤à§à¦° à¦¸à§à¦¥à¦¾à¦ªà¦¨ à¦•à¦°à¦¤à§‡ à¦¸à¦•à§à¦·à¦® à¦•à¦°à§‡, à¦®à¦¾à¦²à§à¦Ÿà¦¿-à¦ªà§à¦²à§à¦¯à¦¾à¦Ÿà¦«à¦°à§à¦® à¦…à§à¦¯à¦¾à¦ªà§à¦²à¦¿à¦•à§‡à¦¶à¦¨à§‡à¦° à¦œà¦¨à§à¦¯ à¦‰à¦¨à§à¦¨à¦¯à¦¼à¦¨ à¦à¦¬à¦‚ à¦°à¦•à§à¦·à¦£à¦¾à¦¬à§‡à¦•à§à¦·à¦£à§‡à¦° à¦“à¦­à¦¾à¦°à¦¹à§‡à¦¡ à¦‰à¦²à§à¦²à§‡à¦–à¦¯à§‹à¦—à§à¦¯à¦­à¦¾à¦¬à§‡ à¦¹à§à¦°à¦¾à¦¸ à¦•à¦°à§‡à¥¤

**à¦¹à¦¾à¦°à§à¦¡à¦“à¦¯à¦¼à§à¦¯à¦¾à¦° à¦¤à§à¦¬à¦°à¦£ à¦¬à¦¿à¦•à¦²à§à¦ª**: à¦«à§à¦°à§‡à¦®à¦“à¦¯à¦¼à¦¾à¦°à§à¦•à¦Ÿà¦¿ à¦¬à¦¿à¦­à¦¿à¦¨à§à¦¨ à¦¹à¦¾à¦°à§à¦¡à¦“à¦¯à¦¼à§à¦¯à¦¾à¦° à¦•à¦¨à¦«à¦¿à¦—à¦¾à¦°à§‡à¦¶à¦¨à§‡à¦° à¦œà¦¨à§à¦¯ à¦…à¦ªà§à¦Ÿà¦¿à¦®à¦¾à¦‡à¦œà¦¡ à¦à¦•à§à¦¸à¦¿à¦•à¦¿à¦‰à¦¶à¦¨ à¦ªà§à¦°à¦¦à¦¾à¦¨ à¦•à¦°à§‡, à¦¯à¦¾à¦° à¦®à¦§à§à¦¯à§‡ à¦°à¦¯à¦¼à§‡à¦›à§‡ CPU (Intel, AMD, ARM), GPU (NVIDIA CUDA, AMD ROCm) à¦à¦¬à¦‚ à¦¬à¦¿à¦¶à§‡à¦·à¦¾à¦¯à¦¼à¦¿à¦¤ à¦…à§à¦¯à¦¾à¦•à§à¦¸à¦¿à¦²à¦¾à¦°à§‡à¦Ÿà¦° (Intel VPU, Qualcomm NPU)à¥¤ SLM à¦à¦œà§‡à¦¨à§à¦Ÿà¦—à§à¦²à¦¿ à¦•à§‹à¦¡ à¦ªà¦°à¦¿à¦¬à¦°à§à¦¤à¦¨ à¦›à¦¾à¦¡à¦¼à¦¾à¦‡ à¦¸à§‡à¦°à¦¾ à¦‰à¦ªà¦²à¦¬à§à¦§ à¦¹à¦¾à¦°à§à¦¡à¦“à¦¯à¦¼à§à¦¯à¦¾à¦° à¦¬à§à¦¯à¦¬à¦¹à¦¾à¦° à¦•à¦°à¦¤à§‡ à¦ªà¦¾à¦°à§‡à¥¤

**à¦ªà§à¦°à§‹à¦¡à¦¾à¦•à¦¶à¦¨-à¦°à§‡à¦¡à¦¿ à¦¬à§ˆà¦¶à¦¿à¦·à§à¦Ÿà§à¦¯**: ONNX Runtime à¦¦à§à¦°à§à¦¤ à¦…à¦¨à§à¦®à¦¾à¦¨à§‡à¦° à¦œà¦¨à§à¦¯ à¦—à§à¦°à¦¾à¦« à¦…à¦ªà§à¦Ÿà¦¿à¦®à¦¾à¦‡à¦œà§‡à¦¶à¦¨, à¦¸à§€à¦®à¦¿à¦¤ à¦¸à¦®à§à¦ªà¦¦ à¦ªà¦°à¦¿à¦¬à§‡à¦¶à§‡à¦° à¦œà¦¨à§à¦¯ à¦®à§‡à¦®à¦°à¦¿ à¦¬à§à¦¯à¦¬à¦¸à§à¦¥à¦¾à¦ªà¦¨à¦¾ à¦à¦¬à¦‚ à¦•à¦°à§à¦®à¦•à§à¦·à¦®à¦¤à¦¾ à¦¬à¦¿à¦¶à§à¦²à§‡à¦·à¦£à§‡à¦° à¦œà¦¨à§à¦¯ à¦¬à§à¦¯à¦¾à¦ªà¦• à¦ªà§à¦°à§‹à¦«à¦¾à¦‡à¦²à¦¿à¦‚ à¦¸à¦°à¦žà§à¦œà¦¾à¦® à¦¸à¦¹ à¦ªà§à¦°à§‹à¦¡à¦¾à¦•à¦¶à¦¨ à¦à¦œà§‡à¦¨à§à¦Ÿ à¦¸à§à¦¥à¦¾à¦ªà¦¨à¦¾à¦° à¦œà¦¨à§à¦¯ à¦ªà§à¦°à¦¯à¦¼à§‹à¦œà¦¨à§€à¦¯à¦¼ à¦à¦¨à§à¦Ÿà¦¾à¦°à¦ªà§à¦°à¦¾à¦‡à¦œ-à¦—à§à¦°à§‡à¦¡ à¦¬à§ˆà¦¶à¦¿à¦·à§à¦Ÿà§à¦¯ à¦ªà§à¦°à¦¦à¦¾à¦¨ à¦•à¦°à§‡à¥¤ à¦«à§à¦°à§‡à¦®à¦“à¦¯à¦¼à¦¾à¦°à§à¦•à¦Ÿà¦¿ Python à¦à¦¬à¦‚ C++ API à¦‰à¦­à¦¯à¦¼à¦‡ à¦¸à¦®à¦°à§à¦¥à¦¨ à¦•à¦°à§‡ à¦¨à¦®à¦¨à§€à¦¯à¦¼ à¦‡à¦¨à§à¦Ÿà¦¿à¦—à§à¦°à§‡à¦¶à¦¨à§‡à¦° à¦œà¦¨à§à¦¯à¥¤
- à¦®à¦¾à¦‡à¦•à§à¦°à§‹à¦¸à¦«à¦Ÿ à¦à¦œà§‡à¦¨à§à¦Ÿ à¦«à§à¦°à§‡à¦®à¦“à¦¯à¦¼à¦¾à¦°à§à¦• à¦‡à¦¨à§à¦Ÿà¦¿à¦—à§à¦°à§‡à¦¶à¦¨ à¦ªà¦°à§€à¦•à§à¦·à¦¾ à¦•à¦°à§à¦¨  
- à¦…à¦«à¦²à¦¾à¦‡à¦¨ à¦…à¦ªà¦¾à¦°à§‡à¦¶à¦¨ à¦¸à¦•à§à¦·à¦®à¦¤à¦¾ à¦¯à¦¾à¦šà¦¾à¦‡ à¦•à¦°à§à¦¨  
- à¦«à§‡à¦‡à¦²à¦“à¦­à¦¾à¦° à¦ªà¦°à¦¿à¦¸à§à¦¥à¦¿à¦¤à¦¿ à¦à¦¬à¦‚ à¦¤à§à¦°à§à¦Ÿà¦¿ à¦ªà¦°à¦¿à¦šà¦¾à¦²à¦¨à¦¾ à¦ªà¦°à§€à¦•à§à¦·à¦¾ à¦•à¦°à§à¦¨  
- à¦à¦œà§‡à¦¨à§à¦Ÿà§‡à¦° à¦¸à¦®à§à¦ªà§‚à¦°à§à¦£ à¦•à¦¾à¦°à§à¦¯à¦ªà§à¦°à¦¬à¦¾à¦¹ à¦¯à¦¾à¦šà¦¾à¦‡ à¦•à¦°à§à¦¨  

**Foundry Local-à¦à¦° à¦¸à¦¾à¦¥à§‡ à¦¤à§à¦²à¦¨à¦¾**:

| à¦¬à§ˆà¦¶à¦¿à¦·à§à¦Ÿà§à¦¯ | Foundry Local | Ollama |
|---------|---------------|--------|
| **à¦²à¦•à§à¦·à§à¦¯ à¦¬à§à¦¯à¦¬à¦¹à¦¾à¦° à¦•à§à¦·à§‡à¦¤à§à¦°** | à¦à¦¨à§à¦Ÿà¦¾à¦°à¦ªà§à¦°à¦¾à¦‡à¦œ à¦ªà§à¦°à§‹à¦¡à¦¾à¦•à¦¶à¦¨ | à¦¡à§‡à¦­à§‡à¦²à¦ªà¦®à§‡à¦¨à§à¦Ÿ à¦à¦¬à¦‚ à¦•à¦®à¦¿à¦‰à¦¨à¦¿à¦Ÿà¦¿ |
| **à¦®à¦¡à§‡à¦² à¦‡à¦•à§‹à¦¸à¦¿à¦¸à§à¦Ÿà§‡à¦®** | à¦®à¦¾à¦‡à¦•à§à¦°à§‹à¦¸à¦«à¦Ÿ-à¦•à¦¿à¦‰à¦°à§‡à¦Ÿà§‡à¦¡ | à¦¬à¦¿à¦¸à§à¦¤à§ƒà¦¤ à¦•à¦®à¦¿à¦‰à¦¨à¦¿à¦Ÿà¦¿ |
| **à¦¹à¦¾à¦°à§à¦¡à¦“à¦¯à¦¼à§à¦¯à¦¾à¦° à¦…à¦ªà§à¦Ÿà¦¿à¦®à¦¾à¦‡à¦œà§‡à¦¶à¦¨** | à¦¸à§à¦¬à¦¯à¦¼à¦‚à¦•à§à¦°à¦¿à¦¯à¦¼ (CUDA/NPU/CPU) | à¦®à§à¦¯à¦¾à¦¨à§à¦¯à¦¼à¦¾à¦² à¦•à¦¨à¦«à¦¿à¦—à¦¾à¦°à§‡à¦¶à¦¨ |
| **à¦à¦¨à§à¦Ÿà¦¾à¦°à¦ªà§à¦°à¦¾à¦‡à¦œ à¦¬à§ˆà¦¶à¦¿à¦·à§à¦Ÿà§à¦¯** | à¦¬à¦¿à¦²à§à¦Ÿ-à¦‡à¦¨ à¦®à¦¨à¦¿à¦Ÿà¦°à¦¿à¦‚, à¦¸à¦¿à¦•à¦¿à¦‰à¦°à¦¿à¦Ÿà¦¿ | à¦•à¦®à¦¿à¦‰à¦¨à¦¿à¦Ÿà¦¿ à¦Ÿà§à¦²à¦¸ |
| **à¦¡à¦¿à¦ªà§à¦²à¦¯à¦¼à¦®à§‡à¦¨à§à¦Ÿ à¦œà¦Ÿà¦¿à¦²à¦¤à¦¾** | à¦¸à¦¹à¦œ (winget à¦‡à¦¨à¦¸à§à¦Ÿà¦²) | à¦¸à¦¹à¦œ (curl à¦‡à¦¨à¦¸à§à¦Ÿà¦²) |
| **API à¦¸à¦¾à¦®à¦žà§à¦œà¦¸à§à¦¯à¦¤à¦¾** | OpenAI + à¦à¦•à§à¦¸à¦Ÿà§‡à¦¨à¦¶à¦¨ | OpenAI à¦¸à§à¦Ÿà§à¦¯à¦¾à¦¨à§à¦¡à¦¾à¦°à§à¦¡ |
| **à¦¸à¦¾à¦ªà§‹à¦°à§à¦Ÿ** | à¦®à¦¾à¦‡à¦•à§à¦°à§‹à¦¸à¦«à¦Ÿ à¦…à¦«à¦¿à¦¸à¦¿à¦¯à¦¼à¦¾à¦² | à¦•à¦®à¦¿à¦‰à¦¨à¦¿à¦Ÿà¦¿-à¦¡à§à¦°à¦¿à¦­à§‡à¦¨ |
| **à¦¸à§‡à¦°à¦¾ à¦¬à§à¦¯à¦¬à¦¹à¦¾à¦° à¦•à§à¦·à§‡à¦¤à§à¦°** | à¦ªà§à¦°à§‹à¦¡à¦¾à¦•à¦¶à¦¨ à¦à¦œà§‡à¦¨à§à¦Ÿ | à¦ªà§à¦°à§‹à¦Ÿà§‹à¦Ÿà¦¾à¦‡à¦ªà¦¿à¦‚, à¦—à¦¬à§‡à¦·à¦£à¦¾ |

**à¦•à¦–à¦¨ Ollama à¦¬à§‡à¦›à§‡ à¦¨à§‡à¦¬à§‡à¦¨**:
- **à¦¡à§‡à¦­à§‡à¦²à¦ªà¦®à§‡à¦¨à§à¦Ÿ à¦à¦¬à¦‚ à¦ªà§à¦°à§‹à¦Ÿà§‹à¦Ÿà¦¾à¦‡à¦ªà¦¿à¦‚**: à¦¬à¦¿à¦­à¦¿à¦¨à§à¦¨ à¦®à¦¡à§‡à¦²à§‡à¦° à¦¸à¦¾à¦¥à§‡ à¦¦à§à¦°à§à¦¤ à¦ªà¦°à§€à¦•à§à¦·à¦¾-à¦¨à¦¿à¦°à§€à¦•à§à¦·à¦¾  
- **à¦•à¦®à¦¿à¦‰à¦¨à¦¿à¦Ÿà¦¿ à¦®à¦¡à§‡à¦²**: à¦¸à¦°à§à¦¬à¦¶à§‡à¦· à¦•à¦®à¦¿à¦‰à¦¨à¦¿à¦Ÿà¦¿-à¦•à¦¨à§à¦Ÿà§à¦°à¦¿à¦¬à¦¿à¦‰à¦Ÿà§‡à¦¡ à¦®à¦¡à§‡à¦²à¦—à§à¦²à¦¿à¦¤à§‡ à¦…à§à¦¯à¦¾à¦•à§à¦¸à§‡à¦¸  
- **à¦¶à¦¿à¦•à§à¦·à¦¾à¦®à§‚à¦²à¦• à¦¬à§à¦¯à¦¬à¦¹à¦¾à¦°**: AI à¦à¦œà§‡à¦¨à§à¦Ÿ à¦¡à§‡à¦­à§‡à¦²à¦ªà¦®à§‡à¦¨à§à¦Ÿ à¦¶à§‡à¦–à¦¾ à¦à¦¬à¦‚ à¦¶à§‡à¦–à¦¾à¦¨à§‹  
- **à¦—à¦¬à§‡à¦·à¦£à¦¾ à¦ªà§à¦°à¦•à¦²à§à¦ª**: à¦¬à¦¿à¦­à¦¿à¦¨à§à¦¨ à¦®à¦¡à§‡à¦² à¦…à§à¦¯à¦¾à¦•à§à¦¸à§‡à¦¸à§‡à¦° à¦ªà§à¦°à¦¯à¦¼à§‹à¦œà¦¨à§€à¦¯à¦¼ à¦à¦•à¦¾à¦¡à§‡à¦®à¦¿à¦• à¦—à¦¬à§‡à¦·à¦£à¦¾  
- **à¦•à¦¾à¦¸à§à¦Ÿà¦® à¦®à¦¡à§‡à¦²**: à¦•à¦¾à¦¸à§à¦Ÿà¦® à¦«à¦¾à¦‡à¦¨-à¦Ÿà¦¿à¦‰à¦¨à¦¡ à¦®à¦¡à§‡à¦² à¦¤à§ˆà¦°à¦¿ à¦à¦¬à¦‚ à¦ªà¦°à§€à¦•à§à¦·à¦¾ à¦•à¦°à¦¾  

### VLLM: à¦‰à¦šà§à¦š-à¦ªà§à¦°à¦¦à¦°à§à¦¶à¦¨ SLM à¦à¦œà§‡à¦¨à§à¦Ÿ à¦‡à¦¨à¦«à¦¾à¦°à§‡à¦¨à§à¦¸

VLLM (Very Large Language Model inference) à¦à¦•à¦Ÿà¦¿ à¦‰à¦šà§à¦š-à¦¥à§à¦°à§à¦ªà§à¦Ÿ, à¦®à§‡à¦®à§‹à¦°à¦¿-à¦¦à¦•à§à¦· à¦‡à¦¨à¦«à¦¾à¦°à§‡à¦¨à§à¦¸ à¦‡à¦žà§à¦œà¦¿à¦¨ à¦ªà§à¦°à¦¦à¦¾à¦¨ à¦•à¦°à§‡ à¦¯à¦¾ à¦¸à§à¦•à§‡à¦²à§‡ à¦ªà§à¦°à§‹à¦¡à¦¾à¦•à¦¶à¦¨ SLM à¦¡à¦¿à¦ªà§à¦²à¦¯à¦¼à¦®à§‡à¦¨à§à¦Ÿà§‡à¦° à¦œà¦¨à§à¦¯ à¦¬à¦¿à¦¶à§‡à¦·à¦­à¦¾à¦¬à§‡ à¦…à¦ªà§à¦Ÿà¦¿à¦®à¦¾à¦‡à¦œ à¦•à¦°à¦¾ à¦¹à¦¯à¦¼à§‡à¦›à§‡à¥¤ à¦¯à§‡à¦–à¦¾à¦¨à§‡ Foundry Local à¦¸à¦¹à¦œ à¦¬à§à¦¯à¦¬à¦¹à¦¾à¦°à§‡ à¦®à¦¨à§‹à¦¯à§‹à¦— à¦¦à§‡à¦¯à¦¼ à¦à¦¬à¦‚ Ollama à¦•à¦®à¦¿à¦‰à¦¨à¦¿à¦Ÿà¦¿ à¦®à¦¡à§‡à¦²à¦—à§à¦²à¦¿à¦•à§‡ à¦—à§à¦°à§à¦¤à§à¦¬ à¦¦à§‡à¦¯à¦¼, VLLM à¦‰à¦šà§à¦š-à¦ªà§à¦°à¦¦à¦°à§à¦¶à¦¨ à¦ªà¦°à¦¿à¦¸à§à¦¥à¦¿à¦¤à¦¿à¦¤à§‡ à¦‰à§Žà¦•à§ƒà¦·à§à¦Ÿ à¦¯à§‡à¦–à¦¾à¦¨à§‡ à¦¸à¦°à§à¦¬à¦¾à¦§à¦¿à¦• à¦¥à§à¦°à§à¦ªà§à¦Ÿ à¦à¦¬à¦‚ à¦¦à¦•à§à¦· à¦°à¦¿à¦¸à§‹à¦°à§à¦¸ à¦¬à§à¦¯à¦¬à¦¹à¦¾à¦° à¦ªà§à¦°à¦¯à¦¼à§‹à¦œà¦¨à¥¤

**à¦®à§‚à¦² à¦†à¦°à§à¦•à¦¿à¦Ÿà§‡à¦•à¦šà¦¾à¦° à¦à¦¬à¦‚ à¦¬à§ˆà¦¶à¦¿à¦·à§à¦Ÿà§à¦¯**:
- **PagedAttention**: à¦•à¦¾à¦°à§à¦¯à¦•à¦° à¦…à§à¦¯à¦¾à¦Ÿà§‡à¦¨à¦¶à¦¨ à¦—à¦£à¦¨à¦¾à¦° à¦œà¦¨à§à¦¯ à¦¬à¦¿à¦ªà§à¦²à¦¬à§€ à¦®à§‡à¦®à§‹à¦°à¦¿ à¦®à§à¦¯à¦¾à¦¨à§‡à¦œà¦®à§‡à¦¨à§à¦Ÿ  
- **Dynamic Batching**: à¦¸à¦°à§à¦¬à§‹à¦¤à§à¦¤à¦® à¦¥à§à¦°à§à¦ªà§à¦Ÿà§‡à¦° à¦œà¦¨à§à¦¯ à¦¬à§à¦¦à§à¦§à¦¿à¦®à¦¾à¦¨ à¦…à¦¨à§à¦°à§‹à¦§ à¦¬à§à¦¯à¦¾à¦šà¦¿à¦‚  
- **GPU à¦…à¦ªà§à¦Ÿà¦¿à¦®à¦¾à¦‡à¦œà§‡à¦¶à¦¨**: à¦‰à¦¨à§à¦¨à¦¤ CUDA à¦•à¦¾à¦°à§à¦¨à§‡à¦² à¦à¦¬à¦‚ à¦Ÿà§‡à¦¨à¦¸à¦° à¦ªà§à¦¯à¦¾à¦°à¦¾à¦²à§‡à¦²à¦¿à¦œà¦® à¦¸à¦¾à¦ªà§‹à¦°à§à¦Ÿ  
- **OpenAI à¦¸à¦¾à¦®à¦žà§à¦œà¦¸à§à¦¯à¦¤à¦¾**: à¦¨à¦¿à¦°à§à¦¬à¦¿à¦˜à§à¦¨ à¦‡à¦¨à§à¦Ÿà¦¿à¦—à§à¦°à§‡à¦¶à¦¨à§‡à¦° à¦œà¦¨à§à¦¯ à¦¸à¦®à§à¦ªà§‚à¦°à§à¦£ API à¦¸à¦¾à¦®à¦žà§à¦œà¦¸à§à¦¯à¦¤à¦¾  
- **Speculative Decoding**: à¦‰à¦¨à§à¦¨à¦¤ à¦‡à¦¨à¦«à¦¾à¦°à§‡à¦¨à§à¦¸ à¦¤à§à¦¬à¦°à¦¾à¦¨à§à¦¬à¦¿à¦¤ à¦•à¦°à¦¾à¦° à¦•à§Œà¦¶à¦²  
- **Quantization à¦¸à¦¾à¦ªà§‹à¦°à§à¦Ÿ**: à¦®à§‡à¦®à§‹à¦°à¦¿ à¦¦à¦•à§à¦·à¦¤à¦¾à¦° à¦œà¦¨à§à¦¯ INT4, INT8, à¦à¦¬à¦‚ FP16 à¦•à§‹à¦¯à¦¼à¦¾à¦¨à§à¦Ÿà¦¾à¦‡à¦œà§‡à¦¶à¦¨  

#### à¦‡à¦¨à¦¸à§à¦Ÿà¦²à§‡à¦¶à¦¨ à¦à¦¬à¦‚ à¦¸à§‡à¦Ÿà¦†à¦ª

**à¦‡à¦¨à¦¸à§à¦Ÿà¦²à§‡à¦¶à¦¨ à¦…à¦ªà¦¶à¦¨**:  
```bash
# Standard installation
pip install vllm

# With additional dependencies for agent frameworks
pip install vllm[agent] openai

# Docker deployment for production
docker pull vllm/vllm-openai:latest

# From source for latest features
git clone https://github.com/vllm-project/vllm.git
cd vllm
pip install -e .
```
  
**à¦à¦œà§‡à¦¨à§à¦Ÿ à¦¡à§‡à¦­à§‡à¦²à¦ªà¦®à§‡à¦¨à§à¦Ÿà§‡à¦° à¦œà¦¨à§à¦¯ à¦¦à§à¦°à§à¦¤ à¦¶à§à¦°à§**:  
```bash
# Start VLLM server with SLM model
python -m vllm.entrypoints.openai.api_server \
    --model microsoft/Phi-3.5-mini-instruct \
    --trust-remote-code \
    --max-model-len 4096 \
    --gpu-memory-utilization 0.8

# Alternative: Start with Qwen2.5 for lightweight agents
python -m vllm.entrypoints.openai.api_server \
    --model Qwen/Qwen2.5-0.5B-Instruct \
    --trust-remote-code \
    --max-model-len 2048 \
    --tensor-parallel-size 1

# Test API endpoint
curl http://localhost:8000/v1/models

# Test chat completion
curl http://localhost:8000/v1/chat/completions \
    -H "Content-Type: application/json" \
    -d '{
        "model": "microsoft/Phi-3.5-mini-instruct",
        "messages": [{"role": "user", "content": "Hello!"}]
    }'
```
  

#### à¦à¦œà§‡à¦¨à§à¦Ÿ à¦«à§à¦°à§‡à¦®à¦“à¦¯à¦¼à¦¾à¦°à§à¦• à¦‡à¦¨à§à¦Ÿà¦¿à¦—à§à¦°à§‡à¦¶à¦¨

**VLLM à¦à¦¬à¦‚ à¦®à¦¾à¦‡à¦•à§à¦°à§‹à¦¸à¦«à¦Ÿ à¦à¦œà§‡à¦¨à§à¦Ÿ à¦«à§à¦°à§‡à¦®à¦“à¦¯à¦¼à¦¾à¦°à§à¦•**:  
```python
from microsoft_agent_framework import Agent, Config
import openai
import subprocess
import time
import requests
from typing import Optional, Dict, Any

class VLLMManager:
    def __init__(self, model_name: str, 
                 host: str = "localhost", 
                 port: int = 8000,
                 gpu_memory_utilization: float = 0.8,
                 max_model_len: int = 4096):
        self.model_name = model_name
        self.host = host
        self.port = port
        self.base_url = f"http://{host}:{port}"
        self.gpu_memory_utilization = gpu_memory_utilization
        self.max_model_len = max_model_len
        self.process = None
        self.client = None
        
    def start_server(self) -> bool:
        """Start VLLM server with optimized settings for agents."""
        try:
            cmd = [
                "python", "-m", "vllm.entrypoints.openai.api_server",
                "--model", self.model_name,
                "--host", self.host,
                "--port", str(self.port),
                "--gpu-memory-utilization", str(self.gpu_memory_utilization),
                "--max-model-len", str(self.max_model_len),
                "--trust-remote-code",
                "--disable-log-requests",  # Reduce logging for agents
                "--served-model-name", self.get_served_model_name()
            ]
            
            self.process = subprocess.Popen(cmd, 
                stdout=subprocess.PIPE, 
                stderr=subprocess.PIPE)
            
            # Wait for server to start
            max_retries = 30
            for _ in range(max_retries):
                if self.health_check():
                    self.client = openai.OpenAI(base_url=f"{self.base_url}/v1")
                    return True
                time.sleep(2)
                
            return False
            
        except Exception as e:
            print(f"Failed to start VLLM server: {e}")
            return False
    
    def get_served_model_name(self) -> str:
        """Get a clean model name for serving."""
        return self.model_name.replace("/", "--")
    
    def health_check(self) -> bool:
        """Check if VLLM server is healthy."""
        try:
            response = requests.get(f"{self.base_url}/health", timeout=5)
            return response.status_code == 200
        except:
            return False
    
    def get_openai_client(self) -> openai.OpenAI:
        """Get OpenAI-compatible client for VLLM."""
        if not self.client:
            self.client = openai.OpenAI(base_url=f"{self.base_url}/v1")
        return self.client
    
    def get_model_info(self) -> Dict[str, Any]:
        """Get model information and statistics."""
        try:
            response = requests.get(f"{self.base_url}/v1/models")
            if response.status_code == 200:
                return response.json()
        except:
            pass
        return {}
    
    def shutdown(self):
        """Shutdown VLLM server."""
        if self.process:
            self.process.terminate()
            self.process.wait()

# Initialize VLLM for high-performance agents
vllm_manager = VLLMManager("microsoft/Phi-3.5-mini-instruct")
if vllm_manager.start_server():
    print("VLLM server started successfully")
    
    # Configure agent with VLLM backend
    agent_config = Config(
        name="vllm-performance-agent",
        model_provider="vllm",
        model_id=vllm_manager.get_served_model_name(),
        endpoint=f"{vllm_manager.base_url}/v1",
        api_key="none"  # VLLM doesn't require API key
    )
    
    agent = Agent(config=agent_config)
else:
    print("Failed to start VLLM server")
```
  
**à¦‰à¦šà§à¦š-à¦¥à§à¦°à§à¦ªà§à¦Ÿ à¦®à¦¾à¦²à§à¦Ÿà¦¿-à¦à¦œà§‡à¦¨à§à¦Ÿ à¦¸à§‡à¦Ÿà¦†à¦ª**:  
```python
import asyncio
from concurrent.futures import ThreadPoolExecutor
from microsoft_agent_framework import Agent, Config
import openai

class VLLMHighThroughputManager:
    def __init__(self):
        self.model_configs = {
            "lightweight": {
                "model": "Qwen/Qwen2.5-0.5B-Instruct",
                "port": 8000,
                "max_model_len": 2048,
                "gpu_memory_utilization": 0.3
            },
            "balanced": {
                "model": "microsoft/Phi-3.5-mini-instruct",
                "port": 8001,
                "max_model_len": 4096,
                "gpu_memory_utilization": 0.5
            },
            "capable": {
                "model": "meta-llama/Llama-3.2-3B-Instruct",
                "port": 8002,
                "max_model_len": 8192,
                "gpu_memory_utilization": 0.7
            }
        }
        self.managers = {}
        self.agents = {}
        self.client_pool = {}
        
    async def initialize_all_models(self):
        """Initialize all VLLM models in parallel."""
        initialization_tasks = []
        
        for category, config in self.model_configs.items():
            task = self._initialize_model(category, config)
            initialization_tasks.append(task)
        
        results = await asyncio.gather(*initialization_tasks, return_exceptions=True)
        
        successful_inits = 0
        for i, result in enumerate(results):
            category = list(self.model_configs.keys())[i]
            if isinstance(result, Exception):
                print(f"Failed to initialize {category}: {result}")
            else:
                successful_inits += 1
                print(f"Successfully initialized {category} model")
        
        return successful_inits
    
    async def _initialize_model(self, category: str, config: Dict[str, Any]):
        """Initialize a single VLLM model instance."""
        manager = VLLMManager(
            model_name=config["model"],
            port=config["port"],
            max_model_len=config["max_model_len"],
            gpu_memory_utilization=config["gpu_memory_utilization"]
        )
        
        # Start server in thread to avoid blocking
        loop = asyncio.get_event_loop()
        with ThreadPoolExecutor() as executor:
            success = await loop.run_in_executor(executor, manager.start_server)
        
        if success:
            self.managers[category] = manager
            
            # Create agent
            agent_config = Config(
                name=f"vllm-{category}-agent",
                model_provider="vllm",
                model_id=manager.get_served_model_name(),
                endpoint=f"{manager.base_url}/v1",
                api_key="none"
            )
            
            self.agents[category] = Agent(config=agent_config)
            
            # Create client pool for high throughput
            self.client_pool[category] = [
                openai.OpenAI(base_url=f"{manager.base_url}/v1")
                for _ in range(5)  # 5 clients per model for parallelism
            ]
            
            return True
        else:
            raise Exception(f"Failed to start VLLM server for {category}")
    
    def get_optimal_agent(self, request_complexity: str, current_load: Dict[str, int]) -> str:
        """Select optimal agent based on request complexity and current load."""
        complexity_mapping = {
            "simple": "lightweight",
            "moderate": "balanced", 
            "complex": "capable"
        }
        
        preferred_category = complexity_mapping.get(request_complexity, "balanced")
        
        # Check if preferred agent is available and not overloaded
        if (preferred_category in self.agents and 
            current_load.get(preferred_category, 0) < 10):  # Max 10 concurrent per agent
            return preferred_category
        
        # Fallback to least loaded available agent
        available_agents = [(cat, load) for cat, load in current_load.items() 
                          if cat in self.agents and load < 10]
        
        if available_agents:
            return min(available_agents, key=lambda x: x[1])[0]
        
        return "balanced"  # Default fallback
    
    async def process_batch_requests(self, requests: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """Process multiple requests in parallel for maximum throughput."""
        current_load = {cat: 0 for cat in self.agents.keys()}
        tasks = []
        
        for request in requests:
            # Determine optimal agent
            complexity = request.get("complexity", "moderate")
            agent_category = self.get_optimal_agent(complexity, current_load)
            current_load[agent_category] += 1
            
            # Create processing task
            task = self._process_single_request(request, agent_category)
            tasks.append(task)
        
        # Process all requests in parallel
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # Format results
        formatted_results = []
        for i, result in enumerate(results):
            if isinstance(result, Exception):
                formatted_results.append({
                    "request_id": requests[i].get("id", i),
                    "status": "error",
                    "error": str(result)
                })
            else:
                formatted_results.append(result)
        
        return formatted_results
    
    async def _process_single_request(self, request: Dict[str, Any], agent_category: str) -> Dict[str, Any]:
        """Process a single request with the specified agent."""
        start_time = time.time()
        
        try:
            agent = self.agents[agent_category]
            response = await agent.chat_async(request["message"])
            
            processing_time = time.time() - start_time
            
            return {
                "request_id": request.get("id"),
                "status": "success",
                "response": response,
                "agent_used": agent_category,
                "processing_time": processing_time
            }
            
        except Exception as e:
            return {
                "request_id": request.get("id"),
                "status": "error",
                "error": str(e),
                "agent_used": agent_category,
                "processing_time": time.time() - start_time
            }

# High-throughput usage example
throughput_manager = VLLMHighThroughputManager()

# Initialize all models
initialized_count = await throughput_manager.initialize_all_models()
print(f"Initialized {initialized_count} models")

# Process batch requests
batch_requests = [
    {"id": 1, "message": "Simple question", "complexity": "simple"},
    {"id": 2, "message": "Complex analysis needed", "complexity": "complex"},
    {"id": 3, "message": "Moderate difficulty task", "complexity": "moderate"}
]

results = await throughput_manager.process_batch_requests(batch_requests)
for result in results:
    print(f"Request {result['request_id']}: {result['status']} in {result.get('processing_time', 0):.2f}s")
```
  

#### à¦ªà§à¦°à§‹à¦¡à¦¾à¦•à¦¶à¦¨ à¦¡à¦¿à¦ªà§à¦²à¦¯à¦¼à¦®à§‡à¦¨à§à¦Ÿ à¦ªà§à¦¯à¦¾à¦Ÿà¦¾à¦°à§à¦¨

**à¦à¦¨à§à¦Ÿà¦¾à¦°à¦ªà§à¦°à¦¾à¦‡à¦œ VLLM à¦ªà§à¦°à§‹à¦¡à¦¾à¦•à¦¶à¦¨ à¦¸à¦¾à¦°à§à¦­à¦¿à¦¸**:  
```python
import asyncio
import logging
import time
from typing import Dict, List, Optional
from dataclasses import dataclass
from microsoft_agent_framework import Agent, Config
import uvicorn
from fastapi import FastAPI, HTTPException, BackgroundTasks
from pydantic import BaseModel

@dataclass
class VLLMServerConfig:
    model_name: str
    port: int
    gpu_memory_utilization: float
    max_model_len: int
    tensor_parallel_size: int = 1
    quantization: Optional[str] = None

class AgentRequest(BaseModel):
    message: str
    agent_type: str = "general"
    priority: str = "normal"
    timeout: int = 30

class VLLMProductionService:
    def __init__(self, server_configs: Dict[str, VLLMServerConfig]):
        self.server_configs = server_configs
        self.managers = {}
        self.agents = {}
        self.metrics = {
            "requests_processed": 0,
            "requests_failed": 0,
            "total_processing_time": 0,
            "agent_usage": {name: 0 for name in server_configs.keys()},
            "throughput_per_minute": 0
        }
        self.request_queue = asyncio.Queue(maxsize=1000)
        self.processing_workers = []
        self.app = FastAPI(title="VLLM Agent Service")
        self._setup_routes()
        
    async def initialize_production_environment(self):
        """Initialize all VLLM servers for production."""
        logging.info("Initializing VLLM production environment...")
        
        initialization_tasks = []
        for name, config in self.server_configs.items():
            task = self._initialize_server(name, config)
            initialization_tasks.append(task)
        
        results = await asyncio.gather(*initialization_tasks, return_exceptions=True)
        
        successful_servers = 0
        for i, result in enumerate(results):
            server_name = list(self.server_configs.keys())[i]
            if isinstance(result, Exception):
                logging.error(f"Failed to initialize {server_name}: {result}")
            else:
                successful_servers += 1
                logging.info(f"Successfully initialized {server_name}")
        
        if successful_servers == 0:
            raise Exception("No VLLM servers could be initialized")
        
        # Start processing workers
        self.processing_workers = [
            asyncio.create_task(self._processing_worker(i))
            for i in range(min(4, successful_servers))  # 4 workers max
        ]
        
        logging.info(f"Production environment ready with {successful_servers} servers")
        return successful_servers
    
    async def _initialize_server(self, name: str, config: VLLMServerConfig):
        """Initialize a single VLLM server."""
        manager = VLLMManager(
            model_name=config.model_name,
            port=config.port,
            gpu_memory_utilization=config.gpu_memory_utilization,
            max_model_len=config.max_model_len
        )
        
        # Add quantization if specified
        if config.quantization:
            # This would be added to the manager's start command
            pass
        
        success = manager.start_server()
        if success:
            self.managers[name] = manager
            
            # Create production agent
            agent_config = Config(
                name=f"vllm-production-{name}",
                model_provider="vllm",
                model_id=manager.get_served_model_name(),
                endpoint=f"{manager.base_url}/v1",
                api_key="none",
                timeout=30.0
            )
            
            agent = Agent(config=agent_config)
            
            # Add production tools
            self._add_production_tools(agent, name)
            
            self.agents[name] = agent
            return True
        else:
            raise Exception(f"Failed to start VLLM server for {name}")
    
    def _add_production_tools(self, agent: Agent, server_type: str):
        """Add production tools based on server type."""
        if server_type == "customer_service":
            @agent.tool
            def escalate_to_human(issue: str, customer_id: str) -> str:
                """Escalate complex issues to human agents."""
                return f"Escalated issue for customer {customer_id}: {issue}"
            
            @agent.tool
            def lookup_order_status(order_id: str) -> dict:
                """Look up order status from production database."""
                # Production database lookup
                return {"order_id": order_id, "status": "shipped", "eta": "2 days"}
        
        elif server_type == "technical_support":
            @agent.tool
            def run_system_diagnostics(system_id: str) -> dict:
                """Run comprehensive system diagnostics."""
                return {"system_id": system_id, "status": "healthy", "issues": []}
            
            @agent.tool
            def create_incident_report(description: str, severity: str) -> str:
                """Create incident report in production system."""
                incident_id = f"INC-{hash(description) % 100000:05d}"
                return f"Created incident {incident_id} with severity {severity}"
    
    def _setup_routes(self):
        """Set up FastAPI routes for production service."""
        @self.app.post("/chat")
        async def chat_endpoint(request: AgentRequest, background_tasks: BackgroundTasks):
            try:
                # Add request to queue
                await self.request_queue.put({
                    "request": request,
                    "timestamp": time.time(),
                    "future": asyncio.Future()
                })
                
                # Wait for processing (with timeout)
                result = await asyncio.wait_for(
                    self._wait_for_result(request),
                    timeout=request.timeout
                )
                
                return result
                
            except asyncio.TimeoutError:
                raise HTTPException(status_code=408, detail="Request timeout")
            except Exception as e:
                raise HTTPException(status_code=500, detail=str(e))
        
        @self.app.get("/health")
        async def health_endpoint():
            return await self.get_health_status()
        
        @self.app.get("/metrics")
        async def metrics_endpoint():
            return self.get_production_metrics()
    
    async def _processing_worker(self, worker_id: int):
        """Background worker for processing agent requests."""
        logging.info(f"Starting processing worker {worker_id}")
        
        while True:
            try:
                # Get request from queue
                queue_item = await self.request_queue.get()
                request_data = queue_item["request"]
                request_future = queue_item["future"]
                
                # Select appropriate agent
                agent_name = self._select_agent(request_data.agent_type)
                
                if agent_name not in self.agents:
                    request_future.set_exception(Exception(f"Agent {agent_name} not available"))
                    continue
                
                # Process request
                start_time = time.time()
                try:
                    agent = self.agents[agent_name]
                    response = await agent.chat_async(request_data.message)
                    
                    processing_time = time.time() - start_time
                    
                    # Update metrics
                    self.metrics["requests_processed"] += 1
                    self.metrics["total_processing_time"] += processing_time
                    self.metrics["agent_usage"][agent_name] += 1
                    
                    result = {
                        "response": response,
                        "agent_used": agent_name,
                        "processing_time": processing_time,
                        "worker_id": worker_id
                    }
                    
                    request_future.set_result(result)
                    
                except Exception as e:
                    self.metrics["requests_failed"] += 1
                    request_future.set_exception(e)
                
                finally:
                    self.request_queue.task_done()
                    
            except Exception as e:
                logging.error(f"Worker {worker_id} error: {e}")
                await asyncio.sleep(1)
    
    def _select_agent(self, agent_type: str) -> str:
        """Select appropriate agent based on request type."""
        agent_mapping = {
            "customer_service": "customer_service",
            "technical": "technical_support",
            "general": "general_purpose"
        }
        
        return agent_mapping.get(agent_type, "general_purpose")
    
    async def _wait_for_result(self, request: AgentRequest):
        """Wait for request processing to complete."""
        # This is simplified - in production you'd track futures properly
        await asyncio.sleep(0.1)  # Placeholder
        return {"response": "Processed", "status": "success"}
    
    async def get_health_status(self) -> dict:
        """Get comprehensive health status of all services."""
        health_status = {
            "overall_status": "healthy",
            "servers": {},
            "queue_size": self.request_queue.qsize(),
            "active_workers": len([w for w in self.processing_workers if not w.done()]),
            "timestamp": time.time()
        }
        
        unhealthy_servers = 0
        for name, manager in self.managers.items():
            try:
                is_healthy = manager.health_check()
                health_status["servers"][name] = {
                    "status": "healthy" if is_healthy else "unhealthy",
                    "endpoint": manager.base_url,
                    "model": manager.model_name
                }
                if not is_healthy:
                    unhealthy_servers += 1
            except Exception as e:
                health_status["servers"][name] = {
                    "status": "error",
                    "error": str(e)
                }
                unhealthy_servers += 1
        
        if unhealthy_servers > 0:
            health_status["overall_status"] = "degraded" if unhealthy_servers < len(self.managers) else "unhealthy"
        
        return health_status
    
    def get_production_metrics(self) -> dict:
        """Get production performance metrics."""
        total_requests = self.metrics["requests_processed"] + self.metrics["requests_failed"]
        avg_processing_time = (
            self.metrics["total_processing_time"] / self.metrics["requests_processed"]
            if self.metrics["requests_processed"] > 0 else 0
        )
        
        success_rate = (
            self.metrics["requests_processed"] / total_requests * 100
            if total_requests > 0 else 0
        )
        
        return {
            "total_requests": total_requests,
            "successful_requests": self.metrics["requests_processed"],
            "failed_requests": self.metrics["requests_failed"],
            "success_rate_percent": success_rate,
            "average_processing_time_seconds": avg_processing_time,
            "agent_usage_distribution": self.metrics["agent_usage"],
            "queue_size": self.request_queue.qsize()
        }
    
    async def start_production_server(self, host: str = "0.0.0.0", port: int = 8080):
        """Start the production FastAPI server."""
        config = uvicorn.Config(
            self.app,
            host=host,
            port=port,
            log_level="info",
            workers=1  # Single worker for simplicity
        )
        server = uvicorn.Server(config)
        await server.serve()

# Production deployment example
production_configs = {
    "customer_service": VLLMServerConfig(
        model_name="microsoft/Phi-3.5-mini-instruct",
        port=8000,
        gpu_memory_utilization=0.4,
        max_model_len=4096
    ),
    "technical_support": VLLMServerConfig(
        model_name="meta-llama/Llama-3.2-3B-Instruct",
        port=8001,
        gpu_memory_utilization=0.6,
        max_model_len=8192
    ),
    "general_purpose": VLLMServerConfig(
        model_name="Qwen/Qwen2.5-1.5B-Instruct",
        port=8002,
        gpu_memory_utilization=0.3,
        max_model_len=2048
    )
}

production_service = VLLMProductionService(production_configs)

# Initialize and start production service
# await production_service.initialize_production_environment()
# await production_service.start_production_server()
```
  

#### à¦à¦¨à§à¦Ÿà¦¾à¦°à¦ªà§à¦°à¦¾à¦‡à¦œ à¦¬à§ˆà¦¶à¦¿à¦·à§à¦Ÿà§à¦¯ à¦à¦¬à¦‚ à¦®à¦¨à¦¿à¦Ÿà¦°à¦¿à¦‚

**à¦‰à¦¨à§à¦¨à¦¤ VLLM à¦ªà¦¾à¦°à¦«à¦°à¦®à§à¦¯à¦¾à¦¨à§à¦¸ à¦®à¦¨à¦¿à¦Ÿà¦°à¦¿à¦‚**:  
```python
import psutil
import nvidia_ml_py3 as nvml
from dataclasses import dataclass
from typing import List, Dict, Optional
import json
import asyncio

@dataclass
class PerformanceMetrics:
    timestamp: float
    requests_per_second: float
    average_latency_ms: float
    gpu_utilization_percent: float
    gpu_memory_used_gb: float
    cpu_utilization_percent: float
    memory_used_gb: float
    queue_length: int
    active_requests: int

class VLLMAdvancedMonitoring:
    def __init__(self, vllm_managers: Dict[str, VLLMManager]):
        self.managers = vllm_managers
        self.metrics_history = []
        self.alert_thresholds = {
            "gpu_utilization_max": 95,
            "gpu_memory_max_gb": 10,
            "latency_max_ms": 3000,
            "queue_length_max": 50,
            "error_rate_max_percent": 10
        }
        
        # Initialize NVIDIA ML for GPU monitoring
        try:
            nvml.nvmlInit()
            self.gpu_monitoring_available = True
            self.gpu_count = nvml.nvmlDeviceGetCount()
        except:
            self.gpu_monitoring_available = False
            self.gpu_count = 0
    
    async def collect_comprehensive_metrics(self) -> Dict[str, PerformanceMetrics]:
        """Collect detailed performance metrics for all VLLM instances."""
        all_metrics = {}
        
        for name, manager in self.managers.items():
            try:
                metrics = await self._collect_single_instance_metrics(name, manager)
                all_metrics[name] = metrics
            except Exception as e:
                logging.error(f"Failed to collect metrics for {name}: {e}")
                # Create error metrics
                all_metrics[name] = PerformanceMetrics(
                    timestamp=time.time(),
                    requests_per_second=0,
                    average_latency_ms=0,
                    gpu_utilization_percent=0,
                    gpu_memory_used_gb=0,
                    cpu_utilization_percent=0,
                    memory_used_gb=0,
                    queue_length=0,
                    active_requests=0
                )
        
        return all_metrics
    
    async def _collect_single_instance_metrics(self, name: str, manager: VLLMManager) -> PerformanceMetrics:
        """Collect metrics for a single VLLM instance."""
        timestamp = time.time()
        
        # Get VLLM-specific metrics via API
        vllm_stats = await self._get_vllm_stats(manager)
        
        # Get system metrics
        cpu_percent = psutil.cpu_percent(interval=0.1)
        memory_info = psutil.virtual_memory()
        memory_used_gb = memory_info.used / (1024**3)
        
        # Get GPU metrics if available
        gpu_utilization = 0
        gpu_memory_used = 0
        
        if self.gpu_monitoring_available and self.gpu_count > 0:
            try:
                # Assuming first GPU for simplicity
                handle = nvml.nvmlDeviceGetHandleByIndex(0)
                gpu_util = nvml.nvmlDeviceGetUtilizationRates(handle)
                gpu_utilization = gpu_util.gpu
                
                gpu_mem = nvml.nvmlDeviceGetMemoryInfo(handle)
                gpu_memory_used = gpu_mem.used / (1024**3)
                
            except Exception as e:
                logging.warning(f"GPU monitoring failed: {e}")
        
        return PerformanceMetrics(
            timestamp=timestamp,
            requests_per_second=vllm_stats.get("requests_per_second", 0),
            average_latency_ms=vllm_stats.get("average_latency_ms", 0),
            gpu_utilization_percent=gpu_utilization,
            gpu_memory_used_gb=gpu_memory_used,
            cpu_utilization_percent=cpu_percent,
            memory_used_gb=memory_used_gb,
            queue_length=vllm_stats.get("queue_length", 0),
            active_requests=vllm_stats.get("active_requests", 0)
        )
    
    async def _get_vllm_stats(self, manager: VLLMManager) -> dict:
        """Get VLLM-specific statistics via API calls."""
        try:
            # Test inference to measure latency
            start_time = time.time()
            client = manager.get_openai_client()
            
            response = await asyncio.wait_for(
                asyncio.to_thread(
                    client.chat.completions.create,
                    model=manager.get_served_model_name(),
                    messages=[{"role": "user", "content": "ping"}],
                    max_tokens=1
                ),
                timeout=5.0
            )
            
            latency_ms = (time.time() - start_time) * 1000
            
            return {
                "average_latency_ms": latency_ms,
                "requests_per_second": 1000 / latency_ms if latency_ms > 0 else 0,
                "queue_length": 0,  # Would need to be exposed by VLLM
                "active_requests": 1  # Approximation
            }
            
        except Exception as e:
            logging.warning(f"Failed to get VLLM stats: {e}")
            return {
                "average_latency_ms": 0,
                "requests_per_second": 0,
                "queue_length": 0,
                "active_requests": 0
            }
    
    def generate_performance_report(self, time_window_minutes: int = 60) -> dict:
        """Generate comprehensive performance report."""
        cutoff_time = time.time() - (time_window_minutes * 60)
        recent_metrics = [
            metrics for metrics in self.metrics_history
            if any(m.timestamp > cutoff_time for m in metrics.values())
        ]
        
        if not recent_metrics:
            return {"error": "No recent metrics available"}
        
        report = {
            "time_window_minutes": time_window_minutes,
            "total_samples": len(recent_metrics),
            "instances": {}
        }
        
        # Analyze each instance
        for instance_name in self.managers.keys():
            instance_metrics = [
                metrics[instance_name] for metrics in recent_metrics
                if instance_name in metrics
            ]
            
            if instance_metrics:
                report["instances"][instance_name] = {
                    "avg_latency_ms": sum(m.average_latency_ms for m in instance_metrics) / len(instance_metrics),
                    "max_latency_ms": max(m.average_latency_ms for m in instance_metrics),
                    "avg_gpu_utilization": sum(m.gpu_utilization_percent for m in instance_metrics) / len(instance_metrics),
                    "avg_requests_per_second": sum(m.requests_per_second for m in instance_metrics) / len(instance_metrics),
                    "max_queue_length": max(m.queue_length for m in instance_metrics),
                    "availability_percent": (len(instance_metrics) / len(recent_metrics)) * 100
                }
        
        return report
    
    async def auto_scaling_recommendations(self) -> List[dict]:
        """Generate auto-scaling recommendations based on performance metrics."""
        recommendations = []
        
        if not self.metrics_history:
            return recommendations
        
        latest_metrics = self.metrics_history[-1]
        
        for instance_name, metrics in latest_metrics.items():
            # High latency recommendation
            if metrics.average_latency_ms > self.alert_thresholds["latency_max_ms"]:
                recommendations.append({
                    "instance": instance_name,
                    "type": "scale_up",
                    "reason": f"High latency: {metrics.average_latency_ms:.0f}ms",
                    "suggestion": "Consider adding tensor parallelism or increasing GPU memory"
                })
            
            # High GPU utilization recommendation
            if metrics.gpu_utilization_percent > self.alert_thresholds["gpu_utilization_max"]:
                recommendations.append({
                    "instance": instance_name,
                    "type": "scale_out",
                    "reason": f"High GPU utilization: {metrics.gpu_utilization_percent:.1f}%",
                    "suggestion": "Consider adding additional GPU instances"
                })
            
            # Low utilization recommendation
            if (metrics.gpu_utilization_percent < 20 and 
                metrics.requests_per_second < 1):
                recommendations.append({
                    "instance": instance_name,
                    "type": "scale_down",
                    "reason": f"Low utilization: {metrics.gpu_utilization_percent:.1f}% GPU, {metrics.requests_per_second:.1f} RPS",
                    "suggestion": "Consider consolidating workloads or reducing resources"
                })
        
        return recommendations

# Advanced monitoring setup
monitoring = VLLMAdvancedMonitoring({
    "customer_service": vllm_manager,
    # Add other managers as needed
})

async def advanced_monitoring_loop():
    """Advanced monitoring with auto-scaling recommendations."""
    while True:
        try:
            # Collect metrics
            metrics = await monitoring.collect_comprehensive_metrics()
            monitoring.metrics_history.append(metrics)
            
            # Keep only last 1000 entries
            if len(monitoring.metrics_history) > 1000:
                monitoring.metrics_history = monitoring.metrics_history[-1000:]
            
            # Generate recommendations every 5 minutes
            if len(monitoring.metrics_history) % 10 == 0:  # Every 10th collection (5 minutes if collecting every 30s)
                recommendations = await monitoring.auto_scaling_recommendations()
                
                if recommendations:
                    logging.info(f"Auto-scaling recommendations: {recommendations}")
            
            # Generate performance report every hour
            if len(monitoring.metrics_history) % 120 == 0:  # Every 120th collection (1 hour)
                report = monitoring.generate_performance_report(60)
                logging.info(f"Performance report: {json.dumps(report, indent=2)}")
            
        except Exception as e:
            logging.error(f"Advanced monitoring error: {e}")
        
        await asyncio.sleep(30)  # Collect metrics every 30 seconds

# Start advanced monitoring
# asyncio.create_task(advanced_monitoring_loop())
```
  

#### à¦‰à¦¨à§à¦¨à¦¤ à¦•à¦¨à¦«à¦¿à¦—à¦¾à¦°à§‡à¦¶à¦¨ à¦à¦¬à¦‚ à¦…à¦ªà§à¦Ÿà¦¿à¦®à¦¾à¦‡à¦œà§‡à¦¶à¦¨

**à¦ªà§à¦°à§‹à¦¡à¦¾à¦•à¦¶à¦¨ VLLM à¦•à¦¨à¦«à¦¿à¦—à¦¾à¦°à§‡à¦¶à¦¨ à¦Ÿà§‡à¦®à¦ªà§à¦²à§‡à¦Ÿ**:  
```python
from enum import Enum
from typing import Dict, Any

class DeploymentScenario(Enum):
    DEVELOPMENT = "development"
    STAGING = "staging"
    PRODUCTION_LOW = "production_low"
    PRODUCTION_HIGH = "production_high"
    ENTERPRISE = "enterprise"

class VLLMConfigTemplates:
    """Production-ready VLLM configuration templates."""
    
    @staticmethod
    def get_config_template(scenario: DeploymentScenario) -> Dict[str, Any]:
        """Get optimized configuration for deployment scenario."""
        
        templates = {
            DeploymentScenario.DEVELOPMENT: {
                "gpu_memory_utilization": 0.6,
                "max_model_len": 2048,
                "tensor_parallel_size": 1,
                "pipeline_parallel_size": 1,
                "quantization": None,
                "enable_prefix_caching": False,
                "max_num_seqs": 32,
                "max_num_batched_tokens": 2048
            },
            
            DeploymentScenario.STAGING: {
                "gpu_memory_utilization": 0.8,
                "max_model_len": 4096,
                "tensor_parallel_size": 1,
                "pipeline_parallel_size": 1,
                "quantization": "awq",
                "enable_prefix_caching": True,
                "max_num_seqs": 64,
                "max_num_batched_tokens": 4096
            },
            
            DeploymentScenario.PRODUCTION_LOW: {
                "gpu_memory_utilization": 0.85,
                "max_model_len": 4096,
                "tensor_parallel_size": 1,
                "pipeline_parallel_size": 1,
                "quantization": "awq",
                "enable_prefix_caching": True,
                "max_num_seqs": 128,
                "max_num_batched_tokens": 8192,
                "enable_chunked_prefill": True
            },
            
            DeploymentScenario.PRODUCTION_HIGH: {
                "gpu_memory_utilization": 0.9,
                "max_model_len": 8192,
                "tensor_parallel_size": 2,
                "pipeline_parallel_size": 1,
                "quantization": "awq",
                "enable_prefix_caching": True,
                "max_num_seqs": 256,
                "max_num_batched_tokens": 16384,
                "enable_chunked_prefill": True,
                "speculative_model": "small_draft_model"
            },
            
            DeploymentScenario.ENTERPRISE: {
                "gpu_memory_utilization": 0.95,
                "max_model_len": 16384,
                "tensor_parallel_size": 4,
                "pipeline_parallel_size": 2,
                "quantization": "awq",
                "enable_prefix_caching": True,
                "max_num_seqs": 512,
                "max_num_batched_tokens": 32768,
                "enable_chunked_prefill": True,
                "speculative_model": "optimized_draft_model",
                "guided_decoding_backend": "outlines"
            }
        }
        
        return templates[scenario]
    
    @staticmethod
    def generate_vllm_command(model_name: str, 
                             scenario: DeploymentScenario,
                             port: int = 8000,
                             host: str = "0.0.0.0") -> List[str]:
        """Generate optimized VLLM command for deployment scenario."""
        
        config = VLLMConfigTemplates.get_config_template(scenario)
        
        cmd = [
            "python", "-m", "vllm.entrypoints.openai.api_server",
            "--model", model_name,
            "--host", host,
            "--port", str(port),
            "--gpu-memory-utilization", str(config["gpu_memory_utilization"]),
            "--max-model-len", str(config["max_model_len"]),
            "--tensor-parallel-size", str(config["tensor_parallel_size"]),
            "--max-num-seqs", str(config["max_num_seqs"]),
            "--max-num-batched-tokens", str(config["max_num_batched_tokens"]),
            "--trust-remote-code",
            "--disable-log-requests"
        ]
        
        # Add optional parameters
        if config.get("quantization"):
            cmd.extend(["--quantization", config["quantization"]])
        
        if config.get("enable_prefix_caching"):
            cmd.append("--enable-prefix-caching")
        
        if config.get("enable_chunked_prefill"):
            cmd.append("--enable-chunked-prefill")
        
        if config.get("pipeline_parallel_size", 1) > 1:
            cmd.extend(["--pipeline-parallel-size", str(config["pipeline_parallel_size"])])
        
        if config.get("speculative_model"):
            cmd.extend(["--speculative-model", config["speculative_model"]])
        
        return cmd

# Usage examples
dev_cmd = VLLMConfigTemplates.generate_vllm_command(
    "microsoft/Phi-3.5-mini-instruct",
    DeploymentScenario.DEVELOPMENT,
    port=8000
)

prod_cmd = VLLMConfigTemplates.generate_vllm_command(
    "microsoft/Phi-3.5-mini-instruct",
    DeploymentScenario.PRODUCTION_HIGH,
    port=8001
)

print(f"Development command: {' '.join(dev_cmd)}")
print(f"Production command: {' '.join(prod_cmd)}")
```
  
**VLLM-à¦à¦° à¦œà¦¨à§à¦¯ à¦ªà§à¦°à§‹à¦¡à¦¾à¦•à¦¶à¦¨ à¦¡à¦¿à¦ªà§à¦²à¦¯à¦¼à¦®à§‡à¦¨à§à¦Ÿ à¦šà§‡à¦•à¦²à¦¿à¦¸à§à¦Ÿ**:

âœ… **à¦¹à¦¾à¦°à§à¦¡à¦“à¦¯à¦¼à§à¦¯à¦¾à¦° à¦…à¦ªà§à¦Ÿà¦¿à¦®à¦¾à¦‡à¦œà§‡à¦¶à¦¨**:  
- à¦®à¦¾à¦²à§à¦Ÿà¦¿-GPU à¦¸à§‡à¦Ÿà¦†à¦ªà§‡à¦° à¦œà¦¨à§à¦¯ à¦Ÿà§‡à¦¨à¦¸à¦° à¦ªà§à¦¯à¦¾à¦°à¦¾à¦²à§‡à¦²à¦¿à¦œà¦® à¦•à¦¨à¦«à¦¿à¦—à¦¾à¦° à¦•à¦°à§à¦¨  
- à¦®à§‡à¦®à§‹à¦°à¦¿ à¦¦à¦•à§à¦·à¦¤à¦¾à¦° à¦œà¦¨à§à¦¯ à¦•à§‹à¦¯à¦¼à¦¾à¦¨à§à¦Ÿà¦¾à¦‡à¦œà§‡à¦¶à¦¨ (AWQ/GPTQ) à¦¸à¦•à§à¦·à¦® à¦•à¦°à§à¦¨  
- GPU à¦®à§‡à¦®à§‹à¦°à¦¿ à¦¬à§à¦¯à¦¬à¦¹à¦¾à¦° (85-95%) à¦…à¦ªà§à¦Ÿà¦¿à¦®à¦¾à¦‡à¦œ à¦•à¦°à§à¦¨  
- à¦¥à§à¦°à§à¦ªà§à¦Ÿà§‡à¦° à¦œà¦¨à§à¦¯ à¦‰à¦ªà¦¯à§à¦•à§à¦¤ à¦¬à§à¦¯à¦¾à¦š à¦¸à¦¾à¦‡à¦œ à¦•à¦¨à¦«à¦¿à¦—à¦¾à¦° à¦•à¦°à§à¦¨  

âœ… **à¦ªà¦¾à¦°à¦«à¦°à¦®à§à¦¯à¦¾à¦¨à§à¦¸ à¦Ÿà¦¿à¦‰à¦¨à¦¿à¦‚**:  
- à¦ªà§à¦¨à¦°à¦¾à¦¬à§ƒà¦¤à§à¦¤ à¦ªà§à¦°à¦¶à§à¦¨à§‡à¦° à¦œà¦¨à§à¦¯ à¦ªà§à¦°à¦¿à¦«à¦¿à¦•à§à¦¸ à¦•à§à¦¯à¦¾à¦¶à¦¿à¦‚ à¦¸à¦•à§à¦·à¦® à¦•à¦°à§à¦¨  
- à¦¦à§€à¦°à§à¦˜ à¦¸à¦¿à¦•à§‹à¦¯à¦¼à§‡à¦¨à§à¦¸à§‡à¦° à¦œà¦¨à§à¦¯ à¦šà¦¾à¦™à§à¦•à¦¡ à¦ªà§à¦°à¦¿à¦«à¦¿à¦² à¦•à¦¨à¦«à¦¿à¦—à¦¾à¦° à¦•à¦°à§à¦¨  
- à¦¦à§à¦°à§à¦¤ à¦‡à¦¨à¦«à¦¾à¦°à§‡à¦¨à§à¦¸à§‡à¦° à¦œà¦¨à§à¦¯ à¦¸à§à¦ªà§‡à¦•à§à¦²à§‡à¦Ÿà¦¿à¦­ à¦¡à¦¿à¦•à§‹à¦¡à¦¿à¦‚ à¦¸à§‡à¦Ÿ à¦†à¦ª à¦•à¦°à§à¦¨  
- à¦¹à¦¾à¦°à§à¦¡à¦“à¦¯à¦¼à§à¦¯à¦¾à¦°à§‡à¦° à¦‰à¦ªà¦° à¦­à¦¿à¦¤à§à¦¤à¦¿ à¦•à¦°à§‡ max_num_seqs à¦…à¦ªà§à¦Ÿà¦¿à¦®à¦¾à¦‡à¦œ à¦•à¦°à§à¦¨  

âœ… **à¦ªà§à¦°à§‹à¦¡à¦¾à¦•à¦¶à¦¨ à¦¬à§ˆà¦¶à¦¿à¦·à§à¦Ÿà§à¦¯**:  
- à¦¸à§à¦¬à¦¾à¦¸à§à¦¥à§à¦¯ à¦®à¦¨à¦¿à¦Ÿà¦°à¦¿à¦‚ à¦à¦¬à¦‚ à¦®à§‡à¦Ÿà§à¦°à¦¿à¦•à§à¦¸ à¦¸à¦‚à¦—à§à¦°à¦¹ à¦¸à§‡à¦Ÿ à¦†à¦ª à¦•à¦°à§à¦¨  
- à¦¸à§à¦¬à¦¯à¦¼à¦‚à¦•à§à¦°à¦¿à¦¯à¦¼ à¦°à¦¿à¦¸à§à¦Ÿà¦¾à¦°à§à¦Ÿ à¦à¦¬à¦‚ à¦«à§‡à¦‡à¦²à¦“à¦­à¦¾à¦° à¦•à¦¨à¦«à¦¿à¦—à¦¾à¦° à¦•à¦°à§à¦¨  
- à¦…à¦¨à§à¦°à§‹à¦§ à¦•à¦¿à¦‰à¦‡à¦‚ à¦à¦¬à¦‚ à¦²à§‹à¦¡ à¦¬à§à¦¯à¦¾à¦²à§‡à¦¨à§à¦¸à¦¿à¦‚ à¦¬à¦¾à¦¸à§à¦¤à¦¬à¦¾à¦¯à¦¼à¦¨ à¦•à¦°à§à¦¨  
- à¦¬à§à¦¯à¦¾à¦ªà¦• à¦²à¦—à¦¿à¦‚ à¦à¦¬à¦‚ à¦…à§à¦¯à¦¾à¦²à¦¾à¦°à§à¦Ÿà¦¿à¦‚ à¦¸à§‡à¦Ÿ à¦†à¦ª à¦•à¦°à§à¦¨  

âœ… **à¦¨à¦¿à¦°à¦¾à¦ªà¦¤à§à¦¤à¦¾ à¦à¦¬à¦‚ à¦¨à¦¿à¦°à§à¦­à¦°à¦¯à§‹à¦—à§à¦¯à¦¤à¦¾**:  
- à¦«à¦¾à¦¯à¦¼à¦¾à¦°à¦“à¦¯à¦¼à¦¾à¦² à¦¨à¦¿à¦¯à¦¼à¦® à¦à¦¬à¦‚ à¦…à§à¦¯à¦¾à¦•à§à¦¸à§‡à¦¸ à¦•à¦¨à§à¦Ÿà§à¦°à§‹à¦² à¦•à¦¨à¦«à¦¿à¦—à¦¾à¦° à¦•à¦°à§à¦¨  
- API à¦°à§‡à¦Ÿ à¦²à¦¿à¦®à¦¿à¦Ÿà¦¿à¦‚ à¦à¦¬à¦‚ à¦…à¦¥à§‡à¦¨à§à¦Ÿà¦¿à¦•à§‡à¦¶à¦¨ à¦¸à§‡à¦Ÿ à¦†à¦ª à¦•à¦°à§à¦¨  
- à¦—à§à¦°à§‡à¦¸à¦«à§à¦² à¦¶à¦¾à¦Ÿà¦¡à¦¾à¦‰à¦¨ à¦à¦¬à¦‚ à¦•à§à¦²à¦¿à¦¨à¦†à¦ª à¦¬à¦¾à¦¸à§à¦¤à¦¬à¦¾à¦¯à¦¼à¦¨ à¦•à¦°à§à¦¨  
- à¦¬à§à¦¯à¦¾à¦•à¦†à¦ª à¦à¦¬à¦‚ à¦¡à¦¿à¦œà¦¾à¦¸à§à¦Ÿà¦¾à¦° à¦°à¦¿à¦•à¦­à¦¾à¦°à¦¿ à¦•à¦¨à¦«à¦¿à¦—à¦¾à¦° à¦•à¦°à§à¦¨  

âœ… **à¦‡à¦¨à§à¦Ÿà¦¿à¦—à§à¦°à§‡à¦¶à¦¨ à¦Ÿà§‡à¦¸à§à¦Ÿà¦¿à¦‚**:  
- à¦®à¦¾à¦‡à¦•à§à¦°à§‹à¦¸à¦«à¦Ÿ à¦à¦œà§‡à¦¨à§à¦Ÿ à¦«à§à¦°à§‡à¦®à¦“à¦¯à¦¼à¦¾à¦°à§à¦• à¦‡à¦¨à§à¦Ÿà¦¿à¦—à§à¦°à§‡à¦¶à¦¨ à¦ªà¦°à§€à¦•à§à¦·à¦¾ à¦•à¦°à§à¦¨  
- à¦‰à¦šà§à¦š-à¦¥à§à¦°à§à¦ªà§à¦Ÿ à¦ªà¦°à¦¿à¦¸à§à¦¥à¦¿à¦¤à¦¿ à¦¯à¦¾à¦šà¦¾à¦‡ à¦•à¦°à§à¦¨  
- à¦«à§‡à¦‡à¦²à¦“à¦­à¦¾à¦° à¦à¦¬à¦‚ à¦°à¦¿à¦•à¦­à¦¾à¦°à¦¿ à¦ªà¦¦à§à¦§à¦¤à¦¿ à¦ªà¦°à§€à¦•à§à¦·à¦¾ à¦•à¦°à§à¦¨  
- à¦²à§‹à¦¡à§‡à¦° à¦…à¦§à§€à¦¨à§‡ à¦ªà¦¾à¦°à¦«à¦°à¦®à§à¦¯à¦¾à¦¨à§à¦¸ à¦¬à§‡à¦žà§à¦šà¦®à¦¾à¦°à§à¦• à¦•à¦°à§à¦¨  

**à¦…à¦¨à§à¦¯à¦¾à¦¨à§à¦¯ à¦¸à¦®à¦¾à¦§à¦¾à¦¨à§‡à¦° à¦¸à¦¾à¦¥à§‡ à¦¤à§à¦²à¦¨à¦¾**:

| à¦¬à§ˆà¦¶à¦¿à¦·à§à¦Ÿà§à¦¯ | VLLM | Foundry Local | Ollama |
|---------|------|---------------|--------|
| **à¦²à¦•à§à¦·à§à¦¯ à¦¬à§à¦¯à¦¬à¦¹à¦¾à¦° à¦•à§à¦·à§‡à¦¤à§à¦°** | à¦‰à¦šà§à¦š-à¦¥à§à¦°à§à¦ªà§à¦Ÿ à¦ªà§à¦°à§‹à¦¡à¦¾à¦•à¦¶à¦¨ | à¦à¦¨à§à¦Ÿà¦¾à¦°à¦ªà§à¦°à¦¾à¦‡à¦œ à¦¸à¦¹à¦œ à¦¬à§à¦¯à¦¬à¦¹à¦¾à¦° | à¦¡à§‡à¦­à§‡à¦²à¦ªà¦®à§‡à¦¨à§à¦Ÿ à¦à¦¬à¦‚ à¦•à¦®à¦¿à¦‰à¦¨à¦¿à¦Ÿà¦¿ |
| **à¦ªà¦¾à¦°à¦«à¦°à¦®à§à¦¯à¦¾à¦¨à§à¦¸** | à¦¸à¦°à§à¦¬à¦¾à¦§à¦¿à¦• à¦¥à§à¦°à§à¦ªà§à¦Ÿ | à¦¬à§à¦¯à¦¾à¦²à§‡à¦¨à§à¦¸à¦¡ | à¦­à¦¾à¦²à§‹ |
| **à¦®à§‡à¦®à§‹à¦°à¦¿ à¦¦à¦•à§à¦·à¦¤à¦¾** | PagedAttention à¦…à¦ªà§à¦Ÿà¦¿à¦®à¦¾à¦‡à¦œà§‡à¦¶à¦¨ | à¦¸à§à¦¬à¦¯à¦¼à¦‚à¦•à§à¦°à¦¿à¦¯à¦¼ à¦…à¦ªà§à¦Ÿà¦¿à¦®à¦¾à¦‡à¦œà§‡à¦¶à¦¨ | à¦¸à§à¦Ÿà§à¦¯à¦¾à¦¨à§à¦¡à¦¾à¦°à§à¦¡ |
| **à¦¸à§‡à¦Ÿà¦†à¦ª à¦œà¦Ÿà¦¿à¦²à¦¤à¦¾** | à¦‰à¦šà§à¦š (à¦…à¦¨à§‡à¦• à¦ªà§à¦¯à¦¾à¦°à¦¾à¦®à¦¿à¦Ÿà¦¾à¦°) | à¦•à¦® (à¦¸à§à¦¬à¦¯à¦¼à¦‚à¦•à§à¦°à¦¿à¦¯à¦¼) | à¦•à¦® (à¦¸à¦¹à¦œ) |
| **à¦¸à§à¦•à§‡à¦²à§‡à¦¬à¦¿à¦²à¦¿à¦Ÿà¦¿** | à¦šà¦®à§Žà¦•à¦¾à¦° (à¦Ÿà§‡à¦¨à¦¸à¦°/à¦ªà¦¾à¦‡à¦ªà¦²à¦¾à¦‡à¦¨ à¦ªà§à¦¯à¦¾à¦°à¦¾à¦²à§‡à¦²) | à¦­à¦¾à¦²à§‹ | à¦¸à§€à¦®à¦¿à¦¤ |
| **à¦•à§‹à¦¯à¦¼à¦¾à¦¨à§à¦Ÿà¦¾à¦‡à¦œà§‡à¦¶à¦¨** | à¦‰à¦¨à§à¦¨à¦¤ (AWQ, GPTQ, FP8) | à¦¸à§à¦¬à¦¯à¦¼à¦‚à¦•à§à¦°à¦¿à¦¯à¦¼ | à¦¸à§à¦Ÿà§à¦¯à¦¾à¦¨à§à¦¡à¦¾à¦°à§à¦¡ GGUF |
| **à¦à¦¨à§à¦Ÿà¦¾à¦°à¦ªà§à¦°à¦¾à¦‡à¦œ à¦¬à§ˆà¦¶à¦¿à¦·à§à¦Ÿà§à¦¯** | à¦•à¦¾à¦¸à§à¦Ÿà¦® à¦‡à¦®à¦ªà§à¦²à¦¿à¦®à§‡à¦¨à§à¦Ÿà§‡à¦¶à¦¨ à¦ªà§à¦°à¦¯à¦¼à§‹à¦œà¦¨ | à¦¬à¦¿à¦²à§à¦Ÿ-à¦‡à¦¨ | à¦•à¦®à¦¿à¦‰à¦¨à¦¿à¦Ÿà¦¿ à¦Ÿà§à¦²à¦¸ |
| **à¦¸à§‡à¦°à¦¾ à¦¬à§à¦¯à¦¬à¦¹à¦¾à¦° à¦•à§à¦·à§‡à¦¤à§à¦°** | à¦‰à¦šà§à¦š-à¦¸à§à¦•à§‡à¦² à¦ªà§à¦°à§‹à¦¡à¦¾à¦•à¦¶à¦¨ à¦à¦œà§‡à¦¨à§à¦Ÿ | à¦à¦¨à§à¦Ÿà¦¾à¦°à¦ªà§à¦°à¦¾à¦‡à¦œ à¦ªà§à¦°à§‹à¦¡à¦¾à¦•à¦¶à¦¨ | à¦¡à§‡à¦­à§‡à¦²à¦ªà¦®à§‡à¦¨à§à¦Ÿ |

**à¦•à¦–à¦¨ VLLM à¦¬à§‡à¦›à§‡ à¦¨à§‡à¦¬à§‡à¦¨**:
- **à¦‰à¦šà§à¦š-à¦¥à§à¦°à§à¦ªà§à¦Ÿ à¦ªà§à¦°à¦¯à¦¼à§‹à¦œà¦¨à§€à¦¯à¦¼à¦¤à¦¾**: à¦ªà§à¦°à¦¤à¦¿ à¦¸à§‡à¦•à§‡à¦¨à§à¦¡à§‡ à¦¶à¦¤ à¦¶à¦¤ à¦…à¦¨à§à¦°à§‹à¦§ à¦ªà§à¦°à¦•à§à¦°à¦¿à¦¯à¦¼à¦¾à¦•à¦°à¦£  
- **à¦¬à§ƒà¦¹à§Ž-à¦¸à§à¦•à§‡à¦² à¦¡à¦¿à¦ªà§à¦²à¦¯à¦¼à¦®à§‡à¦¨à§à¦Ÿ**: à¦®à¦¾à¦²à§à¦Ÿà¦¿-GPU, à¦®à¦¾à¦²à§à¦Ÿà¦¿-à¦¨à§‹à¦¡ à¦¡à¦¿à¦ªà§à¦²à¦¯à¦¼à¦®à§‡à¦¨à§à¦Ÿ  
- **à¦ªà¦¾à¦°à¦«à¦°à¦®à§à¦¯à¦¾à¦¨à§à¦¸ à¦•à§à¦°à¦¿à¦Ÿà¦¿à¦•à§à¦¯à¦¾à¦²**: à¦¸à§à¦•à§‡à¦²à§‡ à¦¸à¦¾à¦¬-à¦¸à§‡à¦•à§‡à¦¨à§à¦¡ à¦°à§‡à¦¸à¦ªà¦¨à§à¦¸ à¦Ÿà¦¾à¦‡à¦®  
- **à¦‰à¦¨à§à¦¨à¦¤ à¦…à¦ªà§à¦Ÿà¦¿à¦®à¦¾à¦‡à¦œà§‡à¦¶à¦¨**: à¦•à¦¾à¦¸à§à¦Ÿà¦® à¦•à§‹à¦¯à¦¼à¦¾à¦¨à§à¦Ÿà¦¾à¦‡à¦œà§‡à¦¶à¦¨ à¦à¦¬à¦‚ à¦¬à§à¦¯à¦¾à¦šà¦¿à¦‚à¦¯à¦¼à§‡à¦° à¦ªà§à¦°à¦¯à¦¼à§‹à¦œà¦¨  
- **à¦°à¦¿à¦¸à§‹à¦°à§à¦¸ à¦¦à¦•à§à¦·à¦¤à¦¾**: à¦¬à§à¦¯à¦¯à¦¼à¦¬à¦¹à§à¦² GPU à¦¹à¦¾à¦°à§à¦¡à¦“à¦¯à¦¼à§à¦¯à¦¾à¦°à§‡à¦° à¦¸à¦°à§à¦¬à¦¾à¦§à¦¿à¦• à¦¬à§à¦¯à¦¬à¦¹à¦¾à¦°  

## à¦¬à¦¾à¦¸à§à¦¤à¦¬-à¦œà§€à¦¬à¦¨à§‡à¦° SLM à¦à¦œà§‡à¦¨à§à¦Ÿ à¦…à§à¦¯à¦¾à¦ªà§à¦²à¦¿à¦•à§‡à¦¶à¦¨

### à¦•à¦¾à¦¸à§à¦Ÿà¦®à¦¾à¦° à¦¸à¦¾à¦°à§à¦­à¦¿à¦¸ SLM à¦à¦œà§‡à¦¨à§à¦Ÿ
- **SLM à¦¸à¦•à§à¦·à¦®à¦¤à¦¾**: à¦…à§à¦¯à¦¾à¦•à¦¾à¦‰à¦¨à§à¦Ÿ à¦²à§à¦•à¦†à¦ª, à¦ªà¦¾à¦¸à¦“à¦¯à¦¼à¦¾à¦°à§à¦¡ à¦°à¦¿à¦¸à§‡à¦Ÿ, à¦…à¦°à§à¦¡à¦¾à¦° à¦¸à§à¦Ÿà§à¦¯à¦¾à¦Ÿà¦¾à¦¸ à¦šà§‡à¦•  
- **à¦–à¦°à¦š à¦¸à§à¦¬à¦¿à¦§à¦¾**: LLM à¦à¦œà§‡à¦¨à§à¦Ÿà§‡à¦° à¦¤à§à¦²à¦¨à¦¾à¦¯à¦¼ à¦‡à¦¨à¦«à¦¾à¦°à§‡à¦¨à§à¦¸ à¦–à¦°à¦šà§‡ 10x à¦¹à§à¦°à¦¾à¦¸  
- **à¦ªà¦¾à¦°à¦«à¦°à¦®à§à¦¯à¦¾à¦¨à§à¦¸**: à¦°à§à¦Ÿà¦¿à¦¨ à¦ªà§à¦°à¦¶à§à¦¨à§‡à¦° à¦œà¦¨à§à¦¯ à¦¦à§à¦°à§à¦¤ à¦°à§‡à¦¸à¦ªà¦¨à§à¦¸ à¦Ÿà¦¾à¦‡à¦® à¦à¦¬à¦‚ à¦§à¦¾à¦°à¦¾à¦¬à¦¾à¦¹à¦¿à¦• à¦—à§à¦£à¦®à¦¾à¦¨  

### à¦¬à¦¿à¦œà¦¨à§‡à¦¸ à¦ªà§à¦°à¦¸à§‡à¦¸ SLM à¦à¦œà§‡à¦¨à§à¦Ÿ
- **à¦‡à¦¨à¦­à¦¯à¦¼à§‡à¦¸ à¦ªà§à¦°à¦¸à§‡à¦¸à¦¿à¦‚ à¦à¦œà§‡à¦¨à§à¦Ÿ**: à¦¡à§‡à¦Ÿà¦¾ à¦à¦•à§à¦¸à¦Ÿà§à¦°à¦¾à¦•à§à¦Ÿ, à¦¤à¦¥à§à¦¯ à¦¯à¦¾à¦šà¦¾à¦‡, à¦…à¦¨à§à¦®à§‹à¦¦à¦¨à§‡à¦° à¦œà¦¨à§à¦¯ à¦°à¦¾à¦‰à¦Ÿ  
- **à¦‡à¦®à§‡à¦‡à¦² à¦®à§à¦¯à¦¾à¦¨à§‡à¦œà¦®à§‡à¦¨à§à¦Ÿ à¦à¦œà§‡à¦¨à§à¦Ÿ**: à¦¸à§à¦¬à¦¯à¦¼à¦‚à¦•à§à¦°à¦¿à¦¯à¦¼à¦­à¦¾à¦¬à§‡ à¦¶à§à¦°à§‡à¦£à§€à¦¬à¦¦à§à¦§, à¦…à¦—à§à¦°à¦¾à¦§à¦¿à¦•à¦¾à¦° à¦¨à¦¿à¦°à§à¦§à¦¾à¦°à¦£, à¦‰à¦¤à§à¦¤à¦° à¦–à¦¸à¦¡à¦¼à¦¾ à¦¤à§ˆà¦°à¦¿  
- **à¦¶à¦¿à¦¡à¦¿à¦‰à¦²à¦¿à¦‚ à¦à¦œà§‡à¦¨à§à¦Ÿ**: à¦®à¦¿à¦Ÿà¦¿à¦‚ à¦¸à¦®à¦¨à§à¦¬à¦¯à¦¼, à¦•à§à¦¯à¦¾à¦²à§‡à¦¨à§à¦¡à¦¾à¦° à¦ªà¦°à¦¿à¦šà¦¾à¦²à¦¨à¦¾, à¦°à¦¿à¦®à¦¾à¦‡à¦¨à§à¦¡à¦¾à¦° à¦ªà¦¾à¦ à¦¾à¦¨à§‹  

### à¦¬à§à¦¯à¦•à§à¦¤à¦¿à¦—à¦¤ SLM à¦¡à¦¿à¦œà¦¿à¦Ÿà¦¾à¦² à¦…à§à¦¯à¦¾à¦¸à¦¿à¦¸à§à¦Ÿà§à¦¯à¦¾à¦¨à§à¦Ÿ
- **à¦Ÿà¦¾à¦¸à§à¦• à¦®à§à¦¯à¦¾à¦¨à§‡à¦œà¦®à§‡à¦¨à§à¦Ÿ à¦à¦œà§‡à¦¨à§à¦Ÿ**: à¦¦à¦•à§à¦·à¦¤à¦¾à¦° à¦¸à¦¾à¦¥à§‡ à¦Ÿà§-à¦¡à§ à¦²à¦¿à¦¸à§à¦Ÿ à¦¤à§ˆà¦°à¦¿, à¦†à¦ªà¦¡à§‡à¦Ÿ, à¦¸à¦‚à¦—à¦ à¦¿à¦¤  
- **à¦¤à¦¥à§à¦¯ à¦¸à¦‚à¦—à§à¦°à¦¹ à¦à¦œà§‡à¦¨à§à¦Ÿ**: à¦¬à¦¿à¦·à¦¯à¦¼ à¦—à¦¬à§‡à¦·à¦£à¦¾, à¦¸à§à¦¥à¦¾à¦¨à§€à¦¯à¦¼à¦­à¦¾à¦¬à§‡ à¦¸à¦¾à¦°à¦¾à¦‚à¦¶ à¦¤à§ˆà¦°à¦¿  
- **à¦¯à§‹à¦—à¦¾à¦¯à§‹à¦— à¦à¦œà§‡à¦¨à§à¦Ÿ**: à¦‡à¦®à§‡à¦‡à¦², à¦¬à¦¾à¦°à§à¦¤à¦¾, à¦¸à§‹à¦¶à§à¦¯à¦¾à¦² à¦®à¦¿à¦¡à¦¿à¦¯à¦¼à¦¾ à¦ªà§‹à¦¸à§à¦Ÿ à¦–à¦¸à¦¡à¦¼à¦¾ à¦¤à§ˆà¦°à¦¿  

### à¦Ÿà§à¦°à§‡à¦¡à¦¿à¦‚ à¦à¦¬à¦‚ à¦«à¦¿à¦¨à¦¾à¦¨à§à¦¸à¦¿à¦¯à¦¼à¦¾à¦² SLM à¦à¦œà§‡à¦¨à§à¦Ÿ
- **à¦®à¦¾à¦°à§à¦•à§‡à¦Ÿ à¦®à¦¨à¦¿à¦Ÿà¦°à¦¿à¦‚ à¦à¦œà§‡à¦¨à§à¦Ÿ**: à¦°à¦¿à¦¯à¦¼à§‡à¦²-à¦Ÿà¦¾à¦‡à¦®à§‡ à¦¦à¦¾à¦® à¦Ÿà§à¦°à§à¦¯à¦¾à¦• à¦•à¦°à¦¾, à¦ªà§à¦°à¦¬à¦£à¦¤à¦¾ à¦šà¦¿à¦¹à§à¦¨à¦¿à¦¤ à¦•à¦°à¦¾  
- **à¦°à¦¿à¦ªà§‹à¦°à§à¦Ÿ à¦œà§‡à¦¨à¦¾à¦°à§‡à¦¶à¦¨ à¦à¦œà§‡à¦¨à§à¦Ÿ**: à¦¸à§à¦¬à¦¯à¦¼à¦‚à¦•à§à¦°à¦¿à¦¯à¦¼à¦­à¦¾à¦¬à§‡ à¦¦à§ˆà¦¨à¦¿à¦•/à¦¸à¦¾à¦ªà§à¦¤à¦¾à¦¹à¦¿à¦• à¦¸à¦¾à¦°à¦¾à¦‚à¦¶ à¦¤à§ˆà¦°à¦¿  
- **à¦°à¦¿à¦¸à§à¦• à¦…à§à¦¯à¦¾à¦¸à§‡à¦¸à¦®à§‡à¦¨à§à¦Ÿ à¦à¦œà§‡à¦¨à§à¦Ÿ**: à¦¸à§à¦¥à¦¾à¦¨à§€à¦¯à¦¼ à¦¡à§‡à¦Ÿà¦¾ à¦¬à§à¦¯à¦¬à¦¹à¦¾à¦° à¦•à¦°à§‡ à¦ªà§‹à¦°à§à¦Ÿà¦«à§‹à¦²à¦¿à¦“ à¦…à¦¬à¦¸à§à¦¥à¦¾à¦¨ à¦®à§‚à¦²à§à¦¯à¦¾à¦¯à¦¼à¦¨  

### à¦¸à§à¦¬à¦¾à¦¸à§à¦¥à§à¦¯à¦¸à§‡à¦¬à¦¾ à¦¸à¦¹à¦¾à¦¯à¦¼à¦¤à¦¾ SLM à¦à¦œà§‡à¦¨à§à¦Ÿ
- **à¦ªà§‡à¦¶à§‡à¦¨à§à¦Ÿ à¦¶à¦¿à¦¡à¦¿à¦‰à¦²à¦¿à¦‚ à¦à¦œà§‡à¦¨à§à¦Ÿ**: à¦…à§à¦¯à¦¾à¦ªà¦¯à¦¼à§‡à¦¨à§à¦Ÿà¦®à§‡à¦¨à§à¦Ÿ à¦¸à¦®à¦¨à§à¦¬à¦¯à¦¼, à¦¸à§à¦¬à¦¯à¦¼à¦‚à¦•à§à¦°à¦¿à¦¯à¦¼ à¦°à¦¿à¦®à¦¾à¦‡à¦¨à§à¦¡à¦¾à¦° à¦ªà¦¾à¦ à¦¾à¦¨à§‹  
- **à¦¡à¦•à§à¦®à§‡à¦¨à§à¦Ÿà§‡à¦¶à¦¨ à¦à¦œà§‡à¦¨à§à¦Ÿ**: à¦¸à§à¦¥à¦¾à¦¨à§€à¦¯à¦¼à¦­à¦¾à¦¬à§‡ à¦®à§‡à¦¡à¦¿à¦•à§‡à¦² à¦¸à¦¾à¦°à¦¾à¦‚à¦¶, à¦°à¦¿à¦ªà§‹à¦°à§à¦Ÿ à¦¤à§ˆà¦°à¦¿  
- **à¦ªà§à¦°à§‡à¦¸à¦•à§à¦°à¦¿à¦ªà¦¶à¦¨ à¦®à§à¦¯à¦¾à¦¨à§‡à¦œà¦®à§‡à¦¨à§à¦Ÿ à¦à¦œà§‡à¦¨à§à¦Ÿ**: à¦°à¦¿à¦«à¦¿à¦² à¦Ÿà§à¦°à§à¦¯à¦¾à¦• à¦•à¦°à¦¾, à¦¬à§à¦¯à¦•à§à¦¤à¦¿à¦—à¦¤à¦­à¦¾à¦¬à§‡ à¦‡à¦¨à§à¦Ÿà¦¾à¦°à¦…à§à¦¯à¦¾à¦•à¦¶à¦¨ à¦šà§‡à¦• à¦•à¦°à¦¾  

## à¦®à¦¾à¦‡à¦•à§à¦°à§‹à¦¸à¦«à¦Ÿ à¦à¦œà§‡à¦¨à§à¦Ÿ à¦«à§à¦°à§‡à¦®à¦“à¦¯à¦¼à¦¾à¦°à§à¦•: à¦ªà§à¦°à§‹à¦¡à¦¾à¦•à¦¶à¦¨-à¦°à§‡à¦¡à¦¿ à¦à¦œà§‡à¦¨à§à¦Ÿ à¦¡à§‡à¦­à§‡à¦²à¦ªà¦®à§‡à¦¨à§à¦Ÿ

### à¦“à¦­à¦¾à¦°à¦­à¦¿à¦‰ à¦à¦¬à¦‚ à¦†à¦°à§à¦•à¦¿à¦Ÿà§‡à¦•à¦šà¦¾à¦°

à¦®à¦¾à¦‡à¦•à§à¦°à§‹à¦¸à¦«à¦Ÿ à¦à¦œà§‡à¦¨à§à¦Ÿ à¦«à§à¦°à§‡à¦®à¦“à¦¯à¦¼à¦¾à¦°à§à¦• à¦à¦•à¦Ÿà¦¿ à¦¬à§à¦¯à¦¾à¦ªà¦•, à¦à¦¨à§à¦Ÿà¦¾à¦°à¦ªà§à¦°à¦¾à¦‡à¦œ-à¦—à§à¦°à§‡à¦¡ à¦ªà§à¦²à§à¦¯à¦¾à¦Ÿà¦«à¦°à§à¦® à¦ªà§à¦°à¦¦à¦¾à¦¨ à¦•à¦°à§‡ à¦¯à¦¾ AI à¦à¦œà§‡à¦¨à§à¦Ÿ à¦¤à§ˆà¦°à¦¿, à¦¡à¦¿à¦ªà§à¦²à¦¯à¦¼ à¦à¦¬à¦‚ à¦ªà¦°à¦¿à¦šà¦¾à¦²à¦¨à¦¾ à¦•à¦°à¦¤à§‡ à¦¸à¦•à§à¦·à¦® à¦¯à¦¾ à¦•à§à¦²à¦¾à¦‰à¦¡ à¦à¦¬à¦‚ à¦…à¦«à¦²à¦¾à¦‡à¦¨ à¦à¦œ à¦‰à¦­à¦¯à¦¼ à¦ªà¦°à¦¿à¦¬à§‡à¦¶à§‡ à¦•à¦¾à¦œ à¦•à¦°à¦¤à§‡ à¦ªà¦¾à¦°à§‡à¥¤ à¦«à§à¦°à§‡à¦®à¦“à¦¯à¦¼à¦¾à¦°à§à¦•à¦Ÿà¦¿ à¦¬à¦¿à¦¶à§‡à¦·à¦­à¦¾à¦¬à§‡ à¦›à§‹à¦Ÿ à¦­à¦¾à¦·à¦¾à¦° à¦®à¦¡à§‡à¦² à¦à¦¬à¦‚ à¦à¦œ à¦•à¦®à§à¦ªà¦¿à¦‰à¦Ÿà¦¿à¦‚ à¦ªà¦°à¦¿à¦¸à§à¦¥à¦¿à¦¤à¦¿à¦° à¦¸à¦¾à¦¥à§‡ à¦¨à¦¿à¦°à§à¦¬à¦¿à¦˜à§à¦¨à§‡ à¦•à¦¾à¦œ à¦•à¦°à¦¾à¦° à¦œà¦¨à§à¦¯ à¦¡à¦¿à¦œà¦¾à¦‡à¦¨ à¦•à¦°à¦¾ à¦¹à¦¯à¦¼à§‡à¦›à§‡, à¦¯à¦¾ à¦—à§‹à¦ªà¦¨à§€à¦¯à¦¼à¦¤à¦¾-à¦¸à¦‚à¦¬à§‡à¦¦à¦¨à¦¶à§€à¦² à¦à¦¬à¦‚ à¦°à¦¿à¦¸à§‹à¦°à§à¦¸-à¦¸à§€à¦®à¦¾à¦¬à¦¦à§à¦§ à¦¡à¦¿à¦ªà§à¦²à¦¯à¦¼à¦®à§‡à¦¨à§à¦Ÿà§‡à¦° à¦œà¦¨à§à¦¯ à¦†à¦¦à¦°à§à¦¶à¥¤

**à¦®à§‚à¦² à¦«à§à¦°à§‡à¦®à¦“à¦¯à¦¼à¦¾à¦°à§à¦• à¦‰à¦ªà¦¾à¦¦à¦¾à¦¨**:
- **à¦à¦œà§‡à¦¨à§à¦Ÿ à¦°à¦¾à¦¨à¦Ÿà¦¾à¦‡à¦®**: à¦à¦œ à¦¡à¦¿à¦­à¦¾à¦‡à¦¸à§‡à¦° à¦œà¦¨à§à¦¯ à¦…à¦ªà§à¦Ÿà¦¿à¦®à¦¾à¦‡à¦œ à¦•à¦°à¦¾ à¦¹à¦¾à¦²à¦•à¦¾ à¦“à¦œà¦¨à§‡à¦° à¦à¦•à§à¦¸à¦¿à¦•à¦¿à¦‰à¦¶à¦¨ à¦ªà¦°à¦¿à¦¬à§‡à¦¶  
- **à¦Ÿà§à¦² à¦‡à¦¨à§à¦Ÿà¦¿à¦—à§à¦°à§‡à¦¶à¦¨ à¦¸à¦¿à¦¸à§à¦Ÿà§‡à¦®**: à¦¬à¦¾à¦¹à§à¦¯à¦¿à¦• à¦ªà¦°à¦¿à¦·à§‡à¦¬à¦¾ à¦à¦¬à¦‚ API à¦¸à¦‚à¦¯à§‹à¦—à§‡à¦° à¦œà¦¨à§à¦¯ à¦à¦•à§à¦¸à¦Ÿà§‡à¦¨à¦¸à¦¿à¦¬à¦² à¦ªà§à¦²à¦¾à¦—à¦‡à¦¨ à¦†à¦°à§à¦•à¦¿à¦Ÿà§‡à¦•à¦šà¦¾à¦°  
- **à¦¸à§à¦Ÿà§‡à¦Ÿ à¦®à§à¦¯à¦¾à¦¨à§‡à¦œà¦®à§‡à¦¨à§à¦Ÿ**: à¦¸à§‡à¦¶à¦¨ à¦œà§à¦¡à¦¼à§‡ à¦¸à§à¦¥à¦¾à¦¯à¦¼à§€ à¦à¦œà§‡à¦¨à§à¦Ÿ à¦®à§‡à¦®à§‹à¦°à¦¿ à¦à¦¬à¦‚ à¦ªà§à¦°à¦¸à¦™à§à¦— à¦ªà¦°à¦¿à¦šà¦¾à¦²à¦¨à¦¾  
- **à¦¨à¦¿à¦°à¦¾à¦ªà¦¤à§à¦¤à¦¾ à¦¸à§à¦¤à¦°**: à¦à¦¨à§à¦Ÿà¦¾à¦°à¦ªà§à¦°à¦¾à¦‡à¦œ à¦¡à¦¿à¦ªà§à¦²à¦¯à¦¼à¦®à§‡à¦¨à§à¦Ÿà§‡à¦° à¦œà¦¨à§à¦¯ à¦¬à¦¿à¦²à§à¦Ÿ-à¦‡à¦¨ à¦¸à¦¿à¦•à¦¿à¦‰à¦°à¦¿à¦Ÿà¦¿ à¦•à¦¨à§à¦Ÿà§à¦°à§‹à¦²  
- **à¦…à¦°à§à¦•à§‡à¦¸à§à¦Ÿà§à¦°à§‡à¦¶à¦¨ à¦‡à¦žà§à¦œà¦¿à¦¨**: à¦®à¦¾à¦²à§à¦Ÿà¦¿-à¦à¦œà§‡à¦¨à§à¦Ÿ à¦¸à¦®à¦¨à§à¦¬à¦¯à¦¼ à¦à¦¬à¦‚ à¦•à¦¾à¦°à§à¦¯à¦ªà§à¦°à¦¬à¦¾à¦¹ à¦ªà¦°à¦¿à¦šà¦¾à¦²à¦¨à¦¾  

### à¦à¦œ à¦¡à¦¿à¦ªà§à¦²à¦¯à¦¼à¦®à§‡à¦¨à§à¦Ÿà§‡à¦° à¦œà¦¨à§à¦¯ à¦®à§‚à¦² à¦¬à§ˆà¦¶à¦¿à¦·à§à¦Ÿà§à¦¯

**à¦…à¦«à¦²à¦¾à¦‡à¦¨-à¦ªà§à¦°à¦¥à¦® à¦†à¦°à§à¦•à¦¿à¦Ÿà§‡à¦•à¦šà¦¾à¦°**: à¦®à¦¾à¦‡à¦•à§à¦°à§‹à¦¸à¦«à¦Ÿ à¦à¦œà§‡à¦¨à§à¦Ÿ à¦«à§à¦°à§‡à¦®à¦“à¦¯à¦¼à¦¾à¦°à§à¦• à¦…à¦«à¦²à¦¾à¦‡à¦¨-à¦ªà§à¦°à¦¥à¦® à¦¨à§€à¦¤à¦¿à¦° à¦¸à¦¾à¦¥à§‡ à¦¡à¦¿à¦œà¦¾à¦‡à¦¨ à¦•à¦°à¦¾ à¦¹à¦¯à¦¼à§‡à¦›à§‡, à¦¯à¦¾ à¦à¦œà§‡à¦¨à§à¦Ÿà¦¦à§‡à¦° à¦•à§à¦°à¦®à¦¾à¦—à¦¤ à¦‡à¦¨à§à¦Ÿà¦¾à¦°à¦¨à§‡à¦Ÿ à¦¸à¦‚à¦¯à§‹à¦— à¦›à¦¾à¦¡à¦¼à¦¾à¦‡ à¦•à¦¾à¦°à§à¦¯à¦•à¦°à¦­à¦¾à¦¬à§‡ à¦•à¦¾à¦œ à¦•à¦°à¦¤à§‡ à¦¸à¦•à§à¦·à¦® à¦•à¦°à§‡à¥¤ à¦à¦° à¦®à¦§à§à¦¯à§‡ à¦¸à§à¦¥à¦¾à¦¨à§€à¦¯à¦¼ à¦®à¦¡à§‡à¦² à¦‡à¦¨à¦«à¦¾à¦°à§‡à¦¨à§à¦¸, à¦•à§à¦¯à¦¾à¦¶à¦¡ à¦¨à¦²à§‡à¦œ à¦¬à§‡à¦¸, à¦…à¦«à¦²à¦¾à¦‡à¦¨ à¦Ÿà§à¦² à¦à¦•à§à¦¸à¦¿à¦•à¦¿à¦‰à¦¶à¦¨ à¦à¦¬à¦‚ à¦•à§à¦²à¦¾à¦‰à¦¡ à¦ªà¦°à¦¿à¦·à§‡à¦¬à¦¾ à¦…à¦¨à§à¦ªà¦²à¦¬à§à¦§ à¦¥à¦¾à¦•à¦²à§‡ à¦—à§à¦°à§‡à¦¸à¦«à§à¦² à¦¡à¦¿à¦—à§à¦°à§‡à¦¡à§‡à¦¶à¦¨ à¦…à¦¨à§à¦¤à¦°à§à¦­à§à¦•à§à¦¤à¥¤  

**à¦°à¦¿à¦¸à§‹à¦°à§à¦¸ à¦…à¦ªà§à¦Ÿà¦¿à¦®à¦¾à¦‡à¦œà§‡à¦¶à¦¨**: à¦«à§à¦°à§‡à¦®à¦“à¦¯à¦¼à¦¾à¦°à§à¦•à¦Ÿà¦¿ à¦¬à§à¦¦à§à¦§à¦¿à¦®à¦¾à¦¨ à¦°à¦¿à¦¸à§‹à¦°à§à¦¸ à¦®à§à¦¯à¦¾à¦¨à§‡à¦œà¦®à§‡à¦¨à§à¦Ÿ à¦ªà§à¦°à¦¦à¦¾à¦¨ à¦•à¦°à§‡, SLM-à¦à¦° à¦œà¦¨à§à¦¯ à¦¸à§à¦¬à¦¯à¦¼à¦‚à¦•à§à¦°à¦¿à¦¯à¦¼ à¦®à§‡à¦®à§‹à¦°à¦¿ à¦…à¦ªà§à¦Ÿà¦¿à¦®à¦¾à¦‡à¦œà§‡à¦¶à¦¨, à¦à¦œ à¦¡à¦¿à¦­à¦¾à¦‡à¦¸à§‡à¦° à¦œà¦¨à§à¦¯ CPU/GPU à¦²à§‹à¦¡ à¦¬à§à¦¯à¦¾à¦²à§‡à¦¨à§à¦¸à¦¿à¦‚, à¦‰à¦ªà¦²à¦¬à§à¦§ à¦°à¦¿à¦¸à§‹à¦°à§à¦¸à§‡à¦° à¦‰à¦ªà¦° à¦­à¦¿à¦¤à§à¦¤à¦¿ à¦•à¦°à§‡ à¦…à¦­à¦¿à¦¯à§‹à¦œà¦¿à¦¤ à¦®à¦¡à§‡à¦² à¦¨à¦¿à¦°à§à¦¬à¦¾à¦šà¦¨ à¦à¦¬à¦‚ à¦®à§‹à¦¬à¦¾à¦‡à¦² à¦¡à¦¿à¦ªà§à¦²à¦¯à¦¼à¦®à§‡à¦¨à§à¦Ÿà§‡à¦° à¦œà¦¨à§à¦¯ à¦ªà¦¾à¦“à¦¯à¦¼à¦¾à¦°-à¦¦à¦•à§à¦· à¦‡à¦¨à¦«à¦¾à¦°à§‡à¦¨à§à¦¸ à¦ªà§à¦¯à¦¾à¦Ÿà¦¾à¦°à§à¦¨à¥¤  

**à¦¨à¦¿à¦°à¦¾à¦ªà¦¤à§à¦¤à¦¾ à¦à¦¬à¦‚ à¦—à§‹à¦ªà¦¨à§€à¦¯à¦¼à¦¤à¦¾**: à¦à¦¨à§à¦Ÿà¦¾à¦°à¦ªà§à¦°à¦¾à¦‡à¦œ-à¦—à§à¦°à§‡à¦¡ à¦¨à¦¿à¦°à¦¾à¦ªà¦¤à§à¦¤à¦¾ à¦¬à§ˆà¦¶à¦¿à¦·à§à¦Ÿà§à¦¯à¦—à§à¦²à¦¿à¦° à¦®à¦§à§à¦¯à§‡ à¦°à¦¯à¦¼à§‡à¦›à§‡ à¦—à§‹à¦ªà¦¨à§€à¦¯à¦¼à¦¤à¦¾ à¦¬à¦œà¦¾à¦¯à¦¼ à¦°à¦¾à¦–à¦¤à§‡ à¦¸à§à¦¥à¦¾à¦¨à§€à¦¯à¦¼ à¦¡à§‡à¦Ÿà¦¾ à¦ªà§à¦°à¦¸à§‡à¦¸à¦¿à¦‚, à¦à¦¨à¦•à§à¦°à¦¿à¦ªà§à¦Ÿà§‡à¦¡ à¦à¦œà§‡à¦¨à§à¦Ÿ à¦¯à§‹à¦—à¦¾à¦¯à§‹à¦— à¦šà§à¦¯à¦¾à¦¨à§‡à¦², à¦à¦œà§‡à¦¨à§à¦Ÿ à¦¸à¦•à§à¦·à¦®à¦¤à¦¾à¦° à¦œà¦¨à§à¦¯ à¦­à§‚à¦®à¦¿à¦•à¦¾-à¦­à¦¿à¦¤à§à¦¤à¦¿à¦• à¦…à§à¦¯à¦¾à¦•à§à¦¸à§‡à¦¸ à¦¨à¦¿à¦¯à¦¼à¦¨à§à¦¤à§à¦°à¦£ à¦à¦¬à¦‚ à¦¸à¦®à§à¦®à¦¤à¦¿ à¦ªà§à¦°à¦¯à¦¼à§‹à¦œà¦¨à§€à¦¯à¦¼à¦¤à¦¾à¦° à¦œà¦¨à§à¦¯ à¦…à¦¡à¦¿à¦Ÿ à¦²à¦—à¦¿à¦‚à¥¤  

### Foundry Local-à¦à¦° à¦¸à¦¾à¦¥à§‡ à¦‡à¦¨à§à¦Ÿà¦¿à¦—à§à¦°à§‡à¦¶à¦¨

à¦®à¦¾à¦‡à¦•à§à¦°à§‹à¦¸à¦«à¦Ÿ à¦à¦œà§‡à¦¨à§à¦Ÿ à¦«à§à¦°à§‡à¦®à¦“à¦¯à¦¼à¦¾à¦°à§à¦• Foundry Local-à¦à¦° à¦¸à¦¾à¦¥à§‡ à¦¨à¦¿à¦°à§à¦¬à¦¿à¦˜à§à¦¨à§‡ à¦‡à¦¨à§à¦Ÿà¦¿à¦—à§à¦°à§‡à¦Ÿ à¦¹à¦¯à¦¼ à¦à¦¬à¦‚ à¦à¦•à¦Ÿà¦¿ à¦¸à¦®à§à¦ªà§‚à¦°à§à¦£ à¦à¦œ AI à¦¸à¦®à¦¾à¦§à¦¾à¦¨ à¦ªà§à¦°à¦¦à¦¾à¦¨ à¦•à¦°à§‡:

**à¦¸à§à¦¬à¦¯à¦¼à¦‚à¦•à§à¦°à¦¿à¦¯à¦¼ à¦®à¦¡à§‡à¦² à¦†à¦¬à¦¿à¦·à§à¦•à¦¾à¦°**: à¦«à§à¦°à§‡à¦®à¦“à¦¯à¦¼à¦¾à¦°à§à¦•à¦Ÿà¦¿ à¦¸à§à¦¬à¦¯à¦¼à¦‚à¦•à§à¦°à¦¿à¦¯à¦¼à¦­à¦¾à¦¬à§‡ Foundry Local à¦‡à¦¨à¦¸à§à¦Ÿà§à¦¯à¦¾à¦¨à§à¦¸à¦—à§à¦²à¦¿ à¦¸à¦¨à¦¾à¦•à§à¦¤ à¦•à¦°à§‡ à¦à¦¬à¦‚ à¦¸à¦‚à¦¯à§à¦•à§à¦¤ à¦•à¦°à§‡, à¦‰à¦ªà¦²à¦¬à§à¦§ SLM à¦®à¦¡à§‡à¦²à¦—à§à¦²à¦¿ à¦†à¦¬à¦¿à¦·à§à¦•à¦¾à¦° à¦•à¦°à§‡ à¦à¦¬à¦‚ à¦à¦œà§‡à¦¨à§à¦Ÿà§‡à¦° à¦ªà§à¦°à¦¯à¦¼à§‹à¦œà¦¨à§€à¦¯à¦¼à¦¤à¦¾ à¦à¦¬à¦‚ à¦¹à¦¾à¦°à§à¦¡à¦“à¦¯à¦¼à§à¦¯à¦¾à¦° à¦¸à¦•à§à¦·à¦®à¦¤à¦¾à¦° à¦‰à¦ªà¦° à¦­à¦¿à¦¤à§à¦¤à¦¿ à¦•à¦°à§‡ à¦¸à¦°à§à¦¬à§‹à¦¤à§à¦¤à¦® à¦®à¦¡à§‡à¦² à¦¨à¦¿à¦°à§à¦¬à¦¾à¦šà¦¨ à¦•à¦°à§‡à¥¤  

**à¦¡à¦¾à¦¯à¦¼à¦¨à¦¾à¦®à¦¿à¦• à¦®à¦¡à§‡à¦² à¦²à§‹à¦¡à¦¿à¦‚**: à¦à¦œà§‡à¦¨à§à¦Ÿà¦°à¦¾ à¦¨à¦¿à¦°à§à¦¦à¦¿à¦·à§à¦Ÿ à¦•à¦¾à¦œà§‡à¦° à¦œà¦¨à§à¦¯ à¦¬à¦¿à¦­à¦¿à¦¨à§à¦¨ SLM à¦¸à§à¦¥à¦¾à¦¨à§€à¦¯à¦¼à¦­à¦¾à¦¬à§‡ à¦²à§‹à¦¡ à¦•à¦°à¦¤à§‡ à¦ªà¦¾à¦°à§‡, à¦®à¦¾à¦²à§à¦Ÿà¦¿-à¦®à¦¡à§‡à¦² à¦à¦œà§‡à¦¨à§à¦Ÿ à¦¸à¦¿à¦¸à§à¦Ÿà§‡à¦® à¦¸à¦•à§à¦·à¦® à¦•à¦°à§‡ à¦¯à§‡à¦–à¦¾à¦¨à§‡ à¦¬à¦¿à¦­à¦¿à¦¨à§à¦¨ à¦®à¦¡à§‡à¦² à¦¬à¦¿à¦­à¦¿à¦¨à§à¦¨ à¦§à¦°à¦£à§‡à¦° à¦…à¦¨à§à¦°à§‹à¦§ à¦ªà¦°à¦¿à¦šà¦¾à¦²à¦¨à¦¾ à¦•à¦°à§‡ à¦à¦¬à¦‚ à¦‰à¦ªà¦²à¦¬à§à¦§à¦¤à¦¾ à¦à¦¬à¦‚ à¦ªà¦¾à¦°à¦«à¦°à¦®à§à¦¯à¦¾à¦¨à§à¦¸à§‡à¦° à¦‰à¦ªà¦° à¦­à¦¿à¦¤à§à¦¤à¦¿ à¦•à¦°à§‡ à¦®à¦¡à§‡à¦²à¦—à§à¦²à¦¿à¦° à¦®à¦§à§à¦¯à§‡ à¦¸à§à¦¬à¦¯à¦¼à¦‚à¦•à§à¦°à¦¿à¦¯à¦¼ à¦«à§‡à¦‡à¦²à¦“à¦­à¦¾à¦°à¥¤  

**à¦ªà¦¾à¦°à¦«à¦°à¦®à§à¦¯à¦¾à¦¨à§à¦¸ à¦…à¦ªà§à¦Ÿà¦¿à¦®à¦¾à¦‡à¦œà§‡à¦¶à¦¨**: à¦‡à¦¨à§à¦Ÿà¦¿à¦—à§à¦°à§‡à¦Ÿà§‡à¦¡ à¦•à§à¦¯à¦¾à¦¶à¦¿à¦‚ à¦®à§‡à¦•à¦¾à¦¨à¦¿à¦œà¦® à¦®à¦¡à§‡à¦² à¦²à§‹à¦¡à¦¿à¦‚ à¦Ÿà¦¾à¦‡à¦® à¦¹à§à¦°à¦¾à¦¸ à¦•à¦°à§‡, à¦•à¦¾à¦¨à§‡à¦•à¦¶à¦¨ à¦ªà§à¦²à¦¿à¦‚ Foundry Local-à¦ API à¦•à¦² à¦…à¦ªà§à¦Ÿà¦¿à¦®à¦¾à¦‡à¦œ à¦•à¦°à§‡ à¦à¦¬à¦‚ à¦¬à§à¦¦à§à¦§à¦¿à¦®à¦¾à¦¨ à¦¬à§à¦¯à¦¾à¦šà¦¿à¦‚ à¦à¦•à¦¾à¦§à¦¿à¦• à¦à¦œà§‡à¦¨à§à¦Ÿ à¦…à¦¨à§à¦°à§‹à¦§à§‡à¦° à¦œà¦¨à§à¦¯ à¦¥à§à¦°à§à¦ªà§à¦Ÿ à¦‰à¦¨à§à¦¨à¦¤ à¦•à¦°à§‡à¥¤  

### à¦®à¦¾à¦‡à¦•à§à¦°à§‹à¦¸à¦«à¦Ÿ à¦à¦œà§‡à¦¨à§à¦Ÿ à¦«à§à¦°à§‡à¦®à¦“à¦¯à¦¼à¦¾à¦°à§à¦• à¦¦à¦¿à¦¯à¦¼à§‡ à¦à¦œà§‡à¦¨à§à¦Ÿ à¦¤à§ˆà¦°à¦¿

#### à¦à¦œà§‡à¦¨à§à¦Ÿ à¦¸à¦‚à¦œà§à¦žà¦¾ à¦à¦¬à¦‚ à¦•à¦¨à¦«à¦¿à¦—à¦¾à¦°à§‡à¦¶à¦¨

```python
from microsoft_agent_framework import Agent, Tool, Config
from foundry_local import FoundryLocalManager

# Configure agent with Foundry Local integration
config = Config(
    name="customer-service-agent",
    model_provider="foundry-local",
    model_alias="phi-4-mini",
    max_tokens=512,
    temperature=0.1,
    offline_mode=True
)

# Initialize Foundry Local connection
foundry = FoundryLocalManager("phi-4-mini")

# Create agent instance
agent = Agent(
    config=config,
    model_endpoint=foundry.endpoint,
    api_key=foundry.api_key
)
```
  
#### à¦à¦œ à¦Ÿà§à¦² à¦‡à¦¨à§à¦Ÿà¦¿à¦—à§à¦°à§‡à¦¶à¦¨

```python
# Define tools for offline operation
@agent.tool
def lookup_customer_info(customer_id: str) -> dict:
    """Look up customer information from local database."""
    # Local database query - works offline
    return local_db.get_customer(customer_id)

@agent.tool
def create_support_ticket(issue: str, priority: str) -> str:
    """Create a support ticket in local system."""
    # Local ticket creation with sync when online
    ticket_id = local_system.create_ticket(issue, priority)
    return f"Ticket {ticket_id} created successfully"

@agent.tool
def schedule_callback(customer_id: str, preferred_time: str) -> str:
    """Schedule a callback for the customer."""
    # Local scheduling with calendar integration
    return local_calendar.schedule(customer_id, preferred_time)
```
  
#### à¦®à¦¾à¦²à§à¦Ÿà¦¿-à¦à¦œà§‡à¦¨à§à¦Ÿ à¦…à¦°à§à¦•à§‡à¦¸à§à¦Ÿà§à¦°à§‡à¦¶à¦¨

```python
from microsoft_agent_framework import AgentOrchestrator

# Create specialized agents for different domains
scheduling_agent = Agent(
    config=Config(
        name="scheduling-agent",
        model_alias="qwen2.5-0.5b",  # Lightweight for simple tasks
        specialized_for="scheduling"
    )
)

technical_support_agent = Agent(
    config=Config(
        name="technical-agent",
        model_alias="phi-4-mini",  # More capable for complex issues
        specialized_for="technical_support"
    )
)

# Orchestrate multiple agents
orchestrator = AgentOrchestrator([
    scheduling_agent,
    technical_support_agent
])

# Route requests based on intent
result = orchestrator.process_request(
    "I need to schedule a callback for a technical issue",
    routing_strategy="intent-based"
)
```
  

### à¦‰à¦¨à§à¦¨à¦¤ à¦à¦œ à¦¡à¦¿à¦ªà§à¦²à¦¯à¦¼à¦®à§‡à¦¨à§à¦Ÿ à¦ªà§à¦¯à¦¾à¦Ÿà¦¾à¦°à§à¦¨

#### à¦¹à¦¾à¦¯à¦¼à¦¾à¦°à¦¾à¦°à¦•à¦¿à¦•à¦¾à¦² à¦à¦œà§‡à¦¨à§à¦Ÿ à¦†à¦°à§à¦•à¦¿à¦Ÿà§‡à¦•à¦šà¦¾à¦°

**à¦¸à§à¦¥à¦¾à¦¨à§€à¦¯à¦¼ à¦à¦œà§‡à¦¨à§à¦Ÿ à¦•à§à¦²à¦¾à¦¸à§à¦Ÿà¦¾à¦°**: à¦¨à¦¿à¦°à§à¦¦à¦¿à¦·à§à¦Ÿ à¦•à¦¾à¦œà§‡à¦° à¦œà¦¨à§à¦¯ à¦…à¦ªà§à¦Ÿà¦¿à¦®à¦¾à¦‡à¦œ à¦•à¦°à¦¾ à¦à¦•à¦¾à¦§à¦¿à¦• à¦¬à¦¿à¦¶à§‡à¦·à¦¾à¦¯à¦¼à¦¿à¦¤ SLM à¦à¦œà§‡à¦¨à§à¦Ÿ à¦à¦œ à¦¡à¦¿à¦­à¦¾à¦‡à¦¸à§‡ à¦¡à¦¿à¦ªà§à¦²à¦¯à¦¼ à¦•à¦°à§à¦¨à¥¤ à¦¸à¦¹à¦œ à¦°à¦¾à¦‰à¦Ÿà¦¿à¦‚ à¦à¦¬à¦‚ à¦¶à¦¿à¦¡à¦¿à¦‰à¦²à¦¿à¦‚à¦¯à¦¼à§‡à¦° à¦œà¦¨à§à¦¯ Qwen2.5-0.5B-à¦à¦° à¦®à¦¤à§‹ à¦¹à¦¾à¦²à¦•à¦¾ à¦®à¦¡à§‡à¦² à¦¬à§à¦¯à¦¬à¦¹à¦¾à¦° à¦•à¦°à§à¦¨, à¦—à§à¦°à¦¾à¦¹à¦• à¦ªà¦°à¦¿à¦·à§‡à¦¬à¦¾ à¦à¦¬à¦‚ à¦¡à¦•à§à¦®à§‡à¦¨à§à¦Ÿà§‡à¦¶à¦¨à§‡à¦° à¦œà¦¨à§à¦¯ Phi-4-Mini-à¦à¦° à¦®à¦¤à§‹ à¦®à¦¾à¦à¦¾à¦°à¦¿ à¦®à¦¡à§‡à¦² à¦à¦¬à¦‚ à¦œà¦Ÿà¦¿à¦² à¦¯à§à¦•à§à¦¤à¦¿à¦° à¦œà¦¨à§à¦¯ à¦¬à¦¡à¦¼ à¦®à¦¡à§‡à¦² à¦¬à§à¦¯à¦¬à¦¹à¦¾à¦° à¦•à¦°à§à¦¨ à¦¯à¦–à¦¨ à¦°à¦¿à¦¸à§‹à¦°à§à¦¸ à¦‰à¦ªà¦²à¦¬à§à¦§ à¦¥à¦¾à¦•à§‡à¥¤  

**à¦à¦œ-à¦Ÿà§-à¦•à§à¦²à¦¾à¦‰à¦¡ à¦¸à¦®à¦¨à§à¦¬à¦¯à¦¼**: à¦¬à§à¦¦à§à¦§à¦¿à¦®à¦¾à¦¨ à¦à¦¸à¦•à§‡à¦²à§‡à¦¶à¦¨ à¦ªà§à¦¯à¦¾à¦Ÿà¦¾à¦°à§à¦¨ à¦¬à¦¾à¦¸à§à¦¤à¦¬à¦¾à¦¯à¦¼à¦¨ à¦•à¦°à§à¦¨ à¦¯à§‡à¦–à¦¾à¦¨à§‡ à¦¸à§à¦¥à¦¾à¦¨à§€à¦¯à¦¼ à¦à¦œà§‡à¦¨à§à¦Ÿà¦°à¦¾ à¦°à§à¦Ÿà¦¿à¦¨ à¦•à¦¾à¦œ à¦ªà¦°à¦¿à¦šà¦¾à¦²à¦¨à¦¾ à¦•à¦°à§‡, à¦•à§à¦²à¦¾à¦‰à¦¡ à¦à¦œà§‡à¦¨à§à¦Ÿà¦°à¦¾ à¦¸à¦‚à¦¯à§‹à¦— à¦‰à¦ªà¦²à¦¬à§à¦§ à¦¥à¦¾à¦•à¦²à§‡ à¦œà¦Ÿà¦¿à¦² à¦¯à§à¦•à§à¦¤à¦¿ à¦ªà§à¦°à¦¦à¦¾à¦¨ à¦•à¦°à§‡ à¦à¦¬à¦‚ à¦à¦œ à¦à¦¬à¦‚ à¦•à§à¦²à¦¾à¦‰à¦¡ à¦ªà§à¦°à¦¸à§‡à¦¸à¦¿à¦‚à¦¯à¦¼à§‡à¦° à¦®à¦§à§à¦¯à§‡ à¦¨à¦¿à¦°à§à¦¬à¦¿à¦˜à§à¦¨ à¦¹à§à¦¯à¦¾à¦¨à§à¦¡à¦…à¦« à¦§à¦¾à¦°à¦¾à¦¬à¦¾à¦¹à¦¿à¦•à¦¤à¦¾ à¦¬à¦œà¦¾à¦¯à¦¼ à¦°à¦¾à¦–à§‡à¥¤  

#### à¦¡à¦¿à¦ªà§à¦²à¦¯à¦¼à¦®à§‡à¦¨à§à¦Ÿ à¦•à¦¨à¦«à¦¿à¦—à¦¾à¦°à§‡à¦¶à¦¨

**à¦à¦•à¦• à¦¡à¦¿à¦­à¦¾à¦‡à¦¸ à¦¡à¦¿à¦ªà§à¦²à¦¯à¦¼à¦®
**à¦à¦œà§‡à¦¨à§à¦Ÿ à¦¡à¦¿à¦ªà§à¦²à¦¯à¦¼à¦®à§‡à¦¨à§à¦Ÿà§‡à¦° à¦œà¦¨à§à¦¯ à¦«à§à¦°à§‡à¦®à¦“à¦¯à¦¼à¦¾à¦°à§à¦• à¦¨à¦¿à¦°à§à¦¬à¦¾à¦šà¦¨**: à¦²à¦•à§à¦·à§à¦¯ à¦¹à¦¾à¦°à§à¦¡à¦“à¦¯à¦¼à§à¦¯à¦¾à¦° à¦à¦¬à¦‚ à¦à¦œà§‡à¦¨à§à¦Ÿà§‡à¦° à¦ªà§à¦°à¦¯à¦¼à§‹à¦œà¦¨à§€à¦¯à¦¼à¦¤à¦¾à¦° à¦‰à¦ªà¦° à¦­à¦¿à¦¤à§à¦¤à¦¿ à¦•à¦°à§‡ à¦…à¦ªà§à¦Ÿà¦¿à¦®à¦¾à¦‡à¦œà§‡à¦¶à¦¨ à¦«à§à¦°à§‡à¦®à¦“à¦¯à¦¼à¦¾à¦°à§à¦• à¦¨à¦¿à¦°à§à¦¬à¦¾à¦šà¦¨ à¦•à¦°à§à¦¨à¥¤ CPU-à¦…à¦ªà§à¦Ÿà¦¿à¦®à¦¾à¦‡à¦œà¦¡ à¦à¦œà§‡à¦¨à§à¦Ÿ à¦¡à¦¿à¦ªà§à¦²à¦¯à¦¼à¦®à§‡à¦¨à§à¦Ÿà§‡à¦° à¦œà¦¨à§à¦¯ Llama.cpp à¦¬à§à¦¯à¦¬à¦¹à¦¾à¦° à¦•à¦°à§à¦¨, Apple Silicon à¦à¦œà§‡à¦¨à§à¦Ÿ à¦…à§à¦¯à¦¾à¦ªà§à¦²à¦¿à¦•à§‡à¦¶à¦¨à§‡à¦° à¦œà¦¨à§à¦¯ Apple MLX à¦à¦¬à¦‚ à¦•à§à¦°à¦¸-à¦ªà§à¦²à§à¦¯à¦¾à¦Ÿà¦«à¦°à§à¦® à¦à¦œà§‡à¦¨à§à¦Ÿ à¦¸à¦¾à¦®à¦žà§à¦œà¦¸à§à¦¯à§‡à¦° à¦œà¦¨à§à¦¯ ONNX à¦¬à§à¦¯à¦¬à¦¹à¦¾à¦° à¦•à¦°à§à¦¨à¥¤

## à¦¬à¦¾à¦¸à§à¦¤à¦¬ SLM à¦à¦œà§‡à¦¨à§à¦Ÿ à¦°à§‚à¦ªà¦¾à¦¨à§à¦¤à¦° à¦à¦¬à¦‚ à¦¬à§à¦¯à¦¬à¦¹à¦¾à¦° à¦•à§à¦·à§‡à¦¤à§à¦°

### à¦¬à¦¾à¦¸à§à¦¤à¦¬ à¦œà§€à¦¬à¦¨à§‡à¦° à¦à¦œà§‡à¦¨à§à¦Ÿ à¦¡à¦¿à¦ªà§à¦²à¦¯à¦¼à¦®à§‡à¦¨à§à¦Ÿ à¦ªà¦°à¦¿à¦¸à§à¦¥à¦¿à¦¤à¦¿

**à¦®à§‹à¦¬à¦¾à¦‡à¦² à¦à¦œà§‡à¦¨à§à¦Ÿ à¦…à§à¦¯à¦¾à¦ªà§à¦²à¦¿à¦•à§‡à¦¶à¦¨**: à¦¸à§à¦®à¦¾à¦°à§à¦Ÿà¦«à§‹à¦¨ à¦à¦œà§‡à¦¨à§à¦Ÿ à¦…à§à¦¯à¦¾à¦ªà§à¦²à¦¿à¦•à§‡à¦¶à¦¨à§‡à¦° à¦œà¦¨à§à¦¯ Q4_K à¦«à¦°à¦®à§à¦¯à¦¾à¦Ÿ à¦•à¦® à¦®à§‡à¦®à§‹à¦°à¦¿ à¦¬à§à¦¯à¦¬à¦¹à¦¾à¦° à¦•à¦°à§‡ à¦•à¦¾à¦°à§à¦¯à¦•à¦°, à¦¯à§‡à¦–à¦¾à¦¨à§‡ Q8_0 à¦Ÿà§à¦¯à¦¾à¦¬à¦²à§‡à¦Ÿ-à¦­à¦¿à¦¤à§à¦¤à¦¿à¦• à¦à¦œà§‡à¦¨à§à¦Ÿ à¦¸à¦¿à¦¸à§à¦Ÿà§‡à¦®à§‡à¦° à¦œà¦¨à§à¦¯ à¦­à¦¾à¦°à¦¸à¦¾à¦®à§à¦¯à¦ªà§‚à¦°à§à¦£ à¦ªà¦¾à¦°à¦«à¦°à¦®à§à¦¯à¦¾à¦¨à§à¦¸ à¦ªà§à¦°à¦¦à¦¾à¦¨ à¦•à¦°à§‡à¥¤ Q5_K à¦«à¦°à¦®à§à¦¯à¦¾à¦Ÿ à¦®à§‹à¦¬à¦¾à¦‡à¦² à¦ªà§à¦°à§‹à¦¡à¦¾à¦•à§à¦Ÿà¦¿à¦­à¦¿à¦Ÿà¦¿ à¦à¦œà§‡à¦¨à§à¦Ÿà§‡à¦° à¦œà¦¨à§à¦¯ à¦‰à¦šà§à¦šà¦®à¦¾à¦¨à§‡à¦° à¦¸à§‡à¦¬à¦¾ à¦ªà§à¦°à¦¦à¦¾à¦¨ à¦•à¦°à§‡à¥¤

**à¦¡à§‡à¦¸à§à¦•à¦Ÿà¦ª à¦à¦¬à¦‚ à¦à¦œ à¦à¦œà§‡à¦¨à§à¦Ÿ à¦•à¦®à§à¦ªà¦¿à¦‰à¦Ÿà¦¿à¦‚**: à¦¡à§‡à¦¸à§à¦•à¦Ÿà¦ª à¦à¦œà§‡à¦¨à§à¦Ÿ à¦…à§à¦¯à¦¾à¦ªà§à¦²à¦¿à¦•à§‡à¦¶à¦¨à§‡à¦° à¦œà¦¨à§à¦¯ Q5_K à¦¸à¦°à§à¦¬à§‹à¦¤à§à¦¤à¦® à¦ªà¦¾à¦°à¦«à¦°à¦®à§à¦¯à¦¾à¦¨à§à¦¸ à¦ªà§à¦°à¦¦à¦¾à¦¨ à¦•à¦°à§‡, à¦“à¦¯à¦¼à¦¾à¦°à§à¦•à¦¸à§à¦Ÿà§‡à¦¶à¦¨ à¦à¦œà§‡à¦¨à§à¦Ÿ à¦ªà¦°à¦¿à¦¬à§‡à¦¶à§‡à¦° à¦œà¦¨à§à¦¯ Q8_0 à¦‰à¦šà§à¦šà¦®à¦¾à¦¨à§‡à¦° à¦‡à¦¨à¦«à¦¾à¦°à§‡à¦¨à§à¦¸ à¦¸à¦°à¦¬à¦°à¦¾à¦¹ à¦•à¦°à§‡ à¦à¦¬à¦‚ à¦à¦œ à¦à¦œà§‡à¦¨à§à¦Ÿ à¦¡à¦¿à¦­à¦¾à¦‡à¦¸à§‡à¦° à¦œà¦¨à§à¦¯ Q4_K à¦•à¦¾à¦°à§à¦¯à¦•à¦° à¦ªà§à¦°à¦•à§à¦°à¦¿à¦¯à¦¼à¦¾à¦•à¦°à¦£ à¦¸à¦•à§à¦·à¦® à¦•à¦°à§‡à¥¤

**à¦—à¦¬à§‡à¦·à¦£à¦¾ à¦à¦¬à¦‚ à¦ªà¦°à§€à¦•à§à¦·à¦¾à¦®à§‚à¦²à¦• à¦à¦œà§‡à¦¨à§à¦Ÿ**: à¦‰à¦¨à§à¦¨à¦¤ à¦•à§‹à¦¯à¦¼à¦¾à¦¨à§à¦Ÿà¦¾à¦‡à¦œà§‡à¦¶à¦¨ à¦«à¦°à¦®à§à¦¯à¦¾à¦Ÿà¦—à§à¦²à¦¿ à¦…à¦¤à§à¦¯à¦¨à§à¦¤ à¦•à¦® à¦ªà§à¦°à¦¿à¦¸à¦¿à¦¶à¦¨ à¦à¦œà§‡à¦¨à§à¦Ÿ à¦‡à¦¨à¦«à¦¾à¦°à§‡à¦¨à§à¦¸ à¦…à¦¨à§à¦¬à§‡à¦·à¦£à§‡à¦° à¦œà¦¨à§à¦¯ à¦à¦•à¦¾à¦¡à§‡à¦®à¦¿à¦• à¦—à¦¬à§‡à¦·à¦£à¦¾ à¦à¦¬à¦‚ à¦ªà§à¦°à§à¦«-à¦…à¦«-à¦•à¦¨à¦¸à§‡à¦ªà§à¦Ÿ à¦à¦œà§‡à¦¨à§à¦Ÿ à¦…à§à¦¯à¦¾à¦ªà§à¦²à¦¿à¦•à§‡à¦¶à¦¨à§‡à¦° à¦œà¦¨à§à¦¯ à¦‰à¦ªà¦¯à§‹à¦—à§€à¥¤

### SLM à¦à¦œà§‡à¦¨à§à¦Ÿ à¦ªà¦¾à¦°à¦«à¦°à¦®à§à¦¯à¦¾à¦¨à§à¦¸ à¦¬à§‡à¦žà§à¦šà¦®à¦¾à¦°à§à¦•

**à¦à¦œà§‡à¦¨à§à¦Ÿ à¦‡à¦¨à¦«à¦¾à¦°à§‡à¦¨à§à¦¸ à¦—à¦¤à¦¿**: à¦®à§‹à¦¬à¦¾à¦‡à¦² CPU-à¦¤à§‡ Q4_K à¦¦à§à¦°à§à¦¤à¦¤à¦® à¦à¦œà§‡à¦¨à§à¦Ÿ à¦ªà§à¦°à¦¤à¦¿à¦•à§à¦°à¦¿à¦¯à¦¼à¦¾ à¦¸à¦®à¦¯à¦¼ à¦…à¦°à§à¦œà¦¨ à¦•à¦°à§‡, Q5_K à¦¸à¦¾à¦§à¦¾à¦°à¦£ à¦à¦œà§‡à¦¨à§à¦Ÿ à¦…à§à¦¯à¦¾à¦ªà§à¦²à¦¿à¦•à§‡à¦¶à¦¨à§‡à¦° à¦œà¦¨à§à¦¯ à¦—à¦¤à¦¿-à¦—à§à¦£à¦®à¦¾à¦¨à§‡à¦° à¦­à¦¾à¦°à¦¸à¦¾à¦®à§à¦¯ à¦ªà§à¦°à¦¦à¦¾à¦¨ à¦•à¦°à§‡, Q8_0 à¦œà¦Ÿà¦¿à¦² à¦à¦œà§‡à¦¨à§à¦Ÿ à¦•à¦¾à¦œà§‡à¦° à¦œà¦¨à§à¦¯ à¦‰à¦šà§à¦šà¦®à¦¾à¦¨à§‡à¦° à¦¸à§‡à¦¬à¦¾ à¦ªà§à¦°à¦¦à¦¾à¦¨ à¦•à¦°à§‡ à¦à¦¬à¦‚ à¦ªà¦°à§€à¦•à§à¦·à¦¾à¦®à§‚à¦²à¦• à¦«à¦°à¦®à§à¦¯à¦¾à¦Ÿà¦—à§à¦²à¦¿ à¦¬à¦¿à¦¶à§‡à¦·à¦¾à¦¯à¦¼à¦¿à¦¤ à¦à¦œà§‡à¦¨à§à¦Ÿ à¦¹à¦¾à¦°à§à¦¡à¦“à¦¯à¦¼à§à¦¯à¦¾à¦°à§‡à¦° à¦œà¦¨à§à¦¯ à¦¸à¦°à§à¦¬à¦¾à¦§à¦¿à¦• à¦¥à§à¦°à§à¦ªà§à¦Ÿ à¦¸à¦°à¦¬à¦°à¦¾à¦¹ à¦•à¦°à§‡à¥¤

**à¦à¦œà§‡à¦¨à§à¦Ÿ à¦®à§‡à¦®à§‹à¦°à¦¿ à¦ªà§à¦°à¦¯à¦¼à§‹à¦œà¦¨à§€à¦¯à¦¼à¦¤à¦¾**: à¦à¦œà§‡à¦¨à§à¦Ÿà§‡à¦° à¦œà¦¨à§à¦¯ à¦•à§‹à¦¯à¦¼à¦¾à¦¨à§à¦Ÿà¦¾à¦‡à¦œà§‡à¦¶à¦¨ à¦¸à§à¦¤à¦° Q2_K (à¦›à§‹à¦Ÿ à¦à¦œà§‡à¦¨à§à¦Ÿ à¦®à¦¡à§‡à¦²à§‡à¦° à¦œà¦¨à§à¦¯ à§«à§¦à§¦ à¦à¦®à¦¬à¦¿ à¦à¦° à¦¨à¦¿à¦šà§‡) à¦¥à§‡à¦•à§‡ Q8_0 (à¦®à§‚à¦² à¦†à¦•à¦¾à¦°à§‡à¦° à¦ªà§à¦°à¦¾à¦¯à¦¼ à§«à§¦%) à¦ªà¦°à§à¦¯à¦¨à§à¦¤ à¦¬à¦¿à¦¸à§à¦¤à§ƒà¦¤, à¦¯à§‡à¦–à¦¾à¦¨à§‡ à¦ªà¦°à§€à¦•à§à¦·à¦¾à¦®à§‚à¦²à¦• à¦•à¦¨à¦«à¦¿à¦—à¦¾à¦°à§‡à¦¶à¦¨à¦—à§à¦²à¦¿ à¦¸à¦®à§à¦ªà¦¦-à¦¸à§€à¦®à¦¾à¦¬à¦¦à§à¦§ à¦à¦œà§‡à¦¨à§à¦Ÿ à¦ªà¦°à¦¿à¦¬à§‡à¦¶à§‡à¦° à¦œà¦¨à§à¦¯ à¦¸à¦°à§à¦¬à¦¾à¦§à¦¿à¦• à¦•à¦®à§à¦ªà§à¦°à§‡à¦¶à¦¨ à¦…à¦°à§à¦œà¦¨ à¦•à¦°à§‡à¥¤

## SLM à¦à¦œà§‡à¦¨à§à¦Ÿà§‡à¦° à¦šà§à¦¯à¦¾à¦²à§‡à¦žà§à¦œ à¦à¦¬à¦‚ à¦¬à¦¿à¦¬à§‡à¦šà¦¨à¦¾

### à¦à¦œà§‡à¦¨à§à¦Ÿ à¦¸à¦¿à¦¸à§à¦Ÿà§‡à¦®à§‡ à¦ªà¦¾à¦°à¦«à¦°à¦®à§à¦¯à¦¾à¦¨à§à¦¸ à¦Ÿà§à¦°à§‡à¦¡-à¦…à¦«

SLM à¦à¦œà§‡à¦¨à§à¦Ÿ à¦¡à¦¿à¦ªà§à¦²à¦¯à¦¼à¦®à§‡à¦¨à§à¦Ÿà§‡ à¦®à¦¡à§‡à¦²à§‡à¦° à¦†à¦•à¦¾à¦°, à¦à¦œà§‡à¦¨à§à¦Ÿ à¦ªà§à¦°à¦¤à¦¿à¦•à§à¦°à¦¿à¦¯à¦¼à¦¾ à¦—à¦¤à¦¿ à¦à¦¬à¦‚ à¦†à¦‰à¦Ÿà¦ªà§à¦Ÿ à¦—à§à¦£à¦®à¦¾à¦¨à§‡à¦° à¦®à¦§à§à¦¯à§‡ à¦Ÿà§à¦°à§‡à¦¡-à¦…à¦«à¦—à§à¦²à¦¿ à¦¸à¦¾à¦¬à¦§à¦¾à¦¨à§‡ à¦¬à¦¿à¦¬à§‡à¦šà¦¨à¦¾ à¦•à¦°à¦¾ à¦ªà§à¦°à¦¯à¦¼à§‹à¦œà¦¨à¥¤ Q4_K à¦®à§‹à¦¬à¦¾à¦‡à¦² à¦à¦œà§‡à¦¨à§à¦Ÿà§‡à¦° à¦œà¦¨à§à¦¯ à¦…à¦¸à¦¾à¦§à¦¾à¦°à¦£ à¦—à¦¤à¦¿ à¦à¦¬à¦‚ à¦¦à¦•à§à¦·à¦¤à¦¾ à¦ªà§à¦°à¦¦à¦¾à¦¨ à¦•à¦°à§‡, Q8_0 à¦œà¦Ÿà¦¿à¦² à¦à¦œà§‡à¦¨à§à¦Ÿ à¦•à¦¾à¦œà§‡à¦° à¦œà¦¨à§à¦¯ à¦‰à¦šà§à¦šà¦®à¦¾à¦¨à§‡à¦° à¦¸à§‡à¦¬à¦¾ à¦ªà§à¦°à¦¦à¦¾à¦¨ à¦•à¦°à§‡à¥¤ Q5_K à¦¬à§‡à¦¶à¦¿à¦°à¦­à¦¾à¦— à¦¸à¦¾à¦§à¦¾à¦°à¦£ à¦à¦œà§‡à¦¨à§à¦Ÿ à¦…à§à¦¯à¦¾à¦ªà§à¦²à¦¿à¦•à§‡à¦¶à¦¨à§‡à¦° à¦œà¦¨à§à¦¯ à¦à¦•à¦Ÿà¦¿ à¦®à¦§à§à¦¯à¦® à¦ªà¦¥ à¦¤à§ˆà¦°à¦¿ à¦•à¦°à§‡à¥¤

### SLM à¦à¦œà§‡à¦¨à§à¦Ÿà§‡à¦° à¦œà¦¨à§à¦¯ à¦¹à¦¾à¦°à§à¦¡à¦“à¦¯à¦¼à§à¦¯à¦¾à¦° à¦¸à¦¾à¦®à¦žà§à¦œà¦¸à§à¦¯

à¦¬à¦¿à¦­à¦¿à¦¨à§à¦¨ à¦à¦œ à¦¡à¦¿à¦­à¦¾à¦‡à¦¸à§‡à¦° SLM à¦à¦œà§‡à¦¨à§à¦Ÿ à¦¡à¦¿à¦ªà§à¦²à¦¯à¦¼à¦®à§‡à¦¨à§à¦Ÿà§‡à¦° à¦œà¦¨à§à¦¯ à¦¬à¦¿à¦­à¦¿à¦¨à§à¦¨ à¦•à§à¦·à¦®à¦¤à¦¾ à¦°à¦¯à¦¼à§‡à¦›à§‡à¥¤ Q4_K à¦¸à¦¾à¦§à¦¾à¦°à¦£ à¦ªà§à¦°à¦¸à§‡à¦¸à¦°à§‡ à¦¸à¦¹à¦œ à¦à¦œà§‡à¦¨à§à¦Ÿà§‡à¦° à¦œà¦¨à§à¦¯ à¦•à¦¾à¦°à§à¦¯à¦•à¦°à¦­à¦¾à¦¬à§‡ à¦šà¦²à§‡, Q5_K à¦­à¦¾à¦°à¦¸à¦¾à¦®à§à¦¯à¦ªà§‚à¦°à§à¦£ à¦à¦œà§‡à¦¨à§à¦Ÿ à¦ªà¦¾à¦°à¦«à¦°à¦®à§à¦¯à¦¾à¦¨à§à¦¸à§‡à¦° à¦œà¦¨à§à¦¯ à¦®à¦¾à¦à¦¾à¦°à¦¿ à¦•à¦®à§à¦ªà¦¿à¦‰à¦Ÿà§‡à¦¶à¦¨à¦¾à¦² à¦°à¦¿à¦¸à§‹à¦°à§à¦¸ à¦ªà§à¦°à¦¯à¦¼à§‹à¦œà¦¨ à¦à¦¬à¦‚ Q8_0 à¦‰à¦¨à§à¦¨à¦¤ à¦à¦œà§‡à¦¨à§à¦Ÿ à¦•à§à¦·à¦®à¦¤à¦¾à¦° à¦œà¦¨à§à¦¯ à¦‰à¦šà§à¦šà¦®à¦¾à¦¨à§‡à¦° à¦¹à¦¾à¦°à§à¦¡à¦“à¦¯à¦¼à§à¦¯à¦¾à¦° à¦¥à§‡à¦•à§‡ à¦‰à¦ªà¦•à§ƒà¦¤ à¦¹à¦¯à¦¼à¥¤

### SLM à¦à¦œà§‡à¦¨à§à¦Ÿ à¦¸à¦¿à¦¸à§à¦Ÿà§‡à¦®à§‡ à¦¨à¦¿à¦°à¦¾à¦ªà¦¤à§à¦¤à¦¾ à¦à¦¬à¦‚ à¦—à§‹à¦ªà¦¨à§€à¦¯à¦¼à¦¤à¦¾

SLM à¦à¦œà§‡à¦¨à§à¦Ÿ à¦¸à§à¦¥à¦¾à¦¨à§€à¦¯à¦¼ à¦ªà§à¦°à¦•à§à¦°à¦¿à¦¯à¦¼à¦¾à¦•à¦°à¦£à§‡à¦° à¦®à¦¾à¦§à§à¦¯à¦®à§‡ à¦‰à¦¨à§à¦¨à¦¤ à¦—à§‹à¦ªà¦¨à§€à¦¯à¦¼à¦¤à¦¾ à¦¸à¦•à§à¦·à¦® à¦•à¦°à§‡, à¦¤à¦¬à§‡ à¦à¦œà§‡à¦¨à§à¦Ÿ à¦®à¦¡à§‡à¦² à¦à¦¬à¦‚ à¦¡à§‡à¦Ÿà¦¾ à¦¸à§à¦°à¦•à§à¦·à¦¾à¦° à¦œà¦¨à§à¦¯ à¦¸à¦ à¦¿à¦• à¦¨à¦¿à¦°à¦¾à¦ªà¦¤à§à¦¤à¦¾ à¦¬à§à¦¯à¦¬à¦¸à§à¦¥à¦¾ à¦ªà§à¦°à¦¯à¦¼à§‹à¦— à¦•à¦°à¦¾ à¦†à¦¬à¦¶à§à¦¯à¦•à¥¤ à¦à¦Ÿà¦¿ à¦¬à¦¿à¦¶à§‡à¦·à¦¤ à¦—à§à¦°à§à¦¤à§à¦¬à¦ªà§‚à¦°à§à¦£ à¦¯à¦–à¦¨ à¦à¦¨à§à¦Ÿà¦¾à¦°à¦ªà§à¦°à¦¾à¦‡à¦œ à¦ªà¦°à¦¿à¦¬à§‡à¦¶à§‡ à¦‰à¦šà§à¦š-à¦ªà§à¦°à¦¿à¦¸à¦¿à¦¶à¦¨ à¦à¦œà§‡à¦¨à§à¦Ÿ à¦«à¦°à¦®à§à¦¯à¦¾à¦Ÿ à¦¬à¦¾ à¦¸à¦‚à¦•à§à¦·à§‡à¦ªà¦¿à¦¤ à¦à¦œà§‡à¦¨à§à¦Ÿ à¦«à¦°à¦®à§à¦¯à¦¾à¦Ÿà¦—à§à¦²à¦¿ à¦¸à¦‚à¦¬à§‡à¦¦à¦¨à¦¶à§€à¦² à¦¡à§‡à¦Ÿà¦¾ à¦ªà¦°à¦¿à¦šà¦¾à¦²à¦¨à¦¾à¦° à¦…à§à¦¯à¦¾à¦ªà§à¦²à¦¿à¦•à§‡à¦¶à¦¨à§‡ à¦¡à¦¿à¦ªà§à¦²à¦¯à¦¼ à¦•à¦°à¦¾ à¦¹à¦¯à¦¼à¥¤

## SLM à¦à¦œà§‡à¦¨à§à¦Ÿ à¦‰à¦¨à§à¦¨à¦¯à¦¼à¦¨à§‡à¦° à¦­à¦¬à¦¿à¦·à§à¦¯à§Ž à¦ªà§à¦°à¦¬à¦£à¦¤à¦¾

SLM à¦à¦œà§‡à¦¨à§à¦Ÿ à¦²à§à¦¯à¦¾à¦¨à§à¦¡à¦¸à§à¦•à§‡à¦ª à¦•à¦®à§à¦ªà§à¦°à§‡à¦¶à¦¨ à¦•à§Œà¦¶à¦², à¦…à¦ªà§à¦Ÿà¦¿à¦®à¦¾à¦‡à¦œà§‡à¦¶à¦¨ à¦ªà¦¦à§à¦§à¦¤à¦¿ à¦à¦¬à¦‚ à¦à¦œ à¦¡à¦¿à¦ªà§à¦²à¦¯à¦¼à¦®à§‡à¦¨à§à¦Ÿ à¦•à§Œà¦¶à¦²à§‡à¦° à¦…à¦—à§à¦°à¦—à¦¤à¦¿à¦° à¦¸à¦¾à¦¥à§‡ à¦¬à¦¿à¦•à¦¶à¦¿à¦¤ à¦¹à¦¤à§‡ à¦¥à¦¾à¦•à§‡à¥¤ à¦­à¦¬à¦¿à¦·à§à¦¯à¦¤à§‡à¦° à¦‰à¦¨à§à¦¨à¦¯à¦¼à¦¨à¦—à§à¦²à¦¿à¦° à¦®à¦§à§à¦¯à§‡ à¦°à¦¯à¦¼à§‡à¦›à§‡ à¦à¦œà§‡à¦¨à§à¦Ÿ à¦®à¦¡à§‡à¦²à§‡à¦° à¦œà¦¨à§à¦¯ à¦†à¦°à¦“ à¦•à¦¾à¦°à§à¦¯à¦•à¦° à¦•à§‹à¦¯à¦¼à¦¾à¦¨à§à¦Ÿà¦¾à¦‡à¦œà§‡à¦¶à¦¨ à¦…à§à¦¯à¦¾à¦²à¦—à¦°à¦¿à¦¦à¦®, à¦à¦œà§‡à¦¨à§à¦Ÿ à¦“à¦¯à¦¼à¦¾à¦°à§à¦•à¦«à§à¦²à§‹à¦—à§à¦²à¦¿à¦° à¦œà¦¨à§à¦¯ à¦‰à¦¨à§à¦¨à¦¤ à¦•à¦®à§à¦ªà§à¦°à§‡à¦¶à¦¨ à¦ªà¦¦à§à¦§à¦¤à¦¿ à¦à¦¬à¦‚ à¦à¦œà§‡à¦¨à§à¦Ÿ à¦ªà§à¦°à¦•à§à¦°à¦¿à¦¯à¦¼à¦¾à¦•à¦°à¦£à§‡à¦° à¦œà¦¨à§à¦¯ à¦à¦œ à¦¹à¦¾à¦°à§à¦¡à¦“à¦¯à¦¼à§à¦¯à¦¾à¦° à¦…à§à¦¯à¦¾à¦•à§à¦¸à¦¿à¦²à¦¾à¦°à§‡à¦Ÿà¦°à§‡à¦° à¦¸à¦¾à¦¥à§‡ à¦†à¦°à¦“ à¦­à¦¾à¦² à¦‡à¦¨à§à¦Ÿà¦¿à¦—à§à¦°à§‡à¦¶à¦¨à¥¤

**SLM à¦à¦œà§‡à¦¨à§à¦Ÿà§‡à¦° à¦œà¦¨à§à¦¯ à¦¬à¦¾à¦œà¦¾à¦° à¦ªà§‚à¦°à§à¦¬à¦¾à¦­à¦¾à¦¸**: à¦¸à¦¾à¦®à§à¦ªà§à¦°à¦¤à¦¿à¦• à¦—à¦¬à§‡à¦·à¦£à¦¾ à¦…à¦¨à§à¦¸à¦¾à¦°à§‡, à¦à¦œà§‡à¦¨à§à¦Ÿ-à¦šà¦¾à¦²à¦¿à¦¤ à¦…à¦Ÿà§‹à¦®à§‡à¦¶à¦¨ à§¨à§¦à§¨à§­ à¦¸à¦¾à¦²à§‡à¦° à¦®à¦§à§à¦¯à§‡ à¦à¦¨à§à¦Ÿà¦¾à¦°à¦ªà§à¦°à¦¾à¦‡à¦œ à¦“à¦¯à¦¼à¦¾à¦°à§à¦•à¦«à§à¦²à§‹à¦¤à§‡ à§ªà§¦-à§¬à§¦% à¦ªà§à¦¨à¦°à¦¾à¦¬à§ƒà¦¤à§à¦¤à¦¿à¦®à§‚à¦²à¦• à¦•à¦—à¦¨à¦¿à¦Ÿà¦¿à¦­ à¦•à¦¾à¦œ à¦¦à§‚à¦° à¦•à¦°à¦¤à§‡ à¦ªà¦¾à¦°à§‡, à¦¯à§‡à¦–à¦¾à¦¨à§‡ SLM à¦—à§à¦²à¦¿ à¦¤à¦¾à¦¦à§‡à¦° à¦–à¦°à¦š à¦¦à¦•à§à¦·à¦¤à¦¾ à¦à¦¬à¦‚ à¦¡à¦¿à¦ªà§à¦²à¦¯à¦¼à¦®à§‡à¦¨à§à¦Ÿ à¦¨à¦®à¦¨à§€à¦¯à¦¼à¦¤à¦¾à¦° à¦•à¦¾à¦°à¦£à§‡ à¦à¦‡ à¦°à§‚à¦ªà¦¾à¦¨à§à¦¤à¦°à§‡à¦° à¦¨à§‡à¦¤à§ƒà¦¤à§à¦¬ à¦¦à§‡à¦¬à§‡à¥¤

**SLM à¦à¦œà§‡à¦¨à§à¦Ÿà§‡à¦° à¦ªà§à¦°à¦¯à§à¦•à§à¦¤à¦¿à¦—à¦¤ à¦ªà§à¦°à¦¬à¦£à¦¤à¦¾**:
- **à¦¬à¦¿à¦¶à§‡à¦·à¦¾à¦¯à¦¼à¦¿à¦¤ SLM à¦à¦œà§‡à¦¨à§à¦Ÿ**: à¦¨à¦¿à¦°à§à¦¦à¦¿à¦·à§à¦Ÿ à¦à¦œà§‡à¦¨à§à¦Ÿ à¦•à¦¾à¦œ à¦à¦¬à¦‚ à¦¶à¦¿à¦²à§à¦ªà§‡à¦° à¦œà¦¨à§à¦¯ à¦ªà§à¦°à¦¶à¦¿à¦•à§à¦·à¦¿à¦¤ à¦¡à§‹à¦®à§‡à¦‡à¦¨-à¦¨à¦¿à¦°à§à¦¦à¦¿à¦·à§à¦Ÿ à¦®à¦¡à§‡à¦²
- **à¦à¦œ à¦à¦œà§‡à¦¨à§à¦Ÿ à¦•à¦®à§à¦ªà¦¿à¦‰à¦Ÿà¦¿à¦‚**: à¦‰à¦¨à§à¦¨à¦¤ à¦…à¦¨-à¦¡à¦¿à¦­à¦¾à¦‡à¦¸ à¦à¦œà§‡à¦¨à§à¦Ÿ à¦•à§à¦·à¦®à¦¤à¦¾ à¦‰à¦¨à§à¦¨à¦¤ à¦—à§‹à¦ªà¦¨à§€à¦¯à¦¼à¦¤à¦¾ à¦à¦¬à¦‚ à¦•à¦® à¦²à§‡à¦Ÿà§‡à¦¨à§à¦¸à¦¿ à¦¸à¦¹
- **à¦à¦œà§‡à¦¨à§à¦Ÿ à¦…à¦°à§à¦•à§‡à¦¸à§à¦Ÿà§à¦°à§‡à¦¶à¦¨**: à¦à¦•à¦¾à¦§à¦¿à¦• SLM à¦à¦œà§‡à¦¨à§à¦Ÿà§‡à¦° à¦®à¦§à§à¦¯à§‡ à¦†à¦°à¦“ à¦­à¦¾à¦² à¦¸à¦®à¦¨à§à¦¬à¦¯à¦¼, à¦¡à¦¾à¦¯à¦¼à¦¨à¦¾à¦®à¦¿à¦• à¦°à¦¾à¦‰à¦Ÿà¦¿à¦‚ à¦à¦¬à¦‚ à¦²à§‹à¦¡ à¦¬à§à¦¯à¦¾à¦²à§‡à¦¨à§à¦¸à¦¿à¦‚ à¦¸à¦¹
- **à¦—à¦£à¦¤à¦¨à§à¦¤à§à¦°à§€à¦•à¦°à¦£**: SLM à¦à¦° à¦¨à¦®à¦¨à§€à¦¯à¦¼à¦¤à¦¾ à¦à¦œà§‡à¦¨à§à¦Ÿ à¦‰à¦¨à§à¦¨à¦¯à¦¼à¦¨à§‡ à¦¸à¦‚à¦¸à§à¦¥à¦¾à¦—à§à¦²à¦¿à¦° à¦®à¦§à§à¦¯à§‡ à¦¬à¦¿à¦¸à§à¦¤à§ƒà¦¤ à¦…à¦‚à¦¶à¦—à§à¦°à¦¹à¦£ à¦¸à¦•à§à¦·à¦® à¦•à¦°à§‡

## SLM à¦à¦œà§‡à¦¨à§à¦Ÿ à¦¦à¦¿à¦¯à¦¼à§‡ à¦¶à§à¦°à§ à¦•à¦°à¦¾

### à¦§à¦¾à¦ª à§§: Microsoft Agent Framework à¦ªà¦°à¦¿à¦¬à§‡à¦¶ à¦¸à§‡à¦Ÿ à¦†à¦ª à¦•à¦°à§à¦¨

**à¦¡à¦¿à¦ªà§‡à¦¨à§à¦¡à§‡à¦¨à§à¦¸à¦¿ à¦‡à¦¨à¦¸à§à¦Ÿà¦² à¦•à¦°à§à¦¨**:
```bash
# Install Microsoft Agent Framework
pip install microsoft-agent-framework

# Install Foundry Local SDK for edge deployment
pip install foundry-local-sdk

# Install additional dependencies for edge agents
pip install openai asyncio
```

**Foundry Local à¦‡à¦¨à¦¿à¦¶à¦¿à¦¯à¦¼à¦¾à¦²à¦¾à¦‡à¦œ à¦•à¦°à§à¦¨**:
```bash
# Start Foundry Local service
foundry service start

# Load default model for agent development
foundry model run phi-4-mini
```

### à¦§à¦¾à¦ª à§¨: à¦à¦œà§‡à¦¨à§à¦Ÿ à¦…à§à¦¯à¦¾à¦ªà§à¦²à¦¿à¦•à§‡à¦¶à¦¨à§‡à¦° à¦œà¦¨à§à¦¯ à¦†à¦ªà¦¨à¦¾à¦° SLM à¦¨à¦¿à¦°à§à¦¬à¦¾à¦šà¦¨ à¦•à¦°à§à¦¨
Microsoft Agent Framework à¦à¦° à¦œà¦¨à§à¦¯ à¦œà¦¨à¦ªà§à¦°à¦¿à¦¯à¦¼ à¦¬à¦¿à¦•à¦²à§à¦ª:
- **Microsoft Phi-4 Mini (3.8B)**: à¦¸à¦¾à¦§à¦¾à¦°à¦£ à¦à¦œà§‡à¦¨à§à¦Ÿ à¦•à¦¾à¦œà§‡à¦° à¦œà¦¨à§à¦¯ à¦šà¦®à§Žà¦•à¦¾à¦°, à¦­à¦¾à¦°à¦¸à¦¾à¦®à§à¦¯à¦ªà§‚à¦°à§à¦£ à¦ªà¦¾à¦°à¦«à¦°à¦®à§à¦¯à¦¾à¦¨à§à¦¸ à¦¸à¦¹
- **Qwen2.5-0.5B (0.5B)**: à¦¸à¦¹à¦œ à¦°à¦¾à¦‰à¦Ÿà¦¿à¦‚ à¦à¦¬à¦‚ à¦•à§à¦²à¦¾à¦¸à¦¿à¦«à¦¿à¦•à§‡à¦¶à¦¨ à¦à¦œà§‡à¦¨à§à¦Ÿà§‡à¦° à¦œà¦¨à§à¦¯ à¦…à¦¤à§à¦¯à¦¨à§à¦¤ à¦•à¦¾à¦°à§à¦¯à¦•à¦°
- **Qwen2.5-Coder-0.5B (0.5B)**: à¦•à§‹à¦¡-à¦¸à¦®à§à¦ªà¦°à§à¦•à¦¿à¦¤ à¦à¦œà§‡à¦¨à§à¦Ÿ à¦•à¦¾à¦œà§‡à¦° à¦œà¦¨à§à¦¯ à¦¬à¦¿à¦¶à§‡à¦·à¦¾à¦¯à¦¼à¦¿à¦¤
- **Phi-4 (7B)**: à¦‰à¦¨à§à¦¨à¦¤ à¦¯à§à¦•à§à¦¤à¦¿ à¦ªà§à¦°à¦¦à¦¾à¦¨ à¦•à¦°à§‡ à¦œà¦Ÿà¦¿à¦² à¦à¦œ à¦ªà¦°à¦¿à¦¸à§à¦¥à¦¿à¦¤à¦¿à¦° à¦œà¦¨à§à¦¯, à¦¯à¦–à¦¨ à¦¸à¦®à§à¦ªà¦¦ à¦‰à¦ªà¦²à¦¬à§à¦§ à¦¥à¦¾à¦•à§‡

### à¦§à¦¾à¦ª à§©: Microsoft Agent Framework à¦¦à¦¿à¦¯à¦¼à§‡ à¦†à¦ªà¦¨à¦¾à¦° à¦ªà§à¦°à¦¥à¦® à¦à¦œà§‡à¦¨à§à¦Ÿ à¦¤à§ˆà¦°à¦¿ à¦•à¦°à§à¦¨

**à¦¬à§‡à¦¸à¦¿à¦• à¦à¦œà§‡à¦¨à§à¦Ÿ à¦¸à§‡à¦Ÿà¦†à¦ª**:
```python
from microsoft_agent_framework import Agent, Config
from foundry_local import FoundryLocalManager

# Initialize Foundry Local connection
foundry = FoundryLocalManager("phi-4-mini")

# Create agent configuration
config = Config(
    name="my-first-agent",
    model_provider="foundry-local",
    model_alias="phi-4-mini",
    offline_mode=True
)

# Create and configure agent
agent = Agent(
    config=config,
    model_endpoint=foundry.endpoint,
    api_key=foundry.api_key
)

# Define a simple tool
@agent.tool
def get_current_time() -> str:
    """Get the current time."""
    from datetime import datetime
    return datetime.now().strftime("%Y-%m-%d %H:%M:%S")

# Test the agent
response = agent.chat("What time is it?")
print(response)
```

### à¦§à¦¾à¦ª à§ª: à¦à¦œà§‡à¦¨à§à¦Ÿà§‡à¦° à¦¸à§à¦•à§‹à¦ª à¦à¦¬à¦‚ à¦ªà§à¦°à¦¯à¦¼à§‹à¦œà¦¨à§€à¦¯à¦¼à¦¤à¦¾ à¦¨à¦¿à¦°à§à¦§à¦¾à¦°à¦£ à¦•à¦°à§à¦¨
Microsoft Agent Framework à¦¬à§à¦¯à¦¬à¦¹à¦¾à¦° à¦•à¦°à§‡ à¦«à§‹à¦•à¦¾à¦¸à¦¡, à¦¸à§à¦¸à¦‚à¦œà§à¦žà¦¾à¦¯à¦¼à¦¿à¦¤ à¦à¦œà§‡à¦¨à§à¦Ÿ à¦…à§à¦¯à¦¾à¦ªà§à¦²à¦¿à¦•à§‡à¦¶à¦¨ à¦¦à¦¿à¦¯à¦¼à§‡ à¦¶à§à¦°à§ à¦•à¦°à§à¦¨:
- **à¦à¦•à¦• à¦¡à§‹à¦®à§‡à¦‡à¦¨ à¦à¦œà§‡à¦¨à§à¦Ÿ**: à¦•à¦¾à¦¸à§à¦Ÿà¦®à¦¾à¦° à¦¸à¦¾à¦°à§à¦­à¦¿à¦¸ à¦…à¦¥à¦¬à¦¾ à¦¶à¦¿à¦¡à¦¿à¦‰à¦²à¦¿à¦‚ à¦…à¦¥à¦¬à¦¾ à¦—à¦¬à§‡à¦·à¦£à¦¾
- **à¦¸à§à¦ªà¦·à§à¦Ÿ à¦à¦œà§‡à¦¨à§à¦Ÿ à¦‰à¦¦à§à¦¦à§‡à¦¶à§à¦¯**: à¦à¦œà§‡à¦¨à§à¦Ÿ à¦ªà¦¾à¦°à¦«à¦°à¦®à§à¦¯à¦¾à¦¨à§à¦¸à§‡à¦° à¦œà¦¨à§à¦¯ à¦¨à¦¿à¦°à§à¦¦à¦¿à¦·à§à¦Ÿ, à¦ªà¦°à¦¿à¦®à¦¾à¦ªà¦¯à§‹à¦—à§à¦¯ à¦²à¦•à§à¦·à§à¦¯
- **à¦¸à§€à¦®à¦¿à¦¤ à¦Ÿà§à¦² à¦‡à¦¨à§à¦Ÿà¦¿à¦—à§à¦°à§‡à¦¶à¦¨**: à¦ªà§à¦°à¦¾à¦¥à¦®à¦¿à¦• à¦à¦œà§‡à¦¨à§à¦Ÿ à¦¡à¦¿à¦ªà§à¦²à¦¯à¦¼à¦®à§‡à¦¨à§à¦Ÿà§‡à¦° à¦œà¦¨à§à¦¯ à¦¸à¦°à§à¦¬à¦¾à¦§à¦¿à¦• à§©-à§«à¦Ÿà¦¿ à¦Ÿà§à¦²
- **à¦¸à¦‚à¦œà§à¦žà¦¾à¦¯à¦¼à¦¿à¦¤ à¦à¦œà§‡à¦¨à§à¦Ÿ à¦¸à§€à¦®à¦¾à¦¨à¦¾**: à¦œà¦Ÿà¦¿à¦² à¦ªà¦°à¦¿à¦¸à§à¦¥à¦¿à¦¤à¦¿à¦° à¦œà¦¨à§à¦¯ à¦¸à§à¦ªà¦·à§à¦Ÿ à¦à¦¸à¦•à§‡à¦²à§‡à¦¶à¦¨ à¦ªà¦¥
- **à¦à¦œ-à¦ªà§à¦°à¦¥à¦® à¦¡à¦¿à¦œà¦¾à¦‡à¦¨**: à¦…à¦«à¦²à¦¾à¦‡à¦¨ à¦•à¦¾à¦°à§à¦¯à¦•à¦¾à¦°à¦¿à¦¤à¦¾ à¦à¦¬à¦‚ à¦¸à§à¦¥à¦¾à¦¨à§€à¦¯à¦¼ à¦ªà§à¦°à¦•à§à¦°à¦¿à¦¯à¦¼à¦¾à¦•à¦°à¦£à¦•à§‡ à¦…à¦—à§à¦°à¦¾à¦§à¦¿à¦•à¦¾à¦° à¦¦à¦¿à¦¨

### à¦§à¦¾à¦ª à§«: Microsoft Agent Framework à¦¦à¦¿à¦¯à¦¼à§‡ à¦à¦œ à¦¡à¦¿à¦ªà§à¦²à¦¯à¦¼à¦®à§‡à¦¨à§à¦Ÿ à¦¬à¦¾à¦¸à§à¦¤à¦¬à¦¾à¦¯à¦¼à¦¨ à¦•à¦°à§à¦¨

**à¦°à¦¿à¦¸à§‹à¦°à§à¦¸ à¦•à¦¨à¦«à¦¿à¦—à¦¾à¦°à§‡à¦¶à¦¨**:
```python
from microsoft_agent_framework import ResourceConfig

# Configure for edge deployment
resource_config = ResourceConfig(
    max_memory_usage="2GB",
    max_concurrent_agents=2,
    model_cache_size="1GB",
    auto_unload_idle_models=True,
    power_management=True
)

agent = Agent(
    config=config,
    resource_limits=resource_config
)
```

**à¦à¦œ à¦à¦œà§‡à¦¨à§à¦Ÿà§‡à¦° à¦œà¦¨à§à¦¯ à¦¨à¦¿à¦°à¦¾à¦ªà¦¤à§à¦¤à¦¾ à¦¬à§à¦¯à¦¬à¦¸à§à¦¥à¦¾ à¦¡à¦¿à¦ªà§à¦²à¦¯à¦¼ à¦•à¦°à§à¦¨**:
- **à¦¸à§à¦¥à¦¾à¦¨à§€à¦¯à¦¼ à¦‡à¦¨à¦ªà§à¦Ÿ à¦­à§à¦¯à¦¾à¦²à¦¿à¦¡à§‡à¦¶à¦¨**: à¦•à§à¦²à¦¾à¦‰à¦¡ à¦¨à¦¿à¦°à§à¦­à¦°à¦¤à¦¾ à¦›à¦¾à¦¡à¦¼à¦¾à¦‡ à¦…à¦¨à§à¦°à§‹à¦§ à¦¯à¦¾à¦šà¦¾à¦‡ à¦•à¦°à§à¦¨
- **à¦…à¦«à¦²à¦¾à¦‡à¦¨ à¦†à¦‰à¦Ÿà¦ªà§à¦Ÿ à¦«à¦¿à¦²à§à¦Ÿà¦¾à¦°à¦¿à¦‚**: à¦¨à¦¿à¦¶à§à¦šà¦¿à¦¤ à¦•à¦°à§à¦¨ à¦¯à§‡ à¦ªà§à¦°à¦¤à¦¿à¦•à§à¦°à¦¿à¦¯à¦¼à¦¾à¦—à§à¦²à¦¿ à¦¸à§à¦¥à¦¾à¦¨à§€à¦¯à¦¼à¦­à¦¾à¦¬à§‡ à¦®à¦¾à¦¨à§‡à¦° à¦®à¦¾à¦¨ à¦ªà§‚à¦°à¦£ à¦•à¦°à§‡
- **à¦à¦œ à¦¨à¦¿à¦°à¦¾à¦ªà¦¤à§à¦¤à¦¾ à¦¨à¦¿à¦¯à¦¼à¦¨à§à¦¤à§à¦°à¦£**: à¦‡à¦¨à§à¦Ÿà¦¾à¦°à¦¨à§‡à¦Ÿ à¦¸à¦‚à¦¯à§‹à¦—à§‡à¦° à¦ªà§à¦°à¦¯à¦¼à§‹à¦œà¦¨ à¦›à¦¾à¦¡à¦¼à¦¾à¦‡ à¦¨à¦¿à¦°à¦¾à¦ªà¦¤à§à¦¤à¦¾ à¦¬à¦¾à¦¸à§à¦¤à¦¬à¦¾à¦¯à¦¼à¦¨ à¦•à¦°à§à¦¨
- **à¦¸à§à¦¥à¦¾à¦¨à§€à¦¯à¦¼ à¦ªà¦°à§à¦¯à¦¬à§‡à¦•à§à¦·à¦£**: à¦ªà¦¾à¦°à¦«à¦°à¦®à§à¦¯à¦¾à¦¨à§à¦¸ à¦Ÿà§à¦°à§à¦¯à¦¾à¦• à¦•à¦°à§à¦¨ à¦à¦¬à¦‚ à¦à¦œ à¦Ÿà§‡à¦²à¦¿à¦®à§‡à¦Ÿà§à¦°à¦¿ à¦¬à§à¦¯à¦¬à¦¹à¦¾à¦° à¦•à¦°à§‡ à¦¸à¦®à¦¸à§à¦¯à¦¾à¦—à§à¦²à¦¿ à¦šà¦¿à¦¹à§à¦¨à¦¿à¦¤ à¦•à¦°à§à¦¨

### à¦§à¦¾à¦ª à§¬: à¦à¦œ à¦à¦œà§‡à¦¨à§à¦Ÿ à¦ªà¦¾à¦°à¦«à¦°à¦®à§à¦¯à¦¾à¦¨à§à¦¸ à¦ªà¦°à¦¿à¦®à¦¾à¦ª à¦à¦¬à¦‚ à¦…à¦ªà§à¦Ÿà¦¿à¦®à¦¾à¦‡à¦œ à¦•à¦°à§à¦¨
- **à¦à¦œà§‡à¦¨à§à¦Ÿ à¦•à¦¾à¦œ à¦¸à¦®à§à¦ªà¦¨à§à¦¨ à¦•à¦°à¦¾à¦° à¦¹à¦¾à¦°**: à¦…à¦«à¦²à¦¾à¦‡à¦¨ à¦ªà¦°à¦¿à¦¸à§à¦¥à¦¿à¦¤à¦¿à¦¤à§‡ à¦¸à¦¾à¦«à¦²à§à¦¯à§‡à¦° à¦¹à¦¾à¦° à¦ªà¦°à§à¦¯à¦¬à§‡à¦•à§à¦·à¦£ à¦•à¦°à§à¦¨
- **à¦à¦œà§‡à¦¨à§à¦Ÿ à¦ªà§à¦°à¦¤à¦¿à¦•à§à¦°à¦¿à¦¯à¦¼à¦¾ à¦¸à¦®à¦¯à¦¼**: à¦à¦œ à¦¡à¦¿à¦ªà§à¦²à¦¯à¦¼à¦®à§‡à¦¨à§à¦Ÿà§‡à¦° à¦œà¦¨à§à¦¯ à¦¸à§‡à¦•à§‡à¦¨à§à¦¡à§‡à¦° à¦¨à¦¿à¦šà§‡ à¦ªà§à¦°à¦¤à¦¿à¦•à§à¦°à¦¿à¦¯à¦¼à¦¾ à¦¸à¦®à¦¯à¦¼ à¦¨à¦¿à¦¶à§à¦šà¦¿à¦¤ à¦•à¦°à§à¦¨
- **à¦°à¦¿à¦¸à§‹à¦°à§à¦¸ à¦¬à§à¦¯à¦¬à¦¹à¦¾à¦°**: à¦à¦œ à¦¡à¦¿à¦­à¦¾à¦‡à¦¸à§‡ à¦®à§‡à¦®à§‹à¦°à¦¿, CPU à¦à¦¬à¦‚ à¦¬à§à¦¯à¦¾à¦Ÿà¦¾à¦°à¦¿ à¦¬à§à¦¯à¦¬à¦¹à¦¾à¦°à§‡à¦° à¦Ÿà§à¦°à§à¦¯à¦¾à¦• à¦°à¦¾à¦–à§à¦¨
- **à¦–à¦°à¦š à¦¦à¦•à§à¦·à¦¤à¦¾**: à¦à¦œ à¦¡à¦¿à¦ªà§à¦²à¦¯à¦¼à¦®à§‡à¦¨à§à¦Ÿ à¦–à¦°à¦š à¦•à§à¦²à¦¾à¦‰à¦¡-à¦­à¦¿à¦¤à§à¦¤à¦¿à¦• à¦¬à¦¿à¦•à¦²à§à¦ªà¦—à§à¦²à¦¿à¦° à¦¸à¦¾à¦¥à§‡ à¦¤à§à¦²à¦¨à¦¾ à¦•à¦°à§à¦¨
- **à¦…à¦«à¦²à¦¾à¦‡à¦¨ à¦¨à¦¿à¦°à§à¦­à¦°à¦¯à§‹à¦—à§à¦¯à¦¤à¦¾**: à¦¨à§‡à¦Ÿà¦“à¦¯à¦¼à¦¾à¦°à§à¦• à¦¬à¦¿à¦­à§à¦°à¦¾à¦Ÿà§‡à¦° à¦¸à¦®à¦¯à¦¼ à¦à¦œà§‡à¦¨à§à¦Ÿ à¦ªà¦¾à¦°à¦«à¦°à¦®à§à¦¯à¦¾à¦¨à§à¦¸ à¦ªà¦°à¦¿à¦®à¦¾à¦ª à¦•à¦°à§à¦¨

## SLM à¦à¦œà§‡à¦¨à§à¦Ÿ à¦¬à¦¾à¦¸à§à¦¤à¦¬à¦¾à¦¯à¦¼à¦¨à§‡à¦° à¦œà¦¨à§à¦¯ à¦®à§‚à¦² à¦¬à¦¿à¦·à§Ÿà¦—à§à¦²à§‹

1. **SLM à¦à¦œà§‡à¦¨à§à¦Ÿà§‡à¦° à¦œà¦¨à§à¦¯ à¦¯à¦¥à§‡à¦·à§à¦Ÿ**: à¦¬à§‡à¦¶à¦¿à¦°à¦­à¦¾à¦— à¦à¦œà§‡à¦¨à§à¦Ÿ à¦•à¦¾à¦œà§‡à¦° à¦œà¦¨à§à¦¯ à¦›à§‹à¦Ÿ à¦®à¦¡à§‡à¦²à¦—à§à¦²à¦¿ à¦¬à¦¡à¦¼à¦—à§à¦²à¦¿à¦° à¦®à¦¤à§‹à¦‡ à¦•à¦¾à¦°à§à¦¯à¦•à¦°, à¦‰à¦²à§à¦²à§‡à¦–à¦¯à§‹à¦—à§à¦¯ à¦¸à§à¦¬à¦¿à¦§à¦¾ à¦ªà§à¦°à¦¦à¦¾à¦¨ à¦•à¦°à§‡
2. **à¦à¦œà§‡à¦¨à§à¦Ÿà§‡ à¦–à¦°à¦š à¦¦à¦•à§à¦·à¦¤à¦¾**: SLM à¦à¦œà§‡à¦¨à§à¦Ÿ à¦šà¦¾à¦²à¦¾à¦¨à§‹ à§§à§¦-à§©à§¦ à¦—à§à¦£ à¦¸à¦¸à§à¦¤à¦¾, à¦¯à¦¾ à¦¤à¦¾à¦¦à§‡à¦° à¦¬à§à¦¯à¦¾à¦ªà¦• à¦¡à¦¿à¦ªà§à¦²à¦¯à¦¼à¦®à§‡à¦¨à§à¦Ÿà§‡à¦° à¦œà¦¨à§à¦¯ à¦…à¦°à§à¦¥à¦¨à§ˆà¦¤à¦¿à¦•à¦­à¦¾à¦¬à§‡ à¦•à¦¾à¦°à§à¦¯à¦•à¦° à¦•à¦°à§‡ à¦¤à§‹à¦²à§‡
3. **à¦à¦œà§‡à¦¨à§à¦Ÿà§‡à¦° à¦œà¦¨à§à¦¯ à¦¬à¦¿à¦¶à§‡à¦·à¦¾à¦¯à¦¼à¦¨ à¦•à¦¾à¦°à§à¦¯à¦•à¦°**: à¦¨à¦¿à¦°à§à¦¦à¦¿à¦·à§à¦Ÿ à¦à¦œà§‡à¦¨à§à¦Ÿ à¦…à§à¦¯à¦¾à¦ªà§à¦²à¦¿à¦•à§‡à¦¶à¦¨à§‡ à¦«à¦¾à¦‡à¦¨-à¦Ÿà¦¿à¦‰à¦¨à¦¡ SLM à¦¸à¦¾à¦§à¦¾à¦°à¦£ à¦‰à¦¦à§à¦¦à§‡à¦¶à§à¦¯à§‡à¦° LLM à¦•à§‡ à¦›à¦¾à¦¡à¦¼à¦¿à¦¯à¦¼à§‡ à¦¯à¦¾à¦¯à¦¼
4. **à¦¹à¦¾à¦‡à¦¬à§à¦°à¦¿à¦¡ à¦à¦œà§‡à¦¨à§à¦Ÿ à¦†à¦°à§à¦•à¦¿à¦Ÿà§‡à¦•à¦šà¦¾à¦°**: à¦°à§à¦Ÿà¦¿à¦¨ à¦à¦œà§‡à¦¨à§à¦Ÿ à¦•à¦¾à¦œà§‡à¦° à¦œà¦¨à§à¦¯ SLM à¦¬à§à¦¯à¦¬à¦¹à¦¾à¦° à¦•à¦°à§à¦¨, à¦ªà§à¦°à¦¯à¦¼à§‹à¦œà¦¨ à¦¹à¦²à§‡ à¦œà¦Ÿà¦¿à¦² à¦¯à§à¦•à§à¦¤à¦¿à¦° à¦œà¦¨à§à¦¯ LLM à¦¬à§à¦¯à¦¬à¦¹à¦¾à¦° à¦•à¦°à§à¦¨
5. **Microsoft Agent Framework à¦ªà§à¦°à§‹à¦¡à¦¾à¦•à¦¶à¦¨ à¦¡à¦¿à¦ªà§à¦²à¦¯à¦¼à¦®à§‡à¦¨à§à¦Ÿ à¦¸à¦•à§à¦·à¦® à¦•à¦°à§‡**: à¦à¦œ à¦à¦œà§‡à¦¨à§à¦Ÿ à¦¤à§ˆà¦°à¦¿, à¦¡à¦¿à¦ªà§à¦²à¦¯à¦¼ à¦à¦¬à¦‚ à¦ªà¦°à¦¿à¦šà¦¾à¦²à¦¨à¦¾à¦° à¦œà¦¨à§à¦¯ à¦à¦¨à§à¦Ÿà¦¾à¦°à¦ªà§à¦°à¦¾à¦‡à¦œ-à¦—à§à¦°à§‡à¦¡ à¦Ÿà§à¦² à¦¸à¦°à¦¬à¦°à¦¾à¦¹ à¦•à¦°à§‡
6. **à¦à¦œ-à¦ªà§à¦°à¦¥à¦® à¦¡à¦¿à¦œà¦¾à¦‡à¦¨ à¦¨à§€à¦¤à¦¿à¦®à¦¾à¦²à¦¾**: à¦¸à§à¦¥à¦¾à¦¨à§€à¦¯à¦¼ à¦ªà§à¦°à¦•à§à¦°à¦¿à¦¯à¦¼à¦¾à¦•à¦°à¦£ à¦¸à¦¹ à¦…à¦«à¦²à¦¾à¦‡à¦¨-à¦¸à¦•à§à¦·à¦® à¦à¦œà§‡à¦¨à§à¦Ÿ à¦—à§‹à¦ªà¦¨à§€à¦¯à¦¼à¦¤à¦¾ à¦à¦¬à¦‚ à¦¨à¦¿à¦°à§à¦­à¦°à¦¯à§‹à¦—à§à¦¯à¦¤à¦¾ à¦¨à¦¿à¦¶à§à¦šà¦¿à¦¤ à¦•à¦°à§‡
7. **Foundry Local à¦‡à¦¨à§à¦Ÿà¦¿à¦—à§à¦°à§‡à¦¶à¦¨**: Microsoft Agent Framework à¦à¦¬à¦‚ à¦¸à§à¦¥à¦¾à¦¨à§€à¦¯à¦¼ à¦®à¦¡à§‡à¦² à¦‡à¦¨à¦«à¦¾à¦°à§‡à¦¨à§à¦¸à§‡à¦° à¦®à¦§à§à¦¯à§‡ à¦¨à¦¿à¦°à§à¦¬à¦¿à¦˜à§à¦¨ à¦¸à¦‚à¦¯à§‹à¦—
8. **à¦­à¦¬à¦¿à¦·à§à¦¯à§Ž SLM à¦à¦œà§‡à¦¨à§à¦Ÿ**: à¦ªà§à¦°à§‹à¦¡à¦¾à¦•à¦¶à¦¨ à¦«à§à¦°à§‡à¦®à¦“à¦¯à¦¼à¦¾à¦°à§à¦• à¦¸à¦¹ à¦›à§‹à¦Ÿ à¦­à¦¾à¦·à¦¾à¦° à¦®à¦¡à§‡à¦²à¦—à§à¦²à¦¿ à¦à¦œà§‡à¦¨à§à¦Ÿà¦¿à¦• AI à¦à¦° à¦­à¦¬à¦¿à¦·à§à¦¯à§Ž, à¦¯à¦¾ à¦—à¦£à¦¤à¦¨à§à¦¤à§à¦°à§€à¦•à¦°à¦£ à¦à¦¬à¦‚ à¦•à¦¾à¦°à§à¦¯à¦•à¦° à¦à¦œà§‡à¦¨à§à¦Ÿ à¦¡à¦¿à¦ªà§à¦²à¦¯à¦¼à¦®à§‡à¦¨à§à¦Ÿ à¦¸à¦•à§à¦·à¦® à¦•à¦°à§‡

## à¦°à§‡à¦«à¦¾à¦°à§‡à¦¨à§à¦¸ à¦à¦¬à¦‚ à¦†à¦°à¦“ à¦ªà¦¡à¦¼à¦¾à¦¶à§‹à¦¨à¦¾

### à¦®à§‚à¦² à¦—à¦¬à§‡à¦·à¦£à¦¾ à¦ªà¦¤à§à¦° à¦à¦¬à¦‚ à¦ªà§à¦°à¦•à¦¾à¦¶à¦¨à¦¾

#### AI à¦à¦œà§‡à¦¨à§à¦Ÿ à¦à¦¬à¦‚ à¦à¦œà§‡à¦¨à§à¦Ÿà¦¿à¦• à¦¸à¦¿à¦¸à§à¦Ÿà§‡à¦®
- **"Language Agents as Optimizable Graphs"** (à§¨à§¦à§¨à§ª) - à¦à¦œà§‡à¦¨à§à¦Ÿ à¦†à¦°à§à¦•à¦¿à¦Ÿà§‡à¦•à¦šà¦¾à¦° à¦à¦¬à¦‚ à¦…à¦ªà§à¦Ÿà¦¿à¦®à¦¾à¦‡à¦œà§‡à¦¶à¦¨à§‡à¦° à¦‰à¦ªà¦° à¦®à§Œà¦²à¦¿à¦• à¦—à¦¬à§‡à¦·à¦£à¦¾
  - à¦²à§‡à¦–à¦•: Wenyue Hua, Lishan Yang, à¦ªà§à¦°à¦®à§à¦–
  - à¦²à¦¿à¦™à§à¦•: https://arxiv.org/abs/2402.16823
  - à¦®à§‚à¦² à¦…à¦¨à§à¦¤à¦°à§à¦¦à§ƒà¦·à§à¦Ÿà¦¿: à¦—à§à¦°à¦¾à¦«-à¦­à¦¿à¦¤à§à¦¤à¦¿à¦• à¦à¦œà§‡à¦¨à§à¦Ÿ à¦¡à¦¿à¦œà¦¾à¦‡à¦¨ à¦à¦¬à¦‚ à¦…à¦ªà§à¦Ÿà¦¿à¦®à¦¾à¦‡à¦œà§‡à¦¶à¦¨ à¦•à§Œà¦¶à¦²

- **"The Rise and Potential of Large Language Model Based Agents"** (à§¨à§¦à§¨à§©)
  - à¦²à§‡à¦–à¦•: Zhiheng Xi, Wenxiang Chen, à¦ªà§à¦°à¦®à§à¦–
  - à¦²à¦¿à¦™à§à¦•: https://arxiv.org/abs/2309.07864
  - à¦®à§‚à¦² à¦…à¦¨à§à¦¤à¦°à§à¦¦à§ƒà¦·à§à¦Ÿà¦¿: LLM-à¦­à¦¿à¦¤à§à¦¤à¦¿à¦• à¦à¦œà§‡à¦¨à§à¦Ÿà§‡à¦° à¦•à§à¦·à¦®à¦¤à¦¾ à¦à¦¬à¦‚ à¦…à§à¦¯à¦¾à¦ªà§à¦²à¦¿à¦•à§‡à¦¶à¦¨à§‡à¦° à¦¬à§à¦¯à¦¾à¦ªà¦• à¦¸à¦®à§€à¦•à§à¦·à¦¾

- **"Cognitive Architectures for Language Agents"** (à§¨à§¦à§¨à§ª)
  - à¦²à§‡à¦–à¦•: Theodore Sumers, Shunyu Yao, à¦ªà§à¦°à¦®à§à¦–
  - à¦²à¦¿à¦™à§à¦•: https://arxiv.org/abs/2309.02427
  - à¦®à§‚à¦² à¦…à¦¨à§à¦¤à¦°à§à¦¦à§ƒà¦·à§à¦Ÿà¦¿: à¦¬à§à¦¦à§à¦§à¦¿à¦®à¦¾à¦¨ à¦à¦œà§‡à¦¨à§à¦Ÿ à¦¡à¦¿à¦œà¦¾à¦‡à¦¨à§‡à¦° à¦œà¦¨à§à¦¯ à¦•à¦—à¦¨à¦¿à¦Ÿà¦¿à¦­ à¦«à§à¦°à§‡à¦®à¦“à¦¯à¦¼à¦¾à¦°à§à¦•

#### à¦›à§‹à¦Ÿ à¦­à¦¾à¦·à¦¾à¦° à¦®à¦¡à§‡à¦² à¦à¦¬à¦‚ à¦…à¦ªà§à¦Ÿà¦¿à¦®à¦¾à¦‡à¦œà§‡à¦¶à¦¨
- **"Phi-3 Technical Report: A Highly Capable Language Model Locally on Your Phone"** (à§¨à§¦à§¨à§ª)
  - à¦²à§‡à¦–à¦•: Microsoft Research Team
  - à¦²à¦¿à¦™à§à¦•: https://arxiv.org/abs/2404.14219
  - à¦®à§‚à¦² à¦…à¦¨à§à¦¤à¦°à§à¦¦à§ƒà¦·à§à¦Ÿà¦¿: SLM à¦¡à¦¿à¦œà¦¾à¦‡à¦¨ à¦¨à§€à¦¤à¦¿à¦®à¦¾à¦²à¦¾ à¦à¦¬à¦‚ à¦®à§‹à¦¬à¦¾à¦‡à¦² à¦¡à¦¿à¦ªà§à¦²à¦¯à¦¼à¦®à§‡à¦¨à§à¦Ÿ à¦•à§Œà¦¶à¦²

- **"Qwen2.5 Technical Report"** (à§¨à§¦à§¨à§ª)
  - à¦²à§‡à¦–à¦•: Alibaba Cloud Team
  - à¦²à¦¿à¦™à§à¦•: https://arxiv.org/abs/2407.10671
  - à¦®à§‚à¦² à¦…à¦¨à§à¦¤à¦°à§à¦¦à§ƒà¦·à§à¦Ÿà¦¿: à¦‰à¦¨à§à¦¨à¦¤ SLM à¦ªà§à¦°à¦¶à¦¿à¦•à§à¦·à¦£ à¦•à§Œà¦¶à¦² à¦à¦¬à¦‚ à¦ªà¦¾à¦°à¦«à¦°à¦®à§à¦¯à¦¾à¦¨à§à¦¸ à¦…à¦ªà§à¦Ÿà¦¿à¦®à¦¾à¦‡à¦œà§‡à¦¶à¦¨

- **"TinyLlama: An Open-Source Small Language Model"** (à§¨à§¦à§¨à§ª)
  - à¦²à§‡à¦–à¦•: Peiyuan Zhang, Guangtao Zeng, à¦ªà§à¦°à¦®à§à¦–
  - à¦²à¦¿à¦™à§à¦•: https://arxiv.org/abs/2401.02385
  - à¦®à§‚à¦² à¦…à¦¨à§à¦¤à¦°à§à¦¦à§ƒà¦·à§à¦Ÿà¦¿: à¦…à¦¤à¦¿à¦•à§à¦·à§à¦¦à§à¦° à¦®à¦¡à§‡à¦² à¦¡à¦¿à¦œà¦¾à¦‡à¦¨ à¦à¦¬à¦‚ à¦ªà§à¦°à¦¶à¦¿à¦•à§à¦·à¦£à§‡à¦° à¦¦à¦•à§à¦·à¦¤à¦¾

### à¦…à¦«à¦¿à¦¸à¦¿à¦¯à¦¼à¦¾à¦² à¦¡à¦•à§à¦®à§‡à¦¨à§à¦Ÿà§‡à¦¶à¦¨ à¦à¦¬à¦‚ à¦«à§à¦°à§‡à¦®à¦“à¦¯à¦¼à¦¾à¦°à§à¦•

#### Microsoft Agent Framework
- **à¦…à¦«à¦¿à¦¸à¦¿à¦¯à¦¼à¦¾à¦² à¦¡à¦•à§à¦®à§‡à¦¨à§à¦Ÿà§‡à¦¶à¦¨**: https://docs.microsoft.com/en-us/azure/ai-services/agents/
- **GitHub à¦°à¦¿à¦ªà§‹à¦œà¦¿à¦Ÿà¦°à¦¿**: https://github.com/microsoft/agent-framework

#### Foundry Local
- **à¦ªà§à¦°à¦¾à¦‡à¦®à¦¾à¦°à¦¿ à¦°à¦¿à¦ªà§‹à¦œà¦¿à¦Ÿà¦°à¦¿**: https://github.com/microsoft/foundry-local
- **à¦¡à¦•à§à¦®à§‡à¦¨à§à¦Ÿà§‡à¦¶à¦¨**: https://github.com/microsoft/foundry-local/blob/main/docs/README.md


#### VLLM
- **à¦®à§‡à¦‡à¦¨ à¦°à¦¿à¦ªà§‹à¦œà¦¿à¦Ÿà¦°à¦¿**: https://github.com/vllm-project/vllm
- **à¦¡à¦•à§à¦®à§‡à¦¨à§à¦Ÿà§‡à¦¶à¦¨**: https://docs.vllm.ai/


#### Ollama
- **à¦…à¦«à¦¿à¦¸à¦¿à¦¯à¦¼à¦¾à¦² à¦“à¦¯à¦¼à§‡à¦¬à¦¸à¦¾à¦‡à¦Ÿ**: https://ollama.ai/
- **GitHub à¦°à¦¿à¦ªà§‹à¦œà¦¿à¦Ÿà¦°à¦¿**: https://github.com/ollama/ollama

### à¦®à¦¡à§‡à¦² à¦…à¦ªà§à¦Ÿà¦¿à¦®à¦¾à¦‡à¦œà§‡à¦¶à¦¨ à¦«à§à¦°à§‡à¦®à¦“à¦¯à¦¼à¦¾à¦°à§à¦•

#### Llama.cpp
- **à¦°à¦¿à¦ªà§‹à¦œà¦¿à¦Ÿà¦°à¦¿**: https://github.com/ggml-org/llama.cpp


#### Microsoft Olive
- **à¦¡à¦•à§à¦®à§‡à¦¨à§à¦Ÿà§‡à¦¶à¦¨**: https://microsoft.github.io/Olive/
- **GitHub à¦°à¦¿à¦ªà§‹à¦œà¦¿à¦Ÿà¦°à¦¿**: https://github.com/microsoft/Olive

#### OpenVINO
- **à¦…à¦«à¦¿à¦¸à¦¿à¦¯à¦¼à¦¾à¦² à¦¸à¦¾à¦‡à¦Ÿ**: https://docs.openvino.ai/

#### Apple MLX
- **à¦°à¦¿à¦ªà§‹à¦œà¦¿à¦Ÿà¦°à¦¿**: https://github.com/ml-explore/mlx

### à¦¶à¦¿à¦²à§à¦ª à¦°à¦¿à¦ªà§‹à¦°à§à¦Ÿ à¦à¦¬à¦‚ à¦¬à¦¾à¦œà¦¾à¦° à¦¬à¦¿à¦¶à§à¦²à§‡à¦·à¦£

#### AI à¦à¦œà§‡à¦¨à§à¦Ÿ à¦¬à¦¾à¦œà¦¾à¦° à¦—à¦¬à§‡à¦·à¦£à¦¾
- **"The State of AI Agents 2025"** - McKinsey Global Institute
  - à¦²à¦¿à¦™à§à¦•: https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/ai-agents-2025
  - à¦®à§‚à¦² à¦…à¦¨à§à¦¤à¦°à§à¦¦à§ƒà¦·à§à¦Ÿà¦¿: à¦¬à¦¾à¦œà¦¾à¦° à¦ªà§à¦°à¦¬à¦£à¦¤à¦¾ à¦à¦¬à¦‚ à¦à¦¨à§à¦Ÿà¦¾à¦°à¦ªà§à¦°à¦¾à¦‡à¦œ à¦—à§à¦°à¦¹à¦£à§‡à¦° à¦ªà§à¦¯à¦¾à¦Ÿà¦¾à¦°à§à¦¨

#### à¦ªà§à¦°à¦¯à§à¦•à§à¦¤à¦¿à¦—à¦¤ à¦¬à§‡à¦žà§à¦šà¦®à¦¾à¦°à§à¦•

- **"Edge AI Inference Benchmarks"** - MLPerf
  - à¦²à¦¿à¦™à§à¦•: https://mlcommons.org/en/inference-edge/
  - à¦®à§‚à¦² à¦…à¦¨à§à¦¤à¦°à§à¦¦à§ƒà¦·à§à¦Ÿà¦¿: à¦à¦œ à¦¡à¦¿à¦ªà§à¦²à¦¯à¦¼à¦®à§‡à¦¨à§à¦Ÿà§‡à¦° à¦œà¦¨à§à¦¯ à¦®à¦¾à¦¨à¦• à¦ªà¦¾à¦°à¦«à¦°à¦®à§à¦¯à¦¾à¦¨à§à¦¸ à¦®à§‡à¦Ÿà§à¦°à¦¿à¦•

### à¦®à¦¾à¦¨ à¦à¦¬à¦‚ à¦¸à§à¦ªà§‡à¦¸à¦¿à¦«à¦¿à¦•à§‡à¦¶à¦¨

#### à¦®à¦¡à§‡à¦² à¦«à¦°à¦®à§à¦¯à¦¾à¦Ÿ à¦à¦¬à¦‚ à¦®à¦¾à¦¨
- **ONNX (Open Neural Network Exchange)**: https://onnx.ai/
  - à¦†à¦¨à§à¦¤à¦ƒà¦ªà¦°à¦¿à¦šà¦¾à¦²à¦¨à¦¯à§‹à¦—à§à¦¯à¦¤à¦¾à¦° à¦œà¦¨à§à¦¯ à¦•à§à¦°à¦¸-à¦ªà§à¦²à§à¦¯à¦¾à¦Ÿà¦«à¦°à§à¦® à¦®à¦¡à§‡à¦² à¦«à¦°à¦®à§à¦¯à¦¾à¦Ÿ
- **GGUF à¦¸à§à¦ªà§‡à¦¸à¦¿à¦«à¦¿à¦•à§‡à¦¶à¦¨**: https://github.com/ggerganov/ggml/blob/master/docs/gguf.md
  - CPU à¦‡à¦¨à¦«à¦¾à¦°à§‡à¦¨à§à¦¸à§‡à¦° à¦œà¦¨à§à¦¯ à¦•à§‹à¦¯à¦¼à¦¾à¦¨à§à¦Ÿà¦¾à¦‡à¦œà¦¡ à¦®à¦¡à§‡à¦² à¦«à¦°à¦®à§à¦¯à¦¾à¦Ÿ
- **OpenAI API à¦¸à§à¦ªà§‡à¦¸à¦¿à¦«à¦¿à¦•à§‡à¦¶à¦¨**: https://platform.openai.com/docs/api-reference
  - à¦­à¦¾à¦·à¦¾à¦° à¦®à¦¡à§‡à¦² à¦‡à¦¨à§à¦Ÿà¦¿à¦—à§à¦°à§‡à¦¶à¦¨à§‡à¦° à¦œà¦¨à§à¦¯ à¦¸à§à¦Ÿà§à¦¯à¦¾à¦¨à§à¦¡à¦¾à¦°à§à¦¡ API à¦«à¦°à¦®à§à¦¯à¦¾à¦Ÿ

#### à¦¨à¦¿à¦°à¦¾à¦ªà¦¤à§à¦¤à¦¾ à¦à¦¬à¦‚ à¦¸à¦®à§à¦®à¦¤à¦¿
- **NIST AI à¦°à¦¿à¦¸à§à¦• à¦®à§à¦¯à¦¾à¦¨à§‡à¦œà¦®à§‡à¦¨à§à¦Ÿ à¦«à§à¦°à§‡à¦®à¦“à¦¯à¦¼à¦¾à¦°à§à¦•**: https://www.nist.gov/itl/ai-risk

---

**à¦…à¦¸à§à¦¬à§€à¦•à§ƒà¦¤à¦¿**:  
à¦à¦‡ à¦¨à¦¥à¦¿à¦Ÿà¦¿ AI à¦…à¦¨à§à¦¬à¦¾à¦¦ à¦ªà¦°à¦¿à¦·à§‡à¦¬à¦¾ [Co-op Translator](https://github.com/Azure/co-op-translator) à¦¬à§à¦¯à¦¬à¦¹à¦¾à¦° à¦•à¦°à§‡ à¦…à¦¨à§à¦¬à¦¾à¦¦ à¦•à¦°à¦¾ à¦¹à¦¯à¦¼à§‡à¦›à§‡à¥¤ à¦†à¦®à¦°à¦¾ à¦¯à¦¥à¦¾à¦¸à¦¾à¦§à§à¦¯ à¦¸à¦ à¦¿à¦•à¦¤à¦¾à¦° à¦œà¦¨à§à¦¯ à¦šà§‡à¦·à§à¦Ÿà¦¾ à¦•à¦°à¦¿, à¦¤à¦¬à§‡ à¦…à¦¨à§à¦—à§à¦°à¦¹ à¦•à¦°à§‡ à¦®à¦¨à§‡ à¦°à¦¾à¦–à¦¬à§‡à¦¨ à¦¯à§‡ à¦¸à§à¦¬à¦¯à¦¼à¦‚à¦•à§à¦°à¦¿à¦¯à¦¼ à¦…à¦¨à§à¦¬à¦¾à¦¦à§‡ à¦¤à§à¦°à§à¦Ÿà¦¿ à¦¬à¦¾ à¦…à¦¸à¦™à§à¦—à¦¤à¦¿ à¦¥à¦¾à¦•à¦¤à§‡ à¦ªà¦¾à¦°à§‡à¥¤ à¦®à§‚à¦² à¦­à¦¾à¦·à¦¾à¦¯à¦¼ à¦¥à¦¾à¦•à¦¾ à¦¨à¦¥à¦¿à¦Ÿà¦¿à¦•à§‡ à¦ªà§à¦°à¦¾à¦®à¦¾à¦£à¦¿à¦• à¦‰à§Žà¦¸ à¦¹à¦¿à¦¸à§‡à¦¬à§‡ à¦¬à¦¿à¦¬à§‡à¦šà¦¨à¦¾ à¦•à¦°à¦¾ à¦‰à¦šà¦¿à¦¤à¥¤ à¦—à§à¦°à§à¦¤à§à¦¬à¦ªà§‚à¦°à§à¦£ à¦¤à¦¥à§à¦¯à§‡à¦° à¦œà¦¨à§à¦¯, à¦ªà§‡à¦¶à¦¾à¦¦à¦¾à¦° à¦®à¦¾à¦¨à¦¬ à¦…à¦¨à§à¦¬à¦¾à¦¦ à¦¸à§à¦ªà¦¾à¦°à¦¿à¦¶ à¦•à¦°à¦¾ à¦¹à¦¯à¦¼à¥¤ à¦à¦‡ à¦…à¦¨à§à¦¬à¦¾à¦¦ à¦¬à§à¦¯à¦¬à¦¹à¦¾à¦°à§‡à¦° à¦«à¦²à§‡ à¦•à§‹à¦¨à§‹ à¦­à§à¦² à¦¬à§‹à¦à¦¾à¦¬à§à¦à¦¿ à¦¬à¦¾ à¦­à§à¦² à¦¬à§à¦¯à¦¾à¦–à§à¦¯à¦¾ à¦¹à¦²à§‡ à¦†à¦®à¦°à¦¾ à¦¦à¦¾à¦¯à¦¼à¦¬à¦¦à§à¦§ à¦¥à¦¾à¦•à¦¬ à¦¨à¦¾à¥¤