# Section 3: Fine-Tuning - How to Customize Models for Specific Tasks

## Table of Contents
1. [Introduction to Fine-Tuning](../../../Module05)
2. [Why Fine-Tuning Matter](../../../Module05)
3. [Types of Fine-Tuning](../../../Module05)
4. [Fine-Tuning with Microsoft Olive](../../../Module05)
5. [Hands-On Examples](../../../Module05)
6. [Best Practices and Guidelines](../../../Module05)
7. [Advanced Techniques](../../../Module05)
8. [Evaluation and Monitoring](../../../Module05)
9. [Common Challenges and Solutions](../../../Module05)
10. [Conclusion](../../../Module05)

## Introduction to Fine-Tuning

**Fine-tuning** na one strong machine learning method wey dey help adjust pre-trained model so e fit do specific tasks or work with special datasets. Instead of training model from scratch, fine-tuning dey use wetin pre-trained model don already sabi and adjust am for your own use case.

### Wetin be Fine-Tuning?

Fine-tuning na one type of **transfer learning** wey you go:
- Start with pre-trained model wey don sabi general patterns from big datasets
- Adjust the model parameters with your own dataset
- Keep the knowledge wey e don learn but make am specialize for your task

E be like say you dey teach one chef wey sabi cook well how to cook new type of food - e don already sabi cooking basics, but e need learn the new techniques and flavors.

### Key Benefits

- **Time Efficiency**: E fast pass training from scratch
- **Data Efficiency**: E no need plenty data to perform well
- **Cost-Effective**: E no dey use too much computational resources
- **Better Performance**: E dey perform better pass training from scratch
- **Resource Optimization**: E make strong AI dey available for small teams and organizations

## Why Fine-Tuning Matter

### Real-World Applications

Fine-tuning dey important for many situations:

**1. Domain Adaptation**
- Medical AI: Adjust general language models to sabi medical terms and clinical notes
- Legal Tech: Make models sabi legal document analysis and contract review
- Financial Services: Customize models to sabi financial report analysis and risk assessment

**2. Task Specialization**
- Content Generation: Fine-tune models to sabi specific writing styles or tones
- Code Generation: Adjust models to sabi particular programming languages or frameworks
- Translation: Make models perform better for specific language pairs or technical areas

**3. Corporate Applications**
- Customer Service: Build chatbots wey sabi company-specific terms
- Internal Documentation: Create AI assistants wey sabi organizational processes
- Industry-Specific Solutions: Develop models wey sabi sector-specific language and workflows

## Types of Fine-Tuning

### 1. Full Fine-Tuning (Instruction Fine-Tuning)

For full fine-tuning, you go update all model parameters during training. This method:
- Give maximum flexibility and performance potential
- Need plenty computational resources
- Create completely new version of the model
- E good if you get plenty training data and computational resources

### 2. Parameter-Efficient Fine-Tuning (PEFT)

PEFT methods dey update only small part of the parameters, so e dey more efficient:

#### Low-Rank Adaptation (LoRA)
- Add small trainable rank decomposition matrices to existing weights
- Reduce the number of trainable parameters well well
- E still perform close to full fine-tuning
- E make am easy to switch between different adaptations

#### QLoRA (Quantized LoRA)
- Combine LoRA with quantization techniques
- Reduce memory requirements more
- Make e possible to fine-tune bigger models on normal hardware
- Balance efficiency with performance

#### Adapters
- Put small neural networks between existing layers
- Allow targeted fine-tuning while base model dey as e be
- E make am easy to customize model for different tasks

### 3. Task-Specific Fine-Tuning

This one dey focus on adjusting models for specific tasks:
- **Classification**: Adjust models to categorize things
- **Generation**: Optimize models for creating content and text
- **Extraction**: Fine-tune models to extract information and recognize names
- **Summarization**: Make models sabi summarize documents

## Fine-Tuning with Microsoft Olive

Microsoft Olive na one complete model optimization toolkit wey dey make fine-tuning easy and e get enterprise-level features.

### Wetin be Microsoft Olive?

Microsoft Olive na open-source tool wey:
- Make fine-tuning workflows easy for different hardware
- Support popular model architectures like Llama, Phi, Qwen, Gemma
- Fit work for cloud or local deployment
- Work well with Azure ML and other Microsoft AI services
- Support automatic optimization and quantization

### Key Features

- **Hardware-Aware Optimization**: E go optimize models for specific hardware (CPU, GPU, NPU)
- **Multi-Format Support**: E dey work with PyTorch, Hugging Face, and ONNX models
- **Automated Workflows**: E reduce manual setup and trial-and-error
- **Enterprise Integration**: E get built-in support for Azure ML and cloud deployments
- **Extensible Architecture**: You fit add your own optimization techniques

### Installation and Setup

#### Basic Installation

```bash
# Create a virtual environment
python -m venv olive-env
source olive-env/bin/activate  # On Windows: olive-env\Scripts\activate

# Install Olive with auto-optimization features
pip install olive-ai[auto-opt]

# Install additional dependencies
pip install transformers onnxruntime-genai
```

#### Optional Dependencies

```bash
# For CPU optimization
pip install olive-ai[cpu]

# For GPU optimization
pip install olive-ai[gpu]

# For DirectML (Windows)
pip install olive-ai[directml]

# For Azure ML integration
pip install olive-ai[azureml]
```

#### Verify Installation

```bash
# Check Olive CLI is available
olive --help

# Verify installation
python -c "import olive; print('Olive installed successfully')"
```

## Hands-On Examples

### Example 1: Basic Fine-Tuning with Olive CLI

This example go show how to fine-tune small language model for phrase classification:

#### Step 1: Prepare Your Environment

```bash
# Set up the environment
mkdir fine-tuning-project
cd fine-tuning-project

# Download sample data (optional - Olive can fetch data automatically)
huggingface-cli login  # If using private datasets
```

#### Step 2: Fine-Tune the Model

```bash
# Basic fine-tuning command
olive finetune \
  --model_name_or_path meta-llama/Llama-3.2-1B-Instruct \
  --trust_remote_code \
  --output_path models/llama/ft \
  --data_name xxyyzzz/phrase_classification \
  --text_template "<|start_header_id|>user<|end_header_id|>\n{phrase}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n{tone}" \
  --method lora \
  --max_steps 100 \
  --log_level 1
```

#### Step 3: Optimize for Deployment

```bash
# Convert to ONNX format for optimized inference
olive auto-opt \
  --model_name_or_path models/llama/ft/model \
  --adapter_path models/llama/ft/adapter \
  --device cpu \
  --provider CPUExecutionProvider \
  --use_ort_genai \
  --output_path models/llama/onnx \
  --log_level 1
```

### Example 2: Advanced Configuration with Custom Dataset

#### Step 1: Prepare Custom Dataset

Create one JSON file with your training data:

```json
[
  {
    "input": "What is machine learning?",
    "output": "Machine learning is a subset of artificial intelligence that enables computers to learn and improve from experience without being explicitly programmed."
  },
  {
    "input": "Explain neural networks",
    "output": "Neural networks are computing systems inspired by biological neural networks that learn from data through interconnected nodes or neurons."
  }
]
```

#### Step 2: Create Configuration File

```yaml
# olive-config.yaml
model:
  type: PyTorchModel
  config:
    model_path: "microsoft/DialoGPT-medium"
    task: "text-generation"

data_configs:
  - name: "custom_dataset"
    type: "HuggingfaceContainer"
    load_dataset_config:
      data_files: "path/to/your/dataset.json"
      split: "train"
    pre_process_data_config:
      text_template: "User: {input}\nAssistant: {output}"

passes:
  lora:
    type: LoRA
    config:
      r: 16
      lora_alpha: 32
      target_modules: ["c_attn", "c_proj"]
      modules_to_save: ["ln_f", "lm_head"]
```

#### Step 3: Execute Fine-Tuning

```bash
# Run with custom configuration
olive run --config olive-config.yaml --setup
```

### Example 3: QLoRA Fine-Tuning for Memory Efficiency

```bash
# Fine-tune with QLoRA for better memory efficiency
olive finetune \
  --method qlora \
  --model_name_or_path meta-llama/Meta-Llama-3-8B \
  --data_name nampdn-ai/tiny-codes \
  --train_split "train[:4096]" \
  --eval_split "train[4096:4224]" \
  --text_template "### Language: {programming_language} \n### Question: {prompt} \n### Answer: {response}" \
  --per_device_train_batch_size 16 \
  --per_device_eval_batch_size 16 \
  --max_steps 150 \
  --logging_steps 50 \
  --output_path adapters/tiny-codes
```

## Best Practices and Guidelines

### Data Preparation

**1. Data Quality Over Quantity**
- Focus on high-quality, diverse examples instead of plenty bad data
- Make sure data represent your target use case
- Clean and preprocess data well

**2. Data Format and Templates**
- Use consistent format for all training examples
- Create clear input-output templates wey match your use case
- Add correct instruction formatting for instruction-tuned models

**3. Dataset Splitting**
- Keep 10-20% of data for validation
- Make sure train/validation splits get similar distributions
- Use stratified sampling for classification tasks

### Training Configuration

**1. Learning Rate Selection**
- Start with small learning rates (1e-5 to 1e-4) for fine-tuning
- Use learning rate scheduling for better results
- Check loss curves to adjust rates

**2. Batch Size Optimization**
- Balance batch size with available memory
- Use gradient accumulation for bigger effective batch sizes
- Understand how batch size and learning rate dey relate

**3. Training Duration**
- Check validation metrics to avoid overfitting
- Use early stopping if validation performance no dey improve
- Save checkpoints regularly for recovery and analysis

### Model Selection

**1. Base Model Choice**
- Pick models wey don train for similar domains if possible
- Consider model size based on your computational resources
- Check licensing requirements for commercial use

**2. Fine-Tuning Method Selection**
- Use LoRA/QLoRA if resources dey limited
- Choose full fine-tuning if you need maximum performance
- Use adapter-based methods for multiple tasks

### Resource Management

**1. Hardware Optimization**
- Pick hardware wey fit your model size and method
- Use GPU memory well with gradient checkpointing
- Consider cloud solutions for bigger models

**2. Memory Management**
- Use mixed precision training if e dey available
- Implement gradient accumulation for memory constraints
- Monitor GPU memory usage during training

## Advanced Techniques

### Multi-Adapter Training

Train multiple adapters for different tasks while sharing the base model:

```bash
# Train multiple LoRA adapters
olive finetune --method lora --task_name "classification" --output_path adapters/classifier
olive finetune --method lora --task_name "generation" --output_path adapters/generator

# Generate multi-adapter ONNX model
olive generate-adapter \
  --base_model_path models/base \
  --adapter_paths adapters/classifier,adapters/generator \
  --output_path models/multi-adapter
```

### Hyperparameter Optimization

Do systematic hyperparameter tuning:

```yaml
# hyperparameter-search.yaml
search_strategy:
  type: "random"
  num_trials: 20

search_space:
  learning_rate:
    type: "float"
    low: 1e-6
    high: 1e-3
    log: true
  
  lora_r:
    type: "int"
    low: 8
    high: 64
  
  batch_size:
    type: "choice"
    values: [8, 16, 32]
```

### Custom Loss Functions

Create domain-specific loss functions:

```python
# custom_loss.py
import torch
import torch.nn as nn

class CustomContrastiveLoss(nn.Module):
    def __init__(self, margin=1.0):
        super(CustomContrastiveLoss, self).__init__()
        self.margin = margin
        
    def forward(self, output1, output2, label):
        euclidean_distance = nn.functional.pairwise_distance(output1, output2)
        loss_contrastive = torch.mean((1-label) * torch.pow(euclidean_distance, 2) +
                                    (label) * torch.pow(torch.clamp(self.margin - euclidean_distance, min=0.0), 2))
        return loss_contrastive
```

## Evaluation and Monitoring

### Metrics and Evaluation

**1. Standard Metrics**
- **Accuracy**: How correct e dey for classification tasks
- **Perplexity**: Measure of language modeling quality
- **BLEU/ROUGE**: Quality of text generation and summarization
- **F1 Score**: Balance between precision and recall for classification

**2. Domain-Specific Metrics**
- **Task-Specific Benchmarks**: Use benchmarks wey dey your domain
- **Human Evaluation**: Add human assessment for tasks wey no dey straightforward
- **Business Metrics**: Align with business goals

**3. Evaluation Setup**

```python
# evaluation_script.py
from transformers import AutoTokenizer, AutoModelForCausalLM
from datasets import load_dataset
import torch

def evaluate_model(model_path, test_dataset, metric_type="accuracy"):
    """
    Evaluate fine-tuned model performance
    """
    tokenizer = AutoTokenizer.from_pretrained(model_path)
    model = AutoModelForCausalLM.from_pretrained(model_path)
    
    # Evaluation logic here
    results = {}
    
    for example in test_dataset:
        # Process example and calculate metrics
        pass
    
    return results
```

### Monitoring Training Progress

**1. Loss Tracking**
```bash
# Enable detailed logging
olive finetune \
  --logging_steps 10 \
  --eval_steps 50 \
  --save_steps 100 \
  --logging_dir ./logs \
  --report_to tensorboard
```

**2. Validation Monitoring**
- Check validation loss with training loss
- Watch out for overfitting signs (validation loss dey increase while training loss dey reduce)
- Use early stopping based on validation metrics

**3. Resource Monitoring**
- Check GPU/CPU usage
- Track memory usage
- Monitor training speed and throughput

## Common Challenges and Solutions

### Challenge 1: Overfitting

**Symptoms:**
- Training loss dey reduce but validation loss dey increase
- Big gap between training and validation performance
- E no dey perform well for new data

**Solutions:**
```yaml
# Regularization techniques
passes:
  lora:
    type: LoRA
    config:
      r: 16  # Reduce rank to prevent overfitting
      lora_alpha: 16  # Lower alpha value
      lora_dropout: 0.1  # Add dropout
      weight_decay: 0.01  # L2 regularization
```

### Challenge 2: Memory Limitations

**Solutions:**
- Use gradient checkpointing
- Implement gradient accumulation
- Use parameter-efficient methods (LoRA, QLoRA)
- Use model parallelism for big models

```bash
# Memory-efficient training
olive finetune \
  --method qlora \
  --gradient_checkpointing true \
  --per_device_train_batch_size 1 \
  --gradient_accumulation_steps 16
```

### Challenge 3: Slow Training

**Solutions:**
- Optimize data loading pipelines
- Use mixed precision training
- Implement efficient batching strategies
- Try distributed training for big datasets

```yaml
# Performance optimization
training_config:
  fp16: true  # Mixed precision
  dataloader_num_workers: 4
  optim: "adamw_torch"
  lr_scheduler_type: "cosine"
```

### Challenge 4: Poor Performance

**Diagnosis Steps:**
1. Check data quality and formatting
2. Confirm learning rate and training duration
3. Check base model choice
4. Review preprocessing and tokenization

**Solutions:**
- Add more diverse training data
- Adjust learning rate schedule
- Try different base models
- Use data augmentation techniques

## Conclusion

Fine-tuning na strong method wey dey make state-of-the-art AI easy to use. With tools like Microsoft Olive, organizations fit adjust pre-trained models to meet their needs while still optimizing performance and resources.

### Key Takeaways

1. **Choose the Right Approach**: Pick fine-tuning method based on your resources and performance needs
2. **Data Quality Matters**: Use high-quality, representative training data
3. **Monitor and Iterate**: Always check and improve your models
4. **Leverage Tools**: Use tools like Olive to make the process easy
5. **Consider Deployment**: Plan for optimization and deployment from the start

## ➡️ Wetin next?

- [04: Deployment - Production-Ready Model Implementation](./04.SLMOps.Deployment.md)

---

<!-- CO-OP TRANSLATOR DISCLAIMER START -->
**Disclaimer**:  
Dis dokyument don use AI translation service [Co-op Translator](https://github.com/Azure/co-op-translator) do di translation. Even as we dey try make am accurate, abeg sabi say automated translations fit get mistake or no dey correct well. Di original dokyument for im native language na di one wey you go take as di correct source. For important information, e good make professional human translation dey use. We no go fit take blame for any misunderstanding or wrong interpretation wey fit happen because you use dis translation.
<!-- CO-OP TRANSLATOR DISCLAIMER END -->