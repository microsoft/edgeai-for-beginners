# ವಿಭಾಗ 3: ಫೈನ್-ಟ್ಯೂನಿಂಗ್ - ನಿರ್ದಿಷ್ಟ ಕಾರ್ಯಗಳಿಗೆ ಮಾದರಿಗಳನ್ನು ಕಸ್ಟಮೈಸ್ ಮಾಡುವುದು

## ವಿಷಯಗಳ ಪಟ್ಟಿಕೆ
1. [ಫೈನ್-ಟ್ಯೂನಿಂಗ್ ಪರಿಚಯ](../../../Module05)
2. [ಫೈನ್-ಟ್ಯೂನಿಂಗ್ ಮಹತ್ವವೇನು](../../../Module05)
3. [ಫೈನ್-ಟ್ಯೂನಿಂಗ್ ಪ್ರಕಾರಗಳು](../../../Module05)
4. [Microsoft Olive ಮೂಲಕ ಫೈನ್-ಟ್ಯೂನಿಂಗ್](../../../Module05)
5. [ಪ್ರಾಯೋಗಿಕ ಉದಾಹರಣೆಗಳು](../../../Module05)
6. [ಉತ್ತಮ ಅಭ್ಯಾಸಗಳು ಮತ್ತು ಮಾರ್ಗಸೂಚಿಗಳು](../../../Module05)
7. [ಅಧಿಕ ತಂತ್ರಗಳು](../../../Module05)
8. [ಮೌಲ್ಯಮಾಪನ ಮತ್ತು ಮೇಲ್ವಿಚಾರಣೆ](../../../Module05)
9. [ಸಾಮಾನ್ಯ ಸವಾಲುಗಳು ಮತ್ತು ಪರಿಹಾರಗಳು](../../../Module05)
10. [ಸಾರಾಂಶ](../../../Module05)

## ಫೈನ್-ಟ್ಯೂನಿಂಗ್ ಪರಿಚಯ

**ಫೈನ್-ಟ್ಯೂನಿಂಗ್** ಎಂದರೆ ಪೂರ್ವ-ಪ್ರಶಿಕ್ಷಿತ ಮಾದರಿಯನ್ನು ನಿರ್ದಿಷ್ಟ ಕಾರ್ಯಗಳನ್ನು ನಿರ್ವಹಿಸಲು ಅಥವಾ ವಿಶೇಷ ಡೇಟಾಸೆಟ್‌ಗಳೊಂದಿಗೆ ಕೆಲಸ ಮಾಡಲು ಹೊಂದಿಸುವ ಶಕ್ತಿಶಾಲಿ ಯಂತ್ರ ಅಧ್ಯಯನ ತಂತ್ರವಾಗಿದೆ. ಹೊಸದಾಗಿ ಮಾದರಿಯನ್ನು ತರಬೇತಿಗೊಳಿಸುವ ಬದಲು, ಫೈನ್-ಟ್ಯೂನಿಂಗ್ ಪೂರ್ವ-ಪ್ರಶಿಕ್ಷಿತ ಮಾದರಿಯು ಈಗಾಗಲೇ ಕಲಿತ ಜ್ಞಾನವನ್ನು ಬಳಸಿಕೊಂಡು ನಿಮ್ಮ ವಿಶೇಷ ಬಳಕೆಗೆ ಹೊಂದಿಕೊಳ್ಳುತ್ತದೆ.

### ಫೈನ್-ಟ್ಯೂನಿಂಗ್ ಎಂದರೇನು?

ಫೈನ್-ಟ್ಯೂನಿಂಗ್ ಒಂದು **ಟ್ರಾನ್ಸ್‌ಫರ್ ಲರ್ನಿಂಗ್** ರೂಪವಾಗಿದೆ, ಇದರಲ್ಲಿ ನೀವು:
- ದೊಡ್ಡ ಡೇಟಾಸೆಟ್‌ಗಳಿಂದ ಸಾಮಾನ್ಯ ಮಾದರಿಗಳನ್ನು ಕಲಿತ ಪೂರ್ವ-ಪ್ರಶಿಕ್ಷಿತ ಮಾದರಿಯಿಂದ ಪ್ರಾರಂಭಿಸುತ್ತೀರಿ
- ನಿಮ್ಮ ವಿಶೇಷ ಡೇಟಾಸೆಟ್ ಬಳಸಿ ಮಾದರಿಯ ಆಂತರಿಕ ಪರಿಮಾಣಗಳನ್ನು ಹೊಂದಿಸುತ್ತೀರಿ
- ಅಮೂಲ್ಯ ಜ್ಞಾನವನ್ನು ಉಳಿಸಿಕೊಂಡು ನಿಮ್ಮ ಕಾರ್ಯಕ್ಕೆ ಮಾದರಿಯನ್ನು ವಿಶೇಷಗೊಳಿಸುತ್ತೀರಿ

ಇದನ್ನು ನಿಪುಣ ಶೆಫ್ ಹೊಸ ಆಹಾರ ಶೈಲಿಯನ್ನು ಕಲಿಯುವಂತೆ ಭಾವಿಸಬಹುದು - ಅವರು ಅಡುಗೆ ಮೂಲಭೂತಗಳನ್ನು ತಿಳಿದಿದ್ದಾರೆ, ಆದರೆ ಹೊಸ ಶೈಲಿಗೆ ವಿಶೇಷ ತಂತ್ರಗಳು ಮತ್ತು ರುಚಿಗಳನ್ನು ಕಲಿಯಬೇಕಾಗುತ್ತದೆ.

### ಪ್ರಮುಖ ಲಾಭಗಳು

- **ಸಮಯದ ಪರಿಣಾಮಕಾರಿತ್ವ**: ಹೊಸದಾಗಿ ತರಬೇತಿಗೊಳಿಸುವುದಕ್ಕಿಂತ ಬಹಳ ವೇಗವಾಗಿ
- **ಡೇಟಾ ಪರಿಣಾಮಕಾರಿತ್ವ**: ಉತ್ತಮ ಕಾರ್ಯಕ್ಷಮತೆಗಾಗಿ ಕಡಿಮೆ ಡೇಟಾಸೆಟ್ ಅಗತ್ಯ
- **ಖರ್ಚು-ಕಾರ್ಯಕ್ಷಮತೆ**: ಕಡಿಮೆ ಗಣನೀಯ ಸಂಪನ್ಮೂಲ ಅಗತ್ಯ
- **ಉತ್ತಮ ಕಾರ್ಯಕ್ಷಮತೆ**: ಹೊಸದಾಗಿ ತರಬೇತಿಗೊಳಿಸುವುದಕ್ಕಿಂತ ಉತ್ತಮ ಫಲಿತಾಂಶ
- **ಸಂಪನ್ಮೂಲಗಳ ಉತ್ತಮ ಬಳಕೆ**: ಶಕ್ತಿಶಾಲಿ AI ಅನ್ನು ಸಣ್ಣ ತಂಡಗಳು ಮತ್ತು ಸಂಸ್ಥೆಗಳಿಗೂ ಲಭ್ಯವನ್ನಾಗಿಸುತ್ತದೆ

## ಫೈನ್-ಟ್ಯೂನಿಂಗ್ ಮಹತ್ವವೇನು

### ನೈಜ ಜಗತ್ತಿನ ಅನ್ವಯಿಕೆಗಳು

ಫೈನ್-ಟ್ಯೂನಿಂಗ್ ಅನೇಕ ಸಂದರ್ಭಗಳಲ್ಲಿ ಅಗತ್ಯ:

**1. ಡೊಮೇನ್ ಹೊಂದಿಕೆ**
- ವೈದ್ಯಕೀಯ AI: ಸಾಮಾನ್ಯ ಭಾಷಾ ಮಾದರಿಗಳನ್ನು ವೈದ್ಯಕೀಯ ಪದಸಂಪದ ಮತ್ತು ಕ್ಲಿನಿಕಲ್ ನೋಟ್ಗಳಿಗೆ ಹೊಂದಿಸುವುದು
- ಕಾನೂನು ತಂತ್ರಜ್ಞಾನ: ಕಾನೂನು ದಾಖಲೆ ವಿಶ್ಲೇಷಣೆ ಮತ್ತು ಒಪ್ಪಂದ ಪರಿಶೀಲನೆಗೆ ಮಾದರಿಗಳನ್ನು ವಿಶೇಷಗೊಳಿಸುವುದು
- ಹಣಕಾಸು ಸೇವೆಗಳು: ಹಣಕಾಸು ವರದಿ ವಿಶ್ಲೇಷಣೆ ಮತ್ತು ಅಪಾಯ ಮೌಲ್ಯಮಾಪನಕ್ಕೆ ಮಾದರಿಗಳನ್ನು ಕಸ್ಟಮೈಸ್ ಮಾಡುವುದು

**2. ಕಾರ್ಯ ವಿಶೇಷೀಕರಣ**
- ವಿಷಯ ರಚನೆ: ನಿರ್ದಿಷ್ಟ ಬರವಣಿಗೆ ಶೈಲಿಗಳು ಅಥವಾ ಧ್ವನಿಗಳಿಗೆ ಫೈನ್-ಟ್ಯೂನಿಂಗ್
- ಕೋಡ್ ರಚನೆ: ನಿರ್ದಿಷ್ಟ ಪ್ರೋಗ್ರಾಮಿಂಗ್ ಭಾಷೆಗಳು ಅಥವಾ ಫ್ರೇಮ್ವರ್ಕ್‌ಗಳಿಗೆ ಮಾದರಿಗಳನ್ನು ಹೊಂದಿಸುವುದು
- ಅನುವಾದ: ನಿರ್ದಿಷ್ಟ ಭಾಷಾ ಜೋಡಿಗಳು ಅಥವಾ ತಾಂತ್ರಿಕ ಕ್ಷೇತ್ರಗಳಿಗೆ ಕಾರ್ಯಕ್ಷಮತೆ ಸುಧಾರಣೆ

**3. ಕಾರ್ಪೊರೇಟ್ ಅನ್ವಯಿಕೆಗಳು**
- ಗ್ರಾಹಕ ಸೇವೆ: ಕಂಪನಿಯ ವಿಶೇಷ ಪದಸಂಪದವನ್ನು ಅರ್ಥಮಾಡಿಕೊಳ್ಳುವ ಚಾಟ್‌ಬಾಟ್‌ಗಳನ್ನು ರಚಿಸುವುದು
- ಆಂತರಿಕ ದಾಖಲೆ: ಸಂಸ್ಥೆಯ ಪ್ರಕ್ರಿಯೆಗಳಿಗೆ ಪರಿಚಿತ AI ಸಹಾಯಕರನ್ನು ನಿರ್ಮಿಸುವುದು
- ಕೈಗಾರಿಕಾ-ನಿರ್ದಿಷ್ಟ ಪರಿಹಾರಗಳು: ಕ್ಷೇತ್ರ-ನಿರ್ದಿಷ್ಟ ಜಾರ್ಗನ್ ಮತ್ತು ಕಾರ್ಯಪ್ರವಾಹಗಳನ್ನು ಅರ್ಥಮಾಡಿಕೊಳ್ಳುವ ಮಾದರಿಗಳನ್ನು ಅಭಿವೃದ್ಧಿಪಡಿಸುವುದು

## ಫೈನ್-ಟ್ಯೂನಿಂಗ್ ಪ್ರಕಾರಗಳು

### 1. ಸಂಪೂರ್ಣ ಫೈನ್-ಟ್ಯೂನಿಂಗ್ (ನಿರ್ದೇಶನ ಫೈನ್-ಟ್ಯೂನಿಂಗ್)

ಸಂಪೂರ್ಣ ಫೈನ್-ಟ್ಯೂನಿಂಗ್‌ನಲ್ಲಿ, ತರಬೇತಿ ಸಮಯದಲ್ಲಿ ಎಲ್ಲಾ ಮಾದರಿ ಪರಿಮಾಣಗಳನ್ನು ನವೀಕರಿಸಲಾಗುತ್ತದೆ. ಈ ವಿಧಾನ:
- ಗರಿಷ್ಠ ಲವಚಿಕತೆ ಮತ್ತು ಕಾರ್ಯಕ್ಷಮತೆ ಸಾಮರ್ಥ್ಯವನ್ನು ಒದಗಿಸುತ್ತದೆ
- ಮಹತ್ವದ ಗಣನೀಯ ಸಂಪನ್ಮೂಲಗಳನ್ನು ಅಗತ್ಯವಿರುತ್ತದೆ
- ಮಾದರಿಯ ಸಂಪೂರ್ಣ ಹೊಸ ಆವೃತ್ತಿಯನ್ನು ಉತ್ಪಾದಿಸುತ್ತದೆ
- ಸಾಕಷ್ಟು ತರಬೇತಿ ಡೇಟಾ ಮತ್ತು ಗಣನೀಯ ಸಂಪನ್ಮೂಲಗಳಿದ್ದಾಗ ಉತ್ತಮ

### 2. ಪರಿಮಾಣ-ಕಾರ್ಯಕ್ಷಮ ಫೈನ್-ಟ್ಯೂನಿಂಗ್ (PEFT)

PEFT ವಿಧಾನಗಳು ಕೇವಲ ಸಣ್ಣ ಪರಿಮಾಣಗಳ ಗುಂಪನ್ನು ನವೀಕರಿಸುವ ಮೂಲಕ ಪ್ರಕ್ರಿಯೆಯನ್ನು ಹೆಚ್ಚು ಪರಿಣಾಮಕಾರಿಯಾಗಿ ಮಾಡುತ್ತವೆ:

#### ಲೋ-ರ್ಯಾಂಕ್ ಅಡಾಪ್ಟೇಶನ್ (LoRA)
- ಇತ್ತೀಚಿನ ತೂಕಗಳಿಗೆ ಸಣ್ಣ ತರಬೇತಿಗೊಳಿಸುವ ರ್ಯಾಂಕ್ ಡಿಕಂಪೋಜಿಷನ್ ಮ್ಯಾಟ್ರಿಕ್ಸ್‌ಗಳನ್ನು ಸೇರಿಸುತ್ತದೆ
- ತರಬೇತಿಗೊಳಿಸುವ ಪರಿಮಾಣಗಳ ಸಂಖ್ಯೆಯನ್ನು ಬಹಳ ಕಡಿಮೆ ಮಾಡುತ್ತದೆ
- ಸಂಪೂರ್ಣ ಫೈನ್-ಟ್ಯೂನಿಂಗ್‌ಗೆ ಸಮೀಪದ ಕಾರ್ಯಕ್ಷಮತೆಯನ್ನು ಕಾಯ್ದುಕೊಳ್ಳುತ್ತದೆ
- ವಿಭಿನ್ನ ಅಡಾಪ್ಟೇಶನ್‌ಗಳ ನಡುವೆ ಸುಲಭವಾಗಿ ಬದಲಾಯಿಸಲು ಅನುಮತಿಸುತ್ತದೆ

#### QLoRA (ಕ್ವಾಂಟೈಜ್ಡ್ ಲೋ-ರಾ)
- LoRA ಅನ್ನು ಕ್ವಾಂಟೈಜೇಶನ್ ತಂತ್ರಜ್ಞಾನಗಳೊಂದಿಗೆ ಸಂಯೋಜಿಸುತ್ತದೆ
- ಮೆಮೊರಿ ಅಗತ್ಯಗಳನ್ನು ಇನ್ನಷ್ಟು ಕಡಿಮೆ ಮಾಡುತ್ತದೆ
- ಗ್ರಾಹಕ ಹಾರ್ಡ್‌ವೇರ್‌ನಲ್ಲಿ ದೊಡ್ಡ ಮಾದರಿಗಳನ್ನು ಫೈನ್-ಟ್ಯೂನ್ ಮಾಡಲು ಅನುಮತಿಸುತ್ತದೆ
- ಕಾರ್ಯಕ್ಷಮತೆ ಮತ್ತು ಪರಿಣಾಮಕಾರಿತ್ವದ ಸಮತೋಲನ

#### ಅಡಾಪ್ಟರ್‌ಗಳು
- ಇತ್ತೀಚಿನ ಲೇಯರ್‌ಗಳ ನಡುವೆ ಸಣ್ಣ ನ್ಯೂರಲ್ ನೆಟ್‌ವರ್ಕ್‌ಗಳನ್ನು ಸೇರಿಸುತ್ತವೆ
- ಮೂಲ ಮಾದರಿಯನ್ನು ಸ್ಥಿರವಾಗಿರಿಸಿಕೊಂಡು ಗುರಿ ಹೊಂದಿದ ಫೈನ್-ಟ್ಯೂನಿಂಗ್‌ಗೆ ಅವಕಾಶ ನೀಡುತ್ತವೆ
- ಮಾದರಿ ಕಸ್ಟಮೈಜೇಶನ್‌ಗೆ ಮಡ್ಯೂಲರ್ ವಿಧಾನವನ್ನು ಸಕ್ರಿಯಗೊಳಿಸುತ್ತವೆ

### 3. ಕಾರ್ಯ-ನಿರ್ದಿಷ್ಟ ಫೈನ್-ಟ್ಯೂನಿಂಗ್

ನಿರ್ದಿಷ್ಟ ಡೌನ್‌ಸ್ಟ್ರೀಮ್ ಕಾರ್ಯಗಳಿಗೆ ಮಾದರಿಗಳನ್ನು ಹೊಂದಿಸುವುದರ ಮೇಲೆ ಕೇಂದ್ರೀಕರಿಸುತ್ತದೆ:
- **ವರ್ಗೀಕರಣ**: ವರ್ಗೀಕರಣ ಕಾರ್ಯಗಳಿಗೆ ಮಾದರಿಗಳನ್ನು ಹೊಂದಿಸುವುದು
- **ರಚನೆ**: ವಿಷಯ ಸೃಷ್ಟಿ ಮತ್ತು ಪಠ್ಯ ರಚನೆಗಾಗಿ ಆಪ್ಟಿಮೈಸ್ ಮಾಡುವುದು
- **ಎಕ್ಸ್ಟ್ರಾಕ್ಷನ್**: ಮಾಹಿತಿ ಎಕ್ಸ್ಟ್ರಾಕ್ಷನ್ ಮತ್ತು ನಾಮಿತ ಘಟಕ ಗುರುತಿಸುವಿಕೆಗೆ ಫೈನ್-ಟ್ಯೂನಿಂಗ್
- **ಸಾರಾಂಶ**: ದಾಖಲೆ ಸಾರಾಂಶಕ್ಕಾಗಿ ಮಾದರಿಗಳನ್ನು ವಿಶೇಷಗೊಳಿಸುವುದು

## Microsoft Olive ಮೂಲಕ ಫೈನ್-ಟ್ಯೂನಿಂಗ್

Microsoft Olive ಒಂದು ಸಮಗ್ರ ಮಾದರಿ ಆಪ್ಟಿಮೈಜೇಶನ್ ಉಪಕರಣವಾಗಿದೆ, ಇದು ಫೈನ್-ಟ್ಯೂನಿಂಗ್ ಪ್ರಕ್ರಿಯೆಯನ್ನು ಸರಳಗೊಳಿಸುವ ಜೊತೆಗೆ ಎಂಟರ್‌ಪ್ರೈಸ್-ಮಟ್ಟದ ವೈಶಿಷ್ಟ್ಯಗಳನ್ನು ಒದಗಿಸುತ್ತದೆ.

### Microsoft Olive ಎಂದರೇನು?

Microsoft Olive ಒಂದು ಓಪನ್-ಸೋರ್ಸ್ ಮಾದರಿ ಆಪ್ಟಿಮೈಜೇಶನ್ ಉಪಕರಣವಾಗಿದೆ, ಇದು:
- ವಿವಿಧ ಹಾರ್ಡ್‌ವೇರ್ ಗುರಿಗಳಿಗಾಗಿ ಫೈನ್-ಟ್ಯೂನಿಂಗ್ ಕಾರ್ಯಪ್ರವಾಹಗಳನ್ನು ಸರಳಗೊಳಿಸುತ್ತದೆ
- ಜನಪ್ರಿಯ ಮಾದರಿ ವಾಸ್ತುಶಿಲ್ಪಗಳಿಗೆ (Llama, Phi, Qwen, Gemma) ಒಳಗೊಂಡ ಬೆಂಬಲವನ್ನು ಒದಗಿಸುತ್ತದೆ
- ಕ್ಲೌಡ್ ಮತ್ತು ಸ್ಥಳೀಯ ನಿಯೋಜನೆ ಆಯ್ಕೆಗಳನ್ನು ಒದಗಿಸುತ್ತದೆ
- Azure ML ಮತ್ತು ಇತರ Microsoft AI ಸೇವೆಗಳೊಂದಿಗೆ ಸುಗಮವಾಗಿ ಸಂಯೋಜಿಸುತ್ತದೆ
- ಸ್ವಯಂಚಾಲಿತ ಆಪ್ಟಿಮೈಜೇಶನ್ ಮತ್ತು ಕ್ವಾಂಟೈಜೇಶನ್ ಬೆಂಬಲಿಸುತ್ತದೆ

### ಪ್ರಮುಖ ವೈಶಿಷ್ಟ್ಯಗಳು

- **ಹಾರ್ಡ್‌ವೇರ್-ಅವೇರ್ ಆಪ್ಟಿಮೈಜೇಶನ್**: ನಿರ್ದಿಷ್ಟ ಹಾರ್ಡ್‌ವೇರ್ (CPU, GPU, NPU) ಗಾಗಿ ಸ್ವಯಂಚಾಲಿತ ಆಪ್ಟಿಮೈಜೇಶನ್
- **ಬಹು-ಫಾರ್ಮ್ಯಾಟ್ ಬೆಂಬಲ**: PyTorch, Hugging Face, ಮತ್ತು ONNX ಮಾದರಿಗಳೊಂದಿಗೆ ಕೆಲಸ ಮಾಡುತ್ತದೆ
- **ಸ್ವಯಂಚಾಲಿತ ಕಾರ್ಯಪ್ರವಾಹಗಳು**: ಕೈಯಿಂದ ಸಂರಚನೆ ಮತ್ತು ಪ್ರಯೋಗ-ತಪ್ಪು ಕಡಿಮೆ ಮಾಡುತ್ತದೆ
- **ಎಂಟರ್‌ಪ್ರೈಸ್ ಸಂಯೋಜನೆ**: Azure ML ಮತ್ತು ಕ್ಲೌಡ್ ನಿಯೋಜನೆಗಳಿಗೆ ಒಳಗೊಂಡ ಬೆಂಬಲ
- **ವಿಸ್ತರಿಸಬಹುದಾದ ವಾಸ್ತುಶಿಲ್ಪ**: ಕಸ್ಟಮ್ ಆಪ್ಟಿಮೈಜೇಶನ್ ತಂತ್ರಗಳನ್ನು ಅನುಮತಿಸುತ್ತದೆ

### ಸ್ಥಾಪನೆ ಮತ್ತು ಸೆಟ್‌ಅಪ್

#### ಮೂಲ ಸ್ಥಾಪನೆ

```bash
# ವರ್ಚುವಲ್ ಪರಿಸರವನ್ನು ರಚಿಸಿ
python -m venv olive-env
source olive-env/bin/activate  # ವಿಂಡೋಸ್‌ನಲ್ಲಿ: olive-env\Scripts\activate

# ಸ್ವಯಂ-ಆಪ್ಟಿಮೈಜೆಷನ್ ವೈಶಿಷ್ಟ್ಯಗಳೊಂದಿಗೆ Olive ಅನ್ನು ಸ್ಥಾಪಿಸಿ
pip install olive-ai[auto-opt]

# ಹೆಚ್ಚುವರಿ ಅವಲಂಬನೆಗಳನ್ನು ಸ್ಥಾಪಿಸಿ
pip install transformers onnxruntime-genai
```

#### ಐಚ್ಛಿಕ ಅವಲಂಬನೆಗಳು

```bash
# CPU ಗಾಗಿ ಆಪ್ಟಿಮೈಜೆಷನ್
pip install olive-ai[cpu]

# GPU ಗಾಗಿ ಆಪ್ಟಿಮೈಜೆಷನ್
pip install olive-ai[gpu]

# DirectML (ವಿಂಡೋಸ್) ಗಾಗಿ
pip install olive-ai[directml]

# ಅಜೂರ್ ML ಏಕೀಕರಣಕ್ಕಾಗಿ
pip install olive-ai[azureml]
```

#### ಸ್ಥಾಪನೆ ಪರಿಶೀಲನೆ

```bash
# ಒಲಿವ್ CLI ಲಭ್ಯವಿದೆಯೇ ಎಂದು ಪರಿಶೀಲಿಸಿ
olive --help

# ಸ್ಥಾಪನೆಯನ್ನು ಪರಿಶೀಲಿಸಿ
python -c "import olive; print('Olive installed successfully')"
```

## ಪ್ರಾಯೋಗಿಕ ಉದಾಹರಣೆಗಳು

### ಉದಾಹರಣೆ 1: Olive CLI ಮೂಲಕ ಮೂಲ ಫೈನ್-ಟ್ಯೂನಿಂಗ್

ಈ ಉದಾಹರಣೆ ಒಂದು ಸಣ್ಣ ಭಾಷಾ ಮಾದರಿಯನ್ನು ವಾಕ್ಯ ವರ್ಗೀಕರಣಕ್ಕಾಗಿ ಫೈನ್-ಟ್ಯೂನ್ ಮಾಡುವುದನ್ನು ತೋರಿಸುತ್ತದೆ:

#### ಹಂತ 1: ನಿಮ್ಮ ಪರಿಸರವನ್ನು ಸಿದ್ಧಪಡಿಸಿ

```bash
# ಪರಿಸರವನ್ನು ಹೊಂದಿಸಿ
mkdir fine-tuning-project
cd fine-tuning-project

# ಮಾದರಿ ಡೇಟಾವನ್ನು ಡೌನ್‌ಲೋಡ್ ಮಾಡಿ (ಐಚ್ಛಿಕ - ಒಲಿವ್ ಸ್ವಯಂಚಾಲಿತವಾಗಿ ಡೇಟಾವನ್ನು ಪಡೆಯಬಹುದು)
huggingface-cli login  # ಖಾಸಗಿ ಡೇಟಾಸೆಟ್‌ಗಳನ್ನು ಬಳಸುತ್ತಿದ್ದರೆ
```

#### ಹಂತ 2: ಮಾದರಿಯನ್ನು ಫೈನ್-ಟ್ಯೂನ್ ಮಾಡಿ

```bash
# ಮೂಲ ಸೂಕ್ಷ್ಮ-ಸಂಯೋಜನೆ ಆಜ್ಞೆ
olive finetune \
  --model_name_or_path meta-llama/Llama-3.2-1B-Instruct \
  --trust_remote_code \
  --output_path models/llama/ft \
  --data_name xxyyzzz/phrase_classification \
  --text_template "<|start_header_id|>user<|end_header_id|>\n{phrase}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n{tone}" \
  --method lora \
  --max_steps 100 \
  --log_level 1
```

#### ಹಂತ 3: ನಿಯೋಜನೆಗಾಗಿ ಆಪ್ಟಿಮೈಸ್ ಮಾಡಿ

```bash
# ಉತ್ತಮಗೊಳಿಸಿದ ನಿರ್ಣಯಕ್ಕಾಗಿ ONNX ಸ್ವರೂಪಕ್ಕೆ ಪರಿವರ್ತಿಸಿ
olive auto-opt \
  --model_name_or_path models/llama/ft/model \
  --adapter_path models/llama/ft/adapter \
  --device cpu \
  --provider CPUExecutionProvider \
  --use_ort_genai \
  --output_path models/llama/onnx \
  --log_level 1
```

### ಉದಾಹರಣೆ 2: ಕಸ್ಟಮ್ ಡೇಟಾಸೆಟ್ ಮೂಲಕ ಉನ್ನತ ಸಂರಚನೆ

#### ಹಂತ 1: ಕಸ್ಟಮ್ ಡೇಟಾಸೆಟ್ ಸಿದ್ಧಪಡಿಸಿ

ನಿಮ್ಮ ತರಬೇತಿ ಡೇಟಾ ಹೊಂದಿರುವ JSON ಫೈಲ್ ರಚಿಸಿ:

```json
[
  {
    "input": "What is machine learning?",
    "output": "Machine learning is a subset of artificial intelligence that enables computers to learn and improve from experience without being explicitly programmed."
  },
  {
    "input": "Explain neural networks",
    "output": "Neural networks are computing systems inspired by biological neural networks that learn from data through interconnected nodes or neurons."
  }
]
```

#### ಹಂತ 2: ಸಂರಚನಾ ಫೈಲ್ ರಚಿಸಿ

```yaml
# olive-config.yaml
model:
  type: PyTorchModel
  config:
    model_path: "microsoft/DialoGPT-medium"
    task: "text-generation"

data_configs:
  - name: "custom_dataset"
    type: "HuggingfaceContainer"
    load_dataset_config:
      data_files: "path/to/your/dataset.json"
      split: "train"
    pre_process_data_config:
      text_template: "User: {input}\nAssistant: {output}"

passes:
  lora:
    type: LoRA
    config:
      r: 16
      lora_alpha: 32
      target_modules: ["c_attn", "c_proj"]
      modules_to_save: ["ln_f", "lm_head"]
```

#### ಹಂತ 3: ಫೈನ್-ಟ್ಯೂನಿಂಗ್ ಕಾರ್ಯಗತಗೊಳಿಸಿ

```bash
# ಕಸ್ಟಮ್ ಸಂರಚನೆಯೊಂದಿಗೆ ಚಾಲನೆ ಮಾಡಿ
olive run --config olive-config.yaml --setup
```

### ಉದಾಹರಣೆ 3: ಮೆಮೊರಿ ಪರಿಣಾಮಕಾರಿತ್ವಕ್ಕಾಗಿ QLoRA ಫೈನ್-ಟ್ಯೂನಿಂಗ್

```bash
# ಉತ್ತಮ ಮೆಮೊರಿ ಕಾರ್ಯಕ್ಷಮತೆಯಿಗಾಗಿ QLoRA ನೊಂದಿಗೆ ಸೂಕ್ಷ್ಮಸಂಯೋಜನೆ ಮಾಡಿ
olive finetune \
  --method qlora \
  --model_name_or_path meta-llama/Meta-Llama-3-8B \
  --data_name nampdn-ai/tiny-codes \
  --train_split "train[:4096]" \
  --eval_split "train[4096:4224]" \
  --text_template "### Language: {programming_language} \n### Question: {prompt} \n### Answer: {response}" \
  --per_device_train_batch_size 16 \
  --per_device_eval_batch_size 16 \
  --max_steps 150 \
  --logging_steps 50 \
  --output_path adapters/tiny-codes
```

## ಉತ್ತಮ ಅಭ್ಯಾಸಗಳು ಮತ್ತು ಮಾರ್ಗಸೂಚಿಗಳು

### ಡೇಟಾ ಸಿದ್ಧತೆ

**1. ಪ್ರಮಾಣಕ್ಕಿಂತ ಗುಣಮಟ್ಟ ಮುಖ್ಯ**
- ಕಡಿಮೆ ಗುಣಮಟ್ಟದ ದೊಡ್ಡ ಪ್ರಮಾಣದ ಡೇಟಾ ಬದಲು ಉನ್ನತ ಗುಣಮಟ್ಟದ, ವೈವಿಧ್ಯಮಯ ಉದಾಹರಣೆಗಳನ್ನು ಪ್ರಾಥಮ್ಯ ನೀಡಿ
- ನಿಮ್ಮ ಗುರಿ ಬಳಕೆಯ ಪ್ರತಿನಿಧಿತ್ವವನ್ನು ಡೇಟಾ ಹೊಂದಿರಲಿ
- ಡೇಟಾವನ್ನು ನಿರಂತರವಾಗಿ ಸ್ವಚ್ಛಗೊಳಿಸಿ ಮತ್ತು ಪೂರ್ವಸಿದ್ಧಗೊಳಿಸಿ

**2. ಡೇಟಾ ಫಾರ್ಮ್ಯಾಟ್ ಮತ್ತು ಟೆಂಪ್ಲೇಟುಗಳು**
- ಎಲ್ಲಾ ತರಬೇತಿ ಉದಾಹರಣೆಗಳಲ್ಲಿ ಸुसಂಗತ ಫಾರ್ಮ್ಯಾಟ್ ಬಳಸಿ
- ನಿಮ್ಮ ಬಳಕೆಗೆ ಹೊಂದುವ ಸ್ಪಷ್ಟ ಇನ್‌ಪುಟ್-ಔಟ್‌ಪುಟ್ ಟೆಂಪ್ಲೇಟುಗಳನ್ನು ರಚಿಸಿ
- ನಿರ್ದೇಶನ-ಟ್ಯೂನ್ ಮಾಡಲಾದ ಮಾದರಿಗಳಿಗೆ ಸೂಕ್ತ ನಿರ್ದೇಶನ ಫಾರ್ಮ್ಯಾಟ್ ಸೇರಿಸಿ

**3. ಡೇಟಾಸೆಟ್ ವಿಭಜನೆ**
- ಮಾನ್ಯತೆಗಾಗಿ 10-20% ಡೇಟಾವನ್ನು ಮೀಸಲಿಡಿ
- ತರಬೇತಿ/ಮಾನ್ಯತೆ ವಿಭಜನೆಗಳಲ್ಲಿ ಸಮಾನ ವಿತರಣೆಯನ್ನು ಕಾಯ್ದುಕೊಳ್ಳಿ
- ವರ್ಗೀಕರಣ ಕಾರ್ಯಗಳಿಗೆ ವರ್ಗೀಕೃತ ಮಾದರಿಯನ್ನು ಪರಿಗಣಿಸಿ

### ತರಬೇತಿ ಸಂರಚನೆ

**1. ಕಲಿಕೆ ದರ ಆಯ್ಕೆ**
- ಫೈನ್-ಟ್ಯೂನಿಂಗ್‌ಗೆ ಸಣ್ಣ ಕಲಿಕೆ ದರಗಳಿಂದ (1e-5 ರಿಂದ 1e-4) ಪ್ರಾರಂಭಿಸಿ
- ಉತ್ತಮ ಸಂಯೋಜನೆಗಾಗಿ ಕಲಿಕೆ ದರ ಶೆಡ್ಯೂಲಿಂಗ್ ಬಳಸಿ
- ನಷ್ಟ ವಕ್ರಗಳನ್ನು ಗಮನಿಸಿ ದರಗಳನ್ನು ಹೊಂದಿಸಿ

**2. ಬ್ಯಾಚ್ ಗಾತ್ರ ಆಪ್ಟಿಮೈಜೆಷನ್**
- ಲಭ್ಯವಿರುವ ಮೆಮೊರಿಯೊಂದಿಗೆ ಬ್ಯಾಚ್ ಗಾತ್ರವನ್ನು ಸಮತೋಲಿಸಿ
- ದೊಡ್ಡ ಪರಿಣಾಮಕಾರಿ ಬ್ಯಾಚ್ ಗಾತ್ರಗಳಿಗೆ ಗ್ರೇಡಿಯಂಟ್ ಸಂಗ್ರಹಣೆಯನ್ನು ಬಳಸಿ
- ಬ್ಯಾಚ್ ಗಾತ್ರ ಮತ್ತು ಕಲಿಕೆ ದರದ ಸಂಬಂಧವನ್ನು ಪರಿಗಣಿಸಿ

**3. ತರಬೇತಿ ಅವಧಿ**
- ಮಿತಿಮೀರದ ತರಬೇತಿಯನ್ನು ತಪ್ಪಿಸಲು ಮಾನ್ಯತೆ ಮೆಟ್ರಿಕ್‌ಗಳನ್ನು ಗಮನಿಸಿ
- ಮಾನ್ಯತೆ ಕಾರ್ಯಕ್ಷಮತೆ ಸ್ಥಗಿತವಾಗುವಾಗ ಮುಂಚಿತ ನಿಲ್ಲಿಸುವಿಕೆ ಬಳಸಿ
- ಪುನಃಪ್ರಾಪ್ತಿಗೆ ಮತ್ತು ವಿಶ್ಲೇಷಣೆಗೆ ನಿಯಮಿತವಾಗಿ ಚೆಕ್‌ಪಾಯಿಂಟ್‌ಗಳನ್ನು ಉಳಿಸಿ

### ಮಾದರಿ ಆಯ್ಕೆ

**1. ಮೂಲ ಮಾದರಿ ಆಯ್ಕೆ**
- ಸಾಧ್ಯವಾದರೆ ಸಮಾನ ಡೊಮೇನ್‌ಗಳಲ್ಲಿ ಪೂರ್ವ-ಪ್ರಶಿಕ್ಷಿತ ಮಾದರಿಗಳನ್ನು ಆಯ್ಕೆಮಾಡಿ
- ನಿಮ್ಮ ಗಣನೀಯ ನಿರ್ಬಂಧಗಳಿಗೆ ಅನುಗುಣವಾಗಿ ಮಾದರಿ ಗಾತ್ರವನ್ನು ಪರಿಗಣಿಸಿ
- ವಾಣಿಜ್ಯ ಬಳಕೆಗೆ ಪರವಾನಗಿ ಅಗತ್ಯಗಳನ್ನು ಪರಿಶೀಲಿಸಿ

**2. ಫೈನ್-ಟ್ಯೂನಿಂಗ್ ವಿಧಾನ ಆಯ್ಕೆ**
- ಸಂಪನ್ಮೂಲ-ನಿರ್ಬಂಧಿತ ಪರಿಸರಗಳಿಗೆ LoRA/QLoRA ಬಳಸಿ
- ಗರಿಷ್ಠ ಕಾರ್ಯಕ್ಷಮತೆ ಅಗತ್ಯವಿದ್ದಾಗ ಸಂಪೂರ್ಣ ಫೈನ್-ಟ್ಯೂನಿಂಗ್ ಆಯ್ಕೆಮಾಡಿ
- ಬಹು ಕಾರ್ಯ ಸಂದರ್ಭಗಳಿಗೆ ಅಡಾಪ್ಟರ್ ಆಧಾರಿತ ವಿಧಾನಗಳನ್ನು ಪರಿಗಣಿಸಿ

### ಸಂಪನ್ಮೂಲ ನಿರ್ವಹಣೆ

**1. ಹಾರ್ಡ್‌ವೇರ್ ಆಪ್ಟಿಮೈಜೇಶನ್**
- ನಿಮ್ಮ ಮಾದರಿ ಗಾತ್ರ ಮತ್ತು ವಿಧಾನಕ್ಕೆ ಸೂಕ್ತ ಹಾರ್ಡ್‌ವೇರ್ ಆಯ್ಕೆಮಾಡಿ
- ಗ್ರೇಡಿಯಂಟ್ ಚೆಕ್‌ಪಾಯಿಂಟಿಂಗ್ ಮೂಲಕ GPU ಮೆಮೊರಿಯನ್ನು ಪರಿಣಾಮಕಾರಿಯಾಗಿ ಬಳಸಿ
- ದೊಡ್ಡ ಮಾದರಿಗಳಿಗೆ ಕ್ಲೌಡ್ ಆಧಾರಿತ ಪರಿಹಾರಗಳನ್ನು ಪರಿಗಣಿಸಿ

**2. ಮೆಮೊರಿ ನಿರ್ವಹಣೆ**
- ಲಭ್ಯವಿದ್ದರೆ ಮಿಶ್ರಿತ ಪ್ರಿಸಿಷನ್ ತರಬೇತಿಯನ್ನು ಬಳಸಿ
- ಮೆಮೊರಿ ನಿರ್ಬಂಧಗಳಿಗೆ ಗ್ರೇಡಿಯಂಟ್ ಸಂಗ್ರಹಣೆಯನ್ನು ಅನುಷ್ಠಾನಗೊಳಿಸಿ
- ತರಬೇತಿ ಸಮಯದಲ್ಲಿ GPU ಮೆಮೊರಿ ಬಳಕೆಯನ್ನು ಗಮನಿಸಿ

## ಅಧಿಕ ತಂತ್ರಗಳು

### ಬಹು-ಅಡಾಪ್ಟರ್ ತರಬೇತಿ

ಮೂಲ ಮಾದರಿಯನ್ನು ಹಂಚಿಕೊಂಡು ವಿಭಿನ್ನ ಕಾರ್ಯಗಳಿಗೆ ಅನೇಕ ಅಡಾಪ್ಟರ್‌ಗಳನ್ನು ತರಬೇತಿಗೊಳಿಸಿ:

```bash
# ಹಲವಾರು LoRA ಅಡಾಪ್ಟರ್‌ಗಳನ್ನು ತರಬೇತಿ ಮಾಡಿ
olive finetune --method lora --task_name "classification" --output_path adapters/classifier
olive finetune --method lora --task_name "generation" --output_path adapters/generator

# ಬಹು-ಅಡಾಪ್ಟರ್ ONNX ಮಾದರಿಯನ್ನು ರಚಿಸಿ
olive generate-adapter \
  --base_model_path models/base \
  --adapter_paths adapters/classifier,adapters/generator \
  --output_path models/multi-adapter
```

### ಹೈಪರ್‌ಪ್ಯಾರಾಮೀಟರ್ ಆಪ್ಟಿಮೈಜೇಶನ್

ವ್ಯವಸ್ಥಿತ ಹೈಪರ್‌ಪ್ಯಾರಾಮೀಟರ್ ಟ್ಯೂನಿಂಗ್ ಅನ್ನು ಅನುಷ್ಠಾನಗೊಳಿಸಿ:

```yaml
# hyperparameter-search.yaml
search_strategy:
  type: "random"
  num_trials: 20

search_space:
  learning_rate:
    type: "float"
    low: 1e-6
    high: 1e-3
    log: true
  
  lora_r:
    type: "int"
    low: 8
    high: 64
  
  batch_size:
    type: "choice"
    values: [8, 16, 32]
```

### ಕಸ್ಟಮ್ ನಷ್ಟ ಕಾರ್ಯಗಳು

ಡೊಮೇನ್-ನಿರ್ದಿಷ್ಟ ನಷ್ಟ ಕಾರ್ಯಗಳನ್ನು ಅನುಷ್ಠಾನಗೊಳಿಸಿ:

```python
# ಕಸ್ಟಮ್_ಲಾಸ್.py
import torch
import torch.nn as nn

class CustomContrastiveLoss(nn.Module):
    def __init__(self, margin=1.0):
        super(CustomContrastiveLoss, self).__init__()
        self.margin = margin
        
    def forward(self, output1, output2, label):
        euclidean_distance = nn.functional.pairwise_distance(output1, output2)
        loss_contrastive = torch.mean((1-label) * torch.pow(euclidean_distance, 2) +
                                    (label) * torch.pow(torch.clamp(self.margin - euclidean_distance, min=0.0), 2))
        return loss_contrastive
```

## ಮೌಲ್ಯಮಾಪನ ಮತ್ತು ಮೇಲ್ವಿಚಾರಣೆ

### ಮೆಟ್ರಿಕ್‌ಗಳು ಮತ್ತು ಮೌಲ್ಯಮಾಪನ

**1. ಮಾನಕ ಮೆಟ್ರಿಕ್‌ಗಳು**
- **ನಿಖರತೆ**: ವರ್ಗೀಕರಣ ಕಾರ್ಯಗಳ ಒಟ್ಟು ಸರಿಯಾದ ಪ್ರಮಾಣ
- **ಪರ್ಪ್ಲೆಕ್ಸಿಟಿ**: ಭಾಷಾ ಮಾದರೀಕರಣ ಗುಣಮಟ್ಟದ ಅಳೆಯುವಿಕೆ
- **BLEU/ROUGE**: ಪಠ್ಯ ರಚನೆ ಮತ್ತು ಸಾರಾಂಶ ಗುಣಮಟ್ಟ
- **F1 ಸ್ಕೋರ್**: ವರ್ಗೀಕರಣಕ್ಕೆ ಸಮತೋಲಿತ ಪ್ರಿಸಿಷನ್ ಮತ್ತು ರಿಕಾಲ್

**2. ಡೊಮೇನ್-ನಿರ್ದಿಷ್ಟ ಮೆಟ್ರಿಕ್‌ಗಳು**
- **ಕಾರ್ಯ-ನಿರ್ದಿಷ್ಟ ಬೆಂಚ್‌ಮಾರ್ಕ್‌ಗಳು**: ನಿಮ್ಮ ಡೊಮೇನ್ಗೆ ಸ್ಥಾಪಿತ ಬೆಂಚ್‌ಮಾರ್ಕ್‌ಗಳನ್ನು ಬಳಸಿ
- **ಮಾನವ ಮೌಲ್ಯಮಾಪನ**: ವಿಷಯಾತ್ಮಕ ಕಾರ್ಯಗಳಿಗೆ ಮಾನವ ಮೌಲ್ಯಮಾಪನ ಸೇರಿಸಿ
- **ವ್ಯವಹಾರ ಮೆಟ್ರಿಕ್‌ಗಳು**: ನಿಜವಾದ ವ್ಯವಹಾರ ಗುರಿಗಳೊಂದಿಗೆ ಹೊಂದಿಸಿ

**3. ಮೌಲ್ಯಮಾಪನ ಸಂರಚನೆ**

```python
# evaluation_script.py
from transformers import AutoTokenizer, AutoModelForCausalLM
from datasets import load_dataset
import torch

def evaluate_model(model_path, test_dataset, metric_type="accuracy"):
    """
    Evaluate fine-tuned model performance
    """
    tokenizer = AutoTokenizer.from_pretrained(model_path)
    model = AutoModelForCausalLM.from_pretrained(model_path)
    
    # ಮೌಲ್ಯಮಾಪನ ತರ್ಕ ಇಲ್ಲಿ
    results = {}
    
    for example in test_dataset:
        # ಉದಾಹರಣೆಯನ್ನು ಪ್ರಕ್ರಿಯೆ ಮಾಡಿ ಮತ್ತು ಅಳತೆಗಳನ್ನು ಲೆಕ್ಕಿಸಿ
        pass
    
    return results
```

### ತರಬೇತಿ ಪ್ರಗತಿಯನ್ನು ಮೇಲ್ವಿಚಾರಣೆ

**1. ನಷ್ಟ ಟ್ರ್ಯಾಕಿಂಗ್**
```bash
# ವಿವರವಾದ ಲಾಗಿಂಗ್ ಅನ್ನು ಸಕ್ರಿಯಗೊಳಿಸಿ
olive finetune \
  --logging_steps 10 \
  --eval_steps 50 \
  --save_steps 100 \
  --logging_dir ./logs \
  --report_to tensorboard
```

**2. ಮಾನ್ಯತೆ ಮೇಲ್ವಿಚಾರಣೆ**
- ತರಬೇತಿ ನಷ್ಟದ ಜೊತೆಗೆ ಮಾನ್ಯತೆ ನಷ್ಟವನ್ನು ಟ್ರ್ಯಾಕ್ ಮಾಡಿ
- ಮಿತಿಮೀರಿದ ತರಬೇತಿಗೆ ಸೂಚನೆಗಳಿಗಾಗಿ ಗಮನಿಸಿ (ಮಾನ್ಯತೆ ನಷ್ಟ ಹೆಚ್ಚಾಗುತ್ತಿದ್ದು, ತರಬೇತಿ ನಷ್ಟ ಕಡಿಮೆಯಾಗುತ್ತಿದೆ)
- ಮಾನ್ಯತೆ ಮೆಟ್ರಿಕ್‌ಗಳ ಆಧಾರದ ಮೇಲೆ ಮುಂಚಿತ ನಿಲ್ಲಿಸುವಿಕೆ ಬಳಸಿ

**3. ಸಂಪನ್ಮೂಲ ಮೇಲ್ವಿಚಾರಣೆ**
- GPU/CPU ಬಳಕೆಯನ್ನು ಮೇಲ್ವಿಚಾರಣೆ ಮಾಡಿ
- ಮೆಮೊರಿ ಬಳಕೆ ಮಾದರಿಗಳನ್ನು ಟ್ರ್ಯಾಕ್ ಮಾಡಿ
- ತರಬೇತಿ ವೇಗ ಮತ್ತು ಥ್ರೂಪುಟ್ ಅನ್ನು ಗಮನಿಸಿ

## ಸಾಮಾನ್ಯ ಸವಾಲುಗಳು ಮತ್ತು ಪರಿಹಾರಗಳು

### ಸವಾಲು 1: ಮಿತಿಮೀರಿದ ತರಬೇತಿ

**ಲಕ್ಷಣಗಳು:**
- ತರಬೇತಿ ನಷ್ಟ ಕಡಿಮೆಯಾಗುತ್ತಿದ್ದು, ಮಾನ್ಯತೆ ನಷ್ಟ ಹೆಚ್ಚಾಗುತ್ತಿದೆ
- ತರಬೇತಿ ಮತ್ತು ಮಾನ್ಯತೆ ಕಾರ್ಯಕ್ಷಮತೆಯ ನಡುವೆ ದೊಡ್ಡ ವ್ಯತ್ಯಾಸ
- ಹೊಸ ಡೇಟಾಗೆ ಕೆಟ್ಟ ಸಾಮಾನ್ಯೀಕರಣ

**ಪರಿಹಾರಗಳು:**
```yaml
# Regularization techniques
passes:
  lora:
    type: LoRA
    config:
      r: 16  # Reduce rank to prevent overfitting
      lora_alpha: 16  # Lower alpha value
      lora_dropout: 0.1  # Add dropout
      weight_decay: 0.01  # L2 regularization
```

### ಸವಾಲು 2: ಮೆಮೊರಿ ಮಿತಿಗಳು

**ಪರಿಹಾರಗಳು:**
- ಗ್ರೇಡಿಯಂಟ್ ಚೆಕ್‌ಪಾಯಿಂಟಿಂಗ್ ಬಳಸಿ
- ಗ್ರೇಡಿಯಂಟ್ ಸಂಗ್ರಹಣೆ ಅನುಷ್ಠಾನಗೊಳಿಸಿ
- ಪರಿಮಾಣ-ಕಾರ್ಯಕ್ಷಮ ವಿಧಾನಗಳನ್ನು (LoRA, QLoRA) ಆಯ್ಕೆಮಾಡಿ
- ದೊಡ್ಡ ಮಾದರಿಗಳಿಗೆ ಮಾದರಿ ಪ್ಯಾರಲಲಿಸಂ ಬಳಸಿ

```bash
# ಮೆಮೊರಿ-ಕಾರ್ಯಕ್ಷಮ ತರಬೇತಿ
olive finetune \
  --method qlora \
  --gradient_checkpointing true \
  --per_device_train_batch_size 1 \
  --gradient_accumulation_steps 16
```

### ಸವಾಲು 3: ನಿಧಾನ ತರಬೇತಿ

**ಪರಿಹಾರಗಳು:**
- ಡೇಟಾ ಲೋಡಿಂಗ್ ಪೈಪ್‌ಲೈನ್‌ಗಳನ್ನು ಆಪ್ಟಿಮೈಸ್ ಮಾಡಿ
- ಮಿಶ್ರಿತ ಪ್ರಿಸಿಷನ್ ತರಬೇತಿಯನ್ನು ಬಳಸಿ
- ಪರಿಣಾಮಕಾರಿ ಬ್ಯಾಚಿಂಗ್ ತಂತ್ರಗಳನ್ನು ಅನುಷ್ಠಾನಗೊಳಿಸಿ
- ದೊಡ್ಡ ಡೇಟಾಸೆಟ್‌ಗಳಿಗೆ ವಿತರಿತ ತರಬೇತಿಯನ್ನು ಪರಿಗಣಿಸಿ

```yaml
# Performance optimization
training_config:
  fp16: true  # Mixed precision
  dataloader_num_workers: 4
  optim: "adamw_torch"
  lr_scheduler_type: "cosine"
```

### ಸವಾಲು 4: ಕೆಟ್ಟ ಕಾರ್ಯಕ್ಷಮತೆ

**ರೋಗನಿರ್ಣಯ ಹಂತಗಳು:**
1. ಡೇಟಾ ಗುಣಮಟ್ಟ ಮತ್ತು ಫಾರ್ಮ್ಯಾಟ್ ಪರಿಶೀಲಿಸಿ
2. ಕಲಿಕೆ ದರ ಮತ್ತು ತರಬೇತಿ ಅವಧಿ ಪರಿಶೀಲಿಸಿ
3. ಮೂಲ ಮಾದರಿ ಆಯ್ಕೆಮಾಡಿ
4. ಪೂರ್ವಸಿದ್ಧತೆ ಮತ್ತು ಟೋಕನೈಜೆಷನ್ ಪರಿಶೀಲಿಸಿ

**ಪರಿಹಾರಗಳು:**
- ತರಬೇತಿ ಡೇಟಾ ವೈವಿಧ್ಯತೆಯನ್ನು ಹೆಚ್ಚಿಸಿ
- ಕಲಿಕೆ ದರ ಶೆಡ್ಯೂಲ್ ಹೊಂದಿಸಿ
- ವಿಭಿನ್ನ ಮೂಲ ಮಾದರಿಗಳನ್ನು ಪ್ರಯತ್ನಿಸಿ
- ಡೇಟಾ ವೃದ್ಧಿ ತಂತ್ರಗಳನ್ನು ಅನುಷ್ಠಾನಗೊಳಿಸಿ

## ಸಾರಾಂಶ

ಫೈನ್-ಟ್ಯೂನಿಂಗ್ ಒಂದು ಶಕ್ತಿಶಾಲಿ ತಂತ್ರವಾಗಿದೆ, ಇದು ಅತ್ಯಾಧುನಿಕ AI ಸಾಮರ್ಥ್ಯಗಳಿಗೆ ಪ್ರಾಪ್ತಿಯನ್ನು ಜನಸಾಮಾನ್ಯಗೊಳಿಸುತ್ತದೆ. Microsoft Olive ಮುಂತಾದ ಉಪಕರಣಗಳನ್ನು ಬಳಸಿಕೊಂಡು, ಸಂಸ್ಥೆಗಳು ಪೂರ್ವ-ಪ್ರಶಿಕ್ಷಿತ ಮಾದರಿಗಳನ್ನು ತಮ್ಮ ನಿರ್ದಿಷ್ಟ ಅಗತ್ಯಗಳಿಗೆ ಪರಿಣಾಮಕಾರಿಯಾಗಿ ಹೊಂದಿಸಬಹುದು ಮತ್ತು ಕಾರ್ಯಕ್ಷಮತೆ ಮತ್ತು ಸಂಪನ್ಮೂಲ ನಿರ್ಬಂಧಗಳಿಗೆ ಅನುಗುಣವಾಗಿ ಆಪ್ಟಿಮೈಸ್ ಮಾಡಬಹುದು.

### ಪ್ರಮುಖ ಅಂಶಗಳು

1. **ಸರಿಯಾದ ವಿಧಾನ ಆಯ್ಕೆಮಾಡಿ**: ನಿಮ್ಮ ಗಣನೀಯ ಸಂಪನ್ಮೂಲಗಳು ಮತ್ತು ಕಾರ್ಯಕ್ಷಮತೆ ಅಗತ್ಯಗಳ ಆಧಾರದ ಮೇಲೆ ಫೈನ್-ಟ್ಯೂನಿಂಗ್ ವಿಧಾನಗಳನ್ನು ಆಯ್ಕೆಮಾಡಿ
2. **ಡೇಟಾ ಗುಣಮಟ್ಟ ಮುಖ್ಯ**: ಉನ್ನತ ಗುಣಮಟ್ಟದ, ಪ್ರತಿನಿಧಿತ್ವದ ತರಬೇತಿ ಡೇಟಾದಲ್ಲಿ ಹೂಡಿಕೆ ಮಾಡಿ
3. **ಮೌಲ್ಯಮಾಪನ ಮತ್ತು ಪುನರಾವರ್ತನೆ**: ನಿಮ್ಮ ಮಾದರಿಗಳನ್ನು ನಿರಂತರವಾಗಿ ಮೌಲ್ಯಮಾಪನ ಮಾಡಿ ಮತ್ತು ಸುಧಾರಿಸಿ
4. **ಉಪಕರಣಗಳನ್ನು ಬಳಸಿಕೊಳ್ಳಿ**: ಪ್ರಕ್ರಿಯೆಯನ್ನು ಸರಳಗೊಳಿಸಲು ಮತ್ತು ಆಪ್ಟಿಮೈಸ್ ಮಾಡಲು Olive ಮುಂತಾದ ಫ್ರೇಮ್ವರ್ಕ್‌ಗಳನ್ನು ಬಳಸಿ
5. **ನಿಯೋಜನೆ ಪರಿಗಣಿಸಿ**: ಆರಂಭದಿಂದಲೇ ಮಾದರಿ ಆಪ್ಟಿಮೈಜೇಶನ್ ಮತ್ತು ನಿಯೋಜನೆಗಾಗಿ ಯೋಜನೆ ರೂಪಿಸಿ


## ➡️ ಮುಂದೇನು

- [04: ನಿಯೋಜನೆ - ಉತ್ಪಾದನೆ-ಸಿದ್ಧ ಮಾದರಿ ಅನುಷ್ಠಾನ](./04.SLMOps.Deployment.md)

---

<!-- CO-OP TRANSLATOR DISCLAIMER START -->
**ಅಸ್ವೀಕರಣ**:  
ಈ ದಸ್ತಾವೇಜು AI ಅನುವಾದ ಸೇವೆ [Co-op Translator](https://github.com/Azure/co-op-translator) ಬಳಸಿ ಅನುವಾದಿಸಲಾಗಿದೆ. ನಾವು ನಿಖರತೆಯಿಗಾಗಿ ಪ್ರಯತ್ನಿಸುತ್ತಿದ್ದರೂ, ಸ್ವಯಂಚಾಲಿತ ಅನುವಾದಗಳಲ್ಲಿ ದೋಷಗಳು ಅಥವಾ ತಪ್ಪುಗಳು ಇರಬಹುದು ಎಂದು ದಯವಿಟ್ಟು ಗಮನಿಸಿ. ಮೂಲ ಭಾಷೆಯಲ್ಲಿರುವ ಮೂಲ ದಸ್ತಾವೇಜನ್ನು ಅಧಿಕೃತ ಮೂಲವೆಂದು ಪರಿಗಣಿಸಬೇಕು. ಪ್ರಮುಖ ಮಾಹಿತಿಗಾಗಿ, ವೃತ್ತಿಪರ ಮಾನವ ಅನುವಾದವನ್ನು ಶಿಫಾರಸು ಮಾಡಲಾಗುತ್ತದೆ. ಈ ಅನುವಾದ ಬಳಕೆಯಿಂದ ಉಂಟಾಗುವ ಯಾವುದೇ ತಪ್ಪು ಅರ್ಥಮಾಡಿಕೊಳ್ಳುವಿಕೆ ಅಥವಾ ತಪ್ಪು ವಿವರಣೆಗಳಿಗೆ ನಾವು ಹೊಣೆಗಾರರಾಗುವುದಿಲ್ಲ.
<!-- CO-OP TRANSLATOR DISCLAIMER END -->