# ವಿಭಾಗ 2: ಮಾದರಿ ಡಿಸ್ಟಿಲೇಶನ್ - ಸಿದ್ಧಾಂತದಿಂದ ಅಭ್ಯಾಸಕ್ಕೆ

## ವಿಷಯಗಳ ಪಟ್ಟಿಯು
1. [ಮಾದರಿ ಡಿಸ್ಟಿಲೇಶನ್ ಪರಿಚಯ](../../../Module05)
2. [ಡಿಸ್ಟಿಲೇಶನ್ ಮಹತ್ವವೇನು](../../../Module05)
3. [ಡಿಸ್ಟಿಲೇಶನ್ ಪ್ರಕ್ರಿಯೆ](../../../Module05)
4. [ಪ್ರಾಯೋಗಿಕ ಅನುಷ್ಠಾನ](../../../Module05)
5. [ಅಜೂರ್ ಎಂಎಲ್ ಡಿಸ್ಟಿಲೇಶನ್ ಉದಾಹರಣೆ](../../../Module05)
6. [ಉತ್ತಮ ಅಭ್ಯಾಸಗಳು ಮತ್ತು ಆಪ್ಟಿಮೈಜೆಷನ್](../../../Module05)
7. [ವಾಸ್ತವಿಕ ಜಗತ್ತಿನ ಅನ್ವಯಿಕೆಗಳು](../../../Module05)
8. [ನಿರ್ಣಯ](../../../Module05)

## ಮಾದರಿ ಡಿಸ್ಟಿಲೇಶನ್ ಪರಿಚಯ {#introduction}

ಮಾದರಿ ಡಿಸ್ಟಿಲೇಶನ್ ಒಂದು ಶಕ್ತಿಶಾಲಿ ತಂತ್ರಜ್ಞಾನವಾಗಿದ್ದು, ದೊಡ್ಡ ಮತ್ತು ಸಂಕೀರ್ಣ ಮಾದರಿಗಳ ಕಾರ್ಯಕ್ಷಮತೆಯನ್ನು ಉಳಿಸಿಕೊಂಡು, ಚಿಕ್ಕ ಮತ್ತು ಹೆಚ್ಚು ಪರಿಣಾಮಕಾರಿ ಮಾದರಿಗಳನ್ನು ರಚಿಸಲು ಸಹಾಯ ಮಾಡುತ್ತದೆ. ಈ ಪ್ರಕ್ರಿಯೆಯಲ್ಲಿ, ದೊಡ್ಡ "ಶಿಕ್ಷಕ" ಮಾದರಿಯ ವರ್ತನೆಯನ್ನು ಅನುಕರಿಸಲು ಒಂದು ಸಂಕ್ಷಿಪ್ತ "ವಿದ್ಯಾರ್ಥಿ" ಮಾದರಿಯನ್ನು ತರಬೇತಿಗೊಳಿಸಲಾಗುತ್ತದೆ.

**ಮುಖ್ಯ ಲಾಭಗಳು:**
- ನಿರ್ಣಯಕ್ಕಾಗಿ **ಕಂಪ್ಯೂಟೇಶನಲ್ ಅಗತ್ಯಗಳನ್ನು ಕಡಿಮೆ ಮಾಡುವುದು**
- **ಕಡಿಮೆ ಮೆಮೊರಿ ಬಳಕೆ** ಮತ್ತು ಸಂಗ್ರಹಣಾ ಅಗತ್ಯಗಳು
- **ವೇಗವಾದ ನಿರ್ಣಯ ಸಮಯಗಳು** ಸಮರ್ಪಕ ನಿಖರತೆಯನ್ನು ಉಳಿಸಿಕೊಂಡು
- ಸಂಪನ್ಮೂಲ-ನಿಯಂತ್ರಿತ ಪರಿಸರಗಳಲ್ಲಿ **ಖರ್ಚು-ಕಾರ್ಯಕ್ಷಮ ನಿಯೋಜನೆ**

## ಡಿಸ್ಟಿಲೇಶನ್ ಮಹತ್ವವೇನು {#why-distillation-matters}

ದೊಡ್ಡ ಭಾಷಾ ಮಾದರಿಗಳು (LLMs) ದಿನದಿಂದ ದಿನಕ್ಕೆ ಶಕ್ತಿಶಾಲಿಯಾಗುತ್ತಿವೆ ಆದರೆ ಅವು ಹೆಚ್ಚು ಸಂಪನ್ಮೂಲ-ಆಧಾರಿತವಾಗುತ್ತಿವೆ. ಬಿಲಿಯನ್‌ಗಳ ಪರಿಮಾಣಗಳೊಂದಿಗೆ ಮಾದರಿ ಉತ್ತಮ ಫಲಿತಾಂಶಗಳನ್ನು ನೀಡಬಹುದು, ಆದರೆ ಅನೇಕ ವಾಸ್ತವಿಕ ಅನ್ವಯಿಕೆಗಳಿಗೆ ಇದು ಪ್ರಾಯೋಗಿಕವಾಗಿರದು, ಕಾರಣ:

### ಸಂಪನ್ಮೂಲ ನಿರ್ಬಂಧಗಳು
- **ಕಂಪ್ಯೂಟೇಶನಲ್ ಓವರ್‌ಹೆಡ್**: ದೊಡ್ಡ ಮಾದರಿಗಳು ಹೆಚ್ಚಿನ GPU ಮೆಮೊರಿ ಮತ್ತು ಪ್ರೊಸೆಸಿಂಗ್ ಶಕ್ತಿಯನ್ನು ಅಗತ್ಯವಿರಿಸುತ್ತದೆ
- **ನಿರ್ಣಯ ವಿಳಂಬ**: ಸಂಕೀರ್ಣ ಮಾದರಿಗಳು ಪ್ರತಿಕ್ರಿಯೆಗಳನ್ನು ತಯಾರಿಸಲು ಹೆಚ್ಚು ಸಮಯ ತೆಗೆದುಕೊಳ್ಳುತ್ತವೆ
- **ಶಕ್ತಿ ಬಳಕೆ**: ದೊಡ್ಡ ಮಾದರಿಗಳು ಹೆಚ್ಚು ವಿದ್ಯುತ್ ಬಳಕೆ ಮಾಡುತ್ತವೆ, ಕಾರ್ಯಾಚರಣಾ ವೆಚ್ಚವನ್ನು ಹೆಚ್ಚಿಸುತ್ತವೆ
- **ಅಧಿಸೂಚನಾ ವೆಚ್ಚಗಳು**: ದೊಡ್ಡ ಮಾದರಿಗಳನ್ನು ಹೋಸ್ಟ್ ಮಾಡಲು ದುಬಾರಿ ಹಾರ್ಡ್‌ವೇರ್ ಅಗತ್ಯವಿದೆ

### ಪ್ರಾಯೋಗಿಕ ನಿರ್ಬಂಧಗಳು
- **ಮೊಬೈಲ್ ನಿಯೋಜನೆ**: ದೊಡ್ಡ ಮಾದರಿಗಳು ಮೊಬೈಲ್ ಸಾಧನಗಳಲ್ಲಿ ಪರಿಣಾಮಕಾರಿಯಾಗಿ ಕಾರ್ಯನಿರ್ವಹಿಸಲು ಸಾಧ್ಯವಿಲ್ಲ
- **ರಿಯಲ್-ಟೈಮ್ ಅನ್ವಯಿಕೆಗಳು**: ಕಡಿಮೆ ವಿಳಂಬ ಅಗತ್ಯವಿರುವ ಅನ್ವಯಿಕೆಗಳು ನಿಧಾನ ನಿರ್ಣಯವನ್ನು ಸಹಿಸಿಕೊಳ್ಳಲಾರವು
- **ಎಡ್ಜ್ ಕಂಪ್ಯೂಟಿಂಗ್**: ಐಒಟಿ ಮತ್ತು ಎಡ್ಜ್ ಸಾಧನಗಳಿಗೆ ಸೀಮಿತ ಕಂಪ್ಯೂಟೇಶನಲ್ ಸಂಪನ್ಮೂಲಗಳಿವೆ
- **ವೆಚ್ಚ ಪರಿಗಣನೆಗಳು**: ಅನೇಕ ಸಂಸ್ಥೆಗಳು ದೊಡ್ಡ ಮಾದರಿ ನಿಯೋಜನೆಗೆ ಅಗತ್ಯವಿರುವ ಮೂಲಸೌಕರ್ಯವನ್ನು ಭರಿಸಲು ಸಾಧ್ಯವಿಲ್ಲ

## ಡಿಸ್ಟಿಲೇಶನ್ ಪ್ರಕ್ರಿಯೆ {#the-distillation-process}

ಮಾದರಿ ಡಿಸ್ಟಿಲೇಶನ್ ಎರಡು ಹಂತಗಳ ಪ್ರಕ್ರಿಯೆಯನ್ನು ಅನುಸರಿಸುತ್ತದೆ, ಇದು ಶಿಕ್ಷಕ ಮಾದರಿಯಿಂದ ವಿದ್ಯಾರ್ಥಿ ಮಾದರಿಗೆ ಜ್ಞಾನವನ್ನು ವರ್ಗಾಯಿಸುತ್ತದೆ:

### ಹಂತ 1: ಸಿಂಥೆಟಿಕ್ ಡೇಟಾ ಉತ್ಪಾದನೆ

ಶಿಕ್ಷಕ ಮಾದರಿ ನಿಮ್ಮ ತರಬೇತಿ ಡೇಟಾಸೆಟ್‌ಗೆ ಪ್ರತಿಕ್ರಿಯೆಗಳನ್ನು ರಚಿಸುತ್ತದೆ, ಇದು ಶಿಕ್ಷಕನ ಜ್ಞಾನ ಮತ್ತು ತರ್ಕ ಮಾದರಿಗಳನ್ನು ಹಿಡಿದಿಡುವ ಉನ್ನತ-ಗುಣಮಟ್ಟದ ಸಿಂಥೆಟಿಕ್ ಡೇಟಾವನ್ನು ಸೃಷ್ಟಿಸುತ್ತದೆ.

```python
# ಸಂಶ್ಲೇಷಿತ ಡೇಟಾ ಉತ್ಪಾದನೆಯ ಕಲ್ಪನಾತ್ಮಕ ಉದಾಹರಣೆ
def generate_synthetic_data(teacher_model, training_dataset):
    synthetic_data = []
    for input_sample in training_dataset:
        teacher_response = teacher_model.generate(input_sample)
        synthetic_data.append({
            'input': input_sample,
            'teacher_output': teacher_response
        })
    return synthetic_data
```

**ಈ ಹಂತದ ಪ್ರಮುಖ ಅಂಶಗಳು:**
- ಶಿಕ್ಷಕ ಮಾದರಿ ಪ್ರತಿ ತರಬೇತಿ ಉದಾಹರಣೆಯನ್ನು ಪ್ರಕ್ರಿಯೆ ಮಾಡುತ್ತದೆ
- ರಚಿಸಲಾದ ಪ್ರತಿಕ್ರಿಯೆಗಳು ವಿದ್ಯಾರ್ಥಿ ತರಬೇತಿಗೆ "ಗ್ರೌಂಡ್ ಟ್ರೂತ್" ಆಗಿ ಕಾರ್ಯನಿರ್ವಹಿಸುತ್ತವೆ
- ಈ ಪ್ರಕ್ರಿಯೆ ಶಿಕ್ಷಕನ ನಿರ್ಧಾರ-ಮಾಡುವ ಮಾದರಿಗಳನ್ನು ಹಿಡಿದಿಡುತ್ತದೆ
- ಸಿಂಥೆಟಿಕ್ ಡೇಟಾದ ಗುಣಮಟ್ಟ ವಿದ್ಯಾರ್ಥಿ ಮಾದರಿಯ ಕಾರ್ಯಕ್ಷಮತೆಯನ್ನು ನೇರವಾಗಿ ಪ್ರಭಾವಿಸುತ್ತದೆ

### ಹಂತ 2: ವಿದ್ಯಾರ್ಥಿ ಮಾದರಿ ಫೈನ್-ಟ್ಯೂನಿಂಗ್

ವಿದ್ಯಾರ್ಥಿ ಮಾದರಿಯನ್ನು ಸಿಂಥೆಟಿಕ್ ಡೇಟಾಸೆಟ್‌ನಲ್ಲಿ ತರಬೇತಿಗೊಳಿಸಲಾಗುತ್ತದೆ, ಶಿಕ್ಷಕನ ವರ್ತನೆ ಮತ್ತು ಪ್ರತಿಕ್ರಿಯೆಗಳನ್ನು ನಕಲಿಸಲು ಕಲಿಯುತ್ತದೆ.

```python
# ವಿದ್ಯಾರ್ಥಿ ತರಬೇತಿಯ ಕಲ್ಪನಾತ್ಮಕ ಉದಾಹರಣೆ
def train_student_model(student_model, synthetic_data):
    for epoch in range(num_epochs):
        for batch in synthetic_data:
            student_output = student_model(batch['input'])
            loss = compute_loss(student_output, batch['teacher_output'])
            optimizer.step(loss.backward())
    return student_model
```

**ತರಬೇತಿ ಗುರಿಗಳು:**
- ವಿದ್ಯಾರ್ಥಿ ಮತ್ತು ಶಿಕ್ಷಕ ಔಟ್‌ಪುಟ್‌ಗಳ ನಡುವಿನ ವ್ಯತ್ಯಾಸವನ್ನು ಕಡಿಮೆ ಮಾಡುವುದು
- ಶಿಕ್ಷಕನ ಜ್ಞಾನವನ್ನು ಚಿಕ್ಕ ಪರಿಮಾಣದ ಸ್ಥಳದಲ್ಲಿ ಉಳಿಸುವುದು
- ಮಾದರಿ ಸಂಕೀರ್ಣತೆಯನ್ನು ಕಡಿಮೆ ಮಾಡುತ್ತಾ ಕಾರ್ಯಕ್ಷಮತೆಯನ್ನು ಉಳಿಸುವುದು

## ಪ್ರಾಯೋಗಿಕ ಅನುಷ್ಠಾನ {#practical-implementation}

### ಶಿಕ್ಷಕ ಮತ್ತು ವಿದ್ಯಾರ್ಥಿ ಮಾದರಿಗಳನ್ನು ಆಯ್ಕೆ ಮಾಡುವುದು

**ಶಿಕ್ಷಕ ಮಾದರಿ ಆಯ್ಕೆ:**
- ನಿಮ್ಮ ನಿರ್ದಿಷ್ಟ ಕಾರ್ಯದಲ್ಲಿ ಸಾಬೀತಾದ ಕಾರ್ಯಕ್ಷಮತೆಯೊಂದಿಗೆ ದೊಡ್ಡ ಪ್ರಮಾಣದ LLMs (100B+ ಪರಿಮಾಣಗಳು) ಆಯ್ಕೆಮಾಡಿ
- ಜನಪ್ರಿಯ ಶಿಕ್ಷಕ ಮಾದರಿಗಳು:
  - **DeepSeek V3** (671B ಪರಿಮಾಣಗಳು) - ತರ್ಕ ಮತ್ತು ಕೋಡ್ ರಚನೆಗೆ ಅತ್ಯುತ್ತಮ
  - **Meta Llama 3.1 405B Instruct** - ಸಮಗ್ರ ಸಾಮಾನ್ಯ ಉದ್ದೇಶ ಸಾಮರ್ಥ್ಯಗಳು
  - **GPT-4** - ವಿಭಿನ್ನ ಕಾರ್ಯಗಳಲ್ಲಿ ಬಲವಾದ ಕಾರ್ಯಕ್ಷಮತೆ
  - **Claude 3.5 Sonnet** - ಸಂಕೀರ್ಣ ತರ್ಕ ಕಾರ್ಯಗಳಿಗೆ ಅತ್ಯುತ್ತಮ
- ನಿಮ್ಮ ಡೊಮೇನ್-ನಿರ್ದಿಷ್ಟ ಡೇಟಾದಲ್ಲಿ ಶಿಕ್ಷಕ ಮಾದರಿ ಉತ್ತಮ ಕಾರ್ಯನಿರ್ವಹಿಸುವುದನ್ನು ಖಚಿತಪಡಿಸಿಕೊಳ್ಳಿ

**ವಿದ್ಯಾರ್ಥಿ ಮಾದರಿ ಆಯ್ಕೆ:**
- ಮಾದರಿ ಗಾತ್ರ ಮತ್ತು ಕಾರ್ಯಕ್ಷಮತೆ ಅಗತ್ಯಗಳ ನಡುವೆ ಸಮತೋಲನ
- ಪರಿಣಾಮಕಾರಿ, ಚಿಕ್ಕ ಮಾದರಿಗಳ ಮೇಲೆ ಗಮನಹರಿಸಿ:
  - **Microsoft Phi-4-mini** - ಬಲವಾದ ತರ್ಕ ಸಾಮರ್ಥ್ಯಗಳೊಂದಿಗೆ ಇತ್ತೀಚಿನ ಪರಿಣಾಮಕಾರಿ ಮಾದರಿ
  - Meta Llama 3.1 8B Instruct
  - Microsoft Phi-3 Mini (4K ಮತ್ತು 128K ರೂಪಾಂತರಗಳು)
  - Microsoft Phi-3.5 Mini Instruct

### ಅನುಷ್ಠಾನ ಹಂತಗಳು

1. **ಡೇಟಾ ತಯಾರಿ**
   ```python
   # ನಿಮ್ಮ ತರಬೇತಿ ಡೇಟಾಸೆಟ್ ಅನ್ನು ತಯಾರಿಸಿ
   training_data = load_dataset("your_training_data.jsonl")
   validation_data = load_dataset("your_validation_data.jsonl")
   ```

2. **ಶಿಕ್ಷಕ ಮಾದರಿ ಸೆಟ್‌ಅಪ್**
   ```python
   # ದೊಡ್ಡ ಪ್ರಮಾಣದ ಶಿಕ್ಷಕ ಮಾದರಿಯನ್ನು ಪ್ರಾರಂಭಿಸಿ (100B+ ಪರಿಮಾಣಗಳು)
   teacher_model = load_model("deepseek-ai/DeepSeek-V3")
   # ಪರ್ಯಾಯ: teacher_model = load_model("meta-llama/Llama-3.1-405B-Instruct")
   ```

3. **ಸಿಂಥೆಟಿಕ್ ಡೇಟಾ ಉತ್ಪಾದನೆ**
   ```python
   # ಶಿಕ್ಷಕ ಮಾದರಿಯಿಂದ ಪ್ರತಿಕ್ರಿಯೆಗಳನ್ನು ರಚಿಸಿ
   synthetic_training_data = generate_teacher_responses(
       teacher_model, 
       training_data
   )
   synthetic_validation_data = generate_teacher_responses(
       teacher_model, 
       validation_data
   )
   ```

4. **ವಿದ್ಯಾರ್ಥಿ ಮಾದರಿ ತರಬೇತಿ**
   ```python
   # ವಿದ್ಯಾರ್ಥಿ ಮಾದರಿಯಾಗಿ ಫೈ-4-ಮಿನಿ ಅನ್ನು ಸೂಕ್ಷ್ಮವಾಗಿ ಹೊಂದಿಸಿ
   student_model = load_model("microsoft/Phi-4-mini")
   trained_student = fine_tune_student(
       student_model,
       synthetic_training_data,
       synthetic_validation_data
   )
   ```

## ಅಜೂರ್ ಎಂಎಲ್ ಡಿಸ್ಟಿಲೇಶನ್ ಉದಾಹರಣೆ {#azure-ml-example}

ಅಜೂರ್ ಮೆಷಿನ್ ಲರ್ನಿಂಗ್ ಮಾದರಿ ಡಿಸ್ಟಿಲೇಶನ್ ಅನುಷ್ಠಾನಕ್ಕೆ ಸಮಗ್ರ ವೇದಿಕೆಯನ್ನು ಒದಗಿಸುತ್ತದೆ. ನಿಮ್ಮ ಡಿಸ್ಟಿಲೇಶನ್ ವರ್ಕ್‌ಫ್ಲೋಗೆ ಅಜೂರ್ ಎಂಎಲ್ ಅನ್ನು ಹೇಗೆ ಬಳಸುವುದು ಇಲ್ಲಿದೆ:

### ಪೂರ್ವಾಪೇಕ್ಷೆಗಳು

1. **ಅಜೂರ್ ಎಂಎಲ್ ವರ್ಕ್‌ಸ್ಪೇಸ್**: ನಿಮ್ಮ ವರ್ಕ್‌ಸ್ಪೇಸ್ ಅನ್ನು ಸೂಕ್ತ ಪ್ರದೇಶದಲ್ಲಿ ಸೆಟ್‌ಅಪ್ ಮಾಡಿ
   - ದೊಡ್ಡ ಪ್ರಮಾಣದ ಶಿಕ್ಷಕ ಮಾದರಿಗಳ (DeepSeek V3, Llama 405B) ಪ್ರವೇಶವನ್ನು ಖಚಿತಪಡಿಸಿ
   - ಮಾದರಿ ಲಭ್ಯತೆಯ ಆಧಾರದ ಮೇಲೆ ಪ್ರದೇಶಗಳನ್ನು ಸಂರಚಿಸಿ

2. **ಕಂಪ್ಯೂಟ್ ಸಂಪನ್ಮೂಲಗಳು**: ತರಬೇತಿಗಾಗಿ ಸೂಕ್ತ ಕಂಪ್ಯೂಟ್ ಇನ್ಸ್ಟಾನ್ಸ್‌ಗಳನ್ನು ಸಂರಚಿಸಿ
   - ಶಿಕ್ಷಕ ಮಾದರಿ ನಿರ್ಣಯಕ್ಕಾಗಿ ಹೆಚ್ಚಿನ ಮೆಮೊರಿ ಇನ್ಸ್ಟಾನ್ಸ್‌ಗಳು
   - ವಿದ್ಯಾರ್ಥಿ ಮಾದರಿ ಫೈನ್-ಟ್ಯೂನಿಂಗ್‌ಗೆ GPU-ಸಕ್ರಿಯ ಕಂಪ್ಯೂಟ್

### ಬೆಂಬಲಿತ ಕಾರ್ಯ ಪ್ರಕಾರಗಳು

ಅಜೂರ್ ಎಂಎಲ್ ವಿವಿಧ ಕಾರ್ಯಗಳಿಗೆ ಡಿಸ್ಟಿಲೇಶನ್ ಅನ್ನು ಬೆಂಬಲಿಸುತ್ತದೆ:

- **ಸ್ವಾಭಾವಿಕ ಭಾಷಾ ಅರ್ಥಮಾಡಿಕೆ (NLI)**
- **ಸಂವಾದಾತ್ಮಕ AI**
- **ಪ್ರಶ್ನೋತ್ತರ (QA)**
- **ಗಣಿತ ತರ್ಕ**
- **ಪಠ್ಯ ಸಾರಾಂಶ**

### ಮಾದರಿ ಅನುಷ್ಠಾನ

```python
from azure.ai.ml import MLClient
from azure.ai.ml.entities import DistillationJob

# ಅಜೂರ್ ಎಂಎಲ್ ಕ್ಲೈಂಟ್ ಅನ್ನು ಪ್ರಾರಂಭಿಸಿ
ml_client = MLClient.from_config()

# ಡೀಪ್ ಸೀಕ್ V3 ಅನ್ನು ಶಿಕ್ಷಕ ಮತ್ತು ಫೈ-4-ಮಿನಿ ಅನ್ನು ವಿದ್ಯಾರ್ಥಿಯಾಗಿ ಡಿಸ್ಟಿಲೇಶನ್ ಕೆಲಸವನ್ನು ವ್ಯಾಖ್ಯಾನಿಸಿ
distillation_job = DistillationJob(
    teacher_model="deepseek-v3",  # ದೊಡ್ಡ ಪ್ರಮಾಣದ ಶಿಕ್ಷಕ ಮಾದರಿ (671B ಪ್ಯಾರಾಮೀಟರ್‌ಗಳು)
    student_model="phi-4-mini",   # ಪರಿಣಾಮಕಾರಿ ವಿದ್ಯಾರ್ಥಿ ಮಾದರಿ
    training_data="./training_data.jsonl",
    validation_data="./validation_data.jsonl",
    task_type="conversation",
    hyperparameters={
        "learning_rate": 2e-5,    # ಸೂಕ್ಷ್ಮ-ಸಂಶೋಧನೆಗಾಗಿ ಕಡಿಮೆ ಕಲಿಕೆ ದರ
        "batch_size": 2,          # ಮೆಮೊರಿ ಪರಿಣಾಮಕಾರಿತ್ವಕ್ಕಾಗಿ ಚಿಕ್ಕ ಬ್ಯಾಚ್ ಗಾತ್ರ
        "num_epochs": 3,
        "temperature": 0.7        # ಶಿಕ್ಷಕ ಔಟ್‌ಪುಟ್ ಸಾಫ್ಟ್‌ನೆಸ್
    }
)

# ಡಿಸ್ಟಿಲೇಶನ್ ಕೆಲಸವನ್ನು ಸಲ್ಲಿಸಿ
job = ml_client.jobs.create_or_update(distillation_job)
```

### ಮೇಲ್ವಿಚಾರಣೆ ಮತ್ತು ಮೌಲ್ಯಮಾಪನ

```python
# ತರಬೇತಿ ಪ್ರಗತಿಯನ್ನು ಮೇಲ್ವಿಚಾರಣೆ ಮಾಡಿ
job_status = ml_client.jobs.get(job.name)
print(f"Job status: {job_status.status}")

# ಡಿಸ್ಟಿಲ್ಲ್ಡ್ ಫೈ-4-ಮಿನಿ ಮಾದರಿಯನ್ನು ಮೌಲ್ಯಮಾಪನ ಮಾಡಿ
evaluation_results = ml_client.models.evaluate(
    model_name="phi-4-mini-distilled",
    test_data="./test_data.jsonl",
    metrics=["accuracy", "bleu_score", "inference_time"]
)

# ಮೂಲ ಫೈ-4-ಮಿನಿ ಬೇಸ್‌ಲೈನ್ ಜೊತೆಗೆ ಹೋಲಿಸಿ
baseline_results = ml_client.models.evaluate(
    model_name="phi-4-mini-baseline",
    test_data="./test_data.jsonl"
)

print(f"Distilled model accuracy: {evaluation_results['accuracy']}")
print(f"Baseline model accuracy: {baseline_results['accuracy']}")
print(f"Performance improvement: {evaluation_results['accuracy'] - baseline_results['accuracy']}")
```

## ಉತ್ತಮ ಅಭ್ಯಾಸಗಳು ಮತ್ತು ಆಪ್ಟಿಮೈಜೆಷನ್ {#best-practices}

### ಡೇಟಾ ಗುಣಮಟ್ಟ

**ಉನ್ನತ ಗುಣಮಟ್ಟದ ತರಬೇತಿ ಡೇಟಾ ಅತ್ಯಂತ ಮುಖ್ಯ:**
- ವೈವಿಧ್ಯಮಯ ಮತ್ತು ಪ್ರತಿನಿಧಿ ತರಬೇತಿ ಉದಾಹರಣೆಗಳನ್ನು ಖಚಿತಪಡಿಸಿ
- ಸಾಧ್ಯವಾದರೆ ಡೊಮೇನ್-ನಿರ್ದಿಷ್ಟ ಡೇಟಾ ಬಳಸಿ
- ವಿದ್ಯಾರ್ಥಿ ತರಬೇತಿಗೆ ಬಳಸುವ ಮೊದಲು ಶಿಕ್ಷಕ ಮಾದರಿ ಔಟ್‌ಪುಟ್‌ಗಳನ್ನು ಪರಿಶೀಲಿಸಿ
- ವಿದ್ಯಾರ್ಥಿ ಮಾದರಿ ಕಲಿಕೆಯಲ್ಲಿ ಪಕ್ಷಪಾತ ತಪ್ಪಿಸಲು ಡೇಟಾಸೆಟ್ ಸಮತೋಲನ ಮಾಡಿ

### ಹೈಪರ್‌ಪ್ಯಾರಾಮೀಟರ್ ಟ್ಯೂನಿಂಗ್

**ಆಪ್ಟಿಮೈಸ್ ಮಾಡಲು ಪ್ರಮುಖ ಪ್ಯಾರಾಮೀಟರ್‌ಗಳು:**
- **ಕಲಿಕೆ ದರ**: ಫೈನ್-ಟ್ಯೂನಿಂಗ್‌ಗೆ ಸಣ್ಣ ದರಗಳಿಂದ ಪ್ರಾರಂಭಿಸಿ (1e-5 ರಿಂದ 5e-5)
- **ಬ್ಯಾಚ್ ಗಾತ್ರ**: ಮೆಮೊರಿ ನಿರ್ಬಂಧಗಳು ಮತ್ತು ತರಬೇತಿ ಸ್ಥಿರತೆಯ ನಡುವೆ ಸಮತೋಲನ
- **ಎಪೋಕ್‌ಗಳ ಸಂಖ್ಯೆ**: ಓವರ್‌ಫಿಟಿಂಗ್‌ಗೆ ಗಮನವಿಟ್ಟು; ಸಾಮಾನ್ಯವಾಗಿ 2-5 ಎಪೋಕ್‌ಗಳು ಸಾಕಾಗುತ್ತವೆ
- **ತಾಪಮಾನ ಮಾಪನ**: ಉತ್ತಮ ಜ್ಞಾನ ವರ್ಗಾಯಿಸಲು ಶಿಕ್ಷಕ ಔಟ್‌ಪುಟ್ ಸಾಫ್ಟ್‌ನೆಸ್ ಅನ್ನು ಹೊಂದಿಸಿ

### ಮಾದರಿ ವಾಸ್ತುಶಿಲ್ಪ ಪರಿಗಣನೆಗಳು

**ಶಿಕ್ಷಕ-ವಿದ್ಯಾರ್ಥಿ ಹೊಂದಾಣಿಕೆ:**
- ಶಿಕ್ಷಕ ಮತ್ತು ವಿದ್ಯಾರ್ಥಿ ಮಾದರಿಗಳ ನಡುವೆ ವಾಸ್ತುಶಿಲ್ಪ ಹೊಂದಾಣಿಕೆಯನ್ನು ಖಚಿತಪಡಿಸಿ
- ಉತ್ತಮ ಜ್ಞಾನ ವರ್ಗಾಯಿಸಲು ಮಧ್ಯಂತರ ಲೇಯರ್ ಹೊಂದಾಣಿಕೆಯನ್ನು ಪರಿಗಣಿಸಿ
- ಅನ್ವಯಿಸಿದಾಗ ಗಮನ ವರ್ಗಾಯಿಸುವ ತಂತ್ರಗಳನ್ನು ಬಳಸಿ

### ಮೌಲ್ಯಮಾಪನ ತಂತ್ರಗಳು

**ಸಮಗ್ರ ಮೌಲ್ಯಮಾಪನ ವಿಧಾನ:**
```python
# ಬಹು-ಮಾಪಕ ಮೌಲ್ಯಮಾಪನ
evaluation_metrics = {
    'accuracy': evaluate_accuracy(student_model, test_data),
    'latency': measure_inference_time(student_model),
    'memory_usage': profile_memory_consumption(student_model),
    'task_specific_metrics': evaluate_task_performance(student_model, task_data)
}
```

## ವಾಸ್ತವಿಕ ಜಗತ್ತಿನ ಅನ್ವಯಿಕೆಗಳು {#real-world-applications}

### ಮೊಬೈಲ್ ಮತ್ತು ಎಡ್ಜ್ ನಿಯೋಜನೆ

ಡಿಸ್ಟಿಲ್ಡ್ ಮಾದರಿಗಳು ಸಂಪನ್ಮೂಲ-ನಿಯಂತ್ರಿತ ಸಾಧನಗಳಲ್ಲಿ AI ಸಾಮರ್ಥ್ಯಗಳನ್ನು ಸಕ್ರಿಯಗೊಳಿಸುತ್ತವೆ:
- **ಸ್ಮಾರ್ಟ್‌ಫೋನ್ ಅನ್ವಯಿಕೆಗಳು** ರಿಯಲ್-ಟೈಮ್ ಪಠ್ಯ ಪ್ರಕ್ರಿಯೆಗಾಗಿ
- **ಐಒಟಿ ಸಾಧನಗಳು** ಸ್ಥಳೀಯ ನಿರ್ಣಯ ನಡೆಸುವವು
- **ಎಂಬೆಡ್ಡೆಡ್ ಸಿಸ್ಟಮ್ಗಳು** ಸೀಮಿತ ಕಂಪ್ಯೂಟೇಶನಲ್ ಸಂಪನ್ಮೂಲಗಳೊಂದಿಗೆ

### ವೆಚ್ಚ-ಕಾರ್ಯಕ್ಷಮ ಉತ್ಪಾದನಾ ವ್ಯವಸ್ಥೆಗಳು

ಸಂಸ್ಥೆಗಳು ಕಾರ್ಯಾಚರಣಾ ವೆಚ್ಚಗಳನ್ನು ಕಡಿಮೆ ಮಾಡಲು ಡಿಸ್ಟಿಲೇಶನ್ ಬಳಸುತ್ತವೆ:
- **ಗ್ರಾಹಕ ಸೇವೆ ಚಾಟ್‌ಬಾಟ್‌ಗಳು** ವೇಗವಾದ ಪ್ರತಿಕ್ರಿಯೆ ಸಮಯಗಳೊಂದಿಗೆ
- **ವಿಷಯ ನಿಯಂತ್ರಣ ವ್ಯವಸ್ಥೆಗಳು** ಹೆಚ್ಚಿನ ಪ್ರಮಾಣವನ್ನು ಪರಿಣಾಮಕಾರಿಯಾಗಿ ಪ್ರಕ್ರಿಯೆ ಮಾಡುತ್ತವೆ
- **ರಿಯಲ್-ಟೈಮ್ ಅನುವಾದ ಸೇವೆಗಳು** ಕಡಿಮೆ ವಿಳಂಬ ಅಗತ್ಯಗಳೊಂದಿಗೆ

### ಡೊಮೇನ್-ನಿರ್ದಿಷ್ಟ ಅನ್ವಯಿಕೆಗಳು

ಡಿಸ್ಟಿಲೇಶನ್ ವಿಶೇಷ ಮಾದರಿಗಳನ್ನು ರಚಿಸಲು ಸಹಾಯ ಮಾಡುತ್ತದೆ:
- **ವೈದ್ಯಕೀಯ ರೋಗನಿರ್ಣಯ ಸಹಾಯ** ಗೌಪ್ಯತೆ-ರಕ್ಷಿತ ಸ್ಥಳೀಯ ನಿರ್ಣಯದೊಂದಿಗೆ
- **ಕಾನೂನು ದಾಖಲೆ ವಿಶ್ಲೇಷಣೆ** ನಿರ್ದಿಷ್ಟ ಕಾನೂನು ಕ್ಷೇತ್ರಗಳಿಗೆ ಅನುಕೂಲಕರ
- **ಆರ್ಥಿಕ ಅಪಾಯ ಮೌಲ್ಯಮಾಪನ** ವೇಗವಾದ ನಿರ್ಧಾರ-ಮಾಡುವ ಸಾಮರ್ಥ್ಯಗಳೊಂದಿಗೆ

### ಪ್ರಕರಣ ಅಧ್ಯಯನ: DeepSeek V3 → Phi-4-mini ಮೂಲಕ ಗ್ರಾಹಕ ಬೆಂಬಲ

ಒಂದು ತಂತ್ರಜ್ಞಾನ ಕಂಪನಿಯು ತಮ್ಮ ಗ್ರಾಹಕ ಬೆಂಬಲ ವ್ಯವಸ್ಥೆಗೆ ಡಿಸ್ಟಿಲೇಶನ್ ಅನುಷ್ಠಾನಗೊಳಿಸಿತು:

**ಅನುಷ್ಠಾನ ವಿವರಗಳು:**
- **ಶಿಕ್ಷಕ ಮಾದರಿ**: DeepSeek V3 (671B ಪರಿಮಾಣಗಳು) - ಸಂಕೀರ್ಣ ಗ್ರಾಹಕ ಪ್ರಶ್ನೆಗಳಿಗೆ ಅತ್ಯುತ್ತಮ ತರ್ಕ
- **ವಿದ್ಯಾರ್ಥಿ ಮಾದರಿ**: Phi-4-mini - ವೇಗವಾದ ನಿರ್ಣಯ ಮತ್ತು ನಿಯೋಜನೆಗೆ ಆಪ್ಟಿಮೈಸ್ ಮಾಡಲಾಗಿದೆ
- **ತರಬೇತಿ ಡೇಟಾ**: 50,000 ಗ್ರಾಹಕ ಬೆಂಬಲ ಸಂಭಾಷಣೆಗಳು
- **ಕಾರ್ಯ**: ತಾಂತ್ರಿಕ ಸಮಸ್ಯೆ ಪರಿಹಾರದೊಂದಿಗೆ ಬಹು-ತಿರುವು ಸಂವಾದ ಬೆಂಬಲ

**ಪಡೆಯಲಾದ ಫಲಿತಾಂಶಗಳು:**
- ನಿರ್ಣಯ ಸಮಯದಲ್ಲಿ **85% ಕಡಿತ** (3.2 ಸೆಕೆಂಡುಗಳಿಂದ 0.48 ಸೆಕೆಂಡುಗಳಿಗೆ ಪ್ರತಿ ಪ್ರತಿಕ್ರಿಯೆ)
- ಮೆಮೊರಿ ಅಗತ್ಯದಲ್ಲಿ **95% ಇಳಿಕೆ** (1.2TB ರಿಂದ 60GB)
- ಬೆಂಬಲ ಕಾರ್ಯಗಳಲ್ಲಿ ಮೂಲ ಮಾದರಿ ನಿಖರತೆಯ **92% ಉಳಿಕೆ**
- ಕಾರ್ಯಾಚರಣಾ ವೆಚ್ಚದಲ್ಲಿ **60% ಕಡಿತ**
- **ಮಾಪನೀಯತೆ ಸುಧಾರಣೆ** - ಈಗ 10x ಹೆಚ್ಚು ಸಮಕಾಲೀನ ಬಳಕೆದಾರರನ್ನು ನಿರ್ವಹಿಸಬಹುದು

**ಕಾರ್ಯಕ್ಷಮತೆ ವಿವರ:**
```python
# ಹೋಲಿಕೆ ಮಾಪಕಗಳು
performance_comparison = {
    "DeepSeek V3 (Teacher)": {
        "parameters": "671B",
        "memory_usage": "1.2TB",
        "inference_time": "3.2s",
        "accuracy": "94.5%",
        "throughput": "50 queries/hour"
    },
    "Phi-4-mini (Distilled)": {
        "parameters": "14B",
        "memory_usage": "60GB", 
        "inference_time": "0.48s",
        "accuracy": "87.0%",
        "throughput": "500 queries/hour"
    }
}
```

## ನಿರ್ಣಯ {#conclusion}

ಮಾದರಿ ಡಿಸ್ಟಿಲೇಶನ್ ಉನ್ನತ AI ಸಾಮರ್ಥ್ಯಗಳಿಗೆ ಪ್ರಜಾಪ್ರಭುತ್ವವನ್ನು ಒದಗಿಸುವ ಪ್ರಮುಖ ತಂತ್ರವಾಗಿದೆ. ದೊಡ್ಡ ಮಾದರಿಗಳ ಕಾರ್ಯಕ್ಷಮತೆಯ ಬಹುಭಾಗವನ್ನು ಉಳಿಸಿಕೊಂಡು ಚಿಕ್ಕ ಮತ್ತು ಹೆಚ್ಚು ಪರಿಣಾಮಕಾರಿ ಮಾದರಿಗಳನ್ನು ರಚಿಸುವ ಮೂಲಕ, ಡಿಸ್ಟಿಲೇಶನ್ ಪ್ರಾಯೋಗಿಕ AI ನಿಯೋಜನೆಗೆ ಹೆಚ್ಚುತ್ತಿರುವ ಅಗತ್ಯವನ್ನು ಪೂರೈಸುತ್ತದೆ.

### ಪ್ರಮುಖ ಅಂಶಗಳು

1. **ಡಿಸ್ಟಿಲೇಶನ್ ಮಾದರಿ ಕಾರ್ಯಕ್ಷಮತೆ ಮತ್ತು ಪ್ರಾಯೋಗಿಕ ನಿರ್ಬಂಧಗಳ ನಡುವಿನ ಅಂತರವನ್ನು ಸೇರುತ್ತದೆ**
2. **ಎರಡು ಹಂತಗಳ ಪ್ರಕ್ರಿಯೆ** ಶಿಕ್ಷಕನಿಂದ ವಿದ್ಯಾರ್ಥಿಗೆ ಪರಿಣಾಮಕಾರಿ ಜ್ಞಾನ ವರ್ಗಾಯಣೆಯನ್ನು ಖಚಿತಪಡಿಸುತ್ತದೆ
3. **ಅಜೂರ್ ಎಂಎಲ್ ಬಲವಾದ ಮೂಲಸೌಕರ್ಯವನ್ನು ಒದಗಿಸುತ್ತದೆ** ಡಿಸ್ಟಿಲೇಶನ್ ವರ್ಕ್‌ಫ್ಲೋಗಳ ಅನುಷ್ಠಾನಕ್ಕೆ
4. **ಸರಿಯಾದ ಮೌಲ್ಯಮಾಪನ ಮತ್ತು ಆಪ್ಟಿಮೈಜೆಷನ್** ಯಶಸ್ವಿ ಡಿಸ್ಟಿಲೇಶನ್‌ಗೆ ಅಗತ್ಯ
5. **ವಾಸ್ತವಿಕ ಅನ್ವಯಿಕೆಗಳು** ವೆಚ್ಚ, ವೇಗ ಮತ್ತು ಪ್ರವೇಶಾರ್ಹತೆಯಲ್ಲಿ ಮಹತ್ವದ ಲಾಭಗಳನ್ನು ತೋರಿಸುತ್ತವೆ

### ಭವಿಷ್ಯದ ದಿಕ್ಕುಗಳು

ಕ್ಷೇತ್ರ ಮುಂದುವರಿದಂತೆ, ನಾವು ನಿರೀಕ್ಷಿಸಬಹುದು:
- **ಮೇಲ್ಮಟ್ಟದ ಡಿಸ್ಟಿಲೇಶನ್ ತಂತ್ರಗಳು** ಉತ್ತಮ ಜ್ಞಾನ ವರ್ಗಾಯಣಾ ವಿಧಾನಗಳೊಂದಿಗೆ
- **ಬಹು-ಶಿಕ್ಷಕ ಡಿಸ್ಟಿಲೇಶನ್** ವಿದ್ಯಾರ್ಥಿ ಮಾದರಿ ಸಾಮರ್ಥ್ಯಗಳನ್ನು ಹೆಚ್ಚಿಸಲು
- **ಡಿಸ್ಟಿಲೇಶನ್ ಪ್ರಕ್ರಿಯೆಯ ಸ್ವಯಂಚಾಲಿತ ಆಪ್ಟಿಮೈಜೆಷನ್**
- **ವಿವಿಧ ವಾಸ್ತುಶಿಲ್ಪಗಳು ಮತ್ತು ಡೊಮೇನ್‌ಗಳಾದ್ಯಂತ ವ್ಯಾಪಕ ಮಾದರಿ ಬೆಂಬಲ**

ಮಾದರಿ ಡಿಸ್ಟಿಲೇಶನ್ ಸಂಸ್ಥೆಗಳಿಗೆ ಅತ್ಯಾಧುನಿಕ AI ಸಾಮರ್ಥ್ಯಗಳನ್ನು ಬಳಸಿಕೊಳ್ಳಲು ಮತ್ತು ಪ್ರಾಯೋಗಿಕ ನಿಯೋಜನೆ ನಿರ್ಬಂಧಗಳನ್ನು ಉಳಿಸಿಕೊಂಡು, ವಿವಿಧ ಅನ್ವಯಿಕೆಗಳು ಮತ್ತು ಪರಿಸರಗಳಲ್ಲಿ ಉನ್ನತ ಭಾಷಾ ಮಾದರಿಗಳನ್ನು ಪ್ರವೇಶಾರ್ಹಗೊಳಿಸುತ್ತದೆ.


## ➡️ ಮುಂದೇನು

- [03: ಫೈನ್-ಟ್ಯೂನಿಂಗ್ - ನಿರ್ದಿಷ್ಟ ಕಾರ್ಯಗಳಿಗೆ ಮಾದರಿಗಳನ್ನು ಕಸ್ಟಮೈಸ್ ಮಾಡುವುದು](./03.SLMOps-Finetuing.md)

---

<!-- CO-OP TRANSLATOR DISCLAIMER START -->
**ಅಸ್ವೀಕರಣ**:  
ಈ ದಸ್ತಾವೇಜು AI ಅನುವಾದ ಸೇವೆ [Co-op Translator](https://github.com/Azure/co-op-translator) ಬಳಸಿ ಅನುವಾದಿಸಲಾಗಿದೆ. ನಾವು ನಿಖರತೆಯಿಗಾಗಿ ಪ್ರಯತ್ನಿಸುತ್ತಿದ್ದರೂ, ಸ್ವಯಂಚಾಲಿತ ಅನುವಾದಗಳಲ್ಲಿ ದೋಷಗಳು ಅಥವಾ ಅಸತ್ಯತೆಗಳು ಇರಬಹುದು ಎಂದು ದಯವಿಟ್ಟು ಗಮನಿಸಿ. ಮೂಲ ಭಾಷೆಯಲ್ಲಿರುವ ಮೂಲ ದಸ್ತಾವೇಜನ್ನು ಅಧಿಕೃತ ಮೂಲವಾಗಿ ಪರಿಗಣಿಸಬೇಕು. ಮಹತ್ವದ ಮಾಹಿತಿಗಾಗಿ, ವೃತ್ತಿಪರ ಮಾನವ ಅನುವಾದವನ್ನು ಶಿಫಾರಸು ಮಾಡಲಾಗುತ್ತದೆ. ಈ ಅನುವಾದ ಬಳಕೆಯಿಂದ ಉಂಟಾಗುವ ಯಾವುದೇ ತಪ್ಪು ಅರ್ಥಮಾಡಿಕೊಳ್ಳುವಿಕೆ ಅಥವಾ ತಪ್ಪು ವಿವರಣೆಗಳಿಗೆ ನಾವು ಹೊಣೆಗಾರರಾಗುವುದಿಲ್ಲ.
<!-- CO-OP TRANSLATOR DISCLAIMER END -->