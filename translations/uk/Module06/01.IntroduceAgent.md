<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "44bc28c27b993c5fb988791b7a115705",
  "translation_date": "2025-10-30T15:14:13+00:00",
  "source_file": "Module06/01.IntroduceAgent.md",
  "language_code": "uk"
}
-->
# AI-Ð°Ð³ÐµÐ½Ñ‚Ð¸ Ñ‚Ð° Ð¼Ð°Ð»Ñ– Ð¼Ð¾Ð²Ð½Ñ– Ð¼Ð¾Ð´ÐµÐ»Ñ–: Ð’ÑÐµÐ¾ÑÑÐ¶Ð½Ð¸Ð¹ Ð¿Ð¾ÑÑ–Ð±Ð½Ð¸Ðº

## Ð’ÑÑ‚ÑƒÐ¿

Ð£ Ñ†ÑŒÐ¾Ð¼Ñƒ Ð¿Ð¾ÑÑ–Ð±Ð½Ð¸ÐºÑƒ Ð¼Ð¸ Ñ€Ð¾Ð·Ð³Ð»ÑÐ½ÐµÐ¼Ð¾ AI-Ð°Ð³ÐµÐ½Ñ‚Ð¸ Ñ‚Ð° Ð¼Ð°Ð»Ñ– Ð¼Ð¾Ð²Ð½Ñ– Ð¼Ð¾Ð´ÐµÐ»Ñ– (SLM), Ð° Ñ‚Ð°ÐºÐ¾Ð¶ Ñ—Ñ…Ð½Ñ– Ð¿ÐµÑ€ÐµÐ´Ð¾Ð²Ñ– ÑÑ‚Ñ€Ð°Ñ‚ÐµÐ³Ñ–Ñ— Ð²Ð¿Ñ€Ð¾Ð²Ð°Ð´Ð¶ÐµÐ½Ð½Ñ Ð´Ð»Ñ ÑÐµÑ€ÐµÐ´Ð¾Ð²Ð¸Ñ‰ Ð¾Ð±Ñ‡Ð¸ÑÐ»ÐµÐ½ÑŒ Ð½Ð° Ð¿ÐµÑ€Ð¸Ñ„ÐµÑ€Ñ–Ñ—. ÐœÐ¸ Ð¾Ñ…Ð¾Ð¿Ð¸Ð¼Ð¾ Ð¾ÑÐ½Ð¾Ð²Ð½Ñ– ÐºÐ¾Ð½Ñ†ÐµÐ¿Ñ†Ñ–Ñ— Ð°Ð³ÐµÐ½Ñ‚Ð½Ð¾Ð³Ð¾ AI, Ñ‚ÐµÑ…Ð½Ñ–ÐºÐ¸ Ð¾Ð¿Ñ‚Ð¸Ð¼Ñ–Ð·Ð°Ñ†Ñ–Ñ— SLM, Ð¿Ñ€Ð°ÐºÑ‚Ð¸Ñ‡Ð½Ñ– ÑÑ‚Ñ€Ð°Ñ‚ÐµÐ³Ñ–Ñ— Ñ€Ð¾Ð·Ð³Ð¾Ñ€Ñ‚Ð°Ð½Ð½Ñ Ð´Ð»Ñ Ð¿Ñ€Ð¸ÑÑ‚Ñ€Ð¾Ñ—Ð² Ð· Ð¾Ð±Ð¼ÐµÐ¶ÐµÐ½Ð¸Ð¼Ð¸ Ñ€ÐµÑÑƒÑ€ÑÐ°Ð¼Ð¸ Ñ‚Ð° Microsoft Agent Framework Ð´Ð»Ñ ÑÑ‚Ð²Ð¾Ñ€ÐµÐ½Ð½Ñ Ð³Ð¾Ñ‚Ð¾Ð²Ð¸Ñ… Ð´Ð¾ Ð²Ð¸Ñ€Ð¾Ð±Ð½Ð¸Ñ†Ñ‚Ð²Ð° Ð°Ð³ÐµÐ½Ñ‚Ð½Ð¸Ñ… ÑÐ¸ÑÑ‚ÐµÐ¼.

Ð›Ð°Ð½Ð´ÑˆÐ°Ñ„Ñ‚ ÑˆÑ‚ÑƒÑ‡Ð½Ð¾Ð³Ð¾ Ñ–Ð½Ñ‚ÐµÐ»ÐµÐºÑ‚Ñƒ Ð·Ð°Ð·Ð½Ð°Ñ” Ð¿Ð°Ñ€Ð°Ð´Ð¸Ð³Ð¼Ð°Ñ‚Ð¸Ñ‡Ð½Ð¸Ñ… Ð·Ð¼Ñ–Ð½ Ñƒ 2025 Ñ€Ð¾Ñ†Ñ–. Ð¯ÐºÑ‰Ð¾ 2023 Ñ€Ñ–Ðº Ð±ÑƒÐ² Ñ€Ð¾ÐºÐ¾Ð¼ Ñ‡Ð°Ñ‚-Ð±Ð¾Ñ‚Ñ–Ð², Ð° 2024 â€” Ð±ÑƒÐ¼Ð¾Ð¼ ÐºÐ¾Ð¿Ñ–Ð»Ð¾Ñ‚Ñ–Ð², Ñ‚Ð¾ 2025 Ð½Ð°Ð»ÐµÐ¶Ð¸Ñ‚ÑŒ AI-Ð°Ð³ÐµÐ½Ñ‚Ð°Ð¼ â€” Ñ–Ð½Ñ‚ÐµÐ»ÐµÐºÑ‚ÑƒÐ°Ð»ÑŒÐ½Ð¸Ð¼ ÑÐ¸ÑÑ‚ÐµÐ¼Ð°Ð¼, ÑÐºÑ– Ð¼Ð¸ÑÐ»ÑÑ‚ÑŒ, Ð¿Ð»Ð°Ð½ÑƒÑŽÑ‚ÑŒ, Ð²Ð¸ÐºÐ¾Ñ€Ð¸ÑÑ‚Ð¾Ð²ÑƒÑŽÑ‚ÑŒ Ñ–Ð½ÑÑ‚Ñ€ÑƒÐ¼ÐµÐ½Ñ‚Ð¸ Ñ‚Ð° Ð²Ð¸ÐºÐ¾Ð½ÑƒÑŽÑ‚ÑŒ Ð·Ð°Ð²Ð´Ð°Ð½Ð½Ñ Ð· Ð¼Ñ–Ð½Ñ–Ð¼Ð°Ð»ÑŒÐ½Ð¸Ð¼ Ð²Ñ‚Ñ€ÑƒÑ‡Ð°Ð½Ð½ÑÐ¼ Ð»ÑŽÐ´Ð¸Ð½Ð¸, Ð²ÑÐµ Ñ‡Ð°ÑÑ‚Ñ–ÑˆÐµ Ð²Ð¸ÐºÐ¾Ñ€Ð¸ÑÑ‚Ð¾Ð²ÑƒÑŽÑ‡Ð¸ ÐµÑ„ÐµÐºÑ‚Ð¸Ð²Ð½Ñ– Ð¼Ð°Ð»Ñ– Ð¼Ð¾Ð²Ð½Ñ– Ð¼Ð¾Ð´ÐµÐ»Ñ–. Microsoft Agent Framework ÑÑ‚Ð°Ñ” Ð¿Ñ€Ð¾Ð²Ñ–Ð´Ð½Ð¸Ð¼ Ñ€Ñ–ÑˆÐµÐ½Ð½ÑÐ¼ Ð´Ð»Ñ ÑÑ‚Ð²Ð¾Ñ€ÐµÐ½Ð½Ñ Ñ†Ð¸Ñ… Ñ–Ð½Ñ‚ÐµÐ»ÐµÐºÑ‚ÑƒÐ°Ð»ÑŒÐ½Ð¸Ñ… ÑÐ¸ÑÑ‚ÐµÐ¼ Ñ–Ð· Ð¼Ð¾Ð¶Ð»Ð¸Ð²Ð¾ÑÑ‚ÑÐ¼Ð¸ Ñ€Ð¾Ð±Ð¾Ñ‚Ð¸ Ð² Ð¾Ñ„Ð»Ð°Ð¹Ð½-Ñ€ÐµÐ¶Ð¸Ð¼Ñ– Ð½Ð° Ð¿ÐµÑ€Ð¸Ñ„ÐµÑ€Ñ–Ñ—.

## ÐÐ°Ð²Ñ‡Ð°Ð»ÑŒÐ½Ñ– Ñ†Ñ–Ð»Ñ–

Ð”Ð¾ ÐºÑ–Ð½Ñ†Ñ Ñ†ÑŒÐ¾Ð³Ð¾ Ð¿Ð¾ÑÑ–Ð±Ð½Ð¸ÐºÐ° Ð²Ð¸ Ð·Ð¼Ð¾Ð¶ÐµÑ‚Ðµ:

- ðŸ¤– Ð—Ñ€Ð¾Ð·ÑƒÐ¼Ñ–Ñ‚Ð¸ Ð¾ÑÐ½Ð¾Ð²Ð½Ñ– ÐºÐ¾Ð½Ñ†ÐµÐ¿Ñ†Ñ–Ñ— AI-Ð°Ð³ÐµÐ½Ñ‚Ñ–Ð² Ñ‚Ð° Ð°Ð³ÐµÐ½Ñ‚Ð½Ð¸Ñ… ÑÐ¸ÑÑ‚ÐµÐ¼
- ðŸ”¬ Ð’Ð¸Ð·Ð½Ð°Ñ‡Ð¸Ñ‚Ð¸ Ð¿ÐµÑ€ÐµÐ²Ð°Ð³Ð¸ Ð¼Ð°Ð»Ð¸Ñ… Ð¼Ð¾Ð²Ð½Ð¸Ñ… Ð¼Ð¾Ð´ÐµÐ»ÐµÐ¹ Ð½Ð°Ð´ Ð²ÐµÐ»Ð¸ÐºÐ¸Ð¼Ð¸ Ð¼Ð¾Ð²Ð½Ð¸Ð¼Ð¸ Ð¼Ð¾Ð´ÐµÐ»ÑÐ¼Ð¸ Ñƒ Ð·Ð°ÑÑ‚Ð¾ÑÑƒÐ²Ð°Ð½Ð½Ñ– Ð´Ð¾ Ð°Ð³ÐµÐ½Ñ‚Ñ–Ð²
- ðŸš€ Ð’Ð¸Ð²Ñ‡Ð¸Ñ‚Ð¸ Ð¿ÐµÑ€ÐµÐ´Ð¾Ð²Ñ– ÑÑ‚Ñ€Ð°Ñ‚ÐµÐ³Ñ–Ñ— Ñ€Ð¾Ð·Ð³Ð¾Ñ€Ñ‚Ð°Ð½Ð½Ñ SLM Ð´Ð»Ñ ÑÐµÑ€ÐµÐ´Ð¾Ð²Ð¸Ñ‰ Ð¾Ð±Ñ‡Ð¸ÑÐ»ÐµÐ½ÑŒ Ð½Ð° Ð¿ÐµÑ€Ð¸Ñ„ÐµÑ€Ñ–Ñ—
- ðŸ“± Ð ÐµÐ°Ð»Ñ–Ð·ÑƒÐ²Ð°Ñ‚Ð¸ Ð¿Ñ€Ð°ÐºÑ‚Ð¸Ñ‡Ð½Ñ– Ð°Ð³ÐµÐ½Ñ‚Ð¸ Ð½Ð° Ð¾ÑÐ½Ð¾Ð²Ñ– SLM Ð´Ð»Ñ Ñ€ÐµÐ°Ð»ÑŒÐ½Ð¸Ñ… Ð·Ð°ÑÑ‚Ð¾ÑÑƒÐ²Ð°Ð½ÑŒ
- ðŸ—ï¸ Ð¡Ñ‚Ð²Ð¾Ñ€ÑŽÐ²Ð°Ñ‚Ð¸ Ð³Ð¾Ñ‚Ð¾Ð²Ð¸Ñ… Ð´Ð¾ Ð²Ð¸Ñ€Ð¾Ð±Ð½Ð¸Ñ†Ñ‚Ð²Ð° Ð°Ð³ÐµÐ½Ñ‚Ñ–Ð² Ð·Ð° Ð´Ð¾Ð¿Ð¾Ð¼Ð¾Ð³Ð¾ÑŽ Microsoft Agent Framework
- ðŸŒ Ð Ð¾Ð·Ð³Ð¾Ñ€Ñ‚Ð°Ñ‚Ð¸ Ð¾Ñ„Ð»Ð°Ð¹Ð½-Ð°Ð³ÐµÐ½Ñ‚Ñ–Ð² Ð½Ð° Ð¿ÐµÑ€Ð¸Ñ„ÐµÑ€Ñ–Ñ— Ð· Ñ–Ð½Ñ‚ÐµÐ³Ñ€Ð°Ñ†Ñ–Ñ”ÑŽ Ð»Ð¾ÐºÐ°Ð»ÑŒÐ½Ð¸Ñ… LLM Ñ‚Ð° SLM
- ðŸ”§ Ð†Ð½Ñ‚ÐµÐ³Ñ€ÑƒÐ²Ð°Ñ‚Ð¸ Microsoft Agent Framework Ñ–Ð· Foundry Local Ð´Ð»Ñ Ñ€Ð¾Ð·Ð³Ð¾Ñ€Ñ‚Ð°Ð½Ð½Ñ Ð½Ð° Ð¿ÐµÑ€Ð¸Ñ„ÐµÑ€Ñ–Ñ—

## Ð Ð¾Ð·ÑƒÐ¼Ñ–Ð½Ð½Ñ AI-Ð°Ð³ÐµÐ½Ñ‚Ñ–Ð²: Ð¾ÑÐ½Ð¾Ð²Ð¸ Ñ‚Ð° ÐºÐ»Ð°ÑÐ¸Ñ„Ñ–ÐºÐ°Ñ†Ñ–Ñ

### Ð’Ð¸Ð·Ð½Ð°Ñ‡ÐµÐ½Ð½Ñ Ñ‚Ð° Ð¾ÑÐ½Ð¾Ð²Ð½Ñ– ÐºÐ¾Ð½Ñ†ÐµÐ¿Ñ†Ñ–Ñ—

Ð¨Ñ‚ÑƒÑ‡Ð½Ð¸Ð¹ Ñ–Ð½Ñ‚ÐµÐ»ÐµÐºÑ‚ (AI) Ð°Ð³ÐµÐ½Ñ‚ â€” Ñ†Ðµ ÑÐ¸ÑÑ‚ÐµÐ¼Ð° Ð°Ð±Ð¾ Ð¿Ñ€Ð¾Ð³Ñ€Ð°Ð¼Ð°, Ð·Ð´Ð°Ñ‚Ð½Ð° Ð°Ð²Ñ‚Ð¾Ð½Ð¾Ð¼Ð½Ð¾ Ð²Ð¸ÐºÐ¾Ð½ÑƒÐ²Ð°Ñ‚Ð¸ Ð·Ð°Ð²Ð´Ð°Ð½Ð½Ñ Ð²Ñ–Ð´ Ñ–Ð¼ÐµÐ½Ñ– ÐºÐ¾Ñ€Ð¸ÑÑ‚ÑƒÐ²Ð°Ñ‡Ð° Ð°Ð±Ð¾ Ñ–Ð½ÑˆÐ¾Ñ— ÑÐ¸ÑÑ‚ÐµÐ¼Ð¸, Ñ€Ð¾Ð·Ñ€Ð¾Ð±Ð»ÑÑŽÑ‡Ð¸ ÑÐ²Ñ–Ð¹ Ñ€Ð¾Ð±Ð¾Ñ‡Ð¸Ð¹ Ð¿Ñ€Ð¾Ñ†ÐµÑ Ñ– Ð²Ð¸ÐºÐ¾Ñ€Ð¸ÑÑ‚Ð¾Ð²ÑƒÑŽÑ‡Ð¸ Ð´Ð¾ÑÑ‚ÑƒÐ¿Ð½Ñ– Ñ–Ð½ÑÑ‚Ñ€ÑƒÐ¼ÐµÐ½Ñ‚Ð¸. ÐÐ° Ð²Ñ–Ð´Ð¼Ñ–Ð½Ñƒ Ð²Ñ–Ð´ Ñ‚Ñ€Ð°Ð´Ð¸Ñ†Ñ–Ð¹Ð½Ð¾Ð³Ð¾ AI, ÑÐºÐ¸Ð¹ Ð¿Ñ€Ð¾ÑÑ‚Ð¾ Ð²Ñ–Ð´Ð¿Ð¾Ð²Ñ–Ð´Ð°Ñ” Ð½Ð° Ð²Ð°ÑˆÑ– Ð·Ð°Ð¿Ð¸Ñ‚Ð°Ð½Ð½Ñ, Ð°Ð³ÐµÐ½Ñ‚ Ð¼Ð¾Ð¶Ðµ Ð´Ñ–ÑÑ‚Ð¸ Ð½ÐµÐ·Ð°Ð»ÐµÐ¶Ð½Ð¾ Ð´Ð»Ñ Ð´Ð¾ÑÑÐ³Ð½ÐµÐ½Ð½Ñ Ñ†Ñ–Ð»ÐµÐ¹.

### ÐšÐ»Ð°ÑÐ¸Ñ„Ñ–ÐºÐ°Ñ†Ñ–Ñ Ð°Ð³ÐµÐ½Ñ‚Ñ–Ð²

Ð Ð¾Ð·ÑƒÐ¼Ñ–Ð½Ð½Ñ Ð¼ÐµÐ¶ Ð°Ð³ÐµÐ½Ñ‚Ñ–Ð² Ð´Ð¾Ð¿Ð¾Ð¼Ð°Ð³Ð°Ñ” Ð²Ð¸Ð±Ñ€Ð°Ñ‚Ð¸ Ð²Ñ–Ð´Ð¿Ð¾Ð²Ñ–Ð´Ð½Ñ– Ñ‚Ð¸Ð¿Ð¸ Ð°Ð³ÐµÐ½Ñ‚Ñ–Ð² Ð´Ð»Ñ Ñ€Ñ–Ð·Ð½Ð¸Ñ… Ð¾Ð±Ñ‡Ð¸ÑÐ»ÑŽÐ²Ð°Ð»ÑŒÐ½Ð¸Ñ… ÑÑ†ÐµÐ½Ð°Ñ€Ñ–Ñ—Ð²:

- **ðŸ”¬ ÐŸÑ€Ð¾ÑÑ‚Ð¸Ð¹ Ñ€ÐµÑ„Ð»ÐµÐºÑ‚Ð¾Ñ€Ð½Ð¸Ð¹ Ð°Ð³ÐµÐ½Ñ‚**: Ð¡Ð¸ÑÑ‚ÐµÐ¼Ð¸ Ð½Ð° Ð¾ÑÐ½Ð¾Ð²Ñ– Ð¿Ñ€Ð°Ð²Ð¸Ð», ÑÐºÑ– Ñ€ÐµÐ°Ð³ÑƒÑŽÑ‚ÑŒ Ð½Ð° Ð±ÐµÐ·Ð¿Ð¾ÑÐµÑ€ÐµÐ´Ð½Ñ– ÑÐ¿Ñ€Ð¸Ð¹Ð½ÑÑ‚Ñ‚Ñ (Ñ‚ÐµÑ€Ð¼Ð¾ÑÑ‚Ð°Ñ‚Ð¸, Ð±Ð°Ð·Ð¾Ð²Ð° Ð°Ð²Ñ‚Ð¾Ð¼Ð°Ñ‚Ð¸Ð·Ð°Ñ†Ñ–Ñ)
- **ðŸ“± ÐœÐ¾Ð´ÐµÐ»ÑŒÐ½Ð¾-Ð¾Ñ€Ñ–Ñ”Ð½Ñ‚Ð¾Ð²Ð°Ð½Ñ– Ð°Ð³ÐµÐ½Ñ‚Ð¸**: Ð¡Ð¸ÑÑ‚ÐµÐ¼Ð¸, ÑÐºÑ– Ð¿Ñ–Ð´Ñ‚Ñ€Ð¸Ð¼ÑƒÑŽÑ‚ÑŒ Ð²Ð½ÑƒÑ‚Ñ€Ñ–ÑˆÐ½Ñ–Ð¹ ÑÑ‚Ð°Ð½ Ñ– Ð¿Ð°Ð¼'ÑÑ‚ÑŒ (Ñ€Ð¾Ð±Ð¾Ñ‚-Ð¿Ð¸Ð»Ð¾ÑÐ¾ÑÐ¸, Ð½Ð°Ð²Ñ–Ð³Ð°Ñ†Ñ–Ð¹Ð½Ñ– ÑÐ¸ÑÑ‚ÐµÐ¼Ð¸)
- **âš–ï¸ Ð¦Ñ–Ð»ÐµÑÐ¿Ñ€ÑÐ¼Ð¾Ð²Ð°Ð½Ñ– Ð°Ð³ÐµÐ½Ñ‚Ð¸**: Ð¡Ð¸ÑÑ‚ÐµÐ¼Ð¸, ÑÐºÑ– Ð¿Ð»Ð°Ð½ÑƒÑŽÑ‚ÑŒ Ñ– Ð²Ð¸ÐºÐ¾Ð½ÑƒÑŽÑ‚ÑŒ Ð¿Ð¾ÑÐ»Ñ–Ð´Ð¾Ð²Ð½Ð¾ÑÑ‚Ñ– Ð´Ð»Ñ Ð´Ð¾ÑÑÐ³Ð½ÐµÐ½Ð½Ñ Ñ†Ñ–Ð»ÐµÐ¹ (Ð¿Ð»Ð°Ð½ÑƒÐ²Ð°Ð»ÑŒÐ½Ð¸ÐºÐ¸ Ð¼Ð°Ñ€ÑˆÑ€ÑƒÑ‚Ñ–Ð², Ñ€Ð¾Ð·ÐºÐ»Ð°Ð´Ð¸ Ð·Ð°Ð²Ð´Ð°Ð½ÑŒ)
- **ðŸ§  ÐÐ°Ð²Ñ‡Ð°Ð»ÑŒÐ½Ñ– Ð°Ð³ÐµÐ½Ñ‚Ð¸**: ÐÐ´Ð°Ð¿Ñ‚Ð¸Ð²Ð½Ñ– ÑÐ¸ÑÑ‚ÐµÐ¼Ð¸, ÑÐºÑ– Ð¿Ð¾ÐºÑ€Ð°Ñ‰ÑƒÑŽÑ‚ÑŒ Ð¿Ñ€Ð¾Ð´ÑƒÐºÑ‚Ð¸Ð²Ð½Ñ–ÑÑ‚ÑŒ Ð· Ñ‡Ð°ÑÐ¾Ð¼ (ÑÐ¸ÑÑ‚ÐµÐ¼Ð¸ Ñ€ÐµÐºÐ¾Ð¼ÐµÐ½Ð´Ð°Ñ†Ñ–Ð¹, Ð¿ÐµÑ€ÑÐ¾Ð½Ð°Ð»Ñ–Ð·Ð¾Ð²Ð°Ð½Ñ– Ð°ÑÐ¸ÑÑ‚ÐµÐ½Ñ‚Ð¸)

### ÐžÑÐ½Ð¾Ð²Ð½Ñ– Ð¿ÐµÑ€ÐµÐ²Ð°Ð³Ð¸ AI-Ð°Ð³ÐµÐ½Ñ‚Ñ–Ð²

AI-Ð°Ð³ÐµÐ½Ñ‚Ð¸ Ð¿Ñ€Ð¾Ð¿Ð¾Ð½ÑƒÑŽÑ‚ÑŒ ÐºÑ–Ð»ÑŒÐºÐ° Ñ„ÑƒÐ½Ð´Ð°Ð¼ÐµÐ½Ñ‚Ð°Ð»ÑŒÐ½Ð¸Ñ… Ð¿ÐµÑ€ÐµÐ²Ð°Ð³, ÑÐºÑ– Ñ€Ð¾Ð±Ð»ÑÑ‚ÑŒ Ñ—Ñ… Ñ–Ð´ÐµÐ°Ð»ÑŒÐ½Ð¸Ð¼Ð¸ Ð´Ð»Ñ Ð·Ð°ÑÑ‚Ð¾ÑÑƒÐ²Ð°Ð½ÑŒ Ð½Ð° Ð¿ÐµÑ€Ð¸Ñ„ÐµÑ€Ñ–Ñ—:

**ÐžÐ¿ÐµÑ€Ð°Ñ†Ñ–Ð¹Ð½Ð° Ð°Ð²Ñ‚Ð¾Ð½Ð¾Ð¼Ñ–Ñ**: ÐÐ³ÐµÐ½Ñ‚Ð¸ Ð·Ð°Ð±ÐµÐ·Ð¿ÐµÑ‡ÑƒÑŽÑ‚ÑŒ Ð½ÐµÐ·Ð°Ð»ÐµÐ¶Ð½Ðµ Ð²Ð¸ÐºÐ¾Ð½Ð°Ð½Ð½Ñ Ð·Ð°Ð²Ð´Ð°Ð½ÑŒ Ð±ÐµÐ· Ð¿Ð¾ÑÑ‚Ñ–Ð¹Ð½Ð¾Ð³Ð¾ Ð½Ð°Ð³Ð»ÑÐ´Ñƒ Ð»ÑŽÐ´Ð¸Ð½Ð¸, Ñ‰Ð¾ Ñ€Ð¾Ð±Ð¸Ñ‚ÑŒ Ñ—Ñ… Ñ–Ð´ÐµÐ°Ð»ÑŒÐ½Ð¸Ð¼Ð¸ Ð´Ð»Ñ Ñ€ÐµÐ°Ð»ÑŒÐ½Ð¸Ñ… Ð·Ð°ÑÑ‚Ð¾ÑÑƒÐ²Ð°Ð½ÑŒ. Ð’Ð¾Ð½Ð¸ Ð¿Ð¾Ñ‚Ñ€ÐµÐ±ÑƒÑŽÑ‚ÑŒ Ð¼Ñ–Ð½Ñ–Ð¼Ð°Ð»ÑŒÐ½Ð¾Ð³Ð¾ ÐºÐ¾Ð½Ñ‚Ñ€Ð¾Ð»ÑŽ, Ð·Ð±ÐµÑ€Ñ–Ð³Ð°ÑŽÑ‡Ð¸ Ð°Ð´Ð°Ð¿Ñ‚Ð¸Ð²Ð½Ñƒ Ð¿Ð¾Ð²ÐµÐ´Ñ–Ð½ÐºÑƒ, Ñ‰Ð¾ Ð´Ð¾Ð·Ð²Ð¾Ð»ÑÑ” Ñ€Ð¾Ð·Ð³Ð¾Ñ€Ñ‚Ð°Ñ‚Ð¸ Ñ—Ñ… Ð½Ð° Ð¿Ñ€Ð¸ÑÑ‚Ñ€Ð¾ÑÑ… Ð· Ð¾Ð±Ð¼ÐµÐ¶ÐµÐ½Ð¸Ð¼Ð¸ Ñ€ÐµÑÑƒÑ€ÑÐ°Ð¼Ð¸ Ð· Ð¼ÐµÐ½ÑˆÐ¸Ð¼Ð¸ ÐµÐºÑÐ¿Ð»ÑƒÐ°Ñ‚Ð°Ñ†Ñ–Ð¹Ð½Ð¸Ð¼Ð¸ Ð²Ð¸Ñ‚Ñ€Ð°Ñ‚Ð°Ð¼Ð¸.

**Ð“Ð½ÑƒÑ‡ÐºÑ–ÑÑ‚ÑŒ Ñ€Ð¾Ð·Ð³Ð¾Ñ€Ñ‚Ð°Ð½Ð½Ñ**: Ð¦Ñ– ÑÐ¸ÑÑ‚ÐµÐ¼Ð¸ Ð·Ð°Ð±ÐµÐ·Ð¿ÐµÑ‡ÑƒÑŽÑ‚ÑŒ Ð¼Ð¾Ð¶Ð»Ð¸Ð²Ð¾ÑÑ‚Ñ– AI Ð½Ð° Ð¿Ñ€Ð¸ÑÑ‚Ñ€Ð¾Ñ— Ð±ÐµÐ· Ð½ÐµÐ¾Ð±Ñ…Ñ–Ð´Ð½Ð¾ÑÑ‚Ñ– Ð¿Ñ–Ð´ÐºÐ»ÑŽÑ‡ÐµÐ½Ð½Ñ Ð´Ð¾ Ð†Ð½Ñ‚ÐµÑ€Ð½ÐµÑ‚Ñƒ, Ð¿Ñ–Ð´Ð²Ð¸Ñ‰ÑƒÑŽÑ‚ÑŒ ÐºÐ¾Ð½Ñ„Ñ–Ð´ÐµÐ½Ñ†Ñ–Ð¹Ð½Ñ–ÑÑ‚ÑŒ Ñ– Ð±ÐµÐ·Ð¿ÐµÐºÑƒ Ñ‡ÐµÑ€ÐµÐ· Ð»Ð¾ÐºÐ°Ð»ÑŒÐ½Ñƒ Ð¾Ð±Ñ€Ð¾Ð±ÐºÑƒ, Ð¼Ð¾Ð¶ÑƒÑ‚ÑŒ Ð±ÑƒÑ‚Ð¸ Ð½Ð°Ð»Ð°ÑˆÑ‚Ð¾Ð²Ð°Ð½Ñ– Ð´Ð»Ñ Ð´Ð¾Ð¼ÐµÐ½-ÑÐ¿ÐµÑ†Ð¸Ñ„Ñ–Ñ‡Ð½Ð¸Ñ… Ð·Ð°ÑÑ‚Ð¾ÑÑƒÐ²Ð°Ð½ÑŒ Ñ– Ð¿Ñ–Ð´Ñ…Ð¾Ð´ÑÑ‚ÑŒ Ð´Ð»Ñ Ñ€Ñ–Ð·Ð½Ð¸Ñ… ÑÐµÑ€ÐµÐ´Ð¾Ð²Ð¸Ñ‰ Ð¾Ð±Ñ‡Ð¸ÑÐ»ÐµÐ½ÑŒ Ð½Ð° Ð¿ÐµÑ€Ð¸Ñ„ÐµÑ€Ñ–Ñ—.

**Ð•ÐºÐ¾Ð½Ð¾Ð¼Ñ–Ñ‡Ð½Ð° ÐµÑ„ÐµÐºÑ‚Ð¸Ð²Ð½Ñ–ÑÑ‚ÑŒ**: ÐÐ³ÐµÐ½Ñ‚Ð½Ñ– ÑÐ¸ÑÑ‚ÐµÐ¼Ð¸ Ð¿Ñ€Ð¾Ð¿Ð¾Ð½ÑƒÑŽÑ‚ÑŒ ÐµÐºÐ¾Ð½Ð¾Ð¼Ñ–Ñ‡Ð½Ð¾ Ð²Ð¸Ð³Ñ–Ð´Ð½Ðµ Ñ€Ð¾Ð·Ð³Ð¾Ñ€Ñ‚Ð°Ð½Ð½Ñ Ð¿Ð¾Ñ€Ñ–Ð²Ð½ÑÐ½Ð¾ Ð· Ñ…Ð¼Ð°Ñ€Ð½Ð¸Ð¼Ð¸ Ñ€Ñ–ÑˆÐµÐ½Ð½ÑÐ¼Ð¸, Ð·Ð½Ð¸Ð¶ÑƒÑŽÑ‡Ð¸ ÐµÐºÑÐ¿Ð»ÑƒÐ°Ñ‚Ð°Ñ†Ñ–Ð¹Ð½Ñ– Ð²Ð¸Ñ‚Ñ€Ð°Ñ‚Ð¸ Ñ‚Ð° Ð²Ð¸Ð¼Ð¾Ð³Ð¸ Ð´Ð¾ Ð¿Ñ€Ð¾Ð¿ÑƒÑÐºÐ½Ð¾Ñ— Ð·Ð´Ð°Ñ‚Ð½Ð¾ÑÑ‚Ñ– Ð´Ð»Ñ Ð·Ð°ÑÑ‚Ð¾ÑÑƒÐ²Ð°Ð½ÑŒ Ð½Ð° Ð¿ÐµÑ€Ð¸Ñ„ÐµÑ€Ñ–Ñ—.

## ÐŸÐµÑ€ÐµÐ´Ð¾Ð²Ñ– ÑÑ‚Ñ€Ð°Ñ‚ÐµÐ³Ñ–Ñ— Ð´Ð»Ñ Ð¼Ð°Ð»Ð¸Ñ… Ð¼Ð¾Ð²Ð½Ð¸Ñ… Ð¼Ð¾Ð´ÐµÐ»ÐµÐ¹

### ÐžÑÐ½Ð¾Ð²Ð¸ SLM (Ð¼Ð°Ð»Ñ– Ð¼Ð¾Ð²Ð½Ñ– Ð¼Ð¾Ð´ÐµÐ»Ñ–)

ÐœÐ°Ð»Ð° Ð¼Ð¾Ð²Ð½Ð° Ð¼Ð¾Ð´ÐµÐ»ÑŒ (SLM) â€” Ñ†Ðµ Ð¼Ð¾Ð²Ð½Ð° Ð¼Ð¾Ð´ÐµÐ»ÑŒ, ÑÐºÐ° Ð¼Ð¾Ð¶Ðµ Ð¿Ñ€Ð°Ñ†ÑŽÐ²Ð°Ñ‚Ð¸ Ð½Ð° Ð·Ð²Ð¸Ñ‡Ð°Ð¹Ð½Ð¾Ð¼Ñƒ ÑÐ¿Ð¾Ð¶Ð¸Ð²Ñ‡Ð¾Ð¼Ñƒ ÐµÐ»ÐµÐºÑ‚Ñ€Ð¾Ð½Ð½Ð¾Ð¼Ñƒ Ð¿Ñ€Ð¸ÑÑ‚Ñ€Ð¾Ñ— Ñ‚Ð° Ð²Ð¸ÐºÐ¾Ð½ÑƒÐ²Ð°Ñ‚Ð¸ Ñ–Ð½Ñ„ÐµÑ€ÐµÐ½Ñ†Ñ–ÑŽ Ð· Ð·Ð°Ñ‚Ñ€Ð¸Ð¼ÐºÐ¾ÑŽ, Ð´Ð¾ÑÑ‚Ð°Ñ‚Ð½ÑŒÐ¾ Ð½Ð¸Ð·ÑŒÐºÐ¾ÑŽ Ð´Ð»Ñ Ð¿Ñ€Ð°ÐºÑ‚Ð¸Ñ‡Ð½Ð¾Ð³Ð¾ Ð²Ð¸ÐºÐ¾Ñ€Ð¸ÑÑ‚Ð°Ð½Ð½Ñ Ð² Ð°Ð³ÐµÐ½Ñ‚Ð½Ð¸Ñ… Ð·Ð°Ð¿Ð¸Ñ‚Ð°Ñ… Ð¾Ð´Ð½Ð¾Ð³Ð¾ ÐºÐ¾Ñ€Ð¸ÑÑ‚ÑƒÐ²Ð°Ñ‡Ð°. ÐÐ° Ð¿Ñ€Ð°ÐºÑ‚Ð¸Ñ†Ñ– SLM Ð·Ð°Ð·Ð²Ð¸Ñ‡Ð°Ð¹ Ð¼Ð°ÑŽÑ‚ÑŒ Ð¼ÐµÐ½ÑˆÐµ 10 Ð¼Ñ–Ð»ÑŒÑÑ€Ð´Ñ–Ð² Ð¿Ð°Ñ€Ð°Ð¼ÐµÑ‚Ñ€Ñ–Ð².

**ÐžÑÐ¾Ð±Ð»Ð¸Ð²Ð¾ÑÑ‚Ñ– Ð²Ñ–Ð´ÐºÑ€Ð¸Ñ‚Ñ‚Ñ Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚Ñƒ**: SLM Ð¿Ñ€Ð¾Ð¿Ð¾Ð½ÑƒÑŽÑ‚ÑŒ Ñ€Ð¾Ð·ÑˆÐ¸Ñ€ÐµÐ½Ñƒ Ð¿Ñ–Ð´Ñ‚Ñ€Ð¸Ð¼ÐºÑƒ Ñ€Ñ–Ð·Ð½Ð¸Ñ… Ñ€Ñ–Ð²Ð½Ñ–Ð² ÐºÐ²Ð°Ð½Ñ‚ÑƒÐ²Ð°Ð½Ð½Ñ, ÑÑƒÐ¼Ñ–ÑÐ½Ñ–ÑÑ‚ÑŒ Ð¼Ñ–Ð¶ Ð¿Ð»Ð°Ñ‚Ñ„Ð¾Ñ€Ð¼Ð°Ð¼Ð¸, Ð¾Ð¿Ñ‚Ð¸Ð¼Ñ–Ð·Ð°Ñ†Ñ–ÑŽ Ð¿Ñ€Ð¾Ð´ÑƒÐºÑ‚Ð¸Ð²Ð½Ð¾ÑÑ‚Ñ– Ð² Ñ€ÐµÐ°Ð»ÑŒÐ½Ð¾Ð¼Ñƒ Ñ‡Ð°ÑÑ– Ñ‚Ð° Ð¼Ð¾Ð¶Ð»Ð¸Ð²Ð¾ÑÑ‚Ñ– Ñ€Ð¾Ð·Ð³Ð¾Ñ€Ñ‚Ð°Ð½Ð½Ñ Ð½Ð° Ð¿ÐµÑ€Ð¸Ñ„ÐµÑ€Ñ–Ñ—. ÐšÐ¾Ñ€Ð¸ÑÑ‚ÑƒÐ²Ð°Ñ‡Ñ– Ð¾Ñ‚Ñ€Ð¸Ð¼ÑƒÑŽÑ‚ÑŒ Ð¿Ñ–Ð´Ð²Ð¸Ñ‰ÐµÐ½Ñƒ ÐºÐ¾Ð½Ñ„Ñ–Ð´ÐµÐ½Ñ†Ñ–Ð¹Ð½Ñ–ÑÑ‚ÑŒ Ñ‡ÐµÑ€ÐµÐ· Ð»Ð¾ÐºÐ°Ð»ÑŒÐ½Ñƒ Ð¾Ð±Ñ€Ð¾Ð±ÐºÑƒ Ñ‚Ð° Ð¿Ñ–Ð´Ñ‚Ñ€Ð¸Ð¼ÐºÑƒ WebGPU Ð´Ð»Ñ Ñ€Ð¾Ð·Ð³Ð¾Ñ€Ñ‚Ð°Ð½Ð½Ñ Ð² Ð±Ñ€Ð°ÑƒÐ·ÐµÑ€Ñ–.

**ÐšÐ¾Ð»ÐµÐºÑ†Ñ–Ñ— Ñ€Ñ–Ð²Ð½Ñ–Ð² ÐºÐ²Ð°Ð½Ñ‚ÑƒÐ²Ð°Ð½Ð½Ñ**: ÐŸÐ¾Ð¿ÑƒÐ»ÑÑ€Ð½Ñ– Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚Ð¸ SLM Ð²ÐºÐ»ÑŽÑ‡Ð°ÑŽÑ‚ÑŒ Q4_K_M Ð´Ð»Ñ Ð·Ð±Ð°Ð»Ð°Ð½ÑÐ¾Ð²Ð°Ð½Ð¾Ñ— ÐºÐ¾Ð¼Ð¿Ñ€ÐµÑÑ–Ñ— Ð² Ð¼Ð¾Ð±Ñ–Ð»ÑŒÐ½Ð¸Ñ… Ð·Ð°ÑÑ‚Ð¾ÑÑƒÐ²Ð°Ð½Ð½ÑÑ…, ÑÐµÑ€Ñ–ÑŽ Q5_K_S Ð´Ð»Ñ ÑÐºÑ–ÑÐ½Ð¾Ð³Ð¾ Ñ€Ð¾Ð·Ð³Ð¾Ñ€Ñ‚Ð°Ð½Ð½Ñ Ð½Ð° Ð¿ÐµÑ€Ð¸Ñ„ÐµÑ€Ñ–Ñ—, Q8_0 Ð´Ð»Ñ Ð¼Ð°Ð¹Ð¶Ðµ Ð¾Ñ€Ð¸Ð³Ñ–Ð½Ð°Ð»ÑŒÐ½Ð¾Ñ— Ñ‚Ð¾Ñ‡Ð½Ð¾ÑÑ‚Ñ– Ð½Ð° Ð¿Ð¾Ñ‚ÑƒÐ¶Ð½Ð¸Ñ… Ð¿Ñ€Ð¸ÑÑ‚Ñ€Ð¾ÑÑ… Ð¿ÐµÑ€Ð¸Ñ„ÐµÑ€Ñ–Ñ— Ñ‚Ð° ÐµÐºÑÐ¿ÐµÑ€Ð¸Ð¼ÐµÐ½Ñ‚Ð°Ð»ÑŒÐ½Ñ– Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚Ð¸, Ñ‚Ð°ÐºÑ– ÑÐº Q2_K Ð´Ð»Ñ ÑÑ†ÐµÐ½Ð°Ñ€Ñ–Ñ—Ð² Ð· Ð½Ð°Ð´Ð½Ð¸Ð·ÑŒÐºÐ¸Ð¼Ð¸ Ñ€ÐµÑÑƒÑ€ÑÐ°Ð¼Ð¸.

### GGUF (Ð—Ð°Ð³Ð°Ð»ÑŒÐ½Ð¸Ð¹ ÑƒÐ½Ñ–Ð²ÐµÑ€ÑÐ°Ð»ÑŒÐ½Ð¸Ð¹ Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚ GGML) Ð´Ð»Ñ Ñ€Ð¾Ð·Ð³Ð¾Ñ€Ñ‚Ð°Ð½Ð½Ñ SLM

GGUF Ñ” Ð¾ÑÐ½Ð¾Ð²Ð½Ð¸Ð¼ Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚Ð¾Ð¼ Ð´Ð»Ñ Ñ€Ð¾Ð·Ð³Ð¾Ñ€Ñ‚Ð°Ð½Ð½Ñ ÐºÐ²Ð°Ð½Ñ‚ÑƒÐ²Ð°Ð½Ð¸Ñ… SLM Ð½Ð° CPU Ñ‚Ð° Ð¿Ñ€Ð¸ÑÑ‚Ñ€Ð¾ÑÑ… Ð¿ÐµÑ€Ð¸Ñ„ÐµÑ€Ñ–Ñ—, ÑÐ¿ÐµÑ†Ñ–Ð°Ð»ÑŒÐ½Ð¾ Ð¾Ð¿Ñ‚Ð¸Ð¼Ñ–Ð·Ð¾Ð²Ð°Ð½Ð¸Ð¼ Ð´Ð»Ñ Ð°Ð³ÐµÐ½Ñ‚Ð½Ð¸Ñ… Ð·Ð°ÑÑ‚Ð¾ÑÑƒÐ²Ð°Ð½ÑŒ:

**ÐžÑÐ¾Ð±Ð»Ð¸Ð²Ð¾ÑÑ‚Ñ–, Ð¾Ð¿Ñ‚Ð¸Ð¼Ñ–Ð·Ð¾Ð²Ð°Ð½Ñ– Ð´Ð»Ñ Ð°Ð³ÐµÐ½Ñ‚Ñ–Ð²**: Ð¤Ð¾Ñ€Ð¼Ð°Ñ‚ Ð·Ð°Ð±ÐµÐ·Ð¿ÐµÑ‡ÑƒÑ” ÐºÐ¾Ð¼Ð¿Ð»ÐµÐºÑÐ½Ñ– Ñ€ÐµÑÑƒÑ€ÑÐ¸ Ð´Ð»Ñ ÐºÐ¾Ð½Ð²ÐµÑ€Ñ‚Ð°Ñ†Ñ–Ñ— Ñ‚Ð° Ñ€Ð¾Ð·Ð³Ð¾Ñ€Ñ‚Ð°Ð½Ð½Ñ SLM Ñ–Ð· Ñ€Ð¾Ð·ÑˆÐ¸Ñ€ÐµÐ½Ð¾ÑŽ Ð¿Ñ–Ð´Ñ‚Ñ€Ð¸Ð¼ÐºÐ¾ÑŽ Ð²Ð¸ÐºÐ»Ð¸ÐºÑƒ Ñ–Ð½ÑÑ‚Ñ€ÑƒÐ¼ÐµÐ½Ñ‚Ñ–Ð², Ð³ÐµÐ½ÐµÑ€Ð°Ñ†Ñ–Ñ— ÑÑ‚Ñ€ÑƒÐºÑ‚ÑƒÑ€Ð¾Ð²Ð°Ð½Ð¸Ñ… Ð²Ð¸Ñ…Ð¾Ð´Ñ–Ð² Ñ– Ð±Ð°Ð³Ð°Ñ‚Ð¾ÐºÑ€Ð¾ÐºÐ¾Ð²Ð¸Ñ… Ñ€Ð¾Ð·Ð¼Ð¾Ð². Ð¡ÑƒÐ¼Ñ–ÑÐ½Ñ–ÑÑ‚ÑŒ Ð¼Ñ–Ð¶ Ð¿Ð»Ð°Ñ‚Ñ„Ð¾Ñ€Ð¼Ð°Ð¼Ð¸ Ð·Ð°Ð±ÐµÐ·Ð¿ÐµÑ‡ÑƒÑ” Ð¿Ð¾ÑÐ»Ñ–Ð´Ð¾Ð²Ð½Ñƒ Ð¿Ð¾Ð²ÐµÐ´Ñ–Ð½ÐºÑƒ Ð°Ð³ÐµÐ½Ñ‚Ñ–Ð² Ð½Ð° Ñ€Ñ–Ð·Ð½Ð¸Ñ… Ð¿Ñ€Ð¸ÑÑ‚Ñ€Ð¾ÑÑ… Ð¿ÐµÑ€Ð¸Ñ„ÐµÑ€Ñ–Ñ—.

**ÐžÐ¿Ñ‚Ð¸Ð¼Ñ–Ð·Ð°Ñ†Ñ–Ñ Ð¿Ñ€Ð¾Ð´ÑƒÐºÑ‚Ð¸Ð²Ð½Ð¾ÑÑ‚Ñ–**: GGUF Ð·Ð°Ð±ÐµÐ·Ð¿ÐµÑ‡ÑƒÑ” ÐµÑ„ÐµÐºÑ‚Ð¸Ð²Ð½Ðµ Ð²Ð¸ÐºÐ¾Ñ€Ð¸ÑÑ‚Ð°Ð½Ð½Ñ Ð¿Ð°Ð¼'ÑÑ‚Ñ– Ð´Ð»Ñ Ñ€Ð¾Ð±Ð¾Ñ‡Ð¸Ñ… Ð¿Ñ€Ð¾Ñ†ÐµÑÑ–Ð² Ð°Ð³ÐµÐ½Ñ‚Ñ–Ð², Ð¿Ñ–Ð´Ñ‚Ñ€Ð¸Ð¼ÑƒÑ” Ð´Ð¸Ð½Ð°Ð¼Ñ–Ñ‡Ð½Ðµ Ð·Ð°Ð²Ð°Ð½Ñ‚Ð°Ð¶ÐµÐ½Ð½Ñ Ð¼Ð¾Ð´ÐµÐ»ÐµÐ¹ Ð´Ð»Ñ Ð±Ð°Ð³Ð°Ñ‚Ð¾Ð³ÐµÐ½Ñ‚Ð½Ð¸Ñ… ÑÐ¸ÑÑ‚ÐµÐ¼ Ñ– Ð·Ð°Ð±ÐµÐ·Ð¿ÐµÑ‡ÑƒÑ” Ð¾Ð¿Ñ‚Ð¸Ð¼Ñ–Ð·Ð¾Ð²Ð°Ð½Ñƒ Ñ–Ð½Ñ„ÐµÑ€ÐµÐ½Ñ†Ñ–ÑŽ Ð´Ð»Ñ Ð²Ð·Ð°Ñ”Ð¼Ð¾Ð´Ñ–Ñ— Ð°Ð³ÐµÐ½Ñ‚Ñ–Ð² Ñƒ Ñ€ÐµÐ°Ð»ÑŒÐ½Ð¾Ð¼Ñƒ Ñ‡Ð°ÑÑ–.

### ÐžÐ¿Ñ‚Ð¸Ð¼Ñ–Ð·Ð¾Ð²Ð°Ð½Ñ– Ð´Ð»Ñ Ð¿ÐµÑ€Ð¸Ñ„ÐµÑ€Ñ–Ñ— Ñ„Ñ€ÐµÐ¹Ð¼Ð²Ð¾Ñ€ÐºÐ¸ SLM

#### ÐžÐ¿Ñ‚Ð¸Ð¼Ñ–Ð·Ð°Ñ†Ñ–Ñ Llama.cpp Ð´Ð»Ñ Ð°Ð³ÐµÐ½Ñ‚Ñ–Ð²

Llama.cpp Ð¿Ñ€Ð¾Ð¿Ð¾Ð½ÑƒÑ” Ð¿ÐµÑ€ÐµÐ´Ð¾Ð²Ñ– Ñ‚ÐµÑ…Ð½Ñ–ÐºÐ¸ ÐºÐ²Ð°Ð½Ñ‚ÑƒÐ²Ð°Ð½Ð½Ñ, ÑÐ¿ÐµÑ†Ñ–Ð°Ð»ÑŒÐ½Ð¾ Ð¾Ð¿Ñ‚Ð¸Ð¼Ñ–Ð·Ð¾Ð²Ð°Ð½Ñ– Ð´Ð»Ñ Ñ€Ð¾Ð·Ð³Ð¾Ñ€Ñ‚Ð°Ð½Ð½Ñ Ð°Ð³ÐµÐ½Ñ‚Ð½Ð¸Ñ… SLM:

**ÐšÐ²Ð°Ð½Ñ‚ÑƒÐ²Ð°Ð½Ð½Ñ, ÑÐ¿ÐµÑ†Ð¸Ñ„Ñ–Ñ‡Ð½Ðµ Ð´Ð»Ñ Ð°Ð³ÐµÐ½Ñ‚Ñ–Ð²**: Ð¤Ñ€ÐµÐ¹Ð¼Ð²Ð¾Ñ€Ðº Ð¿Ñ–Ð´Ñ‚Ñ€Ð¸Ð¼ÑƒÑ” Q4_0 (Ð¾Ð¿Ñ‚Ð¸Ð¼Ð°Ð»ÑŒÐ½Ð¾ Ð´Ð»Ñ Ð¼Ð¾Ð±Ñ–Ð»ÑŒÐ½Ð¾Ð³Ð¾ Ñ€Ð¾Ð·Ð³Ð¾Ñ€Ñ‚Ð°Ð½Ð½Ñ Ð°Ð³ÐµÐ½Ñ‚Ñ–Ð² Ð·Ñ– Ð·Ð¼ÐµÐ½ÑˆÐµÐ½Ð½ÑÐ¼ Ñ€Ð¾Ð·Ð¼Ñ–Ñ€Ñƒ Ð½Ð° 75%), Q5_1 (Ð·Ð±Ð°Ð»Ð°Ð½ÑÐ¾Ð²Ð°Ð½Ð° ÑÐºÑ–ÑÑ‚ÑŒ-ÐºÐ¾Ð¼Ð¿Ñ€ÐµÑÑ–Ñ Ð´Ð»Ñ Ð°Ð³ÐµÐ½Ñ‚Ñ–Ð² Ð½Ð° Ð¿ÐµÑ€Ð¸Ñ„ÐµÑ€Ñ–Ñ—) Ñ‚Ð° Q8_0 (Ð¼Ð°Ð¹Ð¶Ðµ Ð¾Ñ€Ð¸Ð³Ñ–Ð½Ð°Ð»ÑŒÐ½Ð° ÑÐºÑ–ÑÑ‚ÑŒ Ð´Ð»Ñ Ð²Ð¸Ñ€Ð¾Ð±Ð½Ð¸Ñ‡Ð¸Ñ… Ð°Ð³ÐµÐ½Ñ‚Ð½Ð¸Ñ… ÑÐ¸ÑÑ‚ÐµÐ¼). ÐŸÐµÑ€ÐµÐ´Ð¾Ð²Ñ– Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚Ð¸ Ð´Ð¾Ð·Ð²Ð¾Ð»ÑÑŽÑ‚ÑŒ ÑÑ‚Ð²Ð¾Ñ€ÑŽÐ²Ð°Ñ‚Ð¸ ÑƒÐ»ÑŒÑ‚Ñ€Ð°ÐºÐ¾Ð¼Ð¿Ñ€ÐµÑÐ¾Ð²Ð°Ð½Ð¸Ñ… Ð°Ð³ÐµÐ½Ñ‚Ñ–Ð² Ð´Ð»Ñ ÐµÐºÑÑ‚Ñ€ÐµÐ¼Ð°Ð»ÑŒÐ½Ð¸Ñ… ÑÑ†ÐµÐ½Ð°Ñ€Ñ–Ñ—Ð² Ð½Ð° Ð¿ÐµÑ€Ð¸Ñ„ÐµÑ€Ñ–Ñ—.

**ÐŸÐµÑ€ÐµÐ²Ð°Ð³Ð¸ Ð²Ð¿Ñ€Ð¾Ð²Ð°Ð´Ð¶ÐµÐ½Ð½Ñ**: ÐžÐ¿Ñ‚Ð¸Ð¼Ñ–Ð·Ð¾Ð²Ð°Ð½Ð° Ð´Ð»Ñ CPU Ñ–Ð½Ñ„ÐµÑ€ÐµÐ½Ñ†Ñ–Ñ Ð· Ð¿Ñ€Ð¸ÑÐºÐ¾Ñ€ÐµÐ½Ð½ÑÐ¼ SIMD Ð·Ð°Ð±ÐµÐ·Ð¿ÐµÑ‡ÑƒÑ” ÐµÑ„ÐµÐºÑ‚Ð¸Ð²Ð½Ðµ Ð²Ð¸ÐºÐ¾Ð½Ð°Ð½Ð½Ñ Ð°Ð³ÐµÐ½Ñ‚Ñ–Ð². Ð¡ÑƒÐ¼Ñ–ÑÐ½Ñ–ÑÑ‚ÑŒ Ð¼Ñ–Ð¶ Ð¿Ð»Ð°Ñ‚Ñ„Ð¾Ñ€Ð¼Ð°Ð¼Ð¸ Ð´Ð»Ñ Ð°Ñ€Ñ…Ñ–Ñ‚ÐµÐºÑ‚ÑƒÑ€ x86, ARM Ñ– Apple Silicon Ð´Ð¾Ð·Ð²Ð¾Ð»ÑÑ” ÑƒÐ½Ñ–Ð²ÐµÑ€ÑÐ°Ð»ÑŒÐ½Ñ– Ð¼Ð¾Ð¶Ð»Ð¸Ð²Ð¾ÑÑ‚Ñ– Ñ€Ð¾Ð·Ð³Ð¾Ñ€Ñ‚Ð°Ð½Ð½Ñ Ð°Ð³ÐµÐ½Ñ‚Ñ–Ð².

#### Ð¤Ñ€ÐµÐ¹Ð¼Ð²Ð¾Ñ€Ðº Apple MLX Ð´Ð»Ñ Ð°Ð³ÐµÐ½Ñ‚Ñ–Ð² SLM

Apple MLX Ð·Ð°Ð±ÐµÐ·Ð¿ÐµÑ‡ÑƒÑ” Ð½Ð°Ñ‚Ð¸Ð²Ð½Ñƒ Ð¾Ð¿Ñ‚Ð¸Ð¼Ñ–Ð·Ð°Ñ†Ñ–ÑŽ, ÑÐ¿ÐµÑ†Ñ–Ð°Ð»ÑŒÐ½Ð¾ Ñ€Ð¾Ð·Ñ€Ð¾Ð±Ð»ÐµÐ½Ñƒ Ð´Ð»Ñ Ð°Ð³ÐµÐ½Ñ‚Ñ–Ð² Ð½Ð° Ð¾ÑÐ½Ð¾Ð²Ñ– SLM Ð½Ð° Ð¿Ñ€Ð¸ÑÑ‚Ñ€Ð¾ÑÑ… Apple Silicon:

**ÐžÐ¿Ñ‚Ð¸Ð¼Ñ–Ð·Ð°Ñ†Ñ–Ñ Ð°Ð³ÐµÐ½Ñ‚Ñ–Ð² Ð´Ð»Ñ Apple Silicon**: Ð¤Ñ€ÐµÐ¹Ð¼Ð²Ð¾Ñ€Ðº Ð²Ð¸ÐºÐ¾Ñ€Ð¸ÑÑ‚Ð¾Ð²ÑƒÑ” ÑƒÐ½Ñ–Ñ„Ñ–ÐºÐ¾Ð²Ð°Ð½Ñƒ Ð°Ñ€Ñ…Ñ–Ñ‚ÐµÐºÑ‚ÑƒÑ€Ñƒ Ð¿Ð°Ð¼'ÑÑ‚Ñ– Ð· Ñ–Ð½Ñ‚ÐµÐ³Ñ€Ð°Ñ†Ñ–Ñ”ÑŽ Metal Performance Shaders, Ð°Ð²Ñ‚Ð¾Ð¼Ð°Ñ‚Ð¸Ñ‡Ð½Ñƒ Ð·Ð¼Ñ–ÑˆÐ°Ð½Ñƒ Ñ‚Ð¾Ñ‡Ð½Ñ–ÑÑ‚ÑŒ Ð´Ð»Ñ Ñ–Ð½Ñ„ÐµÑ€ÐµÐ½Ñ†Ñ–Ñ— Ð°Ð³ÐµÐ½Ñ‚Ñ–Ð² Ñ– Ð¾Ð¿Ñ‚Ð¸Ð¼Ñ–Ð·Ð¾Ð²Ð°Ð½Ñƒ Ð¿Ñ€Ð¾Ð¿ÑƒÑÐºÐ½Ñƒ Ð·Ð´Ð°Ñ‚Ð½Ñ–ÑÑ‚ÑŒ Ð¿Ð°Ð¼'ÑÑ‚Ñ– Ð´Ð»Ñ Ð±Ð°Ð³Ð°Ñ‚Ð¾Ð³ÐµÐ½Ñ‚Ð½Ð¸Ñ… ÑÐ¸ÑÑ‚ÐµÐ¼. ÐÐ³ÐµÐ½Ñ‚Ð¸ SLM Ð´ÐµÐ¼Ð¾Ð½ÑÑ‚Ñ€ÑƒÑŽÑ‚ÑŒ Ð²Ð¸Ð½ÑÑ‚ÐºÐ¾Ð²Ñƒ Ð¿Ñ€Ð¾Ð´ÑƒÐºÑ‚Ð¸Ð²Ð½Ñ–ÑÑ‚ÑŒ Ð½Ð° Ñ‡Ð¸Ð¿Ð°Ñ… ÑÐµÑ€Ñ–Ñ— M.

**ÐžÑÐ¾Ð±Ð»Ð¸Ð²Ð¾ÑÑ‚Ñ– Ñ€Ð¾Ð·Ñ€Ð¾Ð±ÐºÐ¸**: ÐŸÑ–Ð´Ñ‚Ñ€Ð¸Ð¼ÐºÐ° API Ð´Ð»Ñ Python Ñ– Swift Ñ–Ð· Ð¾Ð¿Ñ‚Ð¸Ð¼Ñ–Ð·Ð°Ñ†Ñ–ÑÐ¼Ð¸, ÑÐ¿ÐµÑ†Ð¸Ñ„Ñ–Ñ‡Ð½Ð¸Ð¼Ð¸ Ð´Ð»Ñ Ð°Ð³ÐµÐ½Ñ‚Ñ–Ð², Ð°Ð²Ñ‚Ð¾Ð¼Ð°Ñ‚Ð¸Ñ‡Ð½Ðµ Ð´Ð¸Ñ„ÐµÑ€ÐµÐ½Ñ†Ñ–ÑŽÐ²Ð°Ð½Ð½Ñ Ð´Ð»Ñ Ð½Ð°Ð²Ñ‡Ð°Ð½Ð½Ñ Ð°Ð³ÐµÐ½Ñ‚Ñ–Ð² Ñ– Ð±ÐµÐ·ÑˆÐ¾Ð²Ð½Ð° Ñ–Ð½Ñ‚ÐµÐ³Ñ€Ð°Ñ†Ñ–Ñ Ð· Ñ–Ð½ÑÑ‚Ñ€ÑƒÐ¼ÐµÐ½Ñ‚Ð°Ð¼Ð¸ Ñ€Ð¾Ð·Ñ€Ð¾Ð±ÐºÐ¸ Apple Ð·Ð°Ð±ÐµÐ·Ð¿ÐµÑ‡ÑƒÑŽÑ‚ÑŒ ÐºÐ¾Ð¼Ð¿Ð»ÐµÐºÑÐ½Ñ– ÑÐµÑ€ÐµÐ´Ð¾Ð²Ð¸Ñ‰Ð° Ñ€Ð¾Ð·Ñ€Ð¾Ð±ÐºÐ¸ Ð°Ð³ÐµÐ½Ñ‚Ñ–Ð².

#### ONNX Runtime Ð´Ð»Ñ ÐºÑ€Ð¾ÑÐ¿Ð»Ð°Ñ‚Ñ„Ð¾Ñ€Ð¼ÐµÐ½Ð¸Ñ… Ð°Ð³ÐµÐ½Ñ‚Ñ–Ð² SLM

ONNX Runtime Ð·Ð°Ð±ÐµÐ·Ð¿ÐµÑ‡ÑƒÑ” ÑƒÐ½Ñ–Ð²ÐµÑ€ÑÐ°Ð»ÑŒÐ½Ð¸Ð¹ Ð¼ÐµÑ…Ð°Ð½Ñ–Ð·Ð¼ Ñ–Ð½Ñ„ÐµÑ€ÐµÐ½Ñ†Ñ–Ñ—, ÑÐºÐ¸Ð¹ Ð´Ð¾Ð·Ð²Ð¾Ð»ÑÑ” Ð°Ð³ÐµÐ½Ñ‚Ð°Ð¼ SLM Ð¿Ñ€Ð°Ñ†ÑŽÐ²Ð°Ñ‚Ð¸ Ð¿Ð¾ÑÐ»Ñ–Ð´Ð¾Ð²Ð½Ð¾ Ð½Ð° Ñ€Ñ–Ð·Ð½Ð¾Ð¼Ð°Ð½Ñ–Ñ‚Ð½Ð¸Ñ… Ð°Ð¿Ð°Ñ€Ð°Ñ‚Ð½Ð¸Ñ… Ð¿Ð»Ð°Ñ‚Ñ„Ð¾Ñ€Ð¼Ð°Ñ… Ñ– Ð¾Ð¿ÐµÑ€Ð°Ñ†Ñ–Ð¹Ð½Ð¸Ñ… ÑÐ¸ÑÑ‚ÐµÐ¼Ð°Ñ…:

**Ð£Ð½Ñ–Ð²ÐµÑ€ÑÐ°Ð»ÑŒÐ½Ðµ Ñ€Ð¾Ð·Ð³Ð¾Ñ€Ñ‚Ð°Ð½Ð½Ñ**: ONNX Runtime Ð·Ð°Ð±ÐµÐ·Ð¿ÐµÑ‡ÑƒÑ” Ð¿Ð¾ÑÐ»Ñ–Ð´Ð¾Ð²Ð½Ñƒ Ð¿Ð¾Ð²ÐµÐ´Ñ–Ð½ÐºÑƒ Ð°Ð³ÐµÐ½Ñ‚Ñ–Ð² SLM Ð½Ð° Ð¿Ð»Ð°Ñ‚Ñ„Ð¾Ñ€Ð¼Ð°Ñ… Windows, Linux, macOS, iOS Ñ‚Ð° Android. Ð¦Ñ ÐºÑ€Ð¾ÑÐ¿Ð»Ð°Ñ‚Ñ„Ð¾Ñ€Ð¼Ð½Ð° ÑÑƒÐ¼Ñ–ÑÐ½Ñ–ÑÑ‚ÑŒ Ð´Ð¾Ð·Ð²Ð¾Ð»ÑÑ” Ñ€Ð¾Ð·Ñ€Ð¾Ð±Ð½Ð¸ÐºÐ°Ð¼ Ð¿Ð¸ÑÐ°Ñ‚Ð¸ Ð¾Ð´Ð¸Ð½ Ñ€Ð°Ð· Ñ– Ñ€Ð¾Ð·Ð³Ð¾Ñ€Ñ‚Ð°Ñ‚Ð¸ Ð²ÑÑŽÐ´Ð¸, Ð·Ð½Ð°Ñ‡Ð½Ð¾ Ð·Ð½Ð¸Ð¶ÑƒÑŽÑ‡Ð¸ Ð²Ð¸Ñ‚Ñ€Ð°Ñ‚Ð¸ Ð½Ð° Ñ€Ð¾Ð·Ñ€Ð¾Ð±ÐºÑƒ Ñ‚Ð° Ð¾Ð±ÑÐ»ÑƒÐ³Ð¾Ð²ÑƒÐ²Ð°Ð½Ð½Ñ Ð´Ð»Ñ Ð±Ð°Ð³Ð°Ñ‚Ð¾Ð¿Ð»Ð°Ñ‚Ñ„Ð¾Ñ€Ð¼Ð½Ð¸Ñ… Ð·Ð°ÑÑ‚Ð¾ÑÑƒÐ²Ð°Ð½ÑŒ.

**ÐžÐ¿Ñ†Ñ–Ñ— Ð°Ð¿Ð°Ñ€Ð°Ñ‚Ð½Ð¾Ð³Ð¾ Ð¿Ñ€Ð¸ÑÐºÐ¾Ñ€ÐµÐ½Ð½Ñ**: Ð¤Ñ€ÐµÐ¹Ð¼Ð²Ð¾Ñ€Ðº Ð·Ð°Ð±ÐµÐ·Ð¿ÐµÑ‡ÑƒÑ” Ð¾Ð¿Ñ‚Ð¸Ð¼Ñ–Ð·Ð¾Ð²Ð°Ð½Ð¸Ñ… Ð¿Ñ€Ð¾Ð²Ð°Ð¹Ð´ÐµÑ€Ñ–Ð² Ð²Ð¸ÐºÐ¾Ð½Ð°Ð½Ð½Ñ Ð´Ð»Ñ Ñ€Ñ–Ð·Ð½Ð¸Ñ… Ð°Ð¿Ð°Ñ€Ð°Ñ‚Ð½Ð¸Ñ… ÐºÐ¾Ð½Ñ„Ñ–Ð³ÑƒÑ€Ð°Ñ†Ñ–Ð¹, Ð²ÐºÐ»ÑŽÑ‡Ð°ÑŽÑ‡Ð¸ CPU (Intel, AMD, ARM), GPU (NVIDIA CUDA, AMD ROCm) Ñ‚Ð° ÑÐ¿ÐµÑ†Ñ–Ð°Ð»Ñ–Ð·Ð¾Ð²Ð°Ð½Ñ– Ð°ÐºÑÐµÐ»ÐµÑ€Ð°Ñ‚Ð¾Ñ€Ð¸ (Intel VPU, Qualcomm NPU). ÐÐ³ÐµÐ½Ñ‚Ð¸ SLM Ð¼Ð¾Ð¶ÑƒÑ‚ÑŒ Ð°Ð²Ñ‚Ð¾Ð¼Ð°Ñ‚Ð¸Ñ‡Ð½Ð¾ Ð²Ð¸ÐºÐ¾Ñ€Ð¸ÑÑ‚Ð¾Ð²ÑƒÐ²Ð°Ñ‚Ð¸ Ð½Ð°Ð¹ÐºÑ€Ð°Ñ‰Ðµ Ð´Ð¾ÑÑ‚ÑƒÐ¿Ð½Ðµ Ð°Ð¿Ð°Ñ€Ð°Ñ‚Ð½Ðµ Ð·Ð°Ð±ÐµÐ·Ð¿ÐµÑ‡ÐµÐ½Ð½Ñ Ð±ÐµÐ· Ð·Ð¼Ñ–Ð½ Ñƒ ÐºÐ¾Ð´Ñ–.

**ÐžÑÐ¾Ð±Ð»Ð¸Ð²Ð¾ÑÑ‚Ñ– Ð´Ð»Ñ Ð²Ð¸Ñ€Ð¾Ð±Ð½Ð¸Ñ†Ñ‚Ð²Ð°**: ONNX Runtime Ð¿Ñ€Ð¾Ð¿Ð¾Ð½ÑƒÑ” Ñ„ÑƒÐ½ÐºÑ†Ñ–Ñ— ÐºÐ¾Ñ€Ð¿Ð¾Ñ€Ð°Ñ‚Ð¸Ð²Ð½Ð¾Ð³Ð¾ Ñ€Ñ–Ð²Ð½Ñ, Ð½ÐµÐ¾Ð±Ñ…Ñ–Ð´Ð½Ñ– Ð´Ð»Ñ Ñ€Ð¾Ð·Ð³Ð¾Ñ€Ñ‚Ð°Ð½Ð½Ñ Ð°Ð³ÐµÐ½Ñ‚Ñ–Ð² Ñƒ Ð²Ð¸Ñ€Ð¾Ð±Ð½Ð¸Ñ†Ñ‚Ð²Ñ–, Ð²ÐºÐ»ÑŽÑ‡Ð°ÑŽÑ‡Ð¸ Ð¾Ð¿Ñ‚Ð¸Ð¼Ñ–Ð·Ð°Ñ†Ñ–ÑŽ Ð³Ñ€Ð°Ñ„Ñ–Ð² Ð´Ð»Ñ ÑˆÐ²Ð¸Ð´ÑˆÐ¾Ñ— Ñ–Ð½Ñ„ÐµÑ€ÐµÐ½Ñ†Ñ–Ñ—, ÑƒÐ¿Ñ€Ð°Ð²Ð»Ñ–Ð½Ð½Ñ Ð¿Ð°Ð¼'ÑÑ‚Ñ‚ÑŽ Ð´Ð»Ñ ÑÐµÑ€ÐµÐ´Ð¾Ð²Ð¸Ñ‰ Ð· Ð¾Ð±Ð¼ÐµÐ¶ÐµÐ½Ð¸Ð¼Ð¸ Ñ€ÐµÑÑƒÑ€ÑÐ°Ð¼Ð¸ Ñ‚Ð° ÐºÐ¾Ð¼Ð¿Ð»ÐµÐºÑÐ½Ñ– Ñ–Ð½ÑÑ‚Ñ€ÑƒÐ¼ÐµÐ½Ñ‚Ð¸ Ð¿Ñ€Ð¾Ñ„Ñ–Ð»ÑŽÐ²Ð°Ð½Ð½Ñ Ð´Ð»Ñ Ð°Ð½Ð°Ð»Ñ–Ð·Ñƒ Ð¿Ñ€Ð¾Ð´ÑƒÐºÑ‚Ð¸Ð²Ð½Ð¾ÑÑ‚Ñ–. Ð¤Ñ€ÐµÐ¹Ð¼Ð²Ð¾Ñ€Ðº Ð¿Ñ–Ð´Ñ‚Ñ€Ð¸Ð¼ÑƒÑ” ÑÐº Python, Ñ‚Ð°Ðº Ñ– C++ API Ð´Ð»Ñ Ð³Ð½ÑƒÑ‡ÐºÐ¾Ñ— Ñ–Ð½Ñ‚ÐµÐ³Ñ€Ð°Ñ†Ñ–Ñ—.
- Ð¢ÐµÑÑ‚ÑƒÐ²Ð°Ð½Ð½Ñ Ñ–Ð½Ñ‚ÐµÐ³Ñ€Ð°Ñ†Ñ–Ñ— Microsoft Agent Framework  
- ÐŸÐµÑ€ÐµÐ²Ñ–Ñ€ÐºÐ° Ð¼Ð¾Ð¶Ð»Ð¸Ð²Ð¾ÑÑ‚ÐµÐ¹ Ñ€Ð¾Ð±Ð¾Ñ‚Ð¸ Ð² Ð¾Ñ„Ð»Ð°Ð¹Ð½-Ñ€ÐµÐ¶Ð¸Ð¼Ñ–  
- Ð¢ÐµÑÑ‚ÑƒÐ²Ð°Ð½Ð½Ñ ÑÑ†ÐµÐ½Ð°Ñ€Ñ–Ñ—Ð² Ð²Ñ–Ð´Ð¼Ð¾Ð²Ð¸ Ñ‚Ð° Ð¾Ð±Ñ€Ð¾Ð±ÐºÐ¸ Ð¿Ð¾Ð¼Ð¸Ð»Ð¾Ðº  
- Ð’Ð°Ð»Ñ–Ð´Ð°Ñ†Ñ–Ñ Ð½Ð°ÑÐºÑ€Ñ–Ð·Ð½Ð¸Ñ… Ñ€Ð¾Ð±Ð¾Ñ‡Ð¸Ñ… Ð¿Ñ€Ð¾Ñ†ÐµÑÑ–Ð² Ð°Ð³ÐµÐ½Ñ‚Ñ–Ð²  

**ÐŸÐ¾Ñ€Ñ–Ð²Ð½ÑÐ½Ð½Ñ Ð· Foundry Local**:

| Ð¤ÑƒÐ½ÐºÑ†Ñ–Ñ | Foundry Local | Ollama |
|---------|---------------|--------|
| **Ð¦Ñ–Ð»ÑŒÐ¾Ð²Ðµ Ð²Ð¸ÐºÐ¾Ñ€Ð¸ÑÑ‚Ð°Ð½Ð½Ñ** | Ð’Ð¸Ñ€Ð¾Ð±Ð½Ð¸Ñ‡Ðµ ÑÐµÑ€ÐµÐ´Ð¾Ð²Ð¸Ñ‰Ðµ Ð´Ð»Ñ Ð¿Ñ–Ð´Ð¿Ñ€Ð¸Ñ”Ð¼ÑÑ‚Ð² | Ð Ð¾Ð·Ñ€Ð¾Ð±ÐºÐ° Ñ‚Ð° ÑÐ¿Ñ–Ð»ÑŒÐ½Ð¾Ñ‚Ð° |
| **Ð•ÐºÐ¾ÑÐ¸ÑÑ‚ÐµÐ¼Ð° Ð¼Ð¾Ð´ÐµÐ»ÐµÐ¹** | Ð’Ñ–Ð´Ð±Ñ–Ñ€ Microsoft | Ð¨Ð¸Ñ€Ð¾ÐºÐ° ÑÐ¿Ñ–Ð»ÑŒÐ½Ð¾Ñ‚Ð° |
| **ÐžÐ¿Ñ‚Ð¸Ð¼Ñ–Ð·Ð°Ñ†Ñ–Ñ Ð¾Ð±Ð»Ð°Ð´Ð½Ð°Ð½Ð½Ñ** | ÐÐ²Ñ‚Ð¾Ð¼Ð°Ñ‚Ð¸Ñ‡Ð½Ð° (CUDA/NPU/CPU) | Ð ÑƒÑ‡Ð½Ð° ÐºÐ¾Ð½Ñ„Ñ–Ð³ÑƒÑ€Ð°Ñ†Ñ–Ñ |
| **Ð¤ÑƒÐ½ÐºÑ†Ñ–Ñ— Ð´Ð»Ñ Ð¿Ñ–Ð´Ð¿Ñ€Ð¸Ñ”Ð¼ÑÑ‚Ð²** | Ð’Ð±ÑƒÐ´Ð¾Ð²Ð°Ð½Ð¸Ð¹ Ð¼Ð¾Ð½Ñ–Ñ‚Ð¾Ñ€Ð¸Ð½Ð³, Ð±ÐµÐ·Ð¿ÐµÐºÐ° | Ð†Ð½ÑÑ‚Ñ€ÑƒÐ¼ÐµÐ½Ñ‚Ð¸ ÑÐ¿Ñ–Ð»ÑŒÐ½Ð¾Ñ‚Ð¸ |
| **Ð¡ÐºÐ»Ð°Ð´Ð½Ñ–ÑÑ‚ÑŒ Ñ€Ð¾Ð·Ð³Ð¾Ñ€Ñ‚Ð°Ð½Ð½Ñ** | ÐŸÑ€Ð¾ÑÑ‚Ð° (winget install) | ÐŸÑ€Ð¾ÑÑ‚Ð° (curl install) |
| **Ð¡ÑƒÐ¼Ñ–ÑÐ½Ñ–ÑÑ‚ÑŒ API** | OpenAI + Ñ€Ð¾Ð·ÑˆÐ¸Ñ€ÐµÐ½Ð½Ñ | Ð¡Ñ‚Ð°Ð½Ð´Ð°Ñ€Ñ‚ OpenAI |
| **ÐŸÑ–Ð´Ñ‚Ñ€Ð¸Ð¼ÐºÐ°** | ÐžÑ„Ñ–Ñ†Ñ–Ð¹Ð½Ð° Ð¿Ñ–Ð´Ñ‚Ñ€Ð¸Ð¼ÐºÐ° Microsoft | ÐŸÑ–Ð´Ñ‚Ñ€Ð¸Ð¼ÐºÐ° ÑÐ¿Ñ–Ð»ÑŒÐ½Ð¾Ñ‚Ð¸ |
| **ÐÐ°Ð¹ÐºÑ€Ð°Ñ‰Ðµ Ð´Ð»Ñ** | Ð’Ð¸Ñ€Ð¾Ð±Ð½Ð¸Ñ‡Ñ– Ð°Ð³ÐµÐ½Ñ‚Ð¸ | ÐŸÑ€Ð¾Ñ‚Ð¾Ñ‚Ð¸Ð¿ÑƒÐ²Ð°Ð½Ð½Ñ, Ð´Ð¾ÑÐ»Ñ–Ð´Ð¶ÐµÐ½Ð½Ñ |

**ÐšÐ¾Ð»Ð¸ Ð¾Ð±Ñ€Ð°Ñ‚Ð¸ Ollama**:
- **Ð Ð¾Ð·Ñ€Ð¾Ð±ÐºÐ° Ñ‚Ð° Ð¿Ñ€Ð¾Ñ‚Ð¾Ñ‚Ð¸Ð¿ÑƒÐ²Ð°Ð½Ð½Ñ**: Ð¨Ð²Ð¸Ð´ÐºÐµ ÐµÐºÑÐ¿ÐµÑ€Ð¸Ð¼ÐµÐ½Ñ‚ÑƒÐ²Ð°Ð½Ð½Ñ Ð· Ñ€Ñ–Ð·Ð½Ð¸Ð¼Ð¸ Ð¼Ð¾Ð´ÐµÐ»ÑÐ¼Ð¸  
- **ÐœÐ¾Ð´ÐµÐ»Ñ– ÑÐ¿Ñ–Ð»ÑŒÐ½Ð¾Ñ‚Ð¸**: Ð”Ð¾ÑÑ‚ÑƒÐ¿ Ð´Ð¾ Ð½Ð°Ð¹Ð½Ð¾Ð²Ñ–ÑˆÐ¸Ñ… Ð¼Ð¾Ð´ÐµÐ»ÐµÐ¹, ÑÑ‚Ð²Ð¾Ñ€ÐµÐ½Ð¸Ñ… ÑÐ¿Ñ–Ð»ÑŒÐ½Ð¾Ñ‚Ð¾ÑŽ  
- **ÐžÑÐ²Ñ–Ñ‚Ð½Ñ” Ð²Ð¸ÐºÐ¾Ñ€Ð¸ÑÑ‚Ð°Ð½Ð½Ñ**: ÐÐ°Ð²Ñ‡Ð°Ð½Ð½Ñ Ñ‚Ð° Ð²Ð¸ÐºÐ»Ð°Ð´Ð°Ð½Ð½Ñ Ñ€Ð¾Ð·Ñ€Ð¾Ð±ÐºÐ¸ AI-Ð°Ð³ÐµÐ½Ñ‚Ñ–Ð²  
- **Ð”Ð¾ÑÐ»Ñ–Ð´Ð½Ð¸Ñ†ÑŒÐºÑ– Ð¿Ñ€Ð¾ÐµÐºÑ‚Ð¸**: ÐÐºÐ°Ð´ÐµÐ¼Ñ–Ñ‡Ð½Ñ– Ð´Ð¾ÑÐ»Ñ–Ð´Ð¶ÐµÐ½Ð½Ñ Ð· Ð´Ð¾ÑÑ‚ÑƒÐ¿Ð¾Ð¼ Ð´Ð¾ Ñ€Ñ–Ð·Ð½Ð¾Ð¼Ð°Ð½Ñ–Ñ‚Ð½Ð¸Ñ… Ð¼Ð¾Ð´ÐµÐ»ÐµÐ¹  
- **ÐšÐ°ÑÑ‚Ð¾Ð¼Ð½Ñ– Ð¼Ð¾Ð´ÐµÐ»Ñ–**: Ð¡Ñ‚Ð²Ð¾Ñ€ÐµÐ½Ð½Ñ Ñ‚Ð° Ñ‚ÐµÑÑ‚ÑƒÐ²Ð°Ð½Ð½Ñ Ð²Ð»Ð°ÑÐ½Ð¸Ñ… Ð¼Ð¾Ð´ÐµÐ»ÐµÐ¹ Ð· Ñ‚Ð¾Ð½ÐºÐ¸Ð¼ Ð½Ð°Ð»Ð°ÑˆÑ‚ÑƒÐ²Ð°Ð½Ð½ÑÐ¼  

### VLLM: Ð’Ð¸ÑÐ¾ÐºÐ¾Ð¿Ñ€Ð¾Ð´ÑƒÐºÑ‚Ð¸Ð²Ð½Ð¸Ð¹ Ñ–Ð½Ñ„ÐµÑ€ÐµÐ½Ñ SLM Ð°Ð³ÐµÐ½Ñ‚Ñ–Ð²  

VLLM (Ñ–Ð½Ñ„ÐµÑ€ÐµÐ½Ñ Ð´ÑƒÐ¶Ðµ Ð²ÐµÐ»Ð¸ÐºÐ¸Ñ… Ð¼Ð¾Ð²Ð½Ð¸Ñ… Ð¼Ð¾Ð´ÐµÐ»ÐµÐ¹) Ð·Ð°Ð±ÐµÐ·Ð¿ÐµÑ‡ÑƒÑ” Ð²Ð¸ÑÐ¾ÐºÐ¾Ð¿Ñ€Ð¾Ð´ÑƒÐºÑ‚Ð¸Ð²Ð½Ð¸Ð¹, ÐµÑ„ÐµÐºÑ‚Ð¸Ð²Ð½Ð¸Ð¹ Ð· Ñ‚Ð¾Ñ‡ÐºÐ¸ Ð·Ð¾Ñ€Ñƒ Ð¿Ð°Ð¼â€™ÑÑ‚Ñ– Ñ–Ð½Ñ„ÐµÑ€ÐµÐ½Ñ-Ð´Ð²Ð¸Ð³ÑƒÐ½, ÑÐ¿ÐµÑ†Ñ–Ð°Ð»ÑŒÐ½Ð¾ Ð¾Ð¿Ñ‚Ð¸Ð¼Ñ–Ð·Ð¾Ð²Ð°Ð½Ð¸Ð¹ Ð´Ð»Ñ Ð¼Ð°ÑÑˆÑ‚Ð°Ð±Ð½Ð¸Ñ… Ð²Ð¸Ñ€Ð¾Ð±Ð½Ð¸Ñ‡Ð¸Ñ… Ñ€Ð¾Ð·Ð³Ð¾Ñ€Ñ‚Ð°Ð½ÑŒ SLM. Ð£ Ñ‚Ð¾Ð¹ Ñ‡Ð°Ñ ÑÐº Foundry Local Ð·Ð¾ÑÐµÑ€ÐµÐ´Ð¶ÐµÐ½Ð¸Ð¹ Ð½Ð° Ð¿Ñ€Ð¾ÑÑ‚Ð¾Ñ‚Ñ– Ð²Ð¸ÐºÐ¾Ñ€Ð¸ÑÑ‚Ð°Ð½Ð½Ñ, Ð° Ollama Ð°ÐºÑ†ÐµÐ½Ñ‚ÑƒÑ” ÑƒÐ²Ð°Ð³Ñƒ Ð½Ð° Ð¼Ð¾Ð´ÐµÐ»ÑÑ… ÑÐ¿Ñ–Ð»ÑŒÐ½Ð¾Ñ‚Ð¸, VLLM Ð¿ÐµÑ€ÐµÐ²ÐµÑ€ÑˆÑƒÑ” Ð² ÑÑ†ÐµÐ½Ð°Ñ€Ñ–ÑÑ… Ð²Ð¸ÑÐ¾ÐºÐ¾Ñ— Ð¿Ñ€Ð¾Ð´ÑƒÐºÑ‚Ð¸Ð²Ð½Ð¾ÑÑ‚Ñ–, Ñ‰Ð¾ Ð²Ð¸Ð¼Ð°Ð³Ð°ÑŽÑ‚ÑŒ Ð¼Ð°ÐºÑÐ¸Ð¼Ð°Ð»ÑŒÐ½Ð¾Ð³Ð¾ Ð¿Ñ€Ð¾Ð¿ÑƒÑÐºÑƒ Ñ‚Ð° ÐµÑ„ÐµÐºÑ‚Ð¸Ð²Ð½Ð¾Ð³Ð¾ Ð²Ð¸ÐºÐ¾Ñ€Ð¸ÑÑ‚Ð°Ð½Ð½Ñ Ñ€ÐµÑÑƒÑ€ÑÑ–Ð².

**ÐžÑÐ½Ð¾Ð²Ð½Ð° Ð°Ñ€Ñ…Ñ–Ñ‚ÐµÐºÑ‚ÑƒÑ€Ð° Ñ‚Ð° Ñ„ÑƒÐ½ÐºÑ†Ñ–Ñ—**:
- **PagedAttention**: Ð ÐµÐ²Ð¾Ð»ÑŽÑ†Ñ–Ð¹Ð½Ðµ ÑƒÐ¿Ñ€Ð°Ð²Ð»Ñ–Ð½Ð½Ñ Ð¿Ð°Ð¼â€™ÑÑ‚Ñ‚ÑŽ Ð´Ð»Ñ ÐµÑ„ÐµÐºÑ‚Ð¸Ð²Ð½Ð¸Ñ… Ð¾Ð±Ñ‡Ð¸ÑÐ»ÐµÐ½ÑŒ ÑƒÐ²Ð°Ð³Ð¸  
- **Ð”Ð¸Ð½Ð°Ð¼Ñ–Ñ‡Ð½Ðµ Ð³Ñ€ÑƒÐ¿ÑƒÐ²Ð°Ð½Ð½Ñ**: Ð†Ð½Ñ‚ÐµÐ»ÐµÐºÑ‚ÑƒÐ°Ð»ÑŒÐ½Ðµ Ð³Ñ€ÑƒÐ¿ÑƒÐ²Ð°Ð½Ð½Ñ Ð·Ð°Ð¿Ð¸Ñ‚Ñ–Ð² Ð´Ð»Ñ Ð¾Ð¿Ñ‚Ð¸Ð¼Ð°Ð»ÑŒÐ½Ð¾Ð³Ð¾ Ð¿Ñ€Ð¾Ð¿ÑƒÑÐºÑƒ  
- **ÐžÐ¿Ñ‚Ð¸Ð¼Ñ–Ð·Ð°Ñ†Ñ–Ñ GPU**: Ð Ð¾Ð·ÑˆÐ¸Ñ€ÐµÐ½Ñ– ÑÐ´Ñ€Ð° CUDA Ñ‚Ð° Ð¿Ñ–Ð´Ñ‚Ñ€Ð¸Ð¼ÐºÐ° Ð¿Ð°Ñ€Ð°Ð»ÐµÐ»Ñ–Ð·Ð¼Ñƒ Ñ‚ÐµÐ½Ð·Ð¾Ñ€Ñ–Ð²  
- **Ð¡ÑƒÐ¼Ñ–ÑÐ½Ñ–ÑÑ‚ÑŒ Ð· OpenAI**: ÐŸÐ¾Ð²Ð½Ð° ÑÑƒÐ¼Ñ–ÑÐ½Ñ–ÑÑ‚ÑŒ API Ð´Ð»Ñ Ð±ÐµÐ·Ð¿ÐµÑ€ÐµÐ±Ñ–Ð¹Ð½Ð¾Ñ— Ñ–Ð½Ñ‚ÐµÐ³Ñ€Ð°Ñ†Ñ–Ñ—  
- **Ð¡Ð¿ÐµÐºÑƒÐ»ÑÑ‚Ð¸Ð²Ð½Ðµ Ð´ÐµÐºÐ¾Ð´ÑƒÐ²Ð°Ð½Ð½Ñ**: Ð Ð¾Ð·ÑˆÐ¸Ñ€ÐµÐ½Ñ– Ð¼ÐµÑ‚Ð¾Ð´Ð¸ Ð¿Ñ€Ð¸ÑÐºÐ¾Ñ€ÐµÐ½Ð½Ñ Ñ–Ð½Ñ„ÐµÑ€ÐµÐ½ÑÑƒ  
- **ÐŸÑ–Ð´Ñ‚Ñ€Ð¸Ð¼ÐºÐ° ÐºÐ²Ð°Ð½Ñ‚ÑƒÐ²Ð°Ð½Ð½Ñ**: INT4, INT8 Ñ‚Ð° FP16 Ð´Ð»Ñ ÐµÑ„ÐµÐºÑ‚Ð¸Ð²Ð½Ð¾Ð³Ð¾ Ð²Ð¸ÐºÐ¾Ñ€Ð¸ÑÑ‚Ð°Ð½Ð½Ñ Ð¿Ð°Ð¼â€™ÑÑ‚Ñ–  

#### Ð’ÑÑ‚Ð°Ð½Ð¾Ð²Ð»ÐµÐ½Ð½Ñ Ñ‚Ð° Ð½Ð°Ð»Ð°ÑˆÑ‚ÑƒÐ²Ð°Ð½Ð½Ñ  

**ÐžÐ¿Ñ†Ñ–Ñ— Ð²ÑÑ‚Ð°Ð½Ð¾Ð²Ð»ÐµÐ½Ð½Ñ**:  
```bash
# Standard installation
pip install vllm

# With additional dependencies for agent frameworks
pip install vllm[agent] openai

# Docker deployment for production
docker pull vllm/vllm-openai:latest

# From source for latest features
git clone https://github.com/vllm-project/vllm.git
cd vllm
pip install -e .
```
  
**Ð¨Ð²Ð¸Ð´ÐºÐ¸Ð¹ ÑÑ‚Ð°Ñ€Ñ‚ Ð´Ð»Ñ Ñ€Ð¾Ð·Ñ€Ð¾Ð±ÐºÐ¸ Ð°Ð³ÐµÐ½Ñ‚Ñ–Ð²**:  
```bash
# Start VLLM server with SLM model
python -m vllm.entrypoints.openai.api_server \
    --model microsoft/Phi-3.5-mini-instruct \
    --trust-remote-code \
    --max-model-len 4096 \
    --gpu-memory-utilization 0.8

# Alternative: Start with Qwen2.5 for lightweight agents
python -m vllm.entrypoints.openai.api_server \
    --model Qwen/Qwen2.5-0.5B-Instruct \
    --trust-remote-code \
    --max-model-len 2048 \
    --tensor-parallel-size 1

# Test API endpoint
curl http://localhost:8000/v1/models

# Test chat completion
curl http://localhost:8000/v1/chat/completions \
    -H "Content-Type: application/json" \
    -d '{
        "model": "microsoft/Phi-3.5-mini-instruct",
        "messages": [{"role": "user", "content": "Hello!"}]
    }'
```
  

#### Ð†Ð½Ñ‚ÐµÐ³Ñ€Ð°Ñ†Ñ–Ñ Ð· Agent Framework  

**VLLM Ð· Microsoft Agent Framework**:  
```python
from microsoft_agent_framework import Agent, Config
import openai
import subprocess
import time
import requests
from typing import Optional, Dict, Any

class VLLMManager:
    def __init__(self, model_name: str, 
                 host: str = "localhost", 
                 port: int = 8000,
                 gpu_memory_utilization: float = 0.8,
                 max_model_len: int = 4096):
        self.model_name = model_name
        self.host = host
        self.port = port
        self.base_url = f"http://{host}:{port}"
        self.gpu_memory_utilization = gpu_memory_utilization
        self.max_model_len = max_model_len
        self.process = None
        self.client = None
        
    def start_server(self) -> bool:
        """Start VLLM server with optimized settings for agents."""
        try:
            cmd = [
                "python", "-m", "vllm.entrypoints.openai.api_server",
                "--model", self.model_name,
                "--host", self.host,
                "--port", str(self.port),
                "--gpu-memory-utilization", str(self.gpu_memory_utilization),
                "--max-model-len", str(self.max_model_len),
                "--trust-remote-code",
                "--disable-log-requests",  # Reduce logging for agents
                "--served-model-name", self.get_served_model_name()
            ]
            
            self.process = subprocess.Popen(cmd, 
                stdout=subprocess.PIPE, 
                stderr=subprocess.PIPE)
            
            # Wait for server to start
            max_retries = 30
            for _ in range(max_retries):
                if self.health_check():
                    self.client = openai.OpenAI(base_url=f"{self.base_url}/v1")
                    return True
                time.sleep(2)
                
            return False
            
        except Exception as e:
            print(f"Failed to start VLLM server: {e}")
            return False
    
    def get_served_model_name(self) -> str:
        """Get a clean model name for serving."""
        return self.model_name.replace("/", "--")
    
    def health_check(self) -> bool:
        """Check if VLLM server is healthy."""
        try:
            response = requests.get(f"{self.base_url}/health", timeout=5)
            return response.status_code == 200
        except:
            return False
    
    def get_openai_client(self) -> openai.OpenAI:
        """Get OpenAI-compatible client for VLLM."""
        if not self.client:
            self.client = openai.OpenAI(base_url=f"{self.base_url}/v1")
        return self.client
    
    def get_model_info(self) -> Dict[str, Any]:
        """Get model information and statistics."""
        try:
            response = requests.get(f"{self.base_url}/v1/models")
            if response.status_code == 200:
                return response.json()
        except:
            pass
        return {}
    
    def shutdown(self):
        """Shutdown VLLM server."""
        if self.process:
            self.process.terminate()
            self.process.wait()

# Initialize VLLM for high-performance agents
vllm_manager = VLLMManager("microsoft/Phi-3.5-mini-instruct")
if vllm_manager.start_server():
    print("VLLM server started successfully")
    
    # Configure agent with VLLM backend
    agent_config = Config(
        name="vllm-performance-agent",
        model_provider="vllm",
        model_id=vllm_manager.get_served_model_name(),
        endpoint=f"{vllm_manager.base_url}/v1",
        api_key="none"  # VLLM doesn't require API key
    )
    
    agent = Agent(config=agent_config)
else:
    print("Failed to start VLLM server")
```
  
**ÐÐ°Ð»Ð°ÑˆÑ‚ÑƒÐ²Ð°Ð½Ð½Ñ Ð±Ð°Ð³Ð°Ñ‚Ð¾Ð¿Ð¾Ñ‚Ð¾ÐºÐ¾Ð²Ð¾Ð³Ð¾ Ð²Ð¸ÑÐ¾ÐºÐ¾Ð¿Ñ€Ð¾Ð´ÑƒÐºÑ‚Ð¸Ð²Ð½Ð¾Ð³Ð¾ Ð°Ð³ÐµÐ½Ñ‚Ð°**:  
```python
import asyncio
from concurrent.futures import ThreadPoolExecutor
from microsoft_agent_framework import Agent, Config
import openai

class VLLMHighThroughputManager:
    def __init__(self):
        self.model_configs = {
            "lightweight": {
                "model": "Qwen/Qwen2.5-0.5B-Instruct",
                "port": 8000,
                "max_model_len": 2048,
                "gpu_memory_utilization": 0.3
            },
            "balanced": {
                "model": "microsoft/Phi-3.5-mini-instruct",
                "port": 8001,
                "max_model_len": 4096,
                "gpu_memory_utilization": 0.5
            },
            "capable": {
                "model": "meta-llama/Llama-3.2-3B-Instruct",
                "port": 8002,
                "max_model_len": 8192,
                "gpu_memory_utilization": 0.7
            }
        }
        self.managers = {}
        self.agents = {}
        self.client_pool = {}
        
    async def initialize_all_models(self):
        """Initialize all VLLM models in parallel."""
        initialization_tasks = []
        
        for category, config in self.model_configs.items():
            task = self._initialize_model(category, config)
            initialization_tasks.append(task)
        
        results = await asyncio.gather(*initialization_tasks, return_exceptions=True)
        
        successful_inits = 0
        for i, result in enumerate(results):
            category = list(self.model_configs.keys())[i]
            if isinstance(result, Exception):
                print(f"Failed to initialize {category}: {result}")
            else:
                successful_inits += 1
                print(f"Successfully initialized {category} model")
        
        return successful_inits
    
    async def _initialize_model(self, category: str, config: Dict[str, Any]):
        """Initialize a single VLLM model instance."""
        manager = VLLMManager(
            model_name=config["model"],
            port=config["port"],
            max_model_len=config["max_model_len"],
            gpu_memory_utilization=config["gpu_memory_utilization"]
        )
        
        # Start server in thread to avoid blocking
        loop = asyncio.get_event_loop()
        with ThreadPoolExecutor() as executor:
            success = await loop.run_in_executor(executor, manager.start_server)
        
        if success:
            self.managers[category] = manager
            
            # Create agent
            agent_config = Config(
                name=f"vllm-{category}-agent",
                model_provider="vllm",
                model_id=manager.get_served_model_name(),
                endpoint=f"{manager.base_url}/v1",
                api_key="none"
            )
            
            self.agents[category] = Agent(config=agent_config)
            
            # Create client pool for high throughput
            self.client_pool[category] = [
                openai.OpenAI(base_url=f"{manager.base_url}/v1")
                for _ in range(5)  # 5 clients per model for parallelism
            ]
            
            return True
        else:
            raise Exception(f"Failed to start VLLM server for {category}")
    
    def get_optimal_agent(self, request_complexity: str, current_load: Dict[str, int]) -> str:
        """Select optimal agent based on request complexity and current load."""
        complexity_mapping = {
            "simple": "lightweight",
            "moderate": "balanced", 
            "complex": "capable"
        }
        
        preferred_category = complexity_mapping.get(request_complexity, "balanced")
        
        # Check if preferred agent is available and not overloaded
        if (preferred_category in self.agents and 
            current_load.get(preferred_category, 0) < 10):  # Max 10 concurrent per agent
            return preferred_category
        
        # Fallback to least loaded available agent
        available_agents = [(cat, load) for cat, load in current_load.items() 
                          if cat in self.agents and load < 10]
        
        if available_agents:
            return min(available_agents, key=lambda x: x[1])[0]
        
        return "balanced"  # Default fallback
    
    async def process_batch_requests(self, requests: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """Process multiple requests in parallel for maximum throughput."""
        current_load = {cat: 0 for cat in self.agents.keys()}
        tasks = []
        
        for request in requests:
            # Determine optimal agent
            complexity = request.get("complexity", "moderate")
            agent_category = self.get_optimal_agent(complexity, current_load)
            current_load[agent_category] += 1
            
            # Create processing task
            task = self._process_single_request(request, agent_category)
            tasks.append(task)
        
        # Process all requests in parallel
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # Format results
        formatted_results = []
        for i, result in enumerate(results):
            if isinstance(result, Exception):
                formatted_results.append({
                    "request_id": requests[i].get("id", i),
                    "status": "error",
                    "error": str(result)
                })
            else:
                formatted_results.append(result)
        
        return formatted_results
    
    async def _process_single_request(self, request: Dict[str, Any], agent_category: str) -> Dict[str, Any]:
        """Process a single request with the specified agent."""
        start_time = time.time()
        
        try:
            agent = self.agents[agent_category]
            response = await agent.chat_async(request["message"])
            
            processing_time = time.time() - start_time
            
            return {
                "request_id": request.get("id"),
                "status": "success",
                "response": response,
                "agent_used": agent_category,
                "processing_time": processing_time
            }
            
        except Exception as e:
            return {
                "request_id": request.get("id"),
                "status": "error",
                "error": str(e),
                "agent_used": agent_category,
                "processing_time": time.time() - start_time
            }

# High-throughput usage example
throughput_manager = VLLMHighThroughputManager()

# Initialize all models
initialized_count = await throughput_manager.initialize_all_models()
print(f"Initialized {initialized_count} models")

# Process batch requests
batch_requests = [
    {"id": 1, "message": "Simple question", "complexity": "simple"},
    {"id": 2, "message": "Complex analysis needed", "complexity": "complex"},
    {"id": 3, "message": "Moderate difficulty task", "complexity": "moderate"}
]

results = await throughput_manager.process_batch_requests(batch_requests)
for result in results:
    print(f"Request {result['request_id']}: {result['status']} in {result.get('processing_time', 0):.2f}s")
```
  

#### Ð¨Ð°Ð±Ð»Ð¾Ð½Ð¸ Ñ€Ð¾Ð·Ð³Ð¾Ñ€Ñ‚Ð°Ð½Ð½Ñ Ñƒ Ð²Ð¸Ñ€Ð¾Ð±Ð½Ð¸Ñ‡Ð¾Ð¼Ñƒ ÑÐµÑ€ÐµÐ´Ð¾Ð²Ð¸Ñ‰Ñ–  

**Ð’Ð¸Ñ€Ð¾Ð±Ð½Ð¸Ñ‡Ð¸Ð¹ ÑÐµÑ€Ð²Ñ–Ñ VLLM Ð´Ð»Ñ Ð¿Ñ–Ð´Ð¿Ñ€Ð¸Ñ”Ð¼ÑÑ‚Ð²**:  
```python
import asyncio
import logging
import time
from typing import Dict, List, Optional
from dataclasses import dataclass
from microsoft_agent_framework import Agent, Config
import uvicorn
from fastapi import FastAPI, HTTPException, BackgroundTasks
from pydantic import BaseModel

@dataclass
class VLLMServerConfig:
    model_name: str
    port: int
    gpu_memory_utilization: float
    max_model_len: int
    tensor_parallel_size: int = 1
    quantization: Optional[str] = None

class AgentRequest(BaseModel):
    message: str
    agent_type: str = "general"
    priority: str = "normal"
    timeout: int = 30

class VLLMProductionService:
    def __init__(self, server_configs: Dict[str, VLLMServerConfig]):
        self.server_configs = server_configs
        self.managers = {}
        self.agents = {}
        self.metrics = {
            "requests_processed": 0,
            "requests_failed": 0,
            "total_processing_time": 0,
            "agent_usage": {name: 0 for name in server_configs.keys()},
            "throughput_per_minute": 0
        }
        self.request_queue = asyncio.Queue(maxsize=1000)
        self.processing_workers = []
        self.app = FastAPI(title="VLLM Agent Service")
        self._setup_routes()
        
    async def initialize_production_environment(self):
        """Initialize all VLLM servers for production."""
        logging.info("Initializing VLLM production environment...")
        
        initialization_tasks = []
        for name, config in self.server_configs.items():
            task = self._initialize_server(name, config)
            initialization_tasks.append(task)
        
        results = await asyncio.gather(*initialization_tasks, return_exceptions=True)
        
        successful_servers = 0
        for i, result in enumerate(results):
            server_name = list(self.server_configs.keys())[i]
            if isinstance(result, Exception):
                logging.error(f"Failed to initialize {server_name}: {result}")
            else:
                successful_servers += 1
                logging.info(f"Successfully initialized {server_name}")
        
        if successful_servers == 0:
            raise Exception("No VLLM servers could be initialized")
        
        # Start processing workers
        self.processing_workers = [
            asyncio.create_task(self._processing_worker(i))
            for i in range(min(4, successful_servers))  # 4 workers max
        ]
        
        logging.info(f"Production environment ready with {successful_servers} servers")
        return successful_servers
    
    async def _initialize_server(self, name: str, config: VLLMServerConfig):
        """Initialize a single VLLM server."""
        manager = VLLMManager(
            model_name=config.model_name,
            port=config.port,
            gpu_memory_utilization=config.gpu_memory_utilization,
            max_model_len=config.max_model_len
        )
        
        # Add quantization if specified
        if config.quantization:
            # This would be added to the manager's start command
            pass
        
        success = manager.start_server()
        if success:
            self.managers[name] = manager
            
            # Create production agent
            agent_config = Config(
                name=f"vllm-production-{name}",
                model_provider="vllm",
                model_id=manager.get_served_model_name(),
                endpoint=f"{manager.base_url}/v1",
                api_key="none",
                timeout=30.0
            )
            
            agent = Agent(config=agent_config)
            
            # Add production tools
            self._add_production_tools(agent, name)
            
            self.agents[name] = agent
            return True
        else:
            raise Exception(f"Failed to start VLLM server for {name}")
    
    def _add_production_tools(self, agent: Agent, server_type: str):
        """Add production tools based on server type."""
        if server_type == "customer_service":
            @agent.tool
            def escalate_to_human(issue: str, customer_id: str) -> str:
                """Escalate complex issues to human agents."""
                return f"Escalated issue for customer {customer_id}: {issue}"
            
            @agent.tool
            def lookup_order_status(order_id: str) -> dict:
                """Look up order status from production database."""
                # Production database lookup
                return {"order_id": order_id, "status": "shipped", "eta": "2 days"}
        
        elif server_type == "technical_support":
            @agent.tool
            def run_system_diagnostics(system_id: str) -> dict:
                """Run comprehensive system diagnostics."""
                return {"system_id": system_id, "status": "healthy", "issues": []}
            
            @agent.tool
            def create_incident_report(description: str, severity: str) -> str:
                """Create incident report in production system."""
                incident_id = f"INC-{hash(description) % 100000:05d}"
                return f"Created incident {incident_id} with severity {severity}"
    
    def _setup_routes(self):
        """Set up FastAPI routes for production service."""
        @self.app.post("/chat")
        async def chat_endpoint(request: AgentRequest, background_tasks: BackgroundTasks):
            try:
                # Add request to queue
                await self.request_queue.put({
                    "request": request,
                    "timestamp": time.time(),
                    "future": asyncio.Future()
                })
                
                # Wait for processing (with timeout)
                result = await asyncio.wait_for(
                    self._wait_for_result(request),
                    timeout=request.timeout
                )
                
                return result
                
            except asyncio.TimeoutError:
                raise HTTPException(status_code=408, detail="Request timeout")
            except Exception as e:
                raise HTTPException(status_code=500, detail=str(e))
        
        @self.app.get("/health")
        async def health_endpoint():
            return await self.get_health_status()
        
        @self.app.get("/metrics")
        async def metrics_endpoint():
            return self.get_production_metrics()
    
    async def _processing_worker(self, worker_id: int):
        """Background worker for processing agent requests."""
        logging.info(f"Starting processing worker {worker_id}")
        
        while True:
            try:
                # Get request from queue
                queue_item = await self.request_queue.get()
                request_data = queue_item["request"]
                request_future = queue_item["future"]
                
                # Select appropriate agent
                agent_name = self._select_agent(request_data.agent_type)
                
                if agent_name not in self.agents:
                    request_future.set_exception(Exception(f"Agent {agent_name} not available"))
                    continue
                
                # Process request
                start_time = time.time()
                try:
                    agent = self.agents[agent_name]
                    response = await agent.chat_async(request_data.message)
                    
                    processing_time = time.time() - start_time
                    
                    # Update metrics
                    self.metrics["requests_processed"] += 1
                    self.metrics["total_processing_time"] += processing_time
                    self.metrics["agent_usage"][agent_name] += 1
                    
                    result = {
                        "response": response,
                        "agent_used": agent_name,
                        "processing_time": processing_time,
                        "worker_id": worker_id
                    }
                    
                    request_future.set_result(result)
                    
                except Exception as e:
                    self.metrics["requests_failed"] += 1
                    request_future.set_exception(e)
                
                finally:
                    self.request_queue.task_done()
                    
            except Exception as e:
                logging.error(f"Worker {worker_id} error: {e}")
                await asyncio.sleep(1)
    
    def _select_agent(self, agent_type: str) -> str:
        """Select appropriate agent based on request type."""
        agent_mapping = {
            "customer_service": "customer_service",
            "technical": "technical_support",
            "general": "general_purpose"
        }
        
        return agent_mapping.get(agent_type, "general_purpose")
    
    async def _wait_for_result(self, request: AgentRequest):
        """Wait for request processing to complete."""
        # This is simplified - in production you'd track futures properly
        await asyncio.sleep(0.1)  # Placeholder
        return {"response": "Processed", "status": "success"}
    
    async def get_health_status(self) -> dict:
        """Get comprehensive health status of all services."""
        health_status = {
            "overall_status": "healthy",
            "servers": {},
            "queue_size": self.request_queue.qsize(),
            "active_workers": len([w for w in self.processing_workers if not w.done()]),
            "timestamp": time.time()
        }
        
        unhealthy_servers = 0
        for name, manager in self.managers.items():
            try:
                is_healthy = manager.health_check()
                health_status["servers"][name] = {
                    "status": "healthy" if is_healthy else "unhealthy",
                    "endpoint": manager.base_url,
                    "model": manager.model_name
                }
                if not is_healthy:
                    unhealthy_servers += 1
            except Exception as e:
                health_status["servers"][name] = {
                    "status": "error",
                    "error": str(e)
                }
                unhealthy_servers += 1
        
        if unhealthy_servers > 0:
            health_status["overall_status"] = "degraded" if unhealthy_servers < len(self.managers) else "unhealthy"
        
        return health_status
    
    def get_production_metrics(self) -> dict:
        """Get production performance metrics."""
        total_requests = self.metrics["requests_processed"] + self.metrics["requests_failed"]
        avg_processing_time = (
            self.metrics["total_processing_time"] / self.metrics["requests_processed"]
            if self.metrics["requests_processed"] > 0 else 0
        )
        
        success_rate = (
            self.metrics["requests_processed"] / total_requests * 100
            if total_requests > 0 else 0
        )
        
        return {
            "total_requests": total_requests,
            "successful_requests": self.metrics["requests_processed"],
            "failed_requests": self.metrics["requests_failed"],
            "success_rate_percent": success_rate,
            "average_processing_time_seconds": avg_processing_time,
            "agent_usage_distribution": self.metrics["agent_usage"],
            "queue_size": self.request_queue.qsize()
        }
    
    async def start_production_server(self, host: str = "0.0.0.0", port: int = 8080):
        """Start the production FastAPI server."""
        config = uvicorn.Config(
            self.app,
            host=host,
            port=port,
            log_level="info",
            workers=1  # Single worker for simplicity
        )
        server = uvicorn.Server(config)
        await server.serve()

# Production deployment example
production_configs = {
    "customer_service": VLLMServerConfig(
        model_name="microsoft/Phi-3.5-mini-instruct",
        port=8000,
        gpu_memory_utilization=0.4,
        max_model_len=4096
    ),
    "technical_support": VLLMServerConfig(
        model_name="meta-llama/Llama-3.2-3B-Instruct",
        port=8001,
        gpu_memory_utilization=0.6,
        max_model_len=8192
    ),
    "general_purpose": VLLMServerConfig(
        model_name="Qwen/Qwen2.5-1.5B-Instruct",
        port=8002,
        gpu_memory_utilization=0.3,
        max_model_len=2048
    )
}

production_service = VLLMProductionService(production_configs)

# Initialize and start production service
# await production_service.initialize_production_environment()
# await production_service.start_production_server()
```
  

#### Ð¤ÑƒÐ½ÐºÑ†Ñ–Ñ— Ð´Ð»Ñ Ð¿Ñ–Ð´Ð¿Ñ€Ð¸Ñ”Ð¼ÑÑ‚Ð² Ñ‚Ð° Ð¼Ð¾Ð½Ñ–Ñ‚Ð¾Ñ€Ð¸Ð½Ð³  

**Ð Ð¾Ð·ÑˆÐ¸Ñ€ÐµÐ½Ð¸Ð¹ Ð¼Ð¾Ð½Ñ–Ñ‚Ð¾Ñ€Ð¸Ð½Ð³ Ð¿Ñ€Ð¾Ð´ÑƒÐºÑ‚Ð¸Ð²Ð½Ð¾ÑÑ‚Ñ– VLLM**:  
```python
import psutil
import nvidia_ml_py3 as nvml
from dataclasses import dataclass
from typing import List, Dict, Optional
import json
import asyncio

@dataclass
class PerformanceMetrics:
    timestamp: float
    requests_per_second: float
    average_latency_ms: float
    gpu_utilization_percent: float
    gpu_memory_used_gb: float
    cpu_utilization_percent: float
    memory_used_gb: float
    queue_length: int
    active_requests: int

class VLLMAdvancedMonitoring:
    def __init__(self, vllm_managers: Dict[str, VLLMManager]):
        self.managers = vllm_managers
        self.metrics_history = []
        self.alert_thresholds = {
            "gpu_utilization_max": 95,
            "gpu_memory_max_gb": 10,
            "latency_max_ms": 3000,
            "queue_length_max": 50,
            "error_rate_max_percent": 10
        }
        
        # Initialize NVIDIA ML for GPU monitoring
        try:
            nvml.nvmlInit()
            self.gpu_monitoring_available = True
            self.gpu_count = nvml.nvmlDeviceGetCount()
        except:
            self.gpu_monitoring_available = False
            self.gpu_count = 0
    
    async def collect_comprehensive_metrics(self) -> Dict[str, PerformanceMetrics]:
        """Collect detailed performance metrics for all VLLM instances."""
        all_metrics = {}
        
        for name, manager in self.managers.items():
            try:
                metrics = await self._collect_single_instance_metrics(name, manager)
                all_metrics[name] = metrics
            except Exception as e:
                logging.error(f"Failed to collect metrics for {name}: {e}")
                # Create error metrics
                all_metrics[name] = PerformanceMetrics(
                    timestamp=time.time(),
                    requests_per_second=0,
                    average_latency_ms=0,
                    gpu_utilization_percent=0,
                    gpu_memory_used_gb=0,
                    cpu_utilization_percent=0,
                    memory_used_gb=0,
                    queue_length=0,
                    active_requests=0
                )
        
        return all_metrics
    
    async def _collect_single_instance_metrics(self, name: str, manager: VLLMManager) -> PerformanceMetrics:
        """Collect metrics for a single VLLM instance."""
        timestamp = time.time()
        
        # Get VLLM-specific metrics via API
        vllm_stats = await self._get_vllm_stats(manager)
        
        # Get system metrics
        cpu_percent = psutil.cpu_percent(interval=0.1)
        memory_info = psutil.virtual_memory()
        memory_used_gb = memory_info.used / (1024**3)
        
        # Get GPU metrics if available
        gpu_utilization = 0
        gpu_memory_used = 0
        
        if self.gpu_monitoring_available and self.gpu_count > 0:
            try:
                # Assuming first GPU for simplicity
                handle = nvml.nvmlDeviceGetHandleByIndex(0)
                gpu_util = nvml.nvmlDeviceGetUtilizationRates(handle)
                gpu_utilization = gpu_util.gpu
                
                gpu_mem = nvml.nvmlDeviceGetMemoryInfo(handle)
                gpu_memory_used = gpu_mem.used / (1024**3)
                
            except Exception as e:
                logging.warning(f"GPU monitoring failed: {e}")
        
        return PerformanceMetrics(
            timestamp=timestamp,
            requests_per_second=vllm_stats.get("requests_per_second", 0),
            average_latency_ms=vllm_stats.get("average_latency_ms", 0),
            gpu_utilization_percent=gpu_utilization,
            gpu_memory_used_gb=gpu_memory_used,
            cpu_utilization_percent=cpu_percent,
            memory_used_gb=memory_used_gb,
            queue_length=vllm_stats.get("queue_length", 0),
            active_requests=vllm_stats.get("active_requests", 0)
        )
    
    async def _get_vllm_stats(self, manager: VLLMManager) -> dict:
        """Get VLLM-specific statistics via API calls."""
        try:
            # Test inference to measure latency
            start_time = time.time()
            client = manager.get_openai_client()
            
            response = await asyncio.wait_for(
                asyncio.to_thread(
                    client.chat.completions.create,
                    model=manager.get_served_model_name(),
                    messages=[{"role": "user", "content": "ping"}],
                    max_tokens=1
                ),
                timeout=5.0
            )
            
            latency_ms = (time.time() - start_time) * 1000
            
            return {
                "average_latency_ms": latency_ms,
                "requests_per_second": 1000 / latency_ms if latency_ms > 0 else 0,
                "queue_length": 0,  # Would need to be exposed by VLLM
                "active_requests": 1  # Approximation
            }
            
        except Exception as e:
            logging.warning(f"Failed to get VLLM stats: {e}")
            return {
                "average_latency_ms": 0,
                "requests_per_second": 0,
                "queue_length": 0,
                "active_requests": 0
            }
    
    def generate_performance_report(self, time_window_minutes: int = 60) -> dict:
        """Generate comprehensive performance report."""
        cutoff_time = time.time() - (time_window_minutes * 60)
        recent_metrics = [
            metrics for metrics in self.metrics_history
            if any(m.timestamp > cutoff_time for m in metrics.values())
        ]
        
        if not recent_metrics:
            return {"error": "No recent metrics available"}
        
        report = {
            "time_window_minutes": time_window_minutes,
            "total_samples": len(recent_metrics),
            "instances": {}
        }
        
        # Analyze each instance
        for instance_name in self.managers.keys():
            instance_metrics = [
                metrics[instance_name] for metrics in recent_metrics
                if instance_name in metrics
            ]
            
            if instance_metrics:
                report["instances"][instance_name] = {
                    "avg_latency_ms": sum(m.average_latency_ms for m in instance_metrics) / len(instance_metrics),
                    "max_latency_ms": max(m.average_latency_ms for m in instance_metrics),
                    "avg_gpu_utilization": sum(m.gpu_utilization_percent for m in instance_metrics) / len(instance_metrics),
                    "avg_requests_per_second": sum(m.requests_per_second for m in instance_metrics) / len(instance_metrics),
                    "max_queue_length": max(m.queue_length for m in instance_metrics),
                    "availability_percent": (len(instance_metrics) / len(recent_metrics)) * 100
                }
        
        return report
    
    async def auto_scaling_recommendations(self) -> List[dict]:
        """Generate auto-scaling recommendations based on performance metrics."""
        recommendations = []
        
        if not self.metrics_history:
            return recommendations
        
        latest_metrics = self.metrics_history[-1]
        
        for instance_name, metrics in latest_metrics.items():
            # High latency recommendation
            if metrics.average_latency_ms > self.alert_thresholds["latency_max_ms"]:
                recommendations.append({
                    "instance": instance_name,
                    "type": "scale_up",
                    "reason": f"High latency: {metrics.average_latency_ms:.0f}ms",
                    "suggestion": "Consider adding tensor parallelism or increasing GPU memory"
                })
            
            # High GPU utilization recommendation
            if metrics.gpu_utilization_percent > self.alert_thresholds["gpu_utilization_max"]:
                recommendations.append({
                    "instance": instance_name,
                    "type": "scale_out",
                    "reason": f"High GPU utilization: {metrics.gpu_utilization_percent:.1f}%",
                    "suggestion": "Consider adding additional GPU instances"
                })
            
            # Low utilization recommendation
            if (metrics.gpu_utilization_percent < 20 and 
                metrics.requests_per_second < 1):
                recommendations.append({
                    "instance": instance_name,
                    "type": "scale_down",
                    "reason": f"Low utilization: {metrics.gpu_utilization_percent:.1f}% GPU, {metrics.requests_per_second:.1f} RPS",
                    "suggestion": "Consider consolidating workloads or reducing resources"
                })
        
        return recommendations

# Advanced monitoring setup
monitoring = VLLMAdvancedMonitoring({
    "customer_service": vllm_manager,
    # Add other managers as needed
})

async def advanced_monitoring_loop():
    """Advanced monitoring with auto-scaling recommendations."""
    while True:
        try:
            # Collect metrics
            metrics = await monitoring.collect_comprehensive_metrics()
            monitoring.metrics_history.append(metrics)
            
            # Keep only last 1000 entries
            if len(monitoring.metrics_history) > 1000:
                monitoring.metrics_history = monitoring.metrics_history[-1000:]
            
            # Generate recommendations every 5 minutes
            if len(monitoring.metrics_history) % 10 == 0:  # Every 10th collection (5 minutes if collecting every 30s)
                recommendations = await monitoring.auto_scaling_recommendations()
                
                if recommendations:
                    logging.info(f"Auto-scaling recommendations: {recommendations}")
            
            # Generate performance report every hour
            if len(monitoring.metrics_history) % 120 == 0:  # Every 120th collection (1 hour)
                report = monitoring.generate_performance_report(60)
                logging.info(f"Performance report: {json.dumps(report, indent=2)}")
            
        except Exception as e:
            logging.error(f"Advanced monitoring error: {e}")
        
        await asyncio.sleep(30)  # Collect metrics every 30 seconds

# Start advanced monitoring
# asyncio.create_task(advanced_monitoring_loop())
```
  

#### Ð Ð¾Ð·ÑˆÐ¸Ñ€ÐµÐ½Ð° ÐºÐ¾Ð½Ñ„Ñ–Ð³ÑƒÑ€Ð°Ñ†Ñ–Ñ Ñ‚Ð° Ð¾Ð¿Ñ‚Ð¸Ð¼Ñ–Ð·Ð°Ñ†Ñ–Ñ  

**Ð¨Ð°Ð±Ð»Ð¾Ð½Ð¸ ÐºÐ¾Ð½Ñ„Ñ–Ð³ÑƒÑ€Ð°Ñ†Ñ–Ñ— VLLM Ð´Ð»Ñ Ð²Ð¸Ñ€Ð¾Ð±Ð½Ð¸Ñ‡Ð¾Ð³Ð¾ ÑÐµÑ€ÐµÐ´Ð¾Ð²Ð¸Ñ‰Ð°**:  
```python
from enum import Enum
from typing import Dict, Any

class DeploymentScenario(Enum):
    DEVELOPMENT = "development"
    STAGING = "staging"
    PRODUCTION_LOW = "production_low"
    PRODUCTION_HIGH = "production_high"
    ENTERPRISE = "enterprise"

class VLLMConfigTemplates:
    """Production-ready VLLM configuration templates."""
    
    @staticmethod
    def get_config_template(scenario: DeploymentScenario) -> Dict[str, Any]:
        """Get optimized configuration for deployment scenario."""
        
        templates = {
            DeploymentScenario.DEVELOPMENT: {
                "gpu_memory_utilization": 0.6,
                "max_model_len": 2048,
                "tensor_parallel_size": 1,
                "pipeline_parallel_size": 1,
                "quantization": None,
                "enable_prefix_caching": False,
                "max_num_seqs": 32,
                "max_num_batched_tokens": 2048
            },
            
            DeploymentScenario.STAGING: {
                "gpu_memory_utilization": 0.8,
                "max_model_len": 4096,
                "tensor_parallel_size": 1,
                "pipeline_parallel_size": 1,
                "quantization": "awq",
                "enable_prefix_caching": True,
                "max_num_seqs": 64,
                "max_num_batched_tokens": 4096
            },
            
            DeploymentScenario.PRODUCTION_LOW: {
                "gpu_memory_utilization": 0.85,
                "max_model_len": 4096,
                "tensor_parallel_size": 1,
                "pipeline_parallel_size": 1,
                "quantization": "awq",
                "enable_prefix_caching": True,
                "max_num_seqs": 128,
                "max_num_batched_tokens": 8192,
                "enable_chunked_prefill": True
            },
            
            DeploymentScenario.PRODUCTION_HIGH: {
                "gpu_memory_utilization": 0.9,
                "max_model_len": 8192,
                "tensor_parallel_size": 2,
                "pipeline_parallel_size": 1,
                "quantization": "awq",
                "enable_prefix_caching": True,
                "max_num_seqs": 256,
                "max_num_batched_tokens": 16384,
                "enable_chunked_prefill": True,
                "speculative_model": "small_draft_model"
            },
            
            DeploymentScenario.ENTERPRISE: {
                "gpu_memory_utilization": 0.95,
                "max_model_len": 16384,
                "tensor_parallel_size": 4,
                "pipeline_parallel_size": 2,
                "quantization": "awq",
                "enable_prefix_caching": True,
                "max_num_seqs": 512,
                "max_num_batched_tokens": 32768,
                "enable_chunked_prefill": True,
                "speculative_model": "optimized_draft_model",
                "guided_decoding_backend": "outlines"
            }
        }
        
        return templates[scenario]
    
    @staticmethod
    def generate_vllm_command(model_name: str, 
                             scenario: DeploymentScenario,
                             port: int = 8000,
                             host: str = "0.0.0.0") -> List[str]:
        """Generate optimized VLLM command for deployment scenario."""
        
        config = VLLMConfigTemplates.get_config_template(scenario)
        
        cmd = [
            "python", "-m", "vllm.entrypoints.openai.api_server",
            "--model", model_name,
            "--host", host,
            "--port", str(port),
            "--gpu-memory-utilization", str(config["gpu_memory_utilization"]),
            "--max-model-len", str(config["max_model_len"]),
            "--tensor-parallel-size", str(config["tensor_parallel_size"]),
            "--max-num-seqs", str(config["max_num_seqs"]),
            "--max-num-batched-tokens", str(config["max_num_batched_tokens"]),
            "--trust-remote-code",
            "--disable-log-requests"
        ]
        
        # Add optional parameters
        if config.get("quantization"):
            cmd.extend(["--quantization", config["quantization"]])
        
        if config.get("enable_prefix_caching"):
            cmd.append("--enable-prefix-caching")
        
        if config.get("enable_chunked_prefill"):
            cmd.append("--enable-chunked-prefill")
        
        if config.get("pipeline_parallel_size", 1) > 1:
            cmd.extend(["--pipeline-parallel-size", str(config["pipeline_parallel_size"])])
        
        if config.get("speculative_model"):
            cmd.extend(["--speculative-model", config["speculative_model"]])
        
        return cmd

# Usage examples
dev_cmd = VLLMConfigTemplates.generate_vllm_command(
    "microsoft/Phi-3.5-mini-instruct",
    DeploymentScenario.DEVELOPMENT,
    port=8000
)

prod_cmd = VLLMConfigTemplates.generate_vllm_command(
    "microsoft/Phi-3.5-mini-instruct",
    DeploymentScenario.PRODUCTION_HIGH,
    port=8001
)

print(f"Development command: {' '.join(dev_cmd)}")
print(f"Production command: {' '.join(prod_cmd)}")
```
  
**ÐšÐ¾Ð½Ñ‚Ñ€Ð¾Ð»ÑŒÐ½Ð¸Ð¹ ÑÐ¿Ð¸ÑÐ¾Ðº Ð´Ð»Ñ Ñ€Ð¾Ð·Ð³Ð¾Ñ€Ñ‚Ð°Ð½Ð½Ñ VLLM Ñƒ Ð²Ð¸Ñ€Ð¾Ð±Ð½Ð¸Ñ‡Ð¾Ð¼Ñƒ ÑÐµÑ€ÐµÐ´Ð¾Ð²Ð¸Ñ‰Ñ–**:

âœ… **ÐžÐ¿Ñ‚Ð¸Ð¼Ñ–Ð·Ð°Ñ†Ñ–Ñ Ð¾Ð±Ð»Ð°Ð´Ð½Ð°Ð½Ð½Ñ**:
- ÐÐ°Ð»Ð°ÑˆÑ‚ÑƒÐ¹Ñ‚Ðµ Ð¿Ð°Ñ€Ð°Ð»ÐµÐ»Ñ–Ð·Ð¼ Ñ‚ÐµÐ½Ð·Ð¾Ñ€Ñ–Ð² Ð´Ð»Ñ Ð±Ð°Ð³Ð°Ñ‚Ð¾Ð¿Ñ€Ð¾Ñ†ÐµÑÐ¾Ñ€Ð½Ð¸Ñ… ÑƒÑÑ‚Ð°Ð½Ð¾Ð²Ð¾Ðº  
- Ð£Ð²Ñ–Ð¼ÐºÐ½Ñ–Ñ‚ÑŒ ÐºÐ²Ð°Ð½Ñ‚ÑƒÐ²Ð°Ð½Ð½Ñ (AWQ/GPTQ) Ð´Ð»Ñ ÐµÑ„ÐµÐºÑ‚Ð¸Ð²Ð½Ð¾Ð³Ð¾ Ð²Ð¸ÐºÐ¾Ñ€Ð¸ÑÑ‚Ð°Ð½Ð½Ñ Ð¿Ð°Ð¼â€™ÑÑ‚Ñ–  
- Ð’ÑÑ‚Ð°Ð½Ð¾Ð²Ñ–Ñ‚ÑŒ Ð¾Ð¿Ñ‚Ð¸Ð¼Ð°Ð»ÑŒÐ½Ðµ Ð²Ð¸ÐºÐ¾Ñ€Ð¸ÑÑ‚Ð°Ð½Ð½Ñ Ð¿Ð°Ð¼â€™ÑÑ‚Ñ– GPU (85-95%)  
- ÐÐ°Ð»Ð°ÑˆÑ‚ÑƒÐ¹Ñ‚Ðµ Ð²Ñ–Ð´Ð¿Ð¾Ð²Ñ–Ð´Ð½Ñ– Ñ€Ð¾Ð·Ð¼Ñ–Ñ€Ð¸ Ð¿Ð°ÐºÐµÑ‚Ñ–Ð² Ð´Ð»Ñ Ð¿Ñ€Ð¾Ð¿ÑƒÑÐºÑƒ  

âœ… **ÐÐ°Ð»Ð°ÑˆÑ‚ÑƒÐ²Ð°Ð½Ð½Ñ Ð¿Ñ€Ð¾Ð´ÑƒÐºÑ‚Ð¸Ð²Ð½Ð¾ÑÑ‚Ñ–**:
- Ð£Ð²Ñ–Ð¼ÐºÐ½Ñ–Ñ‚ÑŒ ÐºÐµÑˆÑƒÐ²Ð°Ð½Ð½Ñ Ð¿Ñ€ÐµÑ„Ñ–ÐºÑÑ–Ð² Ð´Ð»Ñ Ð¿Ð¾Ð²Ñ‚Ð¾Ñ€ÑŽÐ²Ð°Ð½Ð¸Ñ… Ð·Ð°Ð¿Ð¸Ñ‚Ñ–Ð²  
- ÐÐ°Ð»Ð°ÑˆÑ‚ÑƒÐ¹Ñ‚Ðµ ÑÐµÐ³Ð¼ÐµÐ½Ñ‚Ð¾Ð²Ð°Ð½Ðµ Ð·Ð°Ð¿Ð¾Ð²Ð½ÐµÐ½Ð½Ñ Ð´Ð»Ñ Ð´Ð¾Ð²Ð³Ð¸Ñ… Ð¿Ð¾ÑÐ»Ñ–Ð´Ð¾Ð²Ð½Ð¾ÑÑ‚ÐµÐ¹  
- Ð£Ð²Ñ–Ð¼ÐºÐ½Ñ–Ñ‚ÑŒ ÑÐ¿ÐµÐºÑƒÐ»ÑÑ‚Ð¸Ð²Ð½Ðµ Ð´ÐµÐºÐ¾Ð´ÑƒÐ²Ð°Ð½Ð½Ñ Ð´Ð»Ñ ÑˆÐ²Ð¸Ð´ÑˆÐ¾Ð³Ð¾ Ñ–Ð½Ñ„ÐµÑ€ÐµÐ½ÑÑƒ  
- ÐžÐ¿Ñ‚Ð¸Ð¼Ñ–Ð·ÑƒÐ¹Ñ‚Ðµ max_num_seqs Ð²Ñ–Ð´Ð¿Ð¾Ð²Ñ–Ð´Ð½Ð¾ Ð´Ð¾ Ð¾Ð±Ð»Ð°Ð´Ð½Ð°Ð½Ð½Ñ  

âœ… **Ð¤ÑƒÐ½ÐºÑ†Ñ–Ñ— Ð´Ð»Ñ Ð²Ð¸Ñ€Ð¾Ð±Ð½Ð¸Ñ‡Ð¾Ð³Ð¾ ÑÐµÑ€ÐµÐ´Ð¾Ð²Ð¸Ñ‰Ð°**:
- ÐÐ°Ð»Ð°ÑˆÑ‚ÑƒÐ¹Ñ‚Ðµ Ð¼Ð¾Ð½Ñ–Ñ‚Ð¾Ñ€Ð¸Ð½Ð³ ÑÑ‚Ð°Ð½Ñƒ Ñ‚Ð° Ð·Ð±Ñ–Ñ€ Ð¼ÐµÑ‚Ñ€Ð¸Ðº  
- ÐšÐ¾Ð½Ñ„Ñ–Ð³ÑƒÑ€ÑƒÐ¹Ñ‚Ðµ Ð°Ð²Ñ‚Ð¾Ð¼Ð°Ñ‚Ð¸Ñ‡Ð½Ð¸Ð¹ Ð¿ÐµÑ€ÐµÐ·Ð°Ð¿ÑƒÑÐº Ñ‚Ð° Ð²Ñ–Ð´Ð½Ð¾Ð²Ð»ÐµÐ½Ð½Ñ  
- Ð ÐµÐ°Ð»Ñ–Ð·ÑƒÐ¹Ñ‚Ðµ Ñ‡ÐµÑ€Ð³Ð¸ Ð·Ð°Ð¿Ð¸Ñ‚Ñ–Ð² Ñ‚Ð° Ð±Ð°Ð»Ð°Ð½ÑÑƒÐ²Ð°Ð½Ð½Ñ Ð½Ð°Ð²Ð°Ð½Ñ‚Ð°Ð¶ÐµÐ½Ð½Ñ  
- ÐÐ°Ð»Ð°ÑˆÑ‚ÑƒÐ¹Ñ‚Ðµ ÐºÐ¾Ð¼Ð¿Ð»ÐµÐºÑÐ½Ðµ Ð»Ð¾Ð³ÑƒÐ²Ð°Ð½Ð½Ñ Ñ‚Ð° Ð¾Ð¿Ð¾Ð²Ñ–Ñ‰ÐµÐ½Ð½Ñ  

âœ… **Ð‘ÐµÐ·Ð¿ÐµÐºÐ° Ñ‚Ð° Ð½Ð°Ð´Ñ–Ð¹Ð½Ñ–ÑÑ‚ÑŒ**:
- ÐÐ°Ð»Ð°ÑˆÑ‚ÑƒÐ¹Ñ‚Ðµ Ð¿Ñ€Ð°Ð²Ð¸Ð»Ð° Ð±Ñ€Ð°Ð½Ð´Ð¼Ð°ÑƒÐµÑ€Ð° Ñ‚Ð° ÐºÐ¾Ð½Ñ‚Ñ€Ð¾Ð»ÑŒ Ð´Ð¾ÑÑ‚ÑƒÐ¿Ñƒ  
- Ð’ÑÑ‚Ð°Ð½Ð¾Ð²Ñ–Ñ‚ÑŒ Ð¾Ð±Ð¼ÐµÐ¶ÐµÐ½Ð½Ñ ÑˆÐ²Ð¸Ð´ÐºÐ¾ÑÑ‚Ñ– API Ñ‚Ð° Ð°Ð²Ñ‚ÐµÐ½Ñ‚Ð¸Ñ„Ñ–ÐºÐ°Ñ†Ñ–ÑŽ  
- Ð ÐµÐ°Ð»Ñ–Ð·ÑƒÐ¹Ñ‚Ðµ Ð¿Ð»Ð°Ð²Ð½Ðµ Ð·Ð°Ð²ÐµÑ€ÑˆÐµÐ½Ð½Ñ Ñ€Ð¾Ð±Ð¾Ñ‚Ð¸ Ñ‚Ð° Ð¾Ñ‡Ð¸Ñ‰ÐµÐ½Ð½Ñ  
- ÐÐ°Ð»Ð°ÑˆÑ‚ÑƒÐ¹Ñ‚Ðµ Ñ€ÐµÐ·ÐµÑ€Ð²Ð½Ðµ ÐºÐ¾Ð¿Ñ–ÑŽÐ²Ð°Ð½Ð½Ñ Ñ‚Ð° Ð²Ñ–Ð´Ð½Ð¾Ð²Ð»ÐµÐ½Ð½Ñ Ð¿Ñ–ÑÐ»Ñ Ð°Ð²Ð°Ñ€Ñ–Ð¹  

âœ… **Ð¢ÐµÑÑ‚ÑƒÐ²Ð°Ð½Ð½Ñ Ñ–Ð½Ñ‚ÐµÐ³Ñ€Ð°Ñ†Ñ–Ñ—**:
- Ð¢ÐµÑÑ‚ÑƒÐ²Ð°Ð½Ð½Ñ Ñ–Ð½Ñ‚ÐµÐ³Ñ€Ð°Ñ†Ñ–Ñ— Microsoft Agent Framework  
- Ð’Ð°Ð»Ñ–Ð´Ð°Ñ†Ñ–Ñ ÑÑ†ÐµÐ½Ð°Ñ€Ñ–Ñ—Ð² Ð²Ð¸ÑÐ¾ÐºÐ¾Ñ— Ð¿Ñ€Ð¾Ð¿ÑƒÑÐºÐ½Ð¾Ñ— Ð·Ð´Ð°Ñ‚Ð½Ð¾ÑÑ‚Ñ–  
- Ð¢ÐµÑÑ‚ÑƒÐ²Ð°Ð½Ð½Ñ Ð¿Ñ€Ð¾Ñ†ÐµÐ´ÑƒÑ€ Ð²Ñ–Ð´Ð½Ð¾Ð²Ð»ÐµÐ½Ð½Ñ Ð¿Ñ–ÑÐ»Ñ Ð²Ñ–Ð´Ð¼Ð¾Ð²Ð¸  
- Ð‘ÐµÐ½Ñ‡Ð¼Ð°Ñ€ÐºÑ–Ð½Ð³ Ð¿Ñ€Ð¾Ð´ÑƒÐºÑ‚Ð¸Ð²Ð½Ð¾ÑÑ‚Ñ– Ð¿Ñ–Ð´ Ð½Ð°Ð²Ð°Ð½Ñ‚Ð°Ð¶ÐµÐ½Ð½ÑÐ¼  

**ÐŸÐ¾Ñ€Ñ–Ð²Ð½ÑÐ½Ð½Ñ Ð· Ñ–Ð½ÑˆÐ¸Ð¼Ð¸ Ñ€Ñ–ÑˆÐµÐ½Ð½ÑÐ¼Ð¸**:

| Ð¤ÑƒÐ½ÐºÑ†Ñ–Ñ | VLLM | Foundry Local | Ollama |
|---------|------|---------------|--------|
| **Ð¦Ñ–Ð»ÑŒÐ¾Ð²Ðµ Ð²Ð¸ÐºÐ¾Ñ€Ð¸ÑÑ‚Ð°Ð½Ð½Ñ** | Ð’Ð¸ÑÐ¾ÐºÐ¾Ð¿Ñ€Ð¾Ð´ÑƒÐºÑ‚Ð¸Ð²Ð½Ðµ Ð²Ð¸Ñ€Ð¾Ð±Ð½Ð¸Ñ‡Ðµ ÑÐµÑ€ÐµÐ´Ð¾Ð²Ð¸Ñ‰Ðµ | ÐŸÑ€Ð¾ÑÑ‚Ð¾Ñ‚Ð° Ð´Ð»Ñ Ð¿Ñ–Ð´Ð¿Ñ€Ð¸Ñ”Ð¼ÑÑ‚Ð² | Ð Ð¾Ð·Ñ€Ð¾Ð±ÐºÐ° Ñ‚Ð° ÑÐ¿Ñ–Ð»ÑŒÐ½Ð¾Ñ‚Ð° |
| **ÐŸÑ€Ð¾Ð´ÑƒÐºÑ‚Ð¸Ð²Ð½Ñ–ÑÑ‚ÑŒ** | ÐœÐ°ÐºÑÐ¸Ð¼Ð°Ð»ÑŒÐ½Ð¸Ð¹ Ð¿Ñ€Ð¾Ð¿ÑƒÑÐº | Ð—Ð±Ð°Ð»Ð°Ð½ÑÐ¾Ð²Ð°Ð½Ð° | Ð¥Ð¾Ñ€Ð¾ÑˆÐ° |
| **Ð•Ñ„ÐµÐºÑ‚Ð¸Ð²Ð½Ñ–ÑÑ‚ÑŒ Ð¿Ð°Ð¼â€™ÑÑ‚Ñ–** | ÐžÐ¿Ñ‚Ð¸Ð¼Ñ–Ð·Ð°Ñ†Ñ–Ñ PagedAttention | ÐÐ²Ñ‚Ð¾Ð¼Ð°Ñ‚Ð¸Ñ‡Ð½Ð° Ð¾Ð¿Ñ‚Ð¸Ð¼Ñ–Ð·Ð°Ñ†Ñ–Ñ | Ð¡Ñ‚Ð°Ð½Ð´Ð°Ñ€Ñ‚Ð½Ð° |
| **Ð¡ÐºÐ»Ð°Ð´Ð½Ñ–ÑÑ‚ÑŒ Ð½Ð°Ð»Ð°ÑˆÑ‚ÑƒÐ²Ð°Ð½Ð½Ñ** | Ð’Ð¸ÑÐ¾ÐºÐ° (Ð±Ð°Ð³Ð°Ñ‚Ð¾ Ð¿Ð°Ñ€Ð°Ð¼ÐµÑ‚Ñ€Ñ–Ð²) | ÐÐ¸Ð·ÑŒÐºÐ° (Ð°Ð²Ñ‚Ð¾Ð¼Ð°Ñ‚Ð¸Ñ‡Ð½Ð°) | ÐÐ¸Ð·ÑŒÐºÐ° (Ð¿Ñ€Ð¾ÑÑ‚Ð°) |
| **ÐœÐ°ÑÑˆÑ‚Ð°Ð±Ð¾Ð²Ð°Ð½Ñ–ÑÑ‚ÑŒ** | Ð’Ñ–Ð´Ð¼Ñ–Ð½Ð½Ð° (Ð¿Ð°Ñ€Ð°Ð»ÐµÐ»Ñ–Ð·Ð¼ Ñ‚ÐµÐ½Ð·Ð¾Ñ€Ñ–Ð²/ÐºÐ¾Ð½Ð²ÐµÑ”Ñ€Ñ–Ð²) | Ð¥Ð¾Ñ€Ð¾ÑˆÐ° | ÐžÐ±Ð¼ÐµÐ¶ÐµÐ½Ð° |
| **ÐšÐ²Ð°Ð½Ñ‚ÑƒÐ²Ð°Ð½Ð½Ñ** | Ð Ð¾Ð·ÑˆÐ¸Ñ€ÐµÐ½Ðµ (AWQ, GPTQ, FP8) | ÐÐ²Ñ‚Ð¾Ð¼Ð°Ñ‚Ð¸Ñ‡Ð½Ðµ | Ð¡Ñ‚Ð°Ð½Ð´Ð°Ñ€Ñ‚Ð½Ðµ GGUF |
| **Ð¤ÑƒÐ½ÐºÑ†Ñ–Ñ— Ð´Ð»Ñ Ð¿Ñ–Ð´Ð¿Ñ€Ð¸Ñ”Ð¼ÑÑ‚Ð²** | ÐŸÐ¾Ñ‚Ñ€Ñ–Ð±Ð½Ð° ÐºÐ°ÑÑ‚Ð¾Ð¼Ñ–Ð·Ð°Ñ†Ñ–Ñ | Ð’Ð±ÑƒÐ´Ð¾Ð²Ð°Ð½Ñ– | Ð†Ð½ÑÑ‚Ñ€ÑƒÐ¼ÐµÐ½Ñ‚Ð¸ ÑÐ¿Ñ–Ð»ÑŒÐ½Ð¾Ñ‚Ð¸ |
| **ÐÐ°Ð¹ÐºÑ€Ð°Ñ‰Ðµ Ð´Ð»Ñ** | ÐÐ³ÐµÐ½Ñ‚Ð¸ Ð´Ð»Ñ Ð¼Ð°ÑÑˆÑ‚Ð°Ð±Ð½Ð¾Ð³Ð¾ Ð²Ð¸Ñ€Ð¾Ð±Ð½Ð¸Ñ†Ñ‚Ð²Ð° | Ð’Ð¸Ñ€Ð¾Ð±Ð½Ð¸Ñ‡Ðµ ÑÐµÑ€ÐµÐ´Ð¾Ð²Ð¸Ñ‰Ðµ Ð´Ð»Ñ Ð¿Ñ–Ð´Ð¿Ñ€Ð¸Ñ”Ð¼ÑÑ‚Ð² | Ð Ð¾Ð·Ñ€Ð¾Ð±ÐºÐ° |

**ÐšÐ¾Ð»Ð¸ Ð¾Ð±Ñ€Ð°Ñ‚Ð¸ VLLM**:
- **Ð’Ð¸Ð¼Ð¾Ð³Ð¸ Ð´Ð¾ Ð²Ð¸ÑÐ¾ÐºÐ¾Ñ— Ð¿Ñ€Ð¾Ð¿ÑƒÑÐºÐ½Ð¾Ñ— Ð·Ð´Ð°Ñ‚Ð½Ð¾ÑÑ‚Ñ–**: ÐžÐ±Ñ€Ð¾Ð±ÐºÐ° ÑÐ¾Ñ‚ÐµÐ½ÑŒ Ð·Ð°Ð¿Ð¸Ñ‚Ñ–Ð² Ð·Ð° ÑÐµÐºÑƒÐ½Ð´Ñƒ  
- **ÐœÐ°ÑÑˆÑ‚Ð°Ð±Ð½Ñ– Ñ€Ð¾Ð·Ð³Ð¾Ñ€Ñ‚Ð°Ð½Ð½Ñ**: Ð‘Ð°Ð³Ð°Ñ‚Ð¾Ð¿Ñ€Ð¾Ñ†ÐµÑÐ¾Ñ€Ð½Ñ–, Ð±Ð°Ð³Ð°Ñ‚Ð¾Ð²ÑƒÐ·Ð»Ð¾Ð²Ñ– Ñ€Ð¾Ð·Ð³Ð¾Ñ€Ñ‚Ð°Ð½Ð½Ñ  
- **ÐšÑ€Ð¸Ñ‚Ð¸Ñ‡Ð½Ð° Ð¿Ñ€Ð¾Ð´ÑƒÐºÑ‚Ð¸Ð²Ð½Ñ–ÑÑ‚ÑŒ**: Ð’Ñ–Ð´Ð¿Ð¾Ð²Ñ–Ð´Ñ– Ð·Ð° Ñ‡Ð°ÑÑ‚ÐºÐ¸ ÑÐµÐºÑƒÐ½Ð´Ð¸ Ñƒ Ð¼Ð°ÑÑˆÑ‚Ð°Ð±Ñ–  
- **Ð Ð¾Ð·ÑˆÐ¸Ñ€ÐµÐ½Ð° Ð¾Ð¿Ñ‚Ð¸Ð¼Ñ–Ð·Ð°Ñ†Ñ–Ñ**: ÐŸÐ¾Ñ‚Ñ€ÐµÐ±Ð° Ð² ÐºÐ°ÑÑ‚Ð¾Ð¼Ð½Ð¾Ð¼Ñƒ ÐºÐ²Ð°Ð½Ñ‚ÑƒÐ²Ð°Ð½Ð½Ñ– Ñ‚Ð° Ð³Ñ€ÑƒÐ¿ÑƒÐ²Ð°Ð½Ð½Ñ–  
- **Ð•Ñ„ÐµÐºÑ‚Ð¸Ð²Ð½Ñ–ÑÑ‚ÑŒ Ñ€ÐµÑÑƒÑ€ÑÑ–Ð²**: ÐœÐ°ÐºÑÐ¸Ð¼Ð°Ð»ÑŒÐ½Ðµ Ð²Ð¸ÐºÐ¾Ñ€Ð¸ÑÑ‚Ð°Ð½Ð½Ñ Ð´Ð¾Ñ€Ð¾Ð³Ð¾Ð³Ð¾ Ð¾Ð±Ð»Ð°Ð´Ð½Ð°Ð½Ð½Ñ GPU  

## Ð ÐµÐ°Ð»ÑŒÐ½Ñ– Ð·Ð°ÑÑ‚Ð¾ÑÑƒÐ²Ð°Ð½Ð½Ñ SLM Ð°Ð³ÐµÐ½Ñ‚Ñ–Ð²  

### ÐÐ³ÐµÐ½Ñ‚Ð¸ SLM Ð´Ð»Ñ Ð¾Ð±ÑÐ»ÑƒÐ³Ð¾Ð²ÑƒÐ²Ð°Ð½Ð½Ñ ÐºÐ»Ñ–Ñ”Ð½Ñ‚Ñ–Ð²  
- **ÐœÐ¾Ð¶Ð»Ð¸Ð²Ð¾ÑÑ‚Ñ– SLM**: ÐŸÐµÑ€ÐµÐ²Ñ–Ñ€ÐºÐ° Ð°ÐºÐ°ÑƒÐ½Ñ‚Ñ–Ð², ÑÐºÐ¸Ð´Ð°Ð½Ð½Ñ Ð¿Ð°Ñ€Ð¾Ð»Ñ–Ð², Ð¿ÐµÑ€ÐµÐ²Ñ–Ñ€ÐºÐ° ÑÑ‚Ð°Ñ‚ÑƒÑÑƒ Ð·Ð°Ð¼Ð¾Ð²Ð»ÐµÐ½ÑŒ  
- **Ð•ÐºÐ¾Ð½Ð¾Ð¼Ñ–Ñ Ð²Ð¸Ñ‚Ñ€Ð°Ñ‚**: Ð—Ð½Ð¸Ð¶ÐµÐ½Ð½Ñ Ð²Ð¸Ñ‚Ñ€Ð°Ñ‚ Ð½Ð° Ñ–Ð½Ñ„ÐµÑ€ÐµÐ½Ñ Ñƒ 10 Ñ€Ð°Ð·Ñ–Ð² Ð¿Ð¾Ñ€Ñ–Ð²Ð½ÑÐ½Ð¾ Ð· Ð°Ð³ÐµÐ½Ñ‚Ð°Ð¼Ð¸ LLM  
- **ÐŸÑ€Ð¾Ð´ÑƒÐºÑ‚Ð¸Ð²Ð½Ñ–ÑÑ‚ÑŒ**: Ð¨Ð²Ð¸Ð´ÑˆÑ– Ð²Ñ–Ð´Ð¿Ð¾Ð²Ñ–Ð´Ñ– Ð· Ð¿Ð¾ÑÑ‚Ñ–Ð¹Ð½Ð¾ÑŽ ÑÐºÑ–ÑÑ‚ÑŽ Ð´Ð»Ñ Ñ€ÑƒÑ‚Ð¸Ð½Ð½Ð¸Ñ… Ð·Ð°Ð¿Ð¸Ñ‚Ñ–Ð²  

### ÐÐ³ÐµÐ½Ñ‚Ð¸ SLM Ð´Ð»Ñ Ð±Ñ–Ð·Ð½ÐµÑ-Ð¿Ñ€Ð¾Ñ†ÐµÑÑ–Ð²  
- **ÐÐ³ÐµÐ½Ñ‚Ð¸ Ð´Ð»Ñ Ð¾Ð±Ñ€Ð¾Ð±ÐºÐ¸ Ñ€Ð°Ñ…ÑƒÐ½ÐºÑ–Ð²**: Ð’Ð¸Ñ‚ÑÐ³ Ð´Ð°Ð½Ð¸Ñ…, Ð¿ÐµÑ€ÐµÐ²Ñ–Ñ€ÐºÐ° Ñ–Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ñ–Ñ—, Ð¼Ð°Ñ€ÑˆÑ€ÑƒÑ‚Ð¸Ð·Ð°Ñ†Ñ–Ñ Ð´Ð»Ñ Ð·Ð°Ñ‚Ð²ÐµÑ€Ð´Ð¶ÐµÐ½Ð½Ñ  
- **ÐÐ³ÐµÐ½Ñ‚Ð¸ Ð´Ð»Ñ ÑƒÐ¿Ñ€Ð°Ð²Ð»Ñ–Ð½Ð½Ñ ÐµÐ»ÐµÐºÑ‚Ñ€Ð¾Ð½Ð½Ð¾ÑŽ Ð¿Ð¾ÑˆÑ‚Ð¾ÑŽ**: ÐšÐ°Ñ‚ÐµÐ³Ð¾Ñ€Ð¸Ð·Ð°Ñ†Ñ–Ñ, Ð¿Ñ€Ñ–Ð¾Ñ€Ð¸Ñ‚Ð¸Ð·Ð°Ñ†Ñ–Ñ, Ð°Ð²Ñ‚Ð¾Ð¼Ð°Ñ‚Ð¸Ñ‡Ð½Ðµ ÑÑ‚Ð²Ð¾Ñ€ÐµÐ½Ð½Ñ Ð²Ñ–Ð´Ð¿Ð¾Ð²Ñ–Ð´ÐµÐ¹  
- **ÐÐ³ÐµÐ½Ñ‚Ð¸ Ð´Ð»Ñ Ð¿Ð»Ð°Ð½ÑƒÐ²Ð°Ð½Ð½Ñ**: ÐšÐ¾Ð¾Ñ€Ð´Ð¸Ð½Ð°Ñ†Ñ–Ñ Ð·ÑƒÑÑ‚Ñ€Ñ–Ñ‡ÐµÐ¹, ÑƒÐ¿Ñ€Ð°Ð²Ð»Ñ–Ð½Ð½Ñ ÐºÐ°Ð»ÐµÐ½Ð´Ð°Ñ€ÑÐ¼Ð¸, Ð½Ð°Ð´ÑÐ¸Ð»Ð°Ð½Ð½Ñ Ð½Ð°Ð³Ð°Ð´ÑƒÐ²Ð°Ð½ÑŒ  

### ÐŸÐµÑ€ÑÐ¾Ð½Ð°Ð»ÑŒÐ½Ñ– Ñ†Ð¸Ñ„Ñ€Ð¾Ð²Ñ– Ð°ÑÐ¸ÑÑ‚ÐµÐ½Ñ‚Ð¸ SLM  
- **ÐÐ³ÐµÐ½Ñ‚Ð¸ Ð´Ð»Ñ ÑƒÐ¿Ñ€Ð°Ð²Ð»Ñ–Ð½Ð½Ñ Ð·Ð°Ð²Ð´Ð°Ð½Ð½ÑÐ¼Ð¸**: Ð¡Ñ‚Ð²Ð¾Ñ€ÐµÐ½Ð½Ñ, Ð¾Ð½Ð¾Ð²Ð»ÐµÐ½Ð½Ñ, Ð¾Ñ€Ð³Ð°Ð½Ñ–Ð·Ð°Ñ†Ñ–Ñ ÑÐ¿Ð¸ÑÐºÑ–Ð² ÑÐ¿Ñ€Ð°Ð²  
- **ÐÐ³ÐµÐ½Ñ‚Ð¸ Ð´Ð»Ñ Ð·Ð±Ð¾Ñ€Ñƒ Ñ–Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ñ–Ñ—**: Ð”Ð¾ÑÐ»Ñ–Ð´Ð¶ÐµÐ½Ð½Ñ Ñ‚ÐµÐ¼, Ð»Ð¾ÐºÐ°Ð»ÑŒÐ½Ðµ Ð¿Ñ–Ð´ÑÑƒÐ¼Ð¾Ð²ÑƒÐ²Ð°Ð½Ð½Ñ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ñ–Ð²  
- **ÐÐ³ÐµÐ½Ñ‚Ð¸ Ð´Ð»Ñ ÐºÐ¾Ð¼ÑƒÐ½Ñ–ÐºÐ°Ñ†Ñ–Ñ—**: Ð¡Ñ‚Ð²Ð¾Ñ€ÐµÐ½Ð½Ñ ÐµÐ»ÐµÐºÑ‚Ñ€Ð¾Ð½Ð½Ð¸Ñ… Ð»Ð¸ÑÑ‚Ñ–Ð², Ð¿Ð¾Ð²Ñ–Ð´Ð¾Ð¼Ð»ÐµÐ½ÑŒ, Ð¿Ð¾ÑÑ‚Ñ–Ð² Ñƒ ÑÐ¾Ñ†Ð¼ÐµÑ€ÐµÐ¶Ð°Ñ…  

### ÐÐ³ÐµÐ½Ñ‚Ð¸ SLM Ð´Ð»Ñ Ñ‚Ð¾Ñ€Ð³Ñ–Ð²Ð»Ñ– Ñ‚Ð° Ñ„Ñ–Ð½Ð°Ð½ÑÑ–Ð²  
- **ÐÐ³ÐµÐ½Ñ‚Ð¸ Ð´Ð»Ñ Ð¼Ð¾Ð½Ñ–Ñ‚Ð¾Ñ€Ð¸Ð½Ð³Ñƒ Ñ€Ð¸Ð½ÐºÑƒ**: Ð’Ñ–Ð´ÑÑ‚ÐµÐ¶ÐµÐ½Ð½Ñ Ñ†Ñ–Ð½, Ð²Ð¸Ð·Ð½Ð°Ñ‡ÐµÐ½Ð½Ñ Ñ‚Ñ€ÐµÐ½Ð´Ñ–Ð² Ñƒ Ñ€ÐµÐ°Ð»ÑŒÐ½Ð¾Ð¼Ñƒ Ñ‡Ð°ÑÑ–  
- **ÐÐ³ÐµÐ½Ñ‚Ð¸ Ð´Ð»Ñ ÑÑ‚Ð²Ð¾Ñ€ÐµÐ½Ð½Ñ Ð·Ð²Ñ–Ñ‚Ñ–Ð²**: ÐÐ²Ñ‚Ð¾Ð¼Ð°Ñ‚Ð¸Ñ‡Ð½Ðµ ÑÑ‚Ð²Ð¾Ñ€ÐµÐ½Ð½Ñ Ñ‰Ð¾Ð´ÐµÐ½Ð½Ð¸Ñ…/Ñ‰Ð¾Ñ‚Ð¸Ð¶Ð½ÐµÐ²Ð¸Ñ… Ð¿Ñ–Ð´ÑÑƒÐ¼ÐºÑ–Ð²  
- **ÐÐ³ÐµÐ½Ñ‚Ð¸ Ð´Ð»Ñ Ð¾Ñ†Ñ–Ð½ÐºÐ¸ Ñ€Ð¸Ð·Ð¸ÐºÑ–Ð²**: ÐÐ½Ð°Ð»Ñ–Ð· Ð¿Ð¾Ð·Ð¸Ñ†Ñ–Ð¹ Ð¿Ð¾Ñ€Ñ‚Ñ„ÐµÐ»Ñ Ð· Ð²Ð¸ÐºÐ¾Ñ€Ð¸ÑÑ‚Ð°Ð½Ð½ÑÐ¼ Ð»Ð¾ÐºÐ°Ð»ÑŒÐ½Ð¸Ñ… Ð´Ð°Ð½Ð¸Ñ…  

### ÐÐ³ÐµÐ½Ñ‚Ð¸ SLM Ð´Ð»Ñ Ð¿Ñ–Ð´Ñ‚Ñ€Ð¸Ð¼ÐºÐ¸ Ð² Ð¾Ñ…Ð¾Ñ€Ð¾Ð½Ñ– Ð·Ð´Ð¾Ñ€Ð¾Ð²â€™Ñ  
- **ÐÐ³ÐµÐ½Ñ‚Ð¸ Ð´Ð»Ñ Ð¿Ð»Ð°Ð½ÑƒÐ²Ð°Ð½Ð½Ñ Ð¿Ð°Ñ†Ñ–Ñ”Ð½Ñ‚Ñ–Ð²**: ÐšÐ¾Ð¾Ñ€Ð´Ð¸Ð½Ð°Ñ†Ñ–Ñ Ð·ÑƒÑÑ‚Ñ€Ñ–Ñ‡ÐµÐ¹, Ð°Ð²Ñ‚Ð¾Ð¼Ð°Ñ‚Ð¸Ñ‡Ð½Ñ– Ð½Ð°Ð³Ð°Ð´ÑƒÐ²Ð°Ð½Ð½Ñ  
- **ÐÐ³ÐµÐ½Ñ‚Ð¸ Ð´Ð»Ñ Ð´Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚Ð°Ñ†Ñ–Ñ—**: Ð›Ð¾ÐºÐ°Ð»ÑŒÐ½Ðµ ÑÑ‚Ð²Ð¾Ñ€ÐµÐ½Ð½Ñ Ð¼ÐµÐ´Ð¸Ñ‡Ð½Ð¸Ñ… Ð¿Ñ–Ð´ÑÑƒÐ¼ÐºÑ–Ð², Ð·Ð²Ñ–Ñ‚Ñ–Ð²  
- **ÐÐ³ÐµÐ½Ñ‚Ð¸ Ð´Ð»Ñ ÑƒÐ¿Ñ€Ð°Ð²Ð»Ñ–Ð½Ð½Ñ Ñ€ÐµÑ†ÐµÐ¿Ñ‚Ð°Ð¼Ð¸**: Ð’Ñ–Ð´ÑÑ‚ÐµÐ¶ÐµÐ½Ð½Ñ Ð¿Ð¾Ð²Ñ‚Ð¾Ñ€Ð½Ð¸Ñ… Ð·Ð°Ð¼Ð¾Ð²Ð»ÐµÐ½ÑŒ, Ð¿ÐµÑ€ÐµÐ²Ñ–Ñ€ÐºÐ° Ð²Ð·Ð°Ñ”Ð¼Ð¾Ð´Ñ–Ð¹  

## Microsoft Agent Framework: Ð Ð¾Ð·Ñ€Ð¾Ð±ÐºÐ° Ð°Ð³ÐµÐ½Ñ‚Ñ–Ð² Ð´Ð»Ñ Ð²Ð¸Ñ€Ð¾Ð±Ð½Ð¸Ñ‡Ð¾Ð³Ð¾ ÑÐµÑ€ÐµÐ´Ð¾Ð²Ð¸Ñ‰Ð°  

### ÐžÐ³Ð»ÑÐ´ Ñ‚Ð° Ð°Ñ€Ñ…Ñ–Ñ‚ÐµÐºÑ‚ÑƒÑ€Ð°  

Microsoft Agent Framework Ð·Ð°Ð±ÐµÐ·Ð¿ÐµÑ‡ÑƒÑ” ÐºÐ¾Ð¼Ð¿Ð»ÐµÐºÑÐ½Ñƒ Ð¿Ð»Ð°Ñ‚Ñ„Ð¾Ñ€Ð¼Ñƒ ÐºÐ¾Ñ€Ð¿Ð¾Ñ€Ð°Ñ‚Ð¸Ð²Ð½Ð¾Ð³Ð¾ Ñ€Ñ–Ð²Ð½Ñ Ð´Ð»Ñ ÑÑ‚Ð²Ð¾Ñ€ÐµÐ½Ð½Ñ, Ñ€Ð¾Ð·Ð³Ð¾Ñ€Ñ‚Ð°Ð½Ð½Ñ Ñ‚Ð° ÑƒÐ¿Ñ€Ð°Ð²Ð»Ñ–Ð½Ð½Ñ AI-Ð°Ð³ÐµÐ½Ñ‚Ð°Ð¼Ð¸, ÑÐºÑ– Ð¼Ð¾Ð¶ÑƒÑ‚ÑŒ Ð¿Ñ€Ð°Ñ†ÑŽÐ²Ð°Ñ‚Ð¸ ÑÐº Ñƒ Ñ…Ð¼Ð°Ñ€Ñ–, Ñ‚Ð°Ðº Ñ– Ð² Ð¾Ñ„Ð»Ð°Ð¹Ð½-ÑÐµÑ€ÐµÐ´Ð¾Ð²Ð¸Ñ‰Ñ–. Ð¤Ñ€ÐµÐ¹Ð¼Ð²Ð¾Ñ€Ðº ÑÐ¿ÐµÑ†Ñ–Ð°Ð»ÑŒÐ½Ð¾ Ñ€Ð¾Ð·Ñ€Ð¾Ð±Ð»ÐµÐ½Ð¸Ð¹ Ð´Ð»Ñ Ð±ÐµÐ·Ð¿ÐµÑ€ÐµÐ±Ñ–Ð¹Ð½Ð¾Ñ— Ñ€Ð¾Ð±Ð¾Ñ‚Ð¸ Ð· Ð¼Ð°Ð»Ð¸Ð¼Ð¸ Ð¼Ð¾Ð²Ð½Ð¸Ð¼Ð¸ Ð¼Ð¾Ð´ÐµÐ»ÑÐ¼Ð¸ Ñ‚Ð° ÑÑ†ÐµÐ½Ð°Ñ€Ñ–ÑÐ¼Ð¸ Ð¾Ð±Ñ‡Ð¸ÑÐ»ÐµÐ½ÑŒ Ð½Ð° Ð¿ÐµÑ€Ð¸Ñ„ÐµÑ€Ñ–Ñ—, Ñ‰Ð¾ Ñ€Ð¾Ð±Ð¸Ñ‚ÑŒ Ð¹Ð¾Ð³Ð¾ Ñ–Ð´ÐµÐ°Ð»ÑŒÐ½Ð¸Ð¼ Ð´Ð»Ñ ÐºÐ¾Ð½Ñ„Ñ–Ð´ÐµÐ½Ñ†Ñ–Ð¹Ð½Ð¸Ñ… Ñ‚Ð° Ñ€ÐµÑÑƒÑ€ÑÐ½Ð¾ Ð¾Ð±Ð¼ÐµÐ¶ÐµÐ½Ð¸Ñ… Ñ€Ð¾Ð·Ð³Ð¾Ñ€Ñ‚Ð°Ð½ÑŒ.

**ÐžÑÐ½Ð¾Ð²Ð½Ñ– ÐºÐ¾Ð¼Ð¿Ð¾Ð½ÐµÐ½Ñ‚Ð¸ Ñ„Ñ€ÐµÐ¹Ð¼Ð²Ð¾Ñ€ÐºÑƒ**:
- **Ð¡ÐµÑ€ÐµÐ´Ð¾Ð²Ð¸Ñ‰Ðµ Ð²Ð¸ÐºÐ¾Ð½Ð°Ð½Ð½Ñ Ð°Ð³ÐµÐ½Ñ‚Ñ–Ð²**: Ð›ÐµÐ³ÐºÐµ ÑÐµÑ€ÐµÐ´Ð¾Ð²Ð¸Ñ‰Ðµ Ð²Ð¸ÐºÐ¾Ð½Ð°Ð½Ð½Ñ, Ð¾Ð¿Ñ‚Ð¸Ð¼Ñ–Ð·Ð¾Ð²Ð°Ð½Ðµ Ð´Ð»Ñ Ð¿ÐµÑ€Ð¸Ñ„ÐµÑ€Ñ–Ð¹Ð½Ð¸Ñ… Ð¿Ñ€Ð¸ÑÑ‚Ñ€Ð¾Ñ—Ð²  
- **Ð¡Ð¸ÑÑ‚ÐµÐ¼Ð° Ñ–Ð½Ñ‚ÐµÐ³Ñ€Ð°Ñ†Ñ–Ñ— Ñ–Ð½ÑÑ‚Ñ€ÑƒÐ¼ÐµÐ½Ñ‚Ñ–Ð²**: Ð Ð¾Ð·ÑˆÐ¸Ñ€ÑŽÐ²Ð°Ð½Ð° Ð°Ñ€Ñ…Ñ–Ñ‚ÐµÐºÑ‚ÑƒÑ€Ð° Ð¿Ð»Ð°Ð³Ñ–Ð½Ñ–Ð² Ð´Ð»Ñ Ð¿Ñ–Ð´ÐºÐ»ÑŽÑ‡ÐµÐ½Ð½Ñ Ð·Ð¾Ð²Ð½Ñ–ÑˆÐ½Ñ–Ñ… ÑÐµÑ€Ð²Ñ–ÑÑ–Ð² Ñ‚Ð° API  
- **Ð£Ð¿Ñ€Ð°Ð²Ð»Ñ–Ð½Ð½Ñ ÑÑ‚Ð°Ð½Ð¾Ð¼**: ÐŸÐ¾ÑÑ‚Ñ–Ð¹Ð½Ð° Ð¿Ð°Ð¼â€™ÑÑ‚ÑŒ Ð°Ð³ÐµÐ½Ñ‚Ñ–Ð² Ñ‚Ð° Ð¾Ð±Ñ€Ð¾Ð±ÐºÐ° ÐºÐ¾Ð½Ñ‚ÐµÐºÑÑ‚Ñƒ Ð¼Ñ–Ð¶ ÑÐµÑÑ–ÑÐ¼Ð¸  
- **Ð¨Ð°Ñ€ Ð±ÐµÐ·Ð¿ÐµÐºÐ¸**: Ð’Ð±ÑƒÐ´Ð¾Ð²Ð°Ð½Ñ– Ð·Ð°ÑÐ¾Ð±Ð¸ Ð±ÐµÐ·Ð¿ÐµÐºÐ¸ Ð´Ð»Ñ ÐºÐ¾Ñ€Ð¿Ð¾Ñ€Ð°Ñ‚Ð¸Ð²Ð½Ð¾Ð³Ð¾ Ñ€Ð¾Ð·Ð³Ð¾Ñ€Ñ‚Ð°Ð½Ð½Ñ  
- **Ð”Ð²Ð¸Ð³ÑƒÐ½ Ð¾Ñ€ÐºÐµÑÑ‚Ñ€Ð°Ñ†Ñ–Ñ—**: ÐšÐ¾Ð¾Ñ€Ð´Ð¸Ð½Ð°Ñ†Ñ–Ñ Ð±Ð°Ð³Ð°Ñ‚ÑŒÐ¾Ñ… Ð°Ð³ÐµÐ½Ñ‚Ñ–Ð² Ñ‚Ð° ÑƒÐ¿Ñ€Ð°Ð²Ð»Ñ–Ð½Ð½Ñ Ñ€Ð¾Ð±Ð¾Ñ‡Ð¸Ð¼Ð¸ Ð¿Ñ€Ð¾Ñ†ÐµÑÐ°Ð¼Ð¸  

### ÐžÑÐ½Ð¾Ð²Ð½Ñ– Ñ„ÑƒÐ½ÐºÑ†Ñ–Ñ— Ð´Ð»Ñ Ð¿ÐµÑ€Ð¸Ñ„ÐµÑ€Ñ–Ð¹Ð½Ð¾Ð³Ð¾ Ñ€Ð¾Ð·Ð³Ð¾Ñ€Ñ‚Ð°Ð½Ð½Ñ  

**ÐÑ€Ñ…Ñ–Ñ‚ÐµÐºÑ‚ÑƒÑ€Ð° Ð· Ð¿Ñ€Ñ–Ð¾Ñ€Ð¸Ñ‚ÐµÑ‚Ð¾Ð¼ Ð¾Ñ„Ð»Ð°Ð¹Ð½**: Microsoft Agent Framework Ñ€Ð¾Ð·Ñ€Ð¾Ð±Ð»ÐµÐ½Ð¸Ð¹ Ð· Ð¿Ñ€Ð¸Ð½Ñ†Ð¸Ð¿Ð°Ð¼Ð¸ "offline-first", Ñ‰Ð¾ Ð´Ð¾Ð·Ð²Ð¾Ð»ÑÑ” Ð°Ð³ÐµÐ½Ñ‚Ð°Ð¼ ÐµÑ„ÐµÐºÑ‚Ð¸Ð²Ð½Ð¾ Ð¿Ñ€Ð°Ñ†ÑŽÐ²Ð°Ñ‚Ð¸ Ð±ÐµÐ· Ð¿Ð¾ÑÑ‚Ñ–Ð¹Ð½Ð¾Ð³Ð¾ Ð¿Ñ–Ð´ÐºÐ»ÑŽÑ‡ÐµÐ½Ð½Ñ Ð´Ð¾ Ñ–Ð½Ñ‚ÐµÑ€Ð½ÐµÑ‚Ñƒ. Ð¦Ðµ Ð²ÐºÐ»ÑŽÑ‡Ð°Ñ” Ð»Ð¾ÐºÐ°Ð»ÑŒÐ½Ð¸Ð¹ Ñ–Ð½Ñ„ÐµÑ€ÐµÐ½Ñ Ð¼Ð¾Ð´ÐµÐ»ÐµÐ¹, ÐºÐµÑˆÐ¾Ð²Ð°Ð½Ñ– Ð±Ð°Ð·Ð¸ Ð·Ð½Ð°Ð½ÑŒ, Ð²Ð¸ÐºÐ¾Ð½Ð°Ð½Ð½Ñ Ñ–Ð½ÑÑ‚Ñ€ÑƒÐ¼ÐµÐ½Ñ‚Ñ–Ð² Ð¾Ñ„Ð»Ð°Ð¹Ð½ Ñ‚Ð° Ð¿Ð»Ð°Ð²Ð½Ñƒ Ð´ÐµÐ³Ñ€Ð°Ð´Ð°Ñ†Ñ–ÑŽ Ð¿Ñ€Ð¸ Ð½ÐµÐ´Ð¾ÑÑ‚ÑƒÐ¿Ð½Ð¾ÑÑ‚Ñ– Ñ…Ð¼Ð°Ñ€Ð½Ð¸Ñ… ÑÐµÑ€Ð²Ñ–ÑÑ–Ð².

**ÐžÐ¿Ñ‚Ð¸Ð¼Ñ–Ð·Ð°Ñ†Ñ–Ñ Ñ€ÐµÑÑƒÑ€ÑÑ–Ð²**: Ð¤Ñ€ÐµÐ¹Ð¼Ð²Ð¾Ñ€Ðº Ð·Ð°Ð±ÐµÐ·Ð¿ÐµÑ‡ÑƒÑ” Ñ–Ð½Ñ‚ÐµÐ»ÐµÐºÑ‚ÑƒÐ°Ð»ÑŒÐ½Ðµ ÑƒÐ¿Ñ€Ð°Ð²Ð»Ñ–Ð½Ð½Ñ Ñ€ÐµÑÑƒÑ€ÑÐ°Ð¼Ð¸ Ð· Ð°Ð²Ñ‚Ð¾Ð¼Ð°Ñ‚Ð¸Ñ‡Ð½Ð¾ÑŽ Ð¾Ð¿Ñ‚Ð¸Ð¼Ñ–Ð·Ð°Ñ†Ñ–Ñ”ÑŽ Ð¿Ð°Ð¼â€™ÑÑ‚Ñ– Ð´Ð»Ñ SLM, Ð±Ð°Ð»Ð°Ð½ÑÑƒÐ²Ð°Ð½Ð½ÑÐ¼ Ð½Ð°Ð²Ð°Ð½Ñ‚Ð°Ð¶ÐµÐ½Ð½Ñ CPU/GPU Ð´Ð»Ñ Ð¿ÐµÑ€Ð¸Ñ„ÐµÑ€Ñ–Ð¹Ð½Ð¸Ñ… Ð¿Ñ€Ð¸ÑÑ‚Ñ€Ð¾Ñ—Ð², Ð°Ð´Ð°Ð¿Ñ‚Ð¸Ð²Ð½Ð¸Ð¼ Ð²Ð¸Ð±Ð¾Ñ€Ð¾Ð¼ Ð¼Ð¾Ð´ÐµÐ»ÐµÐ¹ Ð·Ð°Ð»ÐµÐ¶Ð½Ð¾ Ð²Ñ–Ð´ Ð´Ð¾ÑÑ‚ÑƒÐ¿Ð½Ð¸Ñ… Ñ€ÐµÑÑƒÑ€ÑÑ–Ð² Ñ‚Ð° ÐµÐ½ÐµÑ€Ð³Ð¾ÐµÑ„ÐµÐºÑ‚Ð¸Ð²Ð½Ð¸Ð¼Ð¸ ÑˆÐ°Ð±Ð»Ð¾Ð½Ð°Ð¼Ð¸ Ñ–Ð½Ñ„ÐµÑ€ÐµÐ½ÑÑƒ Ð´Ð»Ñ Ð¼Ð¾Ð±Ñ–Ð»ÑŒÐ½Ð¾Ð³Ð¾ Ñ€Ð¾Ð·Ð³Ð¾Ñ€Ñ‚Ð°Ð½Ð½Ñ.

**Ð‘ÐµÐ·Ð¿ÐµÐºÐ° Ñ‚Ð° ÐºÐ¾Ð½Ñ„Ñ–Ð´ÐµÐ½Ñ†Ñ–Ð¹Ð½Ñ–ÑÑ‚ÑŒ**: Ð¤ÑƒÐ½ÐºÑ†Ñ–Ñ— Ð±ÐµÐ·Ð¿ÐµÐºÐ¸ ÐºÐ¾Ñ€Ð¿Ð¾Ñ€Ð°Ñ‚Ð¸Ð²Ð½Ð¾Ð³Ð¾ Ñ€Ñ–Ð²Ð½Ñ Ð²ÐºÐ»ÑŽÑ‡Ð°ÑŽÑ‚ÑŒ Ð»Ð¾ÐºÐ°Ð»ÑŒÐ½Ñƒ Ð¾Ð±Ñ€Ð¾Ð±ÐºÑƒ Ð´Ð°Ð½Ð¸Ñ… Ð´Ð»Ñ Ð·Ð±ÐµÑ€ÐµÐ¶ÐµÐ½Ð½Ñ ÐºÐ¾Ð½Ñ„Ñ–Ð´ÐµÐ½Ñ†Ñ–Ð¹Ð½Ð¾ÑÑ‚Ñ–, Ð·Ð°ÑˆÐ¸Ñ„Ñ€Ð¾Ð²Ð°Ð½Ñ– ÐºÐ°Ð½Ð°Ð»Ð¸ Ð·Ð²â€™ÑÐ·ÐºÑƒ Ð°Ð³ÐµÐ½Ñ‚Ñ–Ð², ÐºÐ¾Ð½Ñ‚Ñ€Ð¾Ð»ÑŒ Ð´Ð¾ÑÑ‚ÑƒÐ¿Ñƒ Ð½Ð° Ð¾ÑÐ½Ð¾Ð²Ñ– Ñ€Ð¾Ð»ÐµÐ¹ Ð´Ð»Ñ Ð¼Ð¾Ð¶Ð»Ð¸Ð²Ð¾ÑÑ‚ÐµÐ¹ Ð°Ð³ÐµÐ½Ñ‚Ñ–Ð² Ñ‚Ð° Ð°ÑƒÐ´Ð¸Ñ‚ Ð»Ð¾Ð³Ñ–Ð² Ð´Ð»Ñ Ð²Ñ–Ð´Ð¿Ð¾Ð²Ñ–Ð´Ð½Ð¾ÑÑ‚Ñ– Ð²Ð¸Ð¼Ð¾Ð³Ð°Ð¼.

### Ð†Ð½Ñ‚ÐµÐ³Ñ€Ð°Ñ†Ñ–Ñ Ð· Foundry Local  

Microsoft Agent Framework Ð±ÐµÐ·Ð¿ÐµÑ€ÐµÐ±Ñ–Ð¹Ð½Ð¾ Ñ–Ð½Ñ‚ÐµÐ³Ñ€ÑƒÑ”Ñ‚ÑŒÑÑ Ð· Foundry Local, Ð·Ð°Ð±ÐµÐ·Ð¿ÐµÑ‡ÑƒÑŽÑ‡Ð¸ Ð¿Ð¾Ð²Ð½Ðµ Ñ€Ñ–ÑˆÐµÐ½Ð½Ñ Ð´Ð»Ñ Ð¿ÐµÑ€Ð¸Ñ„ÐµÑ€Ñ–Ð¹Ð½Ð¾Ð³Ð¾ AI:

**ÐÐ²Ñ‚Ð¾Ð¼Ð°Ñ‚Ð¸Ñ‡Ð½Ðµ Ð²Ð¸ÑÐ²Ð»ÐµÐ½Ð½Ñ Ð¼Ð¾Ð´ÐµÐ»ÐµÐ¹**: Ð¤Ñ€ÐµÐ¹Ð¼Ð²Ð¾Ñ€Ðº Ð°Ð²Ñ‚Ð¾Ð¼Ð°Ñ‚Ð¸Ñ‡Ð½Ð¾ Ð²Ð¸ÑÐ²Ð»ÑÑ” Ñ‚Ð° Ð¿Ñ–Ð´ÐºÐ»ÑŽÑ‡Ð°Ñ”Ñ‚ÑŒÑÑ Ð´Ð¾ Ñ–Ð½ÑÑ‚Ð°Ð½ÑÑ–Ð² Foundry Local, Ð·Ð½Ð°Ñ…Ð¾Ð´Ð¸Ñ‚ÑŒ Ð´Ð¾ÑÑ‚ÑƒÐ¿Ð½Ñ– Ð¼Ð¾Ð´ÐµÐ»Ñ– SLM Ñ‚Ð° Ð²Ð¸Ð±Ð¸Ñ€Ð°Ñ” Ð¾Ð¿Ñ‚Ð¸Ð¼Ð°Ð»ÑŒÐ½Ñ– Ð¼Ð¾Ð´ÐµÐ»Ñ– Ð·Ð°Ð»ÐµÐ¶Ð½Ð¾ Ð²Ñ–Ð´ Ð²Ð¸Ð¼Ð¾Ð³ Ð°Ð³ÐµÐ½Ñ‚Ñ–Ð² Ñ‚Ð° Ð¼Ð¾Ð¶Ð»Ð¸Ð²Ð¾ÑÑ‚ÐµÐ¹ Ð¾Ð±Ð»Ð°Ð´Ð½Ð°Ð½Ð½Ñ.

**Ð”Ð¸Ð½Ð°Ð¼Ñ–Ñ‡Ð½Ðµ Ð·Ð°Ð²Ð°Ð½Ñ‚Ð°Ð¶ÐµÐ½Ð½Ñ Ð¼Ð¾Ð´ÐµÐ»ÐµÐ¹**: ÐÐ³ÐµÐ½Ñ‚Ð¸ Ð¼Ð¾Ð¶ÑƒÑ‚ÑŒ Ð´Ð¸Ð½Ð°Ð¼Ñ–Ñ‡Ð½Ð¾ Ð·Ð°Ð²Ð°Ð½Ñ‚Ð°Ð¶ÑƒÐ²Ð°Ñ‚Ð¸ Ñ€Ñ–Ð·Ð½Ñ– SLM Ð´Ð»Ñ ÐºÐ¾Ð½ÐºÑ€ÐµÑ‚Ð½Ð¸Ñ… Ð·Ð°Ð²Ð´Ð°Ð½ÑŒ, Ñ‰Ð¾ Ð´Ð¾Ð·Ð²Ð¾Ð»ÑÑ” ÑÑ‚Ð²Ð¾Ñ€ÑŽÐ²Ð°Ñ‚Ð¸ Ð±Ð°Ð³Ð°Ñ‚Ð¾Ð¼Ð¾Ð´ÐµÐ»ÑŒÐ½Ñ– ÑÐ¸ÑÑ‚ÐµÐ¼Ð¸ Ð°Ð³ÐµÐ½Ñ‚Ñ–Ð², Ð´Ðµ Ñ€Ñ–Ð·Ð½Ñ– Ð¼Ð¾Ð´ÐµÐ»Ñ– Ð¾Ð±Ñ€Ð¾Ð±Ð»ÑÑŽÑ‚ÑŒ Ñ€Ñ–Ð·Ð½Ñ– Ñ‚Ð¸Ð¿Ð¸ Ð·Ð°Ð¿Ð¸Ñ‚Ñ–Ð², Ð° Ð°Ð²Ñ‚Ð¾Ð¼Ð°Ñ‚Ð¸Ñ‡Ð½Ðµ Ð¿ÐµÑ€ÐµÐºÐ»ÑŽÑ‡ÐµÐ½Ð½Ñ Ð¼Ñ–Ð¶ Ð¼Ð¾Ð´ÐµÐ»ÑÐ¼Ð¸ Ð·Ð°Ð±ÐµÐ·Ð¿ÐµÑ‡ÑƒÑ” Ð±ÐµÐ·Ð¿ÐµÑ€ÐµÐ±Ñ–Ð¹Ð½Ñ–ÑÑ‚ÑŒ Ñ€Ð¾Ð±Ð¾Ñ‚Ð¸ Ð·Ð°Ð»ÐµÐ¶Ð½Ð¾ Ð²Ñ–Ð´ Ð´Ð¾ÑÑ‚ÑƒÐ¿Ð½Ð¾ÑÑ‚Ñ– Ñ‚Ð° Ð¿Ñ€Ð¾Ð´ÑƒÐºÑ‚Ð¸Ð²Ð½Ð¾ÑÑ‚Ñ–.

**ÐžÐ¿Ñ‚Ð¸Ð¼Ñ–Ð·Ð°Ñ†Ñ–Ñ Ð¿Ñ€Ð¾Ð´ÑƒÐºÑ‚Ð¸Ð²Ð½Ð¾ÑÑ‚Ñ–**: Ð†Ð½Ñ‚ÐµÐ³Ñ€Ð¾Ð²Ð°Ð½Ñ– Ð¼ÐµÑ…Ð°Ð½Ñ–Ð·Ð¼Ð¸ ÐºÐµÑˆÑƒÐ²Ð°Ð½Ð½Ñ Ð·Ð¼ÐµÐ½ÑˆÑƒÑŽÑ‚ÑŒ Ñ‡Ð°Ñ Ð·Ð°Ð²Ð°Ð½Ñ‚Ð°Ð¶ÐµÐ½Ð½Ñ Ð¼Ð¾Ð´ÐµÐ»ÐµÐ¹, Ð¿ÑƒÐ»Ñ–Ð½Ð³ Ð·â€™Ñ”Ð´Ð½Ð°Ð½ÑŒ Ð¾Ð¿Ñ‚Ð¸Ð¼Ñ–Ð·ÑƒÑ” API-Ð²Ð¸ÐºÐ»Ð¸ÐºÐ¸ Ð´Ð¾ Foundry Local, Ð° Ñ–Ð½Ñ‚ÐµÐ»ÐµÐºÑ‚ÑƒÐ°Ð»ÑŒÐ½Ðµ Ð³Ñ€ÑƒÐ¿ÑƒÐ²Ð°Ð½Ð½Ñ Ð¿Ð¾ÐºÑ€Ð°Ñ‰ÑƒÑ” Ð¿Ñ€Ð¾Ð¿ÑƒÑÐºÐ½Ñƒ Ð·Ð´Ð°Ñ‚Ð½Ñ–ÑÑ‚ÑŒ Ð´Ð»Ñ Ð±Ð°Ð³Ð°Ñ‚ÑŒÐ¾Ñ… Ð·Ð°Ð¿Ð¸Ñ‚Ñ–Ð² Ð°Ð³ÐµÐ½Ñ‚Ñ–Ð².

### Ð¡Ñ‚Ð²Ð¾Ñ€ÐµÐ½Ð½Ñ Ð°Ð³ÐµÐ½Ñ‚Ñ–Ð² Ð· Microsoft Agent Framework  

#### Ð’Ð¸Ð·Ð½Ð°Ñ‡ÐµÐ½Ð½Ñ Ñ‚Ð° ÐºÐ¾Ð½Ñ„Ñ–Ð³ÑƒÑ€Ð°Ñ†Ñ–Ñ Ð°Ð³ÐµÐ½Ñ‚Ñ–Ð²  

```python
from microsoft_agent_framework import Agent, Tool, Config
from foundry_local import FoundryLocalManager

# Configure agent with Foundry Local integration
config = Config(
    name="customer-service-agent",
    model_provider="foundry-local",
    model_alias="phi-4-mini",
    max_tokens=512,
    temperature=0.1,
    offline_mode=True
)

# Initialize Foundry Local connection
foundry = FoundryLocalManager("phi-4-mini")

# Create agent instance
agent = Agent(
    config=config,
    model_endpoint=foundry.endpoint,
    api_key=foundry.api_key
)
```
  
#### Ð†Ð½Ñ‚ÐµÐ³Ñ€Ð°Ñ†Ñ–Ñ Ñ–Ð½ÑÑ‚Ñ€ÑƒÐ¼ÐµÐ½Ñ‚Ñ–Ð² Ð´Ð»Ñ Ð¿ÐµÑ€Ð¸Ñ„ÐµÑ€Ñ–Ð¹Ð½Ð¸Ñ… ÑÑ†ÐµÐ½Ð°Ñ€Ñ–Ñ—Ð²  

```python
# Define tools for offline operation
@agent.tool
def lookup_customer_info(customer_id: str) -> dict:
    """Look up customer information from local database."""
    # Local database query - works offline
    return local_db.get_customer(customer_id)

@agent.tool
def create_support_ticket(issue: str, priority: str) -> str:
    """Create a support ticket in local system."""
    # Local ticket creation with sync when online
    ticket_id = local_system.create_ticket(issue, priority)
    return f"Ticket {ticket_id} created successfully"

@agent.tool
def schedule_callback(customer_id: str, preferred_time: str) -> str:
    """Schedule a callback for the customer."""
    # Local scheduling with calendar integration
    return local_calendar.schedule(customer_id, preferred_time)
```
  
#### ÐžÑ€ÐºÐµÑÑ‚Ñ€Ð°Ñ†Ñ–Ñ Ð±Ð°Ð³Ð°Ñ‚ÑŒÐ¾Ñ… Ð°Ð³ÐµÐ½Ñ‚Ñ–Ð²  

```python
from microsoft_agent_framework import AgentOrchestrator

# Create specialized agents for different domains
scheduling_agent = Agent(
    config=Config(
        name="scheduling-agent",
        model_alias="qwen2.5-0.5b",  # Lightweight for simple tasks
        specialized_for="scheduling"
    )
)

technical_support_agent = Agent(
    config=Config(
        name="technical-agent",
        model_alias="phi-4-mini",  # More capable for complex issues
        specialized_for="technical_support"
    )
)

# Orchestrate multiple agents
orchestrator = AgentOrchestrator([
    scheduling_agent,
    technical_support_agent
])

# Route requests based on intent
result = orchestrator.process_request(
    "I need to schedule a callback for a technical issue",
    routing_strategy="intent-based"
)
```
  

### Ð Ð¾Ð·ÑˆÐ¸Ñ€ÐµÐ½Ñ– ÑˆÐ°Ð±Ð»Ð¾Ð½Ð¸ Ñ€Ð¾Ð·Ð³Ð¾Ñ€Ñ‚Ð°Ð½Ð½Ñ Ð½Ð° Ð¿ÐµÑ€Ð¸Ñ„ÐµÑ€Ñ–Ñ—  

#### Ð†Ñ”Ñ€Ð°Ñ€Ñ…Ñ–Ñ‡Ð½Ð° Ð°Ñ€Ñ…Ñ–Ñ‚ÐµÐºÑ‚ÑƒÑ€Ð° Ð°Ð³ÐµÐ½Ñ‚Ñ–Ð²  

**Ð›Ð¾ÐºÐ°Ð»ÑŒÐ½Ñ– ÐºÐ»Ð°ÑÑ‚ÐµÑ€Ð¸ Ð°Ð³ÐµÐ½Ñ‚Ñ–Ð²**: Ð Ð¾Ð·Ð³Ð¾Ñ€Ñ‚Ð°Ð½Ð½Ñ ÐºÑ–Ð»ÑŒÐºÐ¾Ñ… ÑÐ¿ÐµÑ†Ñ–Ð°Ð»Ñ–Ð·Ð¾Ð²Ð°Ð½Ð¸Ñ… SLM Ð°Ð³ÐµÐ½Ñ‚Ñ–Ð² Ð½Ð° Ð¿ÐµÑ€Ð¸Ñ„ÐµÑ€Ñ–Ð¹Ð½Ð¸Ñ… Ð¿Ñ€Ð¸ÑÑ‚Ñ€Ð¾ÑÑ…, ÐºÐ¾Ð¶ÐµÐ½ Ð¾Ð¿Ñ‚Ð¸Ð¼Ñ–Ð·Ð¾Ð²Ð°Ð½Ð¸Ð¹ Ð´Ð»Ñ ÐºÐ¾Ð½ÐºÑ€ÐµÑ‚Ð½Ð¸Ñ… Ð·Ð°Ð²Ð´Ð°Ð½ÑŒ. Ð’Ð¸ÐºÐ¾Ñ€Ð¸ÑÑ‚Ð¾Ð²ÑƒÐ¹Ñ‚Ðµ Ð»ÐµÐ³ÐºÑ– Ð¼Ð¾Ð´ÐµÐ»Ñ–, Ñ‚Ð°ÐºÑ– ÑÐº Qwen2.5-0.5B, Ð´Ð»Ñ Ð¿Ñ€Ð¾ÑÑ‚Ð¾Ð³Ð¾ Ð¼Ð°Ñ€ÑˆÑ€ÑƒÑ‚Ð¸Ð·Ð°Ñ†Ñ–Ñ— Ñ‚Ð° Ð¿Ð»Ð°Ð½ÑƒÐ²Ð°Ð½Ð½Ñ, ÑÐµÑ€ÐµÐ´Ð½Ñ– Ð¼Ð¾Ð´ÐµÐ»Ñ–, Ñ‚Ð°ÐºÑ– ÑÐº Phi-4-Mini, Ð´Ð»Ñ Ð¾Ð±ÑÐ»ÑƒÐ³Ð¾Ð²ÑƒÐ²Ð°Ð½Ð½Ñ ÐºÐ»Ñ–Ñ”Ð½Ñ‚Ñ–Ð² Ñ‚Ð° Ð´Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚Ð°Ñ†Ñ–Ñ—, Ñ– Ð±Ñ–Ð»ÑŒÑˆÑ– Ð¼Ð¾Ð´ÐµÐ»Ñ– Ð´Ð»Ñ ÑÐºÐ»Ð°Ð´Ð½Ð¾Ð³Ð¾ Ð°Ð½Ð°Ð»Ñ–Ð·Ñƒ, ÐºÐ¾Ð»Ð¸ Ñ€ÐµÑÑƒÑ€ÑÐ¸ Ð´Ð¾Ð·Ð²Ð¾Ð»ÑÑŽÑ‚ÑŒ.

**ÐšÐ¾Ð¾Ñ€Ð´Ð¸Ð½Ð°Ñ†Ñ–Ñ Ð¿ÐµÑ€Ð¸Ñ„ÐµÑ€Ñ–Ñ— Ñ‚Ð° Ñ…Ð¼Ð°Ñ€Ð¸**: Ð ÐµÐ°Ð»Ñ–Ð·ÑƒÐ¹Ñ‚Ðµ Ñ–Ð½Ñ‚ÐµÐ»ÐµÐºÑ‚ÑƒÐ°Ð»ÑŒÐ½Ñ– ÑˆÐ°Ð±Ð»Ð¾Ð½Ð¸ ÐµÑÐºÐ°Ð»Ð°Ñ†Ñ–Ñ—, Ð´Ðµ Ð»Ð¾ÐºÐ°Ð»ÑŒÐ½Ñ– Ð°Ð³ÐµÐ½Ñ‚Ð¸ Ð¾Ð±Ñ€Ð¾Ð±Ð»ÑÑŽÑ‚ÑŒ Ñ€ÑƒÑ‚Ð¸Ð½Ð½Ñ– Ð·Ð°Ð²Ð´Ð°Ð½Ð½Ñ, Ñ…Ð¼Ð°Ñ€Ð½Ñ– Ð°Ð³ÐµÐ½Ñ‚Ð¸ Ð·Ð°Ð±ÐµÐ·Ð¿ÐµÑ‡ÑƒÑŽÑ‚ÑŒ ÑÐºÐ»Ð°Ð´Ð½Ð¸Ð¹ Ð°Ð½Ð°Ð»Ñ–Ð·, ÐºÐ¾Ð»Ð¸ Ñ” Ð¿Ñ–Ð´ÐºÐ»ÑŽÑ‡ÐµÐ½Ð½Ñ, Ð° Ð±ÐµÐ·Ð¿ÐµÑ€ÐµÐ±Ñ–Ð¹Ð½Ð¸Ð¹ Ð¿ÐµÑ€ÐµÑ…Ñ–Ð´ Ð¼Ñ–Ð¶ Ð¾Ð±Ñ€Ð¾Ð±ÐºÐ¾ÑŽ Ð½Ð° Ð¿ÐµÑ€Ð¸Ñ„ÐµÑ€Ñ–Ñ— Ñ‚Ð° Ð² Ñ…Ð¼Ð°Ñ€Ñ– Ð¿Ñ–Ð´Ñ‚Ñ€Ð¸Ð¼ÑƒÑ” Ð±ÐµÐ·Ð¿ÐµÑ€ÐµÑ€Ð²Ð½Ñ–ÑÑ‚ÑŒ.

#### ÐšÐ¾Ð½Ñ„Ñ–Ð³ÑƒÑ€Ð°Ñ†Ñ–Ñ— Ñ€Ð¾Ð·Ð³Ð¾Ñ€Ñ‚Ð°Ð½Ð½Ñ  

**Ð Ð¾Ð·Ð³Ð¾Ñ€Ñ‚Ð°Ð½Ð½Ñ Ð½Ð° Ð¾Ð´Ð½Ð¾Ð¼Ñƒ Ð¿Ñ€Ð¸ÑÑ‚Ñ€Ð¾Ñ—**:  
```yaml
deployment:
  type: single-device
  hardware: edge-device
  models:
    - alias: "phi-4-mini"
      primary: true
      tasks: ["conversation", "reasoning"]
    - alias: "qwen2.5-0.5b"
      secondary: true
      tasks: ["routing", "classification"]
  agents:
    - name: "primary-agent"
      model: "phi-4-mini"
      tools: ["database", "calendar", "email"]
```
  
**Ð Ð¾Ð·Ð¿Ð¾Ð´Ñ–Ð»ÐµÐ½Ðµ Ñ€Ð¾Ð·Ð³Ð¾Ñ€Ñ‚Ð°Ð½Ð½Ñ Ð½Ð° Ð¿ÐµÑ€Ð¸Ñ„ÐµÑ€Ñ–Ñ—**:  
```yaml
deployment:
  type: distributed-edge
  nodes:
    - id: "edge-1"
      agents: ["customer-service", "scheduling"]
      models: ["phi-4-mini"]
    - id: "edge-2"
      agents: ["technical-support", "documentation"]
      models: ["qwen2.5-coder-0.5b"]
  coordination:
    load_balancing: true
    failover: automatic
```
  

### ÐžÐ¿Ñ‚Ð¸Ð¼Ñ–Ð·Ð°Ñ†Ñ–Ñ Ð¿Ñ€Ð¾Ð´ÑƒÐºÑ‚Ð¸Ð²Ð½Ð¾ÑÑ‚Ñ– Ð´Ð»Ñ Ð¿ÐµÑ€Ð¸Ñ„ÐµÑ€Ñ–Ð¹Ð½Ð¸Ñ… Ð°Ð³ÐµÐ½Ñ‚Ñ–Ð²  

#### Ð¡Ñ‚Ñ€Ð°Ñ‚ÐµÐ³Ñ–Ñ— Ð²Ð¸Ð±Ð¾Ñ€Ñƒ Ð¼Ð¾Ð´ÐµÐ»ÐµÐ¹  

**ÐŸÑ€Ð¸Ð·Ð½Ð°Ñ‡ÐµÐ½Ð½Ñ Ð¼Ð¾Ð´ÐµÐ»ÐµÐ¹ Ð½Ð° Ð¾ÑÐ½Ð¾Ð²Ñ– Ð·Ð°Ð²Ð´Ð°Ð½ÑŒ**: Microsoft Agent Framework Ð´Ð¾Ð·Ð²Ð¾Ð»ÑÑ” Ñ–Ð½Ñ‚ÐµÐ»ÐµÐºÑ‚ÑƒÐ°Ð»ÑŒÐ½Ð¸Ð¹ Ð²Ð¸Ð±Ñ–Ñ€ Ð¼Ð¾Ð´ÐµÐ»ÐµÐ¹ Ð·Ð°Ð»ÐµÐ¶Ð½Ð¾ Ð²Ñ–Ð´ ÑÐºÐ»Ð°Ð´Ð½Ð¾ÑÑ‚Ñ– Ð·Ð°Ð²Ð´Ð°Ð½Ð½Ñ Ñ‚Ð° Ð²Ð¸Ð¼Ð¾Ð³:

- **ÐŸÑ€Ð¾ÑÑ‚Ñ– Ð·Ð°Ð²Ð´Ð°Ð½Ð½Ñ** (Q&A, Ð¼Ð°Ñ€ÑˆÑ€ÑƒÑ‚Ð¸Ð·Ð°Ñ†Ñ–Ñ): Qwen2.5-0.5B (500MB, <100ms Ð²Ñ–Ð´Ð¿Ð¾Ð²Ñ–Ð´ÑŒ)  
- **ÐŸÐ¾Ð¼Ñ–Ñ€Ð½Ñ– Ð·Ð°Ð²Ð´Ð°Ð½Ð½Ñ** (Ð¾Ð±ÑÐ»ÑƒÐ³Ð¾Ð²ÑƒÐ²Ð°Ð½Ð½Ñ ÐºÐ»Ñ–Ñ”Ð½Ñ‚Ñ–Ð², Ð¿Ð»Ð°Ð½ÑƒÐ²Ð°Ð½Ð½Ñ): Phi-4-Mini (2.4GB, 200-500ms Ð²Ñ–Ð´Ð¿Ð¾Ð²Ñ–Ð´ÑŒ)  
- **Ð¡ÐºÐ»Ð°Ð´Ð½Ñ– Ð·Ð°Ð²Ð´Ð°Ð½Ð½Ñ** (Ñ‚ÐµÑ…Ð½Ñ–Ñ‡Ð½Ð¸Ð¹ Ð°Ð½Ð°Ð»Ñ–Ð·, Ð¿Ð»Ð°Ð½ÑƒÐ²Ð°Ð½Ð½Ñ): Phi-4 (7GB, 1-3s Ð²Ñ–Ð´Ð¿Ð¾Ð²Ñ–Ð´ÑŒ, ÐºÐ¾Ð»Ð¸ Ñ€ÐµÑÑƒÑ€ÑÐ¸ Ð´Ð¾Ð·Ð²Ð¾Ð»ÑÑŽÑ‚ÑŒ)  

**Ð”Ð¸Ð½Ð°Ð¼Ñ–Ñ‡Ð½Ðµ Ð¿ÐµÑ€ÐµÐºÐ»ÑŽÑ‡ÐµÐ½Ð½Ñ Ð¼Ð¾Ð´ÐµÐ»ÐµÐ¹**: ÐÐ³ÐµÐ½Ñ‚Ð¸ Ð¼Ð¾Ð¶ÑƒÑ‚ÑŒ Ð¿ÐµÑ€ÐµÐºÐ»ÑŽÑ‡Ð°Ñ‚Ð¸ÑÑ Ð¼Ñ–Ð¶ Ð¼Ð¾Ð´ÐµÐ»ÑÐ¼Ð¸ Ð·Ð°Ð»ÐµÐ¶Ð½Ð¾ Ð²Ñ–Ð´ Ð¿Ð¾Ñ‚Ð¾Ñ‡Ð½Ð¾Ð³Ð¾ Ð½Ð°Ð²Ð°Ð½Ñ‚Ð°Ð¶ÐµÐ½Ð½Ñ ÑÐ¸ÑÑ‚ÐµÐ¼Ð¸, Ð¾Ñ†Ñ–Ð½ÐºÐ¸ ÑÐºÐ»Ð°Ð´Ð½Ð¾ÑÑ‚Ñ– Ð·Ð°Ð²Ð´Ð°Ð½Ð½Ñ, Ð¿Ñ€Ñ–Ð¾Ñ€Ð¸Ñ‚ÐµÑ‚Ñ–Ð² ÐºÐ¾Ñ€Ð¸ÑÑ‚ÑƒÐ²Ð°Ñ‡Ð° Ñ‚Ð° Ð´Ð¾ÑÑ‚ÑƒÐ¿Ð½Ð¸Ñ… Ð°Ð¿Ð°Ñ€Ð°Ñ‚Ð½Ð¸Ñ… Ñ€ÐµÑÑƒÑ€ÑÑ–Ð².

#### Ð£Ð¿Ñ€Ð°Ð²Ð»Ñ–Ð½Ð½Ñ Ð¿Ð°Ð¼â€™ÑÑ‚Ñ‚ÑŽ Ñ‚Ð° Ñ€ÐµÑÑƒÑ€ÑÐ°Ð¼Ð¸  

```python
# Configure resource constraints for edge deployment
resource_config = ResourceConfig(
    max_memory_usage="4GB",
    max_concurrent_agents=3,
    model_cache_size="2GB",
    auto_unload_idle_models=True,
    power_management=True
)

agent = Agent(
    config=config,
    resource_limits=resource_config
)
```
  

### Ð¨Ð°Ð±Ð»Ð¾Ð½Ð¸ Ñ–Ð½Ñ‚ÐµÐ³Ñ€Ð°Ñ†Ñ–Ñ— Ð´Ð»Ñ Ð¿Ñ–Ð´Ð¿Ñ€Ð¸Ñ”Ð¼ÑÑ‚Ð²  

#### Ð‘ÐµÐ·Ð¿ÐµÐºÐ° Ñ‚Ð° Ð²Ñ–Ð´Ð¿Ð¾Ð²Ñ–Ð´Ð½Ñ–ÑÑ‚ÑŒ  

**Ð›Ð¾ÐºÐ°Ð»ÑŒÐ½Ð° Ð¾Ð±Ñ€Ð¾Ð±ÐºÐ° Ð´Ð°Ð½Ð¸Ñ…**: Ð£ÑÑ– Ð¿Ñ€Ð¾Ñ†ÐµÑÐ¸ Ð°Ð³ÐµÐ½Ñ‚Ñ–Ð² Ð²Ð¸ÐºÐ¾Ð½ÑƒÑŽÑ‚ÑŒÑÑ Ð»Ð¾ÐºÐ°Ð»ÑŒÐ½Ð¾, Ð·Ð°Ð±ÐµÐ·Ð¿ÐµÑ‡ÑƒÑŽÑ‡Ð¸, Ñ‰Ð¾ ÐºÐ¾Ð½Ñ„Ñ–Ð´ÐµÐ½Ñ†Ñ–Ð¹Ð½Ñ– Ð´Ð°Ð½Ñ– Ð½Ñ–ÐºÐ¾Ð»Ð¸ Ð½Ðµ Ð·Ð°Ð»Ð¸ÑˆÐ°ÑŽÑ‚ÑŒ Ð¿ÐµÑ€Ð¸Ñ„ÐµÑ€Ñ–Ð¹Ð½Ð¸Ð¹ Ð¿Ñ€Ð¸ÑÑ‚Ñ€Ñ–Ð¹. Ð¦Ðµ Ð²ÐºÐ»ÑŽÑ‡Ð°Ñ” Ð·Ð°Ñ…Ð¸ÑÑ‚ Ñ–Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ñ–Ñ— ÐºÐ»Ñ–Ñ”Ð½Ñ‚Ñ–Ð², Ð²Ñ–Ð´Ð¿Ð¾Ð²Ñ–Ð´Ð½Ñ–ÑÑ‚ÑŒ HIPAA Ð´Ð»Ñ Ð°Ð³ÐµÐ½Ñ‚Ñ–Ð² Ð¾Ñ…Ð¾Ñ€
**Ð’Ð¸Ð±Ñ–Ñ€ Ñ„Ñ€ÐµÐ¹Ð¼Ð²Ð¾Ñ€ÐºÑƒ Ð´Ð»Ñ Ñ€Ð¾Ð·Ð³Ð¾Ñ€Ñ‚Ð°Ð½Ð½Ñ Ð°Ð³ÐµÐ½Ñ‚Ñ–Ð²**: ÐžÐ±Ð¸Ñ€Ð°Ð¹Ñ‚Ðµ Ð¾Ð¿Ñ‚Ð¸Ð¼Ñ–Ð·Ð°Ñ†Ñ–Ð¹Ð½Ñ– Ñ„Ñ€ÐµÐ¹Ð¼Ð²Ð¾Ñ€ÐºÐ¸ Ð·Ð°Ð»ÐµÐ¶Ð½Ð¾ Ð²Ñ–Ð´ Ñ†Ñ–Ð»ÑŒÐ¾Ð²Ð¾Ð³Ð¾ Ð¾Ð±Ð»Ð°Ð´Ð½Ð°Ð½Ð½Ñ Ñ‚Ð° Ð²Ð¸Ð¼Ð¾Ð³ Ð°Ð³ÐµÐ½Ñ‚Ñ–Ð². Ð’Ð¸ÐºÐ¾Ñ€Ð¸ÑÑ‚Ð¾Ð²ÑƒÐ¹Ñ‚Ðµ Llama.cpp Ð´Ð»Ñ Ñ€Ð¾Ð·Ð³Ð¾Ñ€Ñ‚Ð°Ð½Ð½Ñ Ð°Ð³ÐµÐ½Ñ‚Ñ–Ð², Ð¾Ð¿Ñ‚Ð¸Ð¼Ñ–Ð·Ð¾Ð²Ð°Ð½Ð¸Ñ… Ð´Ð»Ñ Ð¿Ñ€Ð¾Ñ†ÐµÑÐ¾Ñ€Ñ–Ð², Apple MLX Ð´Ð»Ñ Ð·Ð°ÑÑ‚Ð¾ÑÑƒÐ½ÐºÑ–Ð² Ð°Ð³ÐµÐ½Ñ‚Ñ–Ð² Ð½Ð° Apple Silicon, Ñ‚Ð° ONNX Ð´Ð»Ñ Ð·Ð°Ð±ÐµÐ·Ð¿ÐµÑ‡ÐµÐ½Ð½Ñ ÑÑƒÐ¼Ñ–ÑÐ½Ð¾ÑÑ‚Ñ– Ð°Ð³ÐµÐ½Ñ‚Ñ–Ð² Ð½Ð° Ñ€Ñ–Ð·Ð½Ð¸Ñ… Ð¿Ð»Ð°Ñ‚Ñ„Ð¾Ñ€Ð¼Ð°Ñ….

## ÐŸÑ€Ð°ÐºÑ‚Ð¸Ñ‡Ð½Ðµ Ð¿ÐµÑ€ÐµÑ‚Ð²Ð¾Ñ€ÐµÐ½Ð½Ñ SLM Ð°Ð³ÐµÐ½Ñ‚Ñ–Ð² Ñ– Ð¿Ñ€Ð¸ÐºÐ»Ð°Ð´Ð¸ Ð²Ð¸ÐºÐ¾Ñ€Ð¸ÑÑ‚Ð°Ð½Ð½Ñ

### Ð ÐµÐ°Ð»ÑŒÐ½Ñ– ÑÑ†ÐµÐ½Ð°Ñ€Ñ–Ñ— Ñ€Ð¾Ð·Ð³Ð¾Ñ€Ñ‚Ð°Ð½Ð½Ñ Ð°Ð³ÐµÐ½Ñ‚Ñ–Ð²

**ÐœÐ¾Ð±Ñ–Ð»ÑŒÐ½Ñ– Ð·Ð°ÑÑ‚Ð¾ÑÑƒÐ½ÐºÐ¸ Ð°Ð³ÐµÐ½Ñ‚Ñ–Ð²**: Ð¤Ð¾Ñ€Ð¼Ð°Ñ‚Ð¸ Q4_K Ñ‡ÑƒÐ´Ð¾Ð²Ð¾ Ð¿Ñ–Ð´Ñ…Ð¾Ð´ÑÑ‚ÑŒ Ð´Ð»Ñ Ð·Ð°ÑÑ‚Ð¾ÑÑƒÐ½ÐºÑ–Ð² Ð°Ð³ÐµÐ½Ñ‚Ñ–Ð² Ð½Ð° ÑÐ¼Ð°Ñ€Ñ‚Ñ„Ð¾Ð½Ð°Ñ… Ð·Ð°Ð²Ð´ÑÐºÐ¸ Ð¼Ñ–Ð½Ñ–Ð¼Ð°Ð»ÑŒÐ½Ð¾Ð¼Ñƒ Ð²Ð¸ÐºÐ¾Ñ€Ð¸ÑÑ‚Ð°Ð½Ð½ÑŽ Ð¿Ð°Ð¼â€™ÑÑ‚Ñ–, Ñ‚Ð¾Ð´Ñ– ÑÐº Q8_0 Ð·Ð°Ð±ÐµÐ·Ð¿ÐµÑ‡ÑƒÑ” Ð·Ð±Ð°Ð»Ð°Ð½ÑÐ¾Ð²Ð°Ð½Ñƒ Ð¿Ñ€Ð¾Ð´ÑƒÐºÑ‚Ð¸Ð²Ð½Ñ–ÑÑ‚ÑŒ Ð´Ð»Ñ ÑÐ¸ÑÑ‚ÐµÐ¼ Ð°Ð³ÐµÐ½Ñ‚Ñ–Ð² Ð½Ð° Ð¿Ð»Ð°Ð½ÑˆÐµÑ‚Ð°Ñ…. Ð¤Ð¾Ñ€Ð¼Ð°Ñ‚Ð¸ Q5_K Ð¿Ñ€Ð¾Ð¿Ð¾Ð½ÑƒÑŽÑ‚ÑŒ Ð²Ð¸ÑÐ¾ÐºÑƒ ÑÐºÑ–ÑÑ‚ÑŒ Ð´Ð»Ñ Ð¼Ð¾Ð±Ñ–Ð»ÑŒÐ½Ð¸Ñ… Ð°Ð³ÐµÐ½Ñ‚Ñ–Ð² Ð¿Ñ€Ð¾Ð´ÑƒÐºÑ‚Ð¸Ð²Ð½Ð¾ÑÑ‚Ñ–.

**ÐžÐ±Ñ‡Ð¸ÑÐ»ÐµÐ½Ð½Ñ Ð½Ð° Ð½Ð°ÑÑ‚Ñ–Ð»ÑŒÐ½Ð¸Ñ… ÐºÐ¾Ð¼Ð¿â€™ÑŽÑ‚ÐµÑ€Ð°Ñ… Ñ– Ð¿Ñ€Ð¸ÑÑ‚Ñ€Ð¾ÑÑ… Edge**: Q5_K Ð·Ð°Ð±ÐµÐ·Ð¿ÐµÑ‡ÑƒÑ” Ð¾Ð¿Ñ‚Ð¸Ð¼Ð°Ð»ÑŒÐ½Ñƒ Ð¿Ñ€Ð¾Ð´ÑƒÐºÑ‚Ð¸Ð²Ð½Ñ–ÑÑ‚ÑŒ Ð´Ð»Ñ Ð·Ð°ÑÑ‚Ð¾ÑÑƒÐ½ÐºÑ–Ð² Ð°Ð³ÐµÐ½Ñ‚Ñ–Ð² Ð½Ð° Ð½Ð°ÑÑ‚Ñ–Ð»ÑŒÐ½Ð¸Ñ… ÐºÐ¾Ð¼Ð¿â€™ÑŽÑ‚ÐµÑ€Ð°Ñ…, Q8_0 Ð¿Ñ€Ð¾Ð¿Ð¾Ð½ÑƒÑ” Ð²Ð¸ÑÐ¾ÐºÑƒ ÑÐºÑ–ÑÑ‚ÑŒ Ð´Ð»Ñ ÑÐµÑ€ÐµÐ´Ð¾Ð²Ð¸Ñ‰ Ð°Ð³ÐµÐ½Ñ‚Ñ–Ð² Ð½Ð° Ñ€Ð¾Ð±Ð¾Ñ‡Ð¸Ñ… ÑÑ‚Ð°Ð½Ñ†Ñ–ÑÑ…, Ð° Q4_K Ð´Ð¾Ð·Ð²Ð¾Ð»ÑÑ” ÐµÑ„ÐµÐºÑ‚Ð¸Ð²Ð½Ð¾ Ð¾Ð±Ñ€Ð¾Ð±Ð»ÑÑ‚Ð¸ Ð´Ð°Ð½Ñ– Ð½Ð° Ð¿Ñ€Ð¸ÑÑ‚Ñ€Ð¾ÑÑ… Edge.

**Ð”Ð¾ÑÐ»Ñ–Ð´Ð½Ð¸Ñ†ÑŒÐºÑ– Ñ‚Ð° ÐµÐºÑÐ¿ÐµÑ€Ð¸Ð¼ÐµÐ½Ñ‚Ð°Ð»ÑŒÐ½Ñ– Ð°Ð³ÐµÐ½Ñ‚Ð¸**: Ð Ð¾Ð·ÑˆÐ¸Ñ€ÐµÐ½Ñ– Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚Ð¸ ÐºÐ²Ð°Ð½Ñ‚ÑƒÐ²Ð°Ð½Ð½Ñ Ð´Ð¾Ð·Ð²Ð¾Ð»ÑÑŽÑ‚ÑŒ Ð´Ð¾ÑÐ»Ñ–Ð´Ð¶ÑƒÐ²Ð°Ñ‚Ð¸ Ð½Ð°Ð´Ð½Ð¸Ð·ÑŒÐºÑƒ Ñ‚Ð¾Ñ‡Ð½Ñ–ÑÑ‚ÑŒ Ñ–Ð½Ñ„ÐµÑ€ÐµÐ½Ñ†Ñ–Ñ— Ð°Ð³ÐµÐ½Ñ‚Ñ–Ð² Ð´Ð»Ñ Ð°ÐºÐ°Ð´ÐµÐ¼Ñ–Ñ‡Ð½Ð¸Ñ… Ð´Ð¾ÑÐ»Ñ–Ð´Ð¶ÐµÐ½ÑŒ Ñ– Ð¿Ñ€Ð¾Ñ‚Ð¾Ñ‚Ð¸Ð¿Ñ–Ð² Ð·Ð°ÑÑ‚Ð¾ÑÑƒÐ½ÐºÑ–Ð² Ð°Ð³ÐµÐ½Ñ‚Ñ–Ð², ÑÐºÑ– Ð¿Ð¾Ñ‚Ñ€ÐµÐ±ÑƒÑŽÑ‚ÑŒ ÐµÐºÑÑ‚Ñ€ÐµÐ¼Ð°Ð»ÑŒÐ½Ð¸Ñ… Ð¾Ð±Ð¼ÐµÐ¶ÐµÐ½ÑŒ Ñ€ÐµÑÑƒÑ€ÑÑ–Ð².

### ÐžÑ†Ñ–Ð½ÐºÐ° Ð¿Ñ€Ð¾Ð´ÑƒÐºÑ‚Ð¸Ð²Ð½Ð¾ÑÑ‚Ñ– SLM Ð°Ð³ÐµÐ½Ñ‚Ñ–Ð²

**Ð¨Ð²Ð¸Ð´ÐºÑ–ÑÑ‚ÑŒ Ñ–Ð½Ñ„ÐµÑ€ÐµÐ½Ñ†Ñ–Ñ— Ð°Ð³ÐµÐ½Ñ‚Ñ–Ð²**: Q4_K Ð·Ð°Ð±ÐµÐ·Ð¿ÐµÑ‡ÑƒÑ” Ð½Ð°Ð¹ÑˆÐ²Ð¸Ð´ÑˆÐ¸Ð¹ Ñ‡Ð°Ñ Ð²Ñ–Ð´Ð¿Ð¾Ð²Ñ–Ð´Ñ– Ð°Ð³ÐµÐ½Ñ‚Ñ–Ð² Ð½Ð° Ð¼Ð¾Ð±Ñ–Ð»ÑŒÐ½Ð¸Ñ… Ð¿Ñ€Ð¾Ñ†ÐµÑÐ¾Ñ€Ð°Ñ…, Q5_K Ð¿Ñ€Ð¾Ð¿Ð¾Ð½ÑƒÑ” Ð·Ð±Ð°Ð»Ð°Ð½ÑÐ¾Ð²Ð°Ð½Ðµ ÑÐ¿Ñ–Ð²Ð²Ñ–Ð´Ð½Ð¾ÑˆÐµÐ½Ð½Ñ ÑˆÐ²Ð¸Ð´ÐºÐ¾ÑÑ‚Ñ– Ñ‚Ð° ÑÐºÐ¾ÑÑ‚Ñ– Ð´Ð»Ñ Ð·Ð°Ð³Ð°Ð»ÑŒÐ½Ð¸Ñ… Ð·Ð°ÑÑ‚Ð¾ÑÑƒÐ½ÐºÑ–Ð² Ð°Ð³ÐµÐ½Ñ‚Ñ–Ð², Q8_0 Ð·Ð°Ð±ÐµÐ·Ð¿ÐµÑ‡ÑƒÑ” Ð²Ð¸ÑÐ¾ÐºÑƒ ÑÐºÑ–ÑÑ‚ÑŒ Ð´Ð»Ñ ÑÐºÐ»Ð°Ð´Ð½Ð¸Ñ… Ð·Ð°Ð²Ð´Ð°Ð½ÑŒ Ð°Ð³ÐµÐ½Ñ‚Ñ–Ð², Ð° ÐµÐºÑÐ¿ÐµÑ€Ð¸Ð¼ÐµÐ½Ñ‚Ð°Ð»ÑŒÐ½Ñ– Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚Ð¸ Ð´Ð¾ÑÑÐ³Ð°ÑŽÑ‚ÑŒ Ð¼Ð°ÐºÑÐ¸Ð¼Ð°Ð»ÑŒÐ½Ð¾Ñ— Ð¿Ñ€Ð¾Ð¿ÑƒÑÐºÐ½Ð¾Ñ— Ð·Ð´Ð°Ñ‚Ð½Ð¾ÑÑ‚Ñ– Ð´Ð»Ñ ÑÐ¿ÐµÑ†Ñ–Ð°Ð»Ñ–Ð·Ð¾Ð²Ð°Ð½Ð¾Ð³Ð¾ Ð¾Ð±Ð»Ð°Ð´Ð½Ð°Ð½Ð½Ñ Ð°Ð³ÐµÐ½Ñ‚Ñ–Ð².

**Ð’Ð¸Ð¼Ð¾Ð³Ð¸ Ð´Ð¾ Ð¿Ð°Ð¼â€™ÑÑ‚Ñ– Ð°Ð³ÐµÐ½Ñ‚Ñ–Ð²**: Ð Ñ–Ð²Ð½Ñ– ÐºÐ²Ð°Ð½Ñ‚ÑƒÐ²Ð°Ð½Ð½Ñ Ð´Ð»Ñ Ð°Ð³ÐµÐ½Ñ‚Ñ–Ð² Ð²Ð°Ñ€Ñ–ÑŽÑŽÑ‚ÑŒÑÑ Ð²Ñ–Ð´ Q2_K (Ð¼ÐµÐ½ÑˆÐµ 500 ÐœÐ‘ Ð´Ð»Ñ Ð½ÐµÐ²ÐµÐ»Ð¸ÐºÐ¸Ñ… Ð¼Ð¾Ð´ÐµÐ»ÐµÐ¹ Ð°Ð³ÐµÐ½Ñ‚Ñ–Ð²) Ð´Ð¾ Q8_0 (Ð¿Ñ€Ð¸Ð±Ð»Ð¸Ð·Ð½Ð¾ 50% Ð²Ñ–Ð´ Ð¿Ð¾Ñ‡Ð°Ñ‚ÐºÐ¾Ð²Ð¾Ð³Ð¾ Ñ€Ð¾Ð·Ð¼Ñ–Ñ€Ñƒ), Ð° ÐµÐºÑÐ¿ÐµÑ€Ð¸Ð¼ÐµÐ½Ñ‚Ð°Ð»ÑŒÐ½Ñ– ÐºÐ¾Ð½Ñ„Ñ–Ð³ÑƒÑ€Ð°Ñ†Ñ–Ñ— Ð´Ð¾ÑÑÐ³Ð°ÑŽÑ‚ÑŒ Ð¼Ð°ÐºÑÐ¸Ð¼Ð°Ð»ÑŒÐ½Ð¾Ñ— ÐºÐ¾Ð¼Ð¿Ñ€ÐµÑÑ–Ñ— Ð´Ð»Ñ ÑÐµÑ€ÐµÐ´Ð¾Ð²Ð¸Ñ‰ Ð°Ð³ÐµÐ½Ñ‚Ñ–Ð² Ð· Ð¾Ð±Ð¼ÐµÐ¶ÐµÐ½Ð¸Ð¼Ð¸ Ñ€ÐµÑÑƒÑ€ÑÐ°Ð¼Ð¸.

## Ð’Ð¸ÐºÐ»Ð¸ÐºÐ¸ Ñ‚Ð° Ð¼Ñ–Ñ€ÐºÑƒÐ²Ð°Ð½Ð½Ñ Ð´Ð»Ñ SLM Ð°Ð³ÐµÐ½Ñ‚Ñ–Ð²

### ÐšÐ¾Ð¼Ð¿Ñ€Ð¾Ð¼Ñ–ÑÐ¸ Ð¿Ñ€Ð¾Ð´ÑƒÐºÑ‚Ð¸Ð²Ð½Ð¾ÑÑ‚Ñ– Ð² ÑÐ¸ÑÑ‚ÐµÐ¼Ð°Ñ… Ð°Ð³ÐµÐ½Ñ‚Ñ–Ð²

Ð Ð¾Ð·Ð³Ð¾Ñ€Ñ‚Ð°Ð½Ð½Ñ SLM Ð°Ð³ÐµÐ½Ñ‚Ñ–Ð² Ð²Ð¸Ð¼Ð°Ð³Ð°Ñ” Ñ€ÐµÑ‚ÐµÐ»ÑŒÐ½Ð¾Ð³Ð¾ Ð²Ñ€Ð°Ñ…ÑƒÐ²Ð°Ð½Ð½Ñ ÐºÐ¾Ð¼Ð¿Ñ€Ð¾Ð¼Ñ–ÑÑ–Ð² Ð¼Ñ–Ð¶ Ñ€Ð¾Ð·Ð¼Ñ–Ñ€Ð¾Ð¼ Ð¼Ð¾Ð´ÐµÐ»Ñ–, ÑˆÐ²Ð¸Ð´ÐºÑ–ÑÑ‚ÑŽ Ð²Ñ–Ð´Ð¿Ð¾Ð²Ñ–Ð´Ñ– Ð°Ð³ÐµÐ½Ñ‚Ñ–Ð² Ñ– ÑÐºÑ–ÑÑ‚ÑŽ Ð²Ð¸Ñ…Ñ–Ð´Ð½Ð¸Ñ… Ð´Ð°Ð½Ð¸Ñ…. Ð¥Ð¾Ñ‡Ð° Q4_K Ð¿Ñ€Ð¾Ð¿Ð¾Ð½ÑƒÑ” Ð²Ð¸Ð½ÑÑ‚ÐºÐ¾Ð²Ñƒ ÑˆÐ²Ð¸Ð´ÐºÑ–ÑÑ‚ÑŒ Ñ– ÐµÑ„ÐµÐºÑ‚Ð¸Ð²Ð½Ñ–ÑÑ‚ÑŒ Ð´Ð»Ñ Ð¼Ð¾Ð±Ñ–Ð»ÑŒÐ½Ð¸Ñ… Ð°Ð³ÐµÐ½Ñ‚Ñ–Ð², Q8_0 Ð·Ð°Ð±ÐµÐ·Ð¿ÐµÑ‡ÑƒÑ” Ð²Ð¸ÑÐ¾ÐºÑƒ ÑÐºÑ–ÑÑ‚ÑŒ Ð´Ð»Ñ ÑÐºÐ»Ð°Ð´Ð½Ð¸Ñ… Ð·Ð°Ð²Ð´Ð°Ð½ÑŒ Ð°Ð³ÐµÐ½Ñ‚Ñ–Ð². Q5_K Ñ” Ð·Ð¾Ð»Ð¾Ñ‚Ð¾ÑŽ ÑÐµÑ€ÐµÐ´Ð¸Ð½Ð¾ÑŽ, ÑÐºÐ° Ð¿Ñ–Ð´Ñ…Ð¾Ð´Ð¸Ñ‚ÑŒ Ð´Ð»Ñ Ð±Ñ–Ð»ÑŒÑˆÐ¾ÑÑ‚Ñ– Ð·Ð°Ð³Ð°Ð»ÑŒÐ½Ð¸Ñ… Ð·Ð°ÑÑ‚Ð¾ÑÑƒÐ½ÐºÑ–Ð² Ð°Ð³ÐµÐ½Ñ‚Ñ–Ð².

### Ð¡ÑƒÐ¼Ñ–ÑÐ½Ñ–ÑÑ‚ÑŒ Ð¾Ð±Ð»Ð°Ð´Ð½Ð°Ð½Ð½Ñ Ð´Ð»Ñ SLM Ð°Ð³ÐµÐ½Ñ‚Ñ–Ð²

Ð Ñ–Ð·Ð½Ñ– Ð¿Ñ€Ð¸ÑÑ‚Ñ€Ð¾Ñ— Edge Ð¼Ð°ÑŽÑ‚ÑŒ Ñ€Ñ–Ð·Ð½Ñ– Ð¼Ð¾Ð¶Ð»Ð¸Ð²Ð¾ÑÑ‚Ñ– Ð´Ð»Ñ Ñ€Ð¾Ð·Ð³Ð¾Ñ€Ñ‚Ð°Ð½Ð½Ñ SLM Ð°Ð³ÐµÐ½Ñ‚Ñ–Ð². Q4_K ÐµÑ„ÐµÐºÑ‚Ð¸Ð²Ð½Ð¾ Ð¿Ñ€Ð°Ñ†ÑŽÑ” Ð½Ð° Ð±Ð°Ð·Ð¾Ð²Ð¸Ñ… Ð¿Ñ€Ð¾Ñ†ÐµÑÐ¾Ñ€Ð°Ñ… Ð´Ð»Ñ Ð¿Ñ€Ð¾ÑÑ‚Ð¸Ñ… Ð°Ð³ÐµÐ½Ñ‚Ñ–Ð², Q5_K Ð¿Ð¾Ñ‚Ñ€ÐµÐ±ÑƒÑ” Ð¿Ð¾Ð¼Ñ–Ñ€Ð½Ð¸Ñ… Ð¾Ð±Ñ‡Ð¸ÑÐ»ÑŽÐ²Ð°Ð»ÑŒÐ½Ð¸Ñ… Ñ€ÐµÑÑƒÑ€ÑÑ–Ð² Ð´Ð»Ñ Ð·Ð±Ð°Ð»Ð°Ð½ÑÐ¾Ð²Ð°Ð½Ð¾Ñ— Ð¿Ñ€Ð¾Ð´ÑƒÐºÑ‚Ð¸Ð²Ð½Ð¾ÑÑ‚Ñ– Ð°Ð³ÐµÐ½Ñ‚Ñ–Ð², Ð° Q8_0 Ð²Ð¸Ð³Ñ€Ð°Ñ” Ð²Ñ–Ð´ Ð²Ð¸ÑÐ¾ÐºÐ¾ÐºÐ»Ð°ÑÐ½Ð¾Ð³Ð¾ Ð¾Ð±Ð»Ð°Ð´Ð½Ð°Ð½Ð½Ñ Ð´Ð»Ñ Ñ€Ð¾Ð·ÑˆÐ¸Ñ€ÐµÐ½Ð¸Ñ… Ð¼Ð¾Ð¶Ð»Ð¸Ð²Ð¾ÑÑ‚ÐµÐ¹ Ð°Ð³ÐµÐ½Ñ‚Ñ–Ð².

### Ð‘ÐµÐ·Ð¿ÐµÐºÐ° Ñ‚Ð° ÐºÐ¾Ð½Ñ„Ñ–Ð´ÐµÐ½Ñ†Ñ–Ð¹Ð½Ñ–ÑÑ‚ÑŒ Ñƒ ÑÐ¸ÑÑ‚ÐµÐ¼Ð°Ñ… SLM Ð°Ð³ÐµÐ½Ñ‚Ñ–Ð²

Ð¥Ð¾Ñ‡Ð° SLM Ð°Ð³ÐµÐ½Ñ‚Ð¸ Ð´Ð¾Ð·Ð²Ð¾Ð»ÑÑŽÑ‚ÑŒ Ð»Ð¾ÐºÐ°Ð»ÑŒÐ½Ñƒ Ð¾Ð±Ñ€Ð¾Ð±ÐºÑƒ Ð´Ð»Ñ Ð¿Ð¾ÐºÑ€Ð°Ñ‰ÐµÐ½Ð½Ñ ÐºÐ¾Ð½Ñ„Ñ–Ð´ÐµÐ½Ñ†Ñ–Ð¹Ð½Ð¾ÑÑ‚Ñ–, Ð½ÐµÐ¾Ð±Ñ…Ñ–Ð´Ð½Ð¾ Ð²Ð¿Ñ€Ð¾Ð²Ð°Ð´Ð¶ÑƒÐ²Ð°Ñ‚Ð¸ Ð½Ð°Ð»ÐµÐ¶Ð½Ñ– Ð·Ð°Ñ…Ð¾Ð´Ð¸ Ð±ÐµÐ·Ð¿ÐµÐºÐ¸ Ð´Ð»Ñ Ð·Ð°Ñ…Ð¸ÑÑ‚Ñƒ Ð¼Ð¾Ð´ÐµÐ»ÐµÐ¹ Ð°Ð³ÐµÐ½Ñ‚Ñ–Ð² Ñ– Ð´Ð°Ð½Ð¸Ñ… Ñƒ ÑÐµÑ€ÐµÐ´Ð¾Ð²Ð¸Ñ‰Ð°Ñ… Edge. Ð¦Ðµ Ð¾ÑÐ¾Ð±Ð»Ð¸Ð²Ð¾ Ð²Ð°Ð¶Ð»Ð¸Ð²Ð¾ Ð¿Ñ€Ð¸ Ñ€Ð¾Ð·Ð³Ð¾Ñ€Ñ‚Ð°Ð½Ð½Ñ– Ð°Ð³ÐµÐ½Ñ‚Ñ–Ð² Ð²Ð¸ÑÐ¾ÐºÐ¾Ñ— Ñ‚Ð¾Ñ‡Ð½Ð¾ÑÑ‚Ñ– Ð² ÐºÐ¾Ñ€Ð¿Ð¾Ñ€Ð°Ñ‚Ð¸Ð²Ð½Ð¸Ñ… ÑÐµÑ€ÐµÐ´Ð¾Ð²Ð¸Ñ‰Ð°Ñ… Ð°Ð±Ð¾ ÑÑ‚Ð¸ÑÐ½ÐµÐ½Ð¸Ñ… Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚Ñ–Ð² Ð°Ð³ÐµÐ½Ñ‚Ñ–Ð² Ñƒ Ð·Ð°ÑÑ‚Ð¾ÑÑƒÐ½ÐºÐ°Ñ…, ÑÐºÑ– Ð¾Ð±Ñ€Ð¾Ð±Ð»ÑÑŽÑ‚ÑŒ ÐºÐ¾Ð½Ñ„Ñ–Ð´ÐµÐ½Ñ†Ñ–Ð¹Ð½Ñ– Ð´Ð°Ð½Ñ–.

## ÐœÐ°Ð¹Ð±ÑƒÑ‚Ð½Ñ– Ñ‚ÐµÐ½Ð´ÐµÐ½Ñ†Ñ–Ñ— Ð² Ñ€Ð¾Ð·Ñ€Ð¾Ð±Ñ†Ñ– SLM Ð°Ð³ÐµÐ½Ñ‚Ñ–Ð²

Ð›Ð°Ð½Ð´ÑˆÐ°Ñ„Ñ‚ SLM Ð°Ð³ÐµÐ½Ñ‚Ñ–Ð² Ð¿Ñ€Ð¾Ð´Ð¾Ð²Ð¶ÑƒÑ” Ñ€Ð¾Ð·Ð²Ð¸Ð²Ð°Ñ‚Ð¸ÑÑ Ð·Ð°Ð²Ð´ÑÐºÐ¸ Ð²Ð´Ð¾ÑÐºÐ¾Ð½Ð°Ð»ÐµÐ½Ð½ÑŽ Ð¼ÐµÑ‚Ð¾Ð´Ñ–Ð² ÐºÐ¾Ð¼Ð¿Ñ€ÐµÑÑ–Ñ—, Ð¾Ð¿Ñ‚Ð¸Ð¼Ñ–Ð·Ð°Ñ†Ñ–Ñ— Ñ‚Ð° ÑÑ‚Ñ€Ð°Ñ‚ÐµÐ³Ñ–Ð¹ Ñ€Ð¾Ð·Ð³Ð¾Ñ€Ñ‚Ð°Ð½Ð½Ñ Ð½Ð° Edge. ÐœÐ°Ð¹Ð±ÑƒÑ‚Ð½Ñ– Ñ€Ð¾Ð·Ñ€Ð¾Ð±ÐºÐ¸ Ð²ÐºÐ»ÑŽÑ‡Ð°ÑŽÑ‚ÑŒ Ð±Ñ–Ð»ÑŒÑˆ ÐµÑ„ÐµÐºÑ‚Ð¸Ð²Ð½Ñ– Ð°Ð»Ð³Ð¾Ñ€Ð¸Ñ‚Ð¼Ð¸ ÐºÐ²Ð°Ð½Ñ‚ÑƒÐ²Ð°Ð½Ð½Ñ Ð´Ð»Ñ Ð¼Ð¾Ð´ÐµÐ»ÐµÐ¹ Ð°Ð³ÐµÐ½Ñ‚Ñ–Ð², Ð¿Ð¾ÐºÑ€Ð°Ñ‰ÐµÐ½Ñ– Ð¼ÐµÑ‚Ð¾Ð´Ð¸ ÐºÐ¾Ð¼Ð¿Ñ€ÐµÑÑ–Ñ— Ð´Ð»Ñ Ñ€Ð¾Ð±Ð¾Ñ‡Ð¸Ñ… Ð¿Ñ€Ð¾Ñ†ÐµÑÑ–Ð² Ð°Ð³ÐµÐ½Ñ‚Ñ–Ð² Ñ– ÐºÑ€Ð°Ñ‰Ñƒ Ñ–Ð½Ñ‚ÐµÐ³Ñ€Ð°Ñ†Ñ–ÑŽ Ð· Ð°Ð¿Ð°Ñ€Ð°Ñ‚Ð½Ð¸Ð¼Ð¸ Ð¿Ñ€Ð¸ÑÐºÐ¾Ñ€ÑŽÐ²Ð°Ñ‡Ð°Ð¼Ð¸ Edge Ð´Ð»Ñ Ð¾Ð±Ñ€Ð¾Ð±ÐºÐ¸ Ð°Ð³ÐµÐ½Ñ‚Ñ–Ð².

**ÐŸÑ€Ð¾Ð³Ð½Ð¾Ð·Ð¸ Ñ€Ð¸Ð½ÐºÑƒ Ð´Ð»Ñ SLM Ð°Ð³ÐµÐ½Ñ‚Ñ–Ð²**: Ð—Ð³Ñ–Ð´Ð½Ð¾ Ð· Ð¾ÑÑ‚Ð°Ð½Ð½Ñ–Ð¼Ð¸ Ð´Ð¾ÑÐ»Ñ–Ð´Ð¶ÐµÐ½Ð½ÑÐ¼Ð¸, Ð°Ð²Ñ‚Ð¾Ð¼Ð°Ñ‚Ð¸Ð·Ð°Ñ†Ñ–Ñ, Ñ‰Ð¾ Ð±Ð°Ð·ÑƒÑ”Ñ‚ÑŒÑÑ Ð½Ð° Ð°Ð³ÐµÐ½Ñ‚Ð°Ñ…, Ð¼Ð¾Ð¶Ðµ ÑƒÑÑƒÐ½ÑƒÑ‚Ð¸ 40â€“60% Ð¿Ð¾Ð²Ñ‚Ð¾Ñ€ÑŽÐ²Ð°Ð½Ð¸Ñ… ÐºÐ¾Ð³Ð½Ñ–Ñ‚Ð¸Ð²Ð½Ð¸Ñ… Ð·Ð°Ð²Ð´Ð°Ð½ÑŒ Ñƒ ÐºÐ¾Ñ€Ð¿Ð¾Ñ€Ð°Ñ‚Ð¸Ð²Ð½Ð¸Ñ… Ñ€Ð¾Ð±Ð¾Ñ‡Ð¸Ñ… Ð¿Ñ€Ð¾Ñ†ÐµÑÐ°Ñ… Ð´Ð¾ 2027 Ñ€Ð¾ÐºÑƒ, Ð¿Ñ€Ð¸Ñ‡Ð¾Ð¼Ñƒ SLM Ð²Ñ–Ð´Ñ–Ð³Ñ€Ð°ÑŽÑ‚ÑŒ ÐºÐ»ÑŽÑ‡Ð¾Ð²Ñƒ Ñ€Ð¾Ð»ÑŒ Ñƒ Ñ†Ñ–Ð¹ Ñ‚Ñ€Ð°Ð½ÑÑ„Ð¾Ñ€Ð¼Ð°Ñ†Ñ–Ñ— Ð·Ð°Ð²Ð´ÑÐºÐ¸ Ñ—Ñ…Ð½Ñ–Ð¹ ÐµÐºÐ¾Ð½Ð¾Ð¼Ñ–Ñ‡Ð½Ñ–Ð¹ ÐµÑ„ÐµÐºÑ‚Ð¸Ð²Ð½Ð¾ÑÑ‚Ñ– Ñ‚Ð° Ð³Ð½ÑƒÑ‡ÐºÐ¾ÑÑ‚Ñ– Ñ€Ð¾Ð·Ð³Ð¾Ñ€Ñ‚Ð°Ð½Ð½Ñ.

**Ð¢ÐµÑ…Ð½Ð¾Ð»Ð¾Ð³Ñ–Ñ‡Ð½Ñ– Ñ‚ÐµÐ½Ð´ÐµÐ½Ñ†Ñ–Ñ— Ð² SLM Ð°Ð³ÐµÐ½Ñ‚Ð°Ñ…**:
- **Ð¡Ð¿ÐµÑ†Ñ–Ð°Ð»Ñ–Ð·Ð¾Ð²Ð°Ð½Ñ– SLM Ð°Ð³ÐµÐ½Ñ‚Ð¸**: ÐœÐ¾Ð´ÐµÐ»Ñ–, Ð¾Ñ€Ñ–Ñ”Ð½Ñ‚Ð¾Ð²Ð°Ð½Ñ– Ð½Ð° ÐºÐ¾Ð½ÐºÑ€ÐµÑ‚Ð½Ñ– Ð·Ð°Ð²Ð´Ð°Ð½Ð½Ñ Ð°Ð³ÐµÐ½Ñ‚Ñ–Ð² Ñ– Ð³Ð°Ð»ÑƒÐ·Ñ–
- **ÐžÐ±Ñ‡Ð¸ÑÐ»ÐµÐ½Ð½Ñ Ð°Ð³ÐµÐ½Ñ‚Ñ–Ð² Ð½Ð° Edge**: ÐŸÐ¾ÐºÑ€Ð°Ñ‰ÐµÐ½Ñ– Ð¼Ð¾Ð¶Ð»Ð¸Ð²Ð¾ÑÑ‚Ñ– Ð°Ð³ÐµÐ½Ñ‚Ñ–Ð² Ð½Ð° Ð¿Ñ€Ð¸ÑÑ‚Ñ€Ð¾ÑÑ… Ñ–Ð· Ð¿Ñ–Ð´Ð²Ð¸Ñ‰ÐµÐ½Ð¾ÑŽ ÐºÐ¾Ð½Ñ„Ñ–Ð´ÐµÐ½Ñ†Ñ–Ð¹Ð½Ñ–ÑÑ‚ÑŽ Ñ‚Ð° Ð·Ð¼ÐµÐ½ÑˆÐµÐ½Ð¾ÑŽ Ð·Ð°Ñ‚Ñ€Ð¸Ð¼ÐºÐ¾ÑŽ
- **ÐžÑ€ÐºÐµÑÑ‚Ñ€Ð°Ñ†Ñ–Ñ Ð°Ð³ÐµÐ½Ñ‚Ñ–Ð²**: ÐšÑ€Ð°Ñ‰Ð° ÐºÐ¾Ð¾Ñ€Ð´Ð¸Ð½Ð°Ñ†Ñ–Ñ Ð¼Ñ–Ð¶ ÐºÑ–Ð»ÑŒÐºÐ¾Ð¼Ð° SLM Ð°Ð³ÐµÐ½Ñ‚Ð°Ð¼Ð¸ Ð· Ð´Ð¸Ð½Ð°Ð¼Ñ–Ñ‡Ð½Ð¸Ð¼ Ð¼Ð°Ñ€ÑˆÑ€ÑƒÑ‚Ð¸Ð·Ð°Ñ†Ñ–Ñ”ÑŽ Ñ‚Ð° Ð±Ð°Ð»Ð°Ð½ÑÑƒÐ²Ð°Ð½Ð½ÑÐ¼ Ð½Ð°Ð²Ð°Ð½Ñ‚Ð°Ð¶ÐµÐ½Ð½Ñ
- **Ð”ÐµÐ¼Ð¾ÐºÑ€Ð°Ñ‚Ð¸Ð·Ð°Ñ†Ñ–Ñ**: Ð“Ð½ÑƒÑ‡ÐºÑ–ÑÑ‚ÑŒ SLM Ð´Ð¾Ð·Ð²Ð¾Ð»ÑÑ” ÑˆÐ¸Ñ€ÑˆÐµ Ð·Ð°Ð»ÑƒÑ‡ÐµÐ½Ð½Ñ Ð´Ð¾ Ñ€Ð¾Ð·Ñ€Ð¾Ð±ÐºÐ¸ Ð°Ð³ÐµÐ½Ñ‚Ñ–Ð² Ñƒ Ñ€Ñ–Ð·Ð½Ð¸Ñ… Ð¾Ñ€Ð³Ð°Ð½Ñ–Ð·Ð°Ñ†Ñ–ÑÑ…

## ÐŸÐ¾Ñ‡Ð°Ñ‚Ð¾Ðº Ñ€Ð¾Ð±Ð¾Ñ‚Ð¸ Ð· SLM Ð°Ð³ÐµÐ½Ñ‚Ð°Ð¼Ð¸

### ÐšÑ€Ð¾Ðº 1: ÐÐ°Ð»Ð°ÑˆÑ‚ÑƒÐ²Ð°Ð½Ð½Ñ ÑÐµÑ€ÐµÐ´Ð¾Ð²Ð¸Ñ‰Ð° Microsoft Agent Framework

**Ð’ÑÑ‚Ð°Ð½Ð¾Ð²Ñ–Ñ‚ÑŒ Ð·Ð°Ð»ÐµÐ¶Ð½Ð¾ÑÑ‚Ñ–**:
```bash
# Install Microsoft Agent Framework
pip install microsoft-agent-framework

# Install Foundry Local SDK for edge deployment
pip install foundry-local-sdk

# Install additional dependencies for edge agents
pip install openai asyncio
```

**Ð†Ð½Ñ–Ñ†Ñ–Ð°Ð»Ñ–Ð·ÑƒÐ¹Ñ‚Ðµ Foundry Local**:
```bash
# Start Foundry Local service
foundry service start

# Load default model for agent development
foundry model run phi-4-mini
```

### ÐšÑ€Ð¾Ðº 2: Ð’Ð¸Ð±ÐµÑ€Ñ–Ñ‚ÑŒ Ð²Ð°Ñˆ SLM Ð´Ð»Ñ Ð·Ð°ÑÑ‚Ð¾ÑÑƒÐ½ÐºÑ–Ð² Ð°Ð³ÐµÐ½Ñ‚Ñ–Ð²
ÐŸÐ¾Ð¿ÑƒÐ»ÑÑ€Ð½Ñ– Ð²Ð°Ñ€Ñ–Ð°Ð½Ñ‚Ð¸ Ð´Ð»Ñ Microsoft Agent Framework:
- **Microsoft Phi-4 Mini (3.8B)**: Ð§ÑƒÐ´Ð¾Ð²Ð¾ Ð¿Ñ–Ð´Ñ…Ð¾Ð´Ð¸Ñ‚ÑŒ Ð´Ð»Ñ Ð·Ð°Ð³Ð°Ð»ÑŒÐ½Ð¸Ñ… Ð·Ð°Ð²Ð´Ð°Ð½ÑŒ Ð°Ð³ÐµÐ½Ñ‚Ñ–Ð² Ñ–Ð· Ð·Ð±Ð°Ð»Ð°Ð½ÑÐ¾Ð²Ð°Ð½Ð¾ÑŽ Ð¿Ñ€Ð¾Ð´ÑƒÐºÑ‚Ð¸Ð²Ð½Ñ–ÑÑ‚ÑŽ
- **Qwen2.5-0.5B (0.5B)**: ÐÐ°Ð´Ð·Ð²Ð¸Ñ‡Ð°Ð¹Ð½Ð¾ ÐµÑ„ÐµÐºÑ‚Ð¸Ð²Ð½Ð¸Ð¹ Ð´Ð»Ñ Ð¿Ñ€Ð¾ÑÑ‚Ð¸Ñ… Ð°Ð³ÐµÐ½Ñ‚Ñ–Ð² Ð¼Ð°Ñ€ÑˆÑ€ÑƒÑ‚Ð¸Ð·Ð°Ñ†Ñ–Ñ— Ñ‚Ð° ÐºÐ»Ð°ÑÐ¸Ñ„Ñ–ÐºÐ°Ñ†Ñ–Ñ—
- **Qwen2.5-Coder-0.5B (0.5B)**: Ð¡Ð¿ÐµÑ†Ñ–Ð°Ð»Ñ–Ð·Ð¾Ð²Ð°Ð½Ð¸Ð¹ Ð´Ð»Ñ Ð·Ð°Ð²Ð´Ð°Ð½ÑŒ Ð°Ð³ÐµÐ½Ñ‚Ñ–Ð², Ð¿Ð¾Ð²â€™ÑÐ·Ð°Ð½Ð¸Ñ… Ñ–Ð· ÐºÐ¾Ð´Ð¾Ð¼
- **Phi-4 (7B)**: Ð Ð¾Ð·ÑˆÐ¸Ñ€ÐµÐ½Ðµ Ð¼Ð¸ÑÐ»ÐµÐ½Ð½Ñ Ð´Ð»Ñ ÑÐºÐ»Ð°Ð´Ð½Ð¸Ñ… ÑÑ†ÐµÐ½Ð°Ñ€Ñ–Ñ—Ð² Edge, ÑÐºÑ‰Ð¾ Ñ€ÐµÑÑƒÑ€ÑÐ¸ Ð´Ð¾Ð·Ð²Ð¾Ð»ÑÑŽÑ‚ÑŒ

### ÐšÑ€Ð¾Ðº 3: Ð¡Ñ‚Ð²Ð¾Ñ€Ñ–Ñ‚ÑŒ ÑÐ²Ð¾Ð³Ð¾ Ð¿ÐµÑ€ÑˆÐ¾Ð³Ð¾ Ð°Ð³ÐµÐ½Ñ‚Ð° Ð·Ð° Ð´Ð¾Ð¿Ð¾Ð¼Ð¾Ð³Ð¾ÑŽ Microsoft Agent Framework

**Ð‘Ð°Ð·Ð¾Ð²Ðµ Ð½Ð°Ð»Ð°ÑˆÑ‚ÑƒÐ²Ð°Ð½Ð½Ñ Ð°Ð³ÐµÐ½Ñ‚Ð°**:
```python
from microsoft_agent_framework import Agent, Config
from foundry_local import FoundryLocalManager

# Initialize Foundry Local connection
foundry = FoundryLocalManager("phi-4-mini")

# Create agent configuration
config = Config(
    name="my-first-agent",
    model_provider="foundry-local",
    model_alias="phi-4-mini",
    offline_mode=True
)

# Create and configure agent
agent = Agent(
    config=config,
    model_endpoint=foundry.endpoint,
    api_key=foundry.api_key
)

# Define a simple tool
@agent.tool
def get_current_time() -> str:
    """Get the current time."""
    from datetime import datetime
    return datetime.now().strftime("%Y-%m-%d %H:%M:%S")

# Test the agent
response = agent.chat("What time is it?")
print(response)
```

### ÐšÑ€Ð¾Ðº 4: Ð’Ð¸Ð·Ð½Ð°Ñ‡Ñ‚Ðµ ÑÑ„ÐµÑ€Ñƒ Ñ‚Ð° Ð²Ð¸Ð¼Ð¾Ð³Ð¸ Ð°Ð³ÐµÐ½Ñ‚Ð°
ÐŸÐ¾Ñ‡Ð½Ñ–Ñ‚ÑŒ Ñ–Ð· ÑÑ„Ð¾ÐºÑƒÑÐ¾Ð²Ð°Ð½Ð¸Ñ…, Ñ‡Ñ–Ñ‚ÐºÐ¾ Ð²Ð¸Ð·Ð½Ð°Ñ‡ÐµÐ½Ð¸Ñ… Ð·Ð°ÑÑ‚Ð¾ÑÑƒÐ½ÐºÑ–Ð² Ð°Ð³ÐµÐ½Ñ‚Ñ–Ð² Ð·Ð° Ð´Ð¾Ð¿Ð¾Ð¼Ð¾Ð³Ð¾ÑŽ Microsoft Agent Framework:
- **ÐÐ³ÐµÐ½Ñ‚Ð¸ Ð´Ð»Ñ Ð¾Ð´Ð½Ñ–Ñ”Ñ— Ð³Ð°Ð»ÑƒÐ·Ñ–**: ÐžÐ±ÑÐ»ÑƒÐ³Ð¾Ð²ÑƒÐ²Ð°Ð½Ð½Ñ ÐºÐ»Ñ–Ñ”Ð½Ñ‚Ñ–Ð² ÐÐ‘Ðž Ð¿Ð»Ð°Ð½ÑƒÐ²Ð°Ð½Ð½Ñ ÐÐ‘Ðž Ð´Ð¾ÑÐ»Ñ–Ð´Ð¶ÐµÐ½Ð½Ñ
- **Ð§Ñ–Ñ‚ÐºÑ– Ñ†Ñ–Ð»Ñ– Ð°Ð³ÐµÐ½Ñ‚Ð°**: ÐšÐ¾Ð½ÐºÑ€ÐµÑ‚Ð½Ñ–, Ð²Ð¸Ð¼Ñ–Ñ€ÑŽÐ²Ð°Ð½Ñ– Ñ†Ñ–Ð»Ñ– Ð´Ð»Ñ Ð¿Ñ€Ð¾Ð´ÑƒÐºÑ‚Ð¸Ð²Ð½Ð¾ÑÑ‚Ñ– Ð°Ð³ÐµÐ½Ñ‚Ð°
- **ÐžÐ±Ð¼ÐµÐ¶ÐµÐ½Ð° Ñ–Ð½Ñ‚ÐµÐ³Ñ€Ð°Ñ†Ñ–Ñ Ñ–Ð½ÑÑ‚Ñ€ÑƒÐ¼ÐµÐ½Ñ‚Ñ–Ð²**: ÐœÐ°ÐºÑÐ¸Ð¼ÑƒÐ¼ 3-5 Ñ–Ð½ÑÑ‚Ñ€ÑƒÐ¼ÐµÐ½Ñ‚Ñ–Ð² Ð´Ð»Ñ Ð¿Ð¾Ñ‡Ð°Ñ‚ÐºÐ¾Ð²Ð¾Ð³Ð¾ Ñ€Ð¾Ð·Ð³Ð¾Ñ€Ñ‚Ð°Ð½Ð½Ñ Ð°Ð³ÐµÐ½Ñ‚Ð°
- **Ð’Ð¸Ð·Ð½Ð°Ñ‡ÐµÐ½Ñ– Ð¼ÐµÐ¶Ñ– Ð°Ð³ÐµÐ½Ñ‚Ð°**: Ð§Ñ–Ñ‚ÐºÑ– ÑˆÐ»ÑÑ…Ð¸ ÐµÑÐºÐ°Ð»Ð°Ñ†Ñ–Ñ— Ð´Ð»Ñ ÑÐºÐ»Ð°Ð´Ð½Ð¸Ñ… ÑÑ†ÐµÐ½Ð°Ñ€Ñ–Ñ—Ð²
- **Ð”Ð¸Ð·Ð°Ð¹Ð½ Ñ–Ð· Ð¿Ñ€Ñ–Ð¾Ñ€Ð¸Ñ‚ÐµÑ‚Ð¾Ð¼ Edge**: ÐŸÑ€Ñ–Ð¾Ñ€Ð¸Ñ‚ÐµÑ‚ Ð¾Ñ„Ð»Ð°Ð¹Ð½-Ñ„ÑƒÐ½ÐºÑ†Ñ–Ð¾Ð½Ð°Ð»ÑŒÐ½Ð¾ÑÑ‚Ñ– Ñ‚Ð° Ð»Ð¾ÐºÐ°Ð»ÑŒÐ½Ð¾Ñ— Ð¾Ð±Ñ€Ð¾Ð±ÐºÐ¸

### ÐšÑ€Ð¾Ðº 5: Ð ÐµÐ°Ð»Ñ–Ð·ÑƒÐ¹Ñ‚Ðµ Ñ€Ð¾Ð·Ð³Ð¾Ñ€Ñ‚Ð°Ð½Ð½Ñ Ð½Ð° Edge Ð·Ð° Ð´Ð¾Ð¿Ð¾Ð¼Ð¾Ð³Ð¾ÑŽ Microsoft Agent Framework

**ÐšÐ¾Ð½Ñ„Ñ–Ð³ÑƒÑ€Ð°Ñ†Ñ–Ñ Ñ€ÐµÑÑƒÑ€ÑÑ–Ð²**:
```python
from microsoft_agent_framework import ResourceConfig

# Configure for edge deployment
resource_config = ResourceConfig(
    max_memory_usage="2GB",
    max_concurrent_agents=2,
    model_cache_size="1GB",
    auto_unload_idle_models=True,
    power_management=True
)

agent = Agent(
    config=config,
    resource_limits=resource_config
)
```

**Ð Ð¾Ð·Ð³Ð¾Ñ€Ñ‚Ð°Ð½Ð½Ñ Ð·Ð°Ñ…Ð¾Ð´Ñ–Ð² Ð±ÐµÐ·Ð¿ÐµÐºÐ¸ Ð´Ð»Ñ Ð°Ð³ÐµÐ½Ñ‚Ñ–Ð² Edge**:
- **Ð›Ð¾ÐºÐ°Ð»ÑŒÐ½Ð° Ð¿ÐµÑ€ÐµÐ²Ñ–Ñ€ÐºÐ° Ð²Ð²ÐµÐ´ÐµÐ½Ð½Ñ**: ÐŸÐµÑ€ÐµÐ²Ñ–Ñ€ÑÐ¹Ñ‚Ðµ Ð·Ð°Ð¿Ð¸Ñ‚Ð¸ Ð±ÐµÐ· Ð·Ð°Ð»ÐµÐ¶Ð½Ð¾ÑÑ‚Ñ– Ð²Ñ–Ð´ Ñ…Ð¼Ð°Ñ€Ð¸
- **Ð¤Ñ–Ð»ÑŒÑ‚Ñ€Ð°Ñ†Ñ–Ñ Ð²Ð¸Ñ…Ñ–Ð´Ð½Ð¸Ñ… Ð´Ð°Ð½Ð¸Ñ… Ð¾Ñ„Ð»Ð°Ð¹Ð½**: ÐŸÐµÑ€ÐµÐºÐ¾Ð½Ð°Ð¹Ñ‚ÐµÑÑ, Ñ‰Ð¾ Ð²Ñ–Ð´Ð¿Ð¾Ð²Ñ–Ð´Ñ– Ð²Ñ–Ð´Ð¿Ð¾Ð²Ñ–Ð´Ð°ÑŽÑ‚ÑŒ ÑÑ‚Ð°Ð½Ð´Ð°Ñ€Ñ‚Ð°Ð¼ ÑÐºÐ¾ÑÑ‚Ñ– Ð»Ð¾ÐºÐ°Ð»ÑŒÐ½Ð¾
- **ÐšÐ¾Ð½Ñ‚Ñ€Ð¾Ð»ÑŒ Ð±ÐµÐ·Ð¿ÐµÐºÐ¸ Edge**: Ð’Ð¿Ñ€Ð¾Ð²Ð°Ð´Ð¶ÑƒÐ¹Ñ‚Ðµ Ð·Ð°Ñ…Ð¾Ð´Ð¸ Ð±ÐµÐ·Ð¿ÐµÐºÐ¸ Ð±ÐµÐ· Ð½ÐµÐ¾Ð±Ñ…Ñ–Ð´Ð½Ð¾ÑÑ‚Ñ– Ð¿Ñ–Ð´ÐºÐ»ÑŽÑ‡ÐµÐ½Ð½Ñ Ð´Ð¾ Ð†Ð½Ñ‚ÐµÑ€Ð½ÐµÑ‚Ñƒ
- **Ð›Ð¾ÐºÐ°Ð»ÑŒÐ½Ð¸Ð¹ Ð¼Ð¾Ð½Ñ–Ñ‚Ð¾Ñ€Ð¸Ð½Ð³**: Ð’Ñ–Ð´ÑÑ‚ÐµÐ¶ÑƒÐ¹Ñ‚Ðµ Ð¿Ñ€Ð¾Ð´ÑƒÐºÑ‚Ð¸Ð²Ð½Ñ–ÑÑ‚ÑŒ Ñ– Ð¿Ð¾Ð·Ð½Ð°Ñ‡Ð°Ð¹Ñ‚Ðµ Ð¿Ñ€Ð¾Ð±Ð»ÐµÐ¼Ð¸ Ð·Ð° Ð´Ð¾Ð¿Ð¾Ð¼Ð¾Ð³Ð¾ÑŽ Ñ‚ÐµÐ»ÐµÐ¼ÐµÑ‚Ñ€Ñ–Ñ— Edge

### ÐšÑ€Ð¾Ðº 6: Ð’Ð¸Ð¼Ñ–Ñ€ÑÐ¹Ñ‚Ðµ Ñ‚Ð° Ð¾Ð¿Ñ‚Ð¸Ð¼Ñ–Ð·ÑƒÐ¹Ñ‚Ðµ Ð¿Ñ€Ð¾Ð´ÑƒÐºÑ‚Ð¸Ð²Ð½Ñ–ÑÑ‚ÑŒ Ð°Ð³ÐµÐ½Ñ‚Ñ–Ð² Edge
- **Ð Ñ–Ð²ÐµÐ½ÑŒ Ð²Ð¸ÐºÐ¾Ð½Ð°Ð½Ð½Ñ Ð·Ð°Ð²Ð´Ð°Ð½ÑŒ Ð°Ð³ÐµÐ½Ñ‚Ñ–Ð²**: Ð’Ñ–Ð´ÑÑ‚ÐµÐ¶ÑƒÐ¹Ñ‚Ðµ Ñ€Ñ–Ð²ÐµÐ½ÑŒ ÑƒÑÐ¿Ñ–ÑˆÐ½Ð¾ÑÑ‚Ñ– Ð² Ð¾Ñ„Ð»Ð°Ð¹Ð½-ÑÑ†ÐµÐ½Ð°Ñ€Ñ–ÑÑ…
- **Ð§Ð°Ñ Ð²Ñ–Ð´Ð¿Ð¾Ð²Ñ–Ð´Ñ– Ð°Ð³ÐµÐ½Ñ‚Ñ–Ð²**: Ð—Ð°Ð±ÐµÐ·Ð¿ÐµÑ‡Ñ‚Ðµ Ñ‡Ð°Ñ Ð²Ñ–Ð´Ð¿Ð¾Ð²Ñ–Ð´Ñ– Ð¼ÐµÐ½ÑˆÐµ ÑÐµÐºÑƒÐ½Ð´Ð¸ Ð´Ð»Ñ Ñ€Ð¾Ð·Ð³Ð¾Ñ€Ñ‚Ð°Ð½Ð½Ñ Ð½Ð° Edge
- **Ð’Ð¸ÐºÐ¾Ñ€Ð¸ÑÑ‚Ð°Ð½Ð½Ñ Ñ€ÐµÑÑƒÑ€ÑÑ–Ð²**: Ð’Ñ–Ð´ÑÑ‚ÐµÐ¶ÑƒÐ¹Ñ‚Ðµ Ð²Ð¸ÐºÐ¾Ñ€Ð¸ÑÑ‚Ð°Ð½Ð½Ñ Ð¿Ð°Ð¼â€™ÑÑ‚Ñ–, Ð¿Ñ€Ð¾Ñ†ÐµÑÐ¾Ñ€Ð° Ñ‚Ð° Ð±Ð°Ñ‚Ð°Ñ€ÐµÑ— Ð½Ð° Ð¿Ñ€Ð¸ÑÑ‚Ñ€Ð¾ÑÑ… Edge
- **Ð•ÐºÐ¾Ð½Ð¾Ð¼Ñ–Ñ‡Ð½Ð° ÐµÑ„ÐµÐºÑ‚Ð¸Ð²Ð½Ñ–ÑÑ‚ÑŒ**: ÐŸÐ¾Ñ€Ñ–Ð²Ð½ÑÐ¹Ñ‚Ðµ Ð²Ð¸Ñ‚Ñ€Ð°Ñ‚Ð¸ Ð½Ð° Ñ€Ð¾Ð·Ð³Ð¾Ñ€Ñ‚Ð°Ð½Ð½Ñ Ð½Ð° Edge Ñ–Ð· Ñ…Ð¼Ð°Ñ€Ð½Ð¸Ð¼Ð¸ Ð°Ð»ÑŒÑ‚ÐµÑ€Ð½Ð°Ñ‚Ð¸Ð²Ð°Ð¼Ð¸
- **ÐÐ°Ð´Ñ–Ð¹Ð½Ñ–ÑÑ‚ÑŒ Ð¾Ñ„Ð»Ð°Ð¹Ð½**: ÐžÑ†Ñ–Ð½Ñ–Ñ‚ÑŒ Ð¿Ñ€Ð¾Ð´ÑƒÐºÑ‚Ð¸Ð²Ð½Ñ–ÑÑ‚ÑŒ Ð°Ð³ÐµÐ½Ñ‚Ñ–Ð² Ð¿Ñ–Ð´ Ñ‡Ð°Ñ Ð¿ÐµÑ€ÐµÐ±Ð¾Ñ—Ð² Ñƒ Ð¼ÐµÑ€ÐµÐ¶Ñ–

## ÐžÑÐ½Ð¾Ð²Ð½Ñ– Ð²Ð¸ÑÐ½Ð¾Ð²ÐºÐ¸ Ð´Ð»Ñ Ð²Ð¿Ñ€Ð¾Ð²Ð°Ð´Ð¶ÐµÐ½Ð½Ñ SLM Ð°Ð³ÐµÐ½Ñ‚Ñ–Ð²

1. **SLM Ð´Ð¾ÑÑ‚Ð°Ñ‚Ð½Ñ– Ð´Ð»Ñ Ð°Ð³ÐµÐ½Ñ‚Ñ–Ð²**: Ð”Ð»Ñ Ð±Ñ–Ð»ÑŒÑˆÐ¾ÑÑ‚Ñ– Ð·Ð°Ð²Ð´Ð°Ð½ÑŒ Ð°Ð³ÐµÐ½Ñ‚Ñ–Ð² Ð½ÐµÐ²ÐµÐ»Ð¸ÐºÑ– Ð¼Ð¾Ð´ÐµÐ»Ñ– Ð¿Ñ€Ð°Ñ†ÑŽÑŽÑ‚ÑŒ Ñ‚Ð°Ðº ÑÐ°Ð¼Ð¾ Ð´Ð¾Ð±Ñ€Ðµ, ÑÐº Ñ– Ð²ÐµÐ»Ð¸ÐºÑ–, Ð¿Ñ€Ð¾Ð¿Ð¾Ð½ÑƒÑŽÑ‡Ð¸ Ð·Ð½Ð°Ñ‡Ð½Ñ– Ð¿ÐµÑ€ÐµÐ²Ð°Ð³Ð¸
2. **Ð•ÐºÐ¾Ð½Ð¾Ð¼Ñ–Ñ‡Ð½Ð° ÐµÑ„ÐµÐºÑ‚Ð¸Ð²Ð½Ñ–ÑÑ‚ÑŒ Ð°Ð³ÐµÐ½Ñ‚Ñ–Ð²**: Ð£ 10-30 Ñ€Ð°Ð·Ñ–Ð² Ð´ÐµÑˆÐµÐ²ÑˆÐµ Ð·Ð°Ð¿ÑƒÑÐºÐ°Ñ‚Ð¸ SLM Ð°Ð³ÐµÐ½Ñ‚Ñ–Ð², Ñ‰Ð¾ Ñ€Ð¾Ð±Ð¸Ñ‚ÑŒ Ñ—Ñ… ÐµÐºÐ¾Ð½Ð¾Ð¼Ñ–Ñ‡Ð½Ð¾ Ð²Ð¸Ð³Ñ–Ð´Ð½Ð¸Ð¼Ð¸ Ð´Ð»Ñ ÑˆÐ¸Ñ€Ð¾ÐºÐ¾Ð³Ð¾ Ñ€Ð¾Ð·Ð³Ð¾Ñ€Ñ‚Ð°Ð½Ð½Ñ
3. **Ð¡Ð¿ÐµÑ†Ñ–Ð°Ð»Ñ–Ð·Ð°Ñ†Ñ–Ñ Ð¿Ñ€Ð°Ñ†ÑŽÑ” Ð´Ð»Ñ Ð°Ð³ÐµÐ½Ñ‚Ñ–Ð²**: Ð¢Ð¾Ð½ÐºÐ¾ Ð½Ð°Ð»Ð°ÑˆÑ‚Ð¾Ð²Ð°Ð½Ñ– SLM Ñ‡Ð°ÑÑ‚Ð¾ Ð¿ÐµÑ€ÐµÐ²ÐµÑ€ÑˆÑƒÑŽÑ‚ÑŒ Ð·Ð°Ð³Ð°Ð»ÑŒÐ½Ñ– LLM Ñƒ ÐºÐ¾Ð½ÐºÑ€ÐµÑ‚Ð½Ð¸Ñ… Ð·Ð°ÑÑ‚Ð¾ÑÑƒÐ½ÐºÐ°Ñ… Ð°Ð³ÐµÐ½Ñ‚Ñ–Ð²
4. **Ð“Ñ–Ð±Ñ€Ð¸Ð´Ð½Ð° Ð°Ñ€Ñ…Ñ–Ñ‚ÐµÐºÑ‚ÑƒÑ€Ð° Ð°Ð³ÐµÐ½Ñ‚Ñ–Ð²**: Ð’Ð¸ÐºÐ¾Ñ€Ð¸ÑÑ‚Ð¾Ð²ÑƒÐ¹Ñ‚Ðµ SLM Ð´Ð»Ñ Ñ€ÑƒÑ‚Ð¸Ð½Ð½Ð¸Ñ… Ð·Ð°Ð²Ð´Ð°Ð½ÑŒ Ð°Ð³ÐµÐ½Ñ‚Ñ–Ð², LLM Ð´Ð»Ñ ÑÐºÐ»Ð°Ð´Ð½Ð¾Ð³Ð¾ Ð¼Ð¸ÑÐ»ÐµÐ½Ð½Ñ, ÐºÐ¾Ð»Ð¸ Ñ†Ðµ Ð½ÐµÐ¾Ð±Ñ…Ñ–Ð´Ð½Ð¾
5. **Microsoft Agent Framework Ð´Ð¾Ð·Ð²Ð¾Ð»ÑÑ” Ñ€Ð¾Ð·Ð³Ð¾Ñ€Ñ‚Ð°Ð½Ð½Ñ Ñƒ Ð²Ð¸Ñ€Ð¾Ð±Ð½Ð¸Ñ†Ñ‚Ð²Ñ–**: Ð—Ð°Ð±ÐµÐ·Ð¿ÐµÑ‡ÑƒÑ” Ñ–Ð½ÑÑ‚Ñ€ÑƒÐ¼ÐµÐ½Ñ‚Ð¸ ÐºÐ¾Ñ€Ð¿Ð¾Ñ€Ð°Ñ‚Ð¸Ð²Ð½Ð¾Ð³Ð¾ Ñ€Ñ–Ð²Ð½Ñ Ð´Ð»Ñ ÑÑ‚Ð²Ð¾Ñ€ÐµÐ½Ð½Ñ, Ñ€Ð¾Ð·Ð³Ð¾Ñ€Ñ‚Ð°Ð½Ð½Ñ Ñ‚Ð° ÑƒÐ¿Ñ€Ð°Ð²Ð»Ñ–Ð½Ð½Ñ Ð°Ð³ÐµÐ½Ñ‚Ð°Ð¼Ð¸ Edge
6. **ÐŸÑ€Ð¸Ð½Ñ†Ð¸Ð¿Ð¸ Ð´Ð¸Ð·Ð°Ð¹Ð½Ñƒ Ð· Ð¿Ñ€Ñ–Ð¾Ñ€Ð¸Ñ‚ÐµÑ‚Ð¾Ð¼ Edge**: ÐÐ³ÐµÐ½Ñ‚Ð¸, Ð·Ð´Ð°Ñ‚Ð½Ñ– Ð¿Ñ€Ð°Ñ†ÑŽÐ²Ð°Ñ‚Ð¸ Ð¾Ñ„Ð»Ð°Ð¹Ð½ Ñ–Ð· Ð»Ð¾ÐºÐ°Ð»ÑŒÐ½Ð¾ÑŽ Ð¾Ð±Ñ€Ð¾Ð±ÐºÐ¾ÑŽ, Ð·Ð°Ð±ÐµÐ·Ð¿ÐµÑ‡ÑƒÑŽÑ‚ÑŒ ÐºÐ¾Ð½Ñ„Ñ–Ð´ÐµÐ½Ñ†Ñ–Ð¹Ð½Ñ–ÑÑ‚ÑŒ Ñ– Ð½Ð°Ð´Ñ–Ð¹Ð½Ñ–ÑÑ‚ÑŒ
7. **Ð†Ð½Ñ‚ÐµÐ³Ñ€Ð°Ñ†Ñ–Ñ Foundry Local**: Ð‘ÐµÐ·Ð¿ÐµÑ€ÐµÐ±Ñ–Ð¹Ð½Ðµ Ð·â€™Ñ”Ð´Ð½Ð°Ð½Ð½Ñ Ð¼Ñ–Ð¶ Microsoft Agent Framework Ñ– Ð»Ð¾ÐºÐ°Ð»ÑŒÐ½Ð¾ÑŽ Ñ–Ð½Ñ„ÐµÑ€ÐµÐ½Ñ†Ñ–Ñ”ÑŽ Ð¼Ð¾Ð´ÐµÐ»ÐµÐ¹
8. **ÐœÐ°Ð¹Ð±ÑƒÑ‚Ð½Ñ” Ð·Ð° SLM Ð°Ð³ÐµÐ½Ñ‚Ð°Ð¼Ð¸**: ÐÐµÐ²ÐµÐ»Ð¸ÐºÑ– Ð¼Ð¾Ð²Ð½Ñ– Ð¼Ð¾Ð´ÐµÐ»Ñ– Ð· Ð²Ð¸Ñ€Ð¾Ð±Ð½Ð¸Ñ‡Ð¸Ð¼Ð¸ Ñ„Ñ€ÐµÐ¹Ð¼Ð²Ð¾Ñ€ÐºÐ°Ð¼Ð¸ Ñ” Ð¼Ð°Ð¹Ð±ÑƒÑ‚Ð½Ñ–Ð¼ Ð°Ð³ÐµÐ½Ñ‚Ð½Ð¾Ð³Ð¾ AI, Ð·Ð°Ð±ÐµÐ·Ð¿ÐµÑ‡ÑƒÑŽÑ‡Ð¸ Ð´ÐµÐ¼Ð¾ÐºÑ€Ð°Ñ‚Ð¸Ð·Ð¾Ð²Ð°Ð½Ðµ Ñ‚Ð° ÐµÑ„ÐµÐºÑ‚Ð¸Ð²Ð½Ðµ Ñ€Ð¾Ð·Ð³Ð¾Ñ€Ñ‚Ð°Ð½Ð½Ñ Ð°Ð³ÐµÐ½Ñ‚Ñ–Ð²

## ÐŸÐ¾ÑÐ¸Ð»Ð°Ð½Ð½Ñ Ñ‚Ð° Ð´Ð¾Ð´Ð°Ñ‚ÐºÐ¾Ð²Ð° Ð»Ñ–Ñ‚ÐµÑ€Ð°Ñ‚ÑƒÑ€Ð°

### ÐžÑÐ½Ð¾Ð²Ð½Ñ– Ð½Ð°ÑƒÐºÐ¾Ð²Ñ– ÑÑ‚Ð°Ñ‚Ñ‚Ñ– Ñ‚Ð° Ð¿ÑƒÐ±Ð»Ñ–ÐºÐ°Ñ†Ñ–Ñ—

#### AI Ð°Ð³ÐµÐ½Ñ‚Ð¸ Ñ‚Ð° Ð°Ð³ÐµÐ½Ñ‚Ð½Ñ– ÑÐ¸ÑÑ‚ÐµÐ¼Ð¸
- **"Language Agents as Optimizable Graphs"** (2024) - ÐžÑÐ½Ð¾Ð²Ð½Ðµ Ð´Ð¾ÑÐ»Ñ–Ð´Ð¶ÐµÐ½Ð½Ñ Ð°Ñ€Ñ…Ñ–Ñ‚ÐµÐºÑ‚ÑƒÑ€Ð¸ Ð°Ð³ÐµÐ½Ñ‚Ñ–Ð² Ñ– ÑÑ‚Ñ€Ð°Ñ‚ÐµÐ³Ñ–Ð¹ Ð¾Ð¿Ñ‚Ð¸Ð¼Ñ–Ð·Ð°Ñ†Ñ–Ñ—
  - ÐÐ²Ñ‚Ð¾Ñ€Ð¸: Wenyue Hua, Lishan Yang Ñ‚Ð° Ñ–Ð½.
  - ÐŸÐ¾ÑÐ¸Ð»Ð°Ð½Ð½Ñ: https://arxiv.org/abs/2402.16823
  - ÐžÑÐ½Ð¾Ð²Ð½Ñ– Ð²Ð¸ÑÐ½Ð¾Ð²ÐºÐ¸: Ð”Ð¸Ð·Ð°Ð¹Ð½ Ð°Ð³ÐµÐ½Ñ‚Ñ–Ð² Ð½Ð° Ð¾ÑÐ½Ð¾Ð²Ñ– Ð³Ñ€Ð°Ñ„Ñ–Ð² Ñ– ÑÑ‚Ñ€Ð°Ñ‚ÐµÐ³Ñ–Ñ— Ð¾Ð¿Ñ‚Ð¸Ð¼Ñ–Ð·Ð°Ñ†Ñ–Ñ—

- **"The Rise and Potential of Large Language Model Based Agents"** (2023)
  - ÐÐ²Ñ‚Ð¾Ñ€Ð¸: Zhiheng Xi, Wenxiang Chen Ñ‚Ð° Ñ–Ð½.
  - ÐŸÐ¾ÑÐ¸Ð»Ð°Ð½Ð½Ñ: https://arxiv.org/abs/2309.07864
  - ÐžÑÐ½Ð¾Ð²Ð½Ñ– Ð²Ð¸ÑÐ½Ð¾Ð²ÐºÐ¸: ÐšÐ¾Ð¼Ð¿Ð»ÐµÐºÑÐ½Ð¸Ð¹ Ð¾Ð³Ð»ÑÐ´ Ð¼Ð¾Ð¶Ð»Ð¸Ð²Ð¾ÑÑ‚ÐµÐ¹ Ñ– Ð·Ð°ÑÑ‚Ð¾ÑÑƒÐ²Ð°Ð½ÑŒ Ð°Ð³ÐµÐ½Ñ‚Ñ–Ð² Ð½Ð° Ð¾ÑÐ½Ð¾Ð²Ñ– LLM

- **"Cognitive Architectures for Language Agents"** (2024)
  - ÐÐ²Ñ‚Ð¾Ñ€Ð¸: Theodore Sumers, Shunyu Yao Ñ‚Ð° Ñ–Ð½.
  - ÐŸÐ¾ÑÐ¸Ð»Ð°Ð½Ð½Ñ: https://arxiv.org/abs/2309.02427
  - ÐžÑÐ½Ð¾Ð²Ð½Ñ– Ð²Ð¸ÑÐ½Ð¾Ð²ÐºÐ¸: ÐšÐ¾Ð³Ð½Ñ–Ñ‚Ð¸Ð²Ð½Ñ– Ñ„Ñ€ÐµÐ¹Ð¼Ð²Ð¾Ñ€ÐºÐ¸ Ð´Ð»Ñ ÑÑ‚Ð²Ð¾Ñ€ÐµÐ½Ð½Ñ Ñ–Ð½Ñ‚ÐµÐ»ÐµÐºÑ‚ÑƒÐ°Ð»ÑŒÐ½Ð¸Ñ… Ð°Ð³ÐµÐ½Ñ‚Ñ–Ð²

#### ÐÐµÐ²ÐµÐ»Ð¸ÐºÑ– Ð¼Ð¾Ð²Ð½Ñ– Ð¼Ð¾Ð´ÐµÐ»Ñ– Ñ‚Ð° Ð¾Ð¿Ñ‚Ð¸Ð¼Ñ–Ð·Ð°Ñ†Ñ–Ñ
- **"Phi-3 Technical Report: A Highly Capable Language Model Locally on Your Phone"** (2024)
  - ÐÐ²Ñ‚Ð¾Ñ€Ð¸: Microsoft Research Team
  - ÐŸÐ¾ÑÐ¸Ð»Ð°Ð½Ð½Ñ: https://arxiv.org/abs/2404.14219
  - ÐžÑÐ½Ð¾Ð²Ð½Ñ– Ð²Ð¸ÑÐ½Ð¾Ð²ÐºÐ¸: ÐŸÑ€Ð¸Ð½Ñ†Ð¸Ð¿Ð¸ Ð´Ð¸Ð·Ð°Ð¹Ð½Ñƒ SLM Ñ– ÑÑ‚Ñ€Ð°Ñ‚ÐµÐ³Ñ–Ñ— Ð¼Ð¾Ð±Ñ–Ð»ÑŒÐ½Ð¾Ð³Ð¾ Ñ€Ð¾Ð·Ð³Ð¾Ñ€Ñ‚Ð°Ð½Ð½Ñ

- **"Qwen2.5 Technical Report"** (2024)
  - ÐÐ²Ñ‚Ð¾Ñ€Ð¸: Alibaba Cloud Team
  - ÐŸÐ¾ÑÐ¸Ð»Ð°Ð½Ð½Ñ: https://arxiv.org/abs/2407.10671
  - ÐžÑÐ½Ð¾Ð²Ð½Ñ– Ð²Ð¸ÑÐ½Ð¾Ð²ÐºÐ¸: Ð Ð¾Ð·ÑˆÐ¸Ñ€ÐµÐ½Ñ– Ñ‚ÐµÑ…Ð½Ñ–ÐºÐ¸ Ð½Ð°Ð²Ñ‡Ð°Ð½Ð½Ñ SLM Ñ– Ð¾Ð¿Ñ‚Ð¸Ð¼Ñ–Ð·Ð°Ñ†Ñ–Ñ Ð¿Ñ€Ð¾Ð´ÑƒÐºÑ‚Ð¸Ð²Ð½Ð¾ÑÑ‚Ñ–

- **"TinyLlama: An Open-Source Small Language Model"** (2024)
  - ÐÐ²Ñ‚Ð¾Ñ€Ð¸: Peiyuan Zhang, Guangtao Zeng Ñ‚Ð° Ñ–Ð½.
  - ÐŸÐ¾ÑÐ¸Ð»Ð°Ð½Ð½Ñ: https://arxiv.org/abs/2401.02385
  - ÐžÑÐ½Ð¾Ð²Ð½Ñ– Ð²Ð¸ÑÐ½Ð¾Ð²ÐºÐ¸: Ð£Ð»ÑŒÑ‚Ñ€Ð°ÐºÐ¾Ð¼Ð¿Ð°ÐºÑ‚Ð½Ð¸Ð¹ Ð´Ð¸Ð·Ð°Ð¹Ð½ Ð¼Ð¾Ð´ÐµÐ»Ñ– Ñ‚Ð° ÐµÑ„ÐµÐºÑ‚Ð¸Ð²Ð½Ñ–ÑÑ‚ÑŒ Ð½Ð°Ð²Ñ‡Ð°Ð½Ð½Ñ

### ÐžÑ„Ñ–Ñ†Ñ–Ð¹Ð½Ð° Ð´Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚Ð°Ñ†Ñ–Ñ Ñ‚Ð° Ñ„Ñ€ÐµÐ¹Ð¼Ð²Ð¾Ñ€ÐºÐ¸

#### Microsoft Agent Framework
- **ÐžÑ„Ñ–Ñ†Ñ–Ð¹Ð½Ð° Ð´Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚Ð°Ñ†Ñ–Ñ**: https://docs.microsoft.com/en-us/azure/ai-services/agents/
- **Ð ÐµÐ¿Ð¾Ð·Ð¸Ñ‚Ð¾Ñ€Ñ–Ð¹ GitHub**: https://github.com/microsoft/agent-framework

#### Foundry Local
- **ÐžÑÐ½Ð¾Ð²Ð½Ð¸Ð¹ Ñ€ÐµÐ¿Ð¾Ð·Ð¸Ñ‚Ð¾Ñ€Ñ–Ð¹**: https://github.com/microsoft/foundry-local
- **Ð”Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚Ð°Ñ†Ñ–Ñ**: https://github.com/microsoft/foundry-local/blob/main/docs/README.md


#### VLLM
- **ÐžÑÐ½Ð¾Ð²Ð½Ð¸Ð¹ Ñ€ÐµÐ¿Ð¾Ð·Ð¸Ñ‚Ð¾Ñ€Ñ–Ð¹**: https://github.com/vllm-project/vllm
- **Ð”Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚Ð°Ñ†Ñ–Ñ**: https://docs.vllm.ai/


#### Ollama
- **ÐžÑ„Ñ–Ñ†Ñ–Ð¹Ð½Ð¸Ð¹ Ð²ÐµÐ±ÑÐ°Ð¹Ñ‚**: https://ollama.ai/
- **Ð ÐµÐ¿Ð¾Ð·Ð¸Ñ‚Ð¾Ñ€Ñ–Ð¹ GitHub**: https://github.com/ollama/ollama

### Ð¤Ñ€ÐµÐ¹Ð¼Ð²Ð¾Ñ€ÐºÐ¸ Ð¾Ð¿Ñ‚Ð¸Ð¼Ñ–Ð·Ð°Ñ†Ñ–Ñ— Ð¼Ð¾Ð´ÐµÐ»ÐµÐ¹

#### Llama.cpp
- **Ð ÐµÐ¿Ð¾Ð·Ð¸Ñ‚Ð¾Ñ€Ñ–Ð¹**: https://github.com/ggml-org/llama.cpp


#### Microsoft Olive
- **Ð”Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚Ð°Ñ†Ñ–Ñ**: https://microsoft.github.io/Olive/
- **Ð ÐµÐ¿Ð¾Ð·Ð¸Ñ‚Ð¾Ñ€Ñ–Ð¹ GitHub**: https://github.com/microsoft/Olive

#### OpenVINO
- **ÐžÑ„Ñ–Ñ†Ñ–Ð¹Ð½Ð¸Ð¹ ÑÐ°Ð¹Ñ‚**: https://docs.openvino.ai/

#### Apple MLX
- **Ð ÐµÐ¿Ð¾Ð·Ð¸Ñ‚Ð¾Ñ€Ñ–Ð¹**: https://github.com/ml-explore/mlx

### Ð“Ð°Ð»ÑƒÐ·ÐµÐ²Ñ– Ð·Ð²Ñ–Ñ‚Ð¸ Ñ‚Ð° Ð°Ð½Ð°Ð»Ñ–Ð· Ñ€Ð¸Ð½ÐºÑƒ

#### Ð”Ð¾ÑÐ»Ñ–Ð´Ð¶ÐµÐ½Ð½Ñ Ñ€Ð¸Ð½ÐºÑƒ AI Ð°Ð³ÐµÐ½Ñ‚Ñ–Ð²
- **"The State of AI Agents 2025"** - McKinsey Global Institute
  - ÐŸÐ¾ÑÐ¸Ð»Ð°Ð½Ð½Ñ: https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/ai-agents-2025
  - ÐžÑÐ½Ð¾Ð²Ð½Ñ– Ð²Ð¸ÑÐ½Ð¾Ð²ÐºÐ¸: Ð¢ÐµÐ½Ð´ÐµÐ½Ñ†Ñ–Ñ— Ñ€Ð¸Ð½ÐºÑƒ Ñ‚Ð° Ð¼Ð¾Ð´ÐµÐ»Ñ– Ð²Ð¿Ñ€Ð¾Ð²Ð°Ð´Ð¶ÐµÐ½Ð½Ñ Ð² Ð¿Ñ–Ð´Ð¿Ñ€Ð¸Ñ”Ð¼ÑÑ‚Ð²Ð°Ñ…

#### Ð¢ÐµÑ…Ð½Ñ–Ñ‡Ð½Ñ– Ð±ÐµÐ½Ñ‡Ð¼Ð°Ñ€ÐºÐ¸

- **"Edge AI Inference Benchmarks"** - MLPerf
  - ÐŸÐ¾ÑÐ¸Ð»Ð°Ð½Ð½Ñ: https://mlcommons.org/en/inference-edge/
  - ÐžÑÐ½Ð¾Ð²Ð½Ñ– Ð²Ð¸ÑÐ½Ð¾Ð²ÐºÐ¸: Ð¡Ñ‚Ð°Ð½Ð´Ð°Ñ€Ñ‚Ð¸Ð·Ð¾Ð²Ð°Ð½Ñ– Ð¿Ð¾ÐºÐ°Ð·Ð½Ð¸ÐºÐ¸ Ð¿Ñ€Ð¾Ð´ÑƒÐºÑ‚Ð¸Ð²Ð½Ð¾ÑÑ‚Ñ– Ð´Ð»Ñ Ñ€Ð¾Ð·Ð³Ð¾Ñ€Ñ‚Ð°Ð½Ð½Ñ Ð½Ð° Edge

### Ð¡Ñ‚Ð°Ð½Ð´Ð°Ñ€Ñ‚Ð¸ Ñ‚Ð° ÑÐ¿ÐµÑ†Ð¸Ñ„Ñ–ÐºÐ°Ñ†Ñ–Ñ—

#### Ð¤Ð¾Ñ€Ð¼Ð°Ñ‚Ð¸ Ð¼Ð¾Ð´ÐµÐ»ÐµÐ¹ Ñ– ÑÑ‚Ð°Ð½Ð´Ð°Ñ€Ñ‚Ð¸
- **ONNX (Open Neural Network Exchange)**: https://onnx.ai/
  - ÐšÑ€Ð¾ÑÐ¿Ð»Ð°Ñ‚Ñ„Ð¾Ñ€Ð¼ÐµÐ½Ð½Ð¸Ð¹ Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚ Ð¼Ð¾Ð´ÐµÐ»Ñ– Ð´Ð»Ñ ÑÑƒÐ¼Ñ–ÑÐ½Ð¾ÑÑ‚Ñ–
- **GGUF Specification**: https://github.com/ggerganov/ggml/blob/master/docs/gguf.md
  - Ð¤Ð¾Ñ€Ð¼Ð°Ñ‚ ÐºÐ²Ð°Ð½Ñ‚ÑƒÐ²Ð°Ð½Ð½Ñ Ð¼Ð¾Ð´ÐµÐ»Ñ– Ð´Ð»Ñ Ñ–Ð½Ñ„ÐµÑ€ÐµÐ½Ñ†Ñ–Ñ— Ð½Ð° Ð¿Ñ€Ð¾Ñ†ÐµÑÐ¾Ñ€Ð°Ñ…
- **OpenAI API Specification**: https://platform.openai.com/docs/api-reference
  - Ð¡Ñ‚Ð°Ð½Ð´Ð°Ñ€Ñ‚Ð½Ð¸Ð¹ Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚ API Ð´Ð»Ñ Ñ–Ð½Ñ‚ÐµÐ³Ñ€Ð°Ñ†Ñ–Ñ— Ð¼Ð¾Ð²Ð½Ð¸Ñ… Ð¼Ð¾Ð´ÐµÐ»ÐµÐ¹

#### Ð‘ÐµÐ·Ð¿ÐµÐºÐ° Ñ‚Ð° Ð²Ñ–Ð´Ð¿Ð¾Ð²Ñ–Ð´Ð½Ñ–ÑÑ‚ÑŒ
- **NIST AI Risk Management Framework**: https://www.nist.gov/itl/ai-risk-management-framework
- **ISO/IEC 23053:2022 - AI Systems**: Ð¤Ñ€ÐµÐ¹Ð¼Ð²Ð¾Ñ€Ðº Ð´Ð»Ñ AI ÑÐ¸ÑÑ‚ÐµÐ¼ Ñ– Ð±ÐµÐ·Ð¿ÐµÐºÐ¸
- **IEEE Standards for AI**: https://standards.ieee.org/industry-connections/ai/

ÐŸÐµÑ€ÐµÑ…Ñ–Ð´ Ð´Ð¾ Ð°Ð³ÐµÐ½Ñ‚Ñ–Ð², Ñ‰Ð¾ Ð¿Ñ€Ð°Ñ†ÑŽÑŽÑ‚ÑŒ Ð½Ð° Ð¾ÑÐ½Ð¾Ð²Ñ– SLM, Ð¿Ñ€ÐµÐ´ÑÑ‚Ð°Ð²Ð»ÑÑ” Ñ„ÑƒÐ½Ð´Ð°Ð¼ÐµÐ½Ñ‚Ð°Ð»ÑŒÐ½Ñƒ Ð·Ð¼Ñ–Ð½Ñƒ Ð² Ð¿Ñ–Ð´Ñ…Ð¾Ð´Ñ– Ð´Ð¾ Ñ€Ð¾Ð·Ð³Ð¾Ñ€Ñ‚Ð°Ð½Ð½Ñ AI. Microsoft Agent Framework, Ñƒ Ð¿Ð¾Ñ”Ð´Ð½Ð°Ð½Ð½Ñ– Ð· Ð»Ð¾ÐºÐ°Ð»ÑŒÐ½Ð¸Ð¼Ð¸ Ð¿Ð»Ð°Ñ‚Ñ„Ð¾Ñ€Ð¼Ð°Ð¼Ð¸ Ñ‚Ð° ÐµÑ„ÐµÐºÑ‚Ð¸Ð²Ð½Ð¸Ð¼Ð¸ Ð½ÐµÐ²ÐµÐ»Ð¸ÐºÐ¸Ð¼Ð¸ Ð¼Ð¾Ð²Ð½Ð¸Ð¼Ð¸ Ð¼Ð¾Ð´ÐµÐ»ÑÐ¼Ð¸, Ð·Ð°Ð±ÐµÐ·Ð¿ÐµÑ‡ÑƒÑ” Ð¿Ð¾Ð²Ð½Ðµ Ñ€Ñ–ÑˆÐµÐ½Ð½Ñ Ð´Ð»Ñ ÑÑ‚Ð²Ð¾Ñ€ÐµÐ½Ð½Ñ Ð³Ð¾Ñ‚Ð¾Ð²Ð¸Ñ… Ð´Ð¾ Ð²Ð¸Ñ€Ð¾Ð±Ð½Ð¸Ñ†Ñ‚Ð²Ð° Ð°Ð³ÐµÐ½Ñ‚Ñ–Ð², ÑÐºÑ– ÐµÑ„ÐµÐºÑ‚Ð¸Ð²Ð½Ð¾ Ð¿Ñ€Ð°Ñ†ÑŽÑŽÑ‚ÑŒ Ñƒ ÑÐµÑ€ÐµÐ´Ð¾Ð²Ð¸Ñ‰Ð°Ñ… Edge. Ð—Ð¾ÑÐµÑ€ÐµÐ´Ð¶ÑƒÑŽÑ‡Ð¸ÑÑŒ Ð½Ð° ÐµÑ„ÐµÐºÑ‚Ð¸Ð²Ð½Ð¾ÑÑ‚Ñ–, ÑÐ¿ÐµÑ†Ñ–Ð°Ð»Ñ–Ð·Ð°Ñ†Ñ–Ñ— Ñ‚Ð° Ð¿Ñ€Ð°ÐºÑ‚Ð¸Ñ‡Ð½Ñ–Ð¹ ÐºÐ¾Ñ€Ð¸ÑÐ½Ð¾ÑÑ‚Ñ–, Ñ†ÐµÐ¹ Ñ‚ÐµÑ…Ð½Ð¾Ð»Ð¾Ð³Ñ–Ñ‡Ð½Ð¸Ð¹ ÑÑ‚ÐµÐº Ñ€Ð¾Ð±Ð¸Ñ‚ÑŒ AI Ð°Ð³ÐµÐ½Ñ‚Ñ–Ð² Ð±Ñ–Ð»ÑŒÑˆ Ð´Ð¾ÑÑ‚ÑƒÐ¿Ð½Ð¸Ð¼Ð¸, ÐµÐºÐ¾Ð½Ð¾Ð¼Ñ–Ñ‡Ð½Ð¾ Ð²Ð¸Ð³Ñ–Ð´Ð½Ð¸Ð¼Ð¸ Ñ‚Ð° ÐµÑ„ÐµÐºÑ‚Ð¸Ð²Ð½Ð¸Ð¼Ð¸ Ð´Ð»Ñ Ñ€ÐµÐ°Ð»ÑŒÐ½Ð¸Ñ… Ð·Ð°ÑÑ‚Ð¾ÑÑƒÐ½ÐºÑ–Ð² Ñƒ ÐºÐ¾Ð¶Ð½Ñ–Ð¹ Ð³Ð°Ð»ÑƒÐ·Ñ– Ñ‚Ð° ÑÐµÑ€ÐµÐ´Ð¾Ð²Ð¸Ñ‰Ñ– Ð¾Ð±Ñ‡Ð¸ÑÐ»ÐµÐ½ÑŒ Ð½Ð° Edge.

Ð£ Ð¼Ñ–Ñ€Ñƒ Ð¿Ñ€Ð¾ÑÑƒÐ²Ð°Ð½Ð½Ñ Ð´Ð¾ 2025

---

**Ð’Ñ–Ð´Ð¼Ð¾Ð²Ð° Ð²Ñ–Ð´ Ð²Ñ–Ð´Ð¿Ð¾Ð²Ñ–Ð´Ð°Ð»ÑŒÐ½Ð¾ÑÑ‚Ñ–**:  
Ð¦ÐµÐ¹ Ð´Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚ Ð±ÑƒÐ² Ð¿ÐµÑ€ÐµÐºÐ»Ð°Ð´ÐµÐ½Ð¸Ð¹ Ð·Ð° Ð´Ð¾Ð¿Ð¾Ð¼Ð¾Ð³Ð¾ÑŽ ÑÐµÑ€Ð²Ñ–ÑÑƒ Ð°Ð²Ñ‚Ð¾Ð¼Ð°Ñ‚Ð¸Ñ‡Ð½Ð¾Ð³Ð¾ Ð¿ÐµÑ€ÐµÐºÐ»Ð°Ð´Ñƒ [Co-op Translator](https://github.com/Azure/co-op-translator). Ð¥Ð¾Ñ‡Ð° Ð¼Ð¸ Ð¿Ñ€Ð°Ð³Ð½ÐµÐ¼Ð¾ Ð´Ð¾ Ñ‚Ð¾Ñ‡Ð½Ð¾ÑÑ‚Ñ–, Ð±ÑƒÐ´ÑŒ Ð»Ð°ÑÐºÐ°, Ð¼Ð°Ð¹Ñ‚Ðµ Ð½Ð° ÑƒÐ²Ð°Ð·Ñ–, Ñ‰Ð¾ Ð°Ð²Ñ‚Ð¾Ð¼Ð°Ñ‚Ð¸Ñ‡Ð½Ñ– Ð¿ÐµÑ€ÐµÐºÐ»Ð°Ð´Ð¸ Ð¼Ð¾Ð¶ÑƒÑ‚ÑŒ Ð¼Ñ–ÑÑ‚Ð¸Ñ‚Ð¸ Ð¿Ð¾Ð¼Ð¸Ð»ÐºÐ¸ Ð°Ð±Ð¾ Ð½ÐµÑ‚Ð¾Ñ‡Ð½Ð¾ÑÑ‚Ñ–. ÐžÑ€Ð¸Ð³Ñ–Ð½Ð°Ð»ÑŒÐ½Ð¸Ð¹ Ð´Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚ Ð½Ð° Ð¹Ð¾Ð³Ð¾ Ñ€Ñ–Ð´Ð½Ñ–Ð¹ Ð¼Ð¾Ð²Ñ– ÑÐ»Ñ–Ð´ Ð²Ð²Ð°Ð¶Ð°Ñ‚Ð¸ Ð°Ð²Ñ‚Ð¾Ñ€Ð¸Ñ‚ÐµÑ‚Ð½Ð¸Ð¼ Ð´Ð¶ÐµÑ€ÐµÐ»Ð¾Ð¼. Ð”Ð»Ñ ÐºÑ€Ð¸Ñ‚Ð¸Ñ‡Ð½Ð¾Ñ— Ñ–Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ñ–Ñ— Ñ€ÐµÐºÐ¾Ð¼ÐµÐ½Ð´ÑƒÑ”Ñ‚ÑŒÑÑ Ð¿Ñ€Ð¾Ñ„ÐµÑÑ–Ð¹Ð½Ð¸Ð¹ Ð»ÑŽÐ´ÑÑŒÐºÐ¸Ð¹ Ð¿ÐµÑ€ÐµÐºÐ»Ð°Ð´. ÐœÐ¸ Ð½Ðµ Ð½ÐµÑÐµÐ¼Ð¾ Ð²Ñ–Ð´Ð¿Ð¾Ð²Ñ–Ð´Ð°Ð»ÑŒÐ½Ð¾ÑÑ‚Ñ– Ð·Ð° Ð±ÑƒÐ´ÑŒ-ÑÐºÑ– Ð½ÐµÐ¿Ð¾Ñ€Ð¾Ð·ÑƒÐ¼Ñ–Ð½Ð½Ñ Ð°Ð±Ð¾ Ð½ÐµÐ¿Ñ€Ð°Ð²Ð¸Ð»ÑŒÐ½Ñ– Ñ‚Ð»ÑƒÐ¼Ð°Ñ‡ÐµÐ½Ð½Ñ, Ñ‰Ð¾ Ð²Ð¸Ð½Ð¸ÐºÐ°ÑŽÑ‚ÑŒ Ð²Ð½Ð°ÑÐ»Ñ–Ð´Ð¾Ðº Ð²Ð¸ÐºÐ¾Ñ€Ð¸ÑÑ‚Ð°Ð½Ð½Ñ Ñ†ÑŒÐ¾Ð³Ð¾ Ð¿ÐµÑ€ÐµÐºÐ»Ð°Ð´Ñƒ.