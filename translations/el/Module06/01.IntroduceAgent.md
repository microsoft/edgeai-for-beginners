# Î ÏÎ¬ÎºÏ„Î¿ÏÎµÏ‚ AI ÎºÎ±Î¹ ÎœÎ¹ÎºÏÎ¬ Î“Î»Ï‰ÏƒÏƒÎ¹ÎºÎ¬ ÎœÎ¿Î½Ï„Î­Î»Î±: ÎŸÎ´Î·Î³ÏŒÏ‚ Î³Î¹Î± Î ÏÎ¿Ï‡Ï‰ÏÎ·Î¼Î­Î½Î¿Ï…Ï‚

## Î•Î¹ÏƒÎ±Î³Ï‰Î³Î®

Î£Îµ Î±Ï…Ï„ÏŒ Ï„Î¿ ÏƒÎµÎ¼Î¹Î½Î¬ÏÎ¹Î¿, Î¸Î± ÎµÎ¾ÎµÏÎµÏ…Î½Î®ÏƒÎ¿Ï…Î¼Îµ Ï„Î¿Ï…Ï‚ Î ÏÎ¬ÎºÏ„Î¿ÏÎµÏ‚ AI ÎºÎ±Î¹ Ï„Î± ÎœÎ¹ÎºÏÎ¬ Î“Î»Ï‰ÏƒÏƒÎ¹ÎºÎ¬ ÎœÎ¿Î½Ï„Î­Î»Î± (SLMs) ÎºÎ±Î¸ÏŽÏ‚ ÎºÎ±Î¹ Ï„Î¹Ï‚ Ï€ÏÎ¿Î·Î³Î¼Î­Î½ÎµÏ‚ ÏƒÏ„ÏÎ±Ï„Î·Î³Î¹ÎºÎ­Ï‚ Ï…Î»Î¿Ï€Î¿Î¯Î·ÏƒÎ®Ï‚ Ï„Î¿Ï…Ï‚ Î³Î¹Î± Ï€ÎµÏÎ¹Î²Î¬Î»Î»Î¿Î½Ï„Î± Ï…Ï€Î¿Î»Î¿Î³Î¹ÏƒÎ¼Î¿Ï Î±Î¹Ï‡Î¼Î®Ï‚. Î˜Î± ÎºÎ±Î»ÏÏˆÎ¿Ï…Î¼Îµ Ï„Î¹Ï‚ Î²Î±ÏƒÎ¹ÎºÎ­Ï‚ Î­Î½Î½Î¿Î¹ÎµÏ‚ Ï„Î·Ï‚ Ï€ÏÎ±ÎºÏ„Î¿ÏÎ¹ÎºÎ®Ï‚ AI, Ï„Î¹Ï‚ Ï„ÎµÏ‡Î½Î¹ÎºÎ­Ï‚ Î²ÎµÎ»Ï„Î¹ÏƒÏ„Î¿Ï€Î¿Î¯Î·ÏƒÎ·Ï‚ SLM, Ï„Î¹Ï‚ Ï€ÏÎ±ÎºÏ„Î¹ÎºÎ­Ï‚ ÏƒÏ„ÏÎ±Ï„Î·Î³Î¹ÎºÎ­Ï‚ Î±Î½Î¬Ï€Ï„Ï…Î¾Î·Ï‚ Î³Î¹Î± ÏƒÏ…ÏƒÎºÎµÏ…Î­Ï‚ Î¼Îµ Ï€ÎµÏÎ¹Î¿ÏÎ¹ÏƒÎ¼Î­Î½Î¿Ï…Ï‚ Ï€ÏŒÏÎ¿Ï…Ï‚ ÎºÎ±Î¹ Ï„Î¿ Microsoft Agent Framework Î³Î¹Î± Ï„Î· Î´Î·Î¼Î¹Î¿Ï…ÏÎ³Î¯Î± ÏƒÏ…ÏƒÏ„Î·Î¼Î¬Ï„Ï‰Î½ Ï€ÏÎ±ÎºÏ„ÏŒÏÏ‰Î½ Î­Ï„Î¿Î¹Î¼Ï‰Î½ Î³Î¹Î± Ï€Î±ÏÎ±Î³Ï‰Î³Î®.

Î¤Î¿ Ï„Î¿Ï€Î¯Î¿ Ï„Î·Ï‚ Ï„ÎµÏ‡Î½Î·Ï„Î®Ï‚ Î½Î¿Î·Î¼Î¿ÏƒÏÎ½Î·Ï‚ Î²Î¹ÏŽÎ½ÎµÎ¹ Î¼Î¹Î± Ï€Î±ÏÎ±Î´ÎµÎ¹Î³Î¼Î±Ï„Î¹ÎºÎ® Î±Î»Î»Î±Î³Î® Ï„Î¿ 2025. Î•Î½ÏŽ Ï„Î¿ 2023 Î®Ï„Î±Î½ Î· Ï‡ÏÎ¿Î½Î¹Î¬ Ï„Ï‰Î½ chatbots ÎºÎ±Î¹ Ï„Î¿ 2024 ÎµÎ¯Î´Îµ Ï„Î·Î½ Î¬Î½Î¸Î·ÏƒÎ· Ï„Ï‰Î½ copilots, Ï„Î¿ 2025 Î±Î½Î®ÎºÎµÎ¹ ÏƒÏ„Î¿Ï…Ï‚ Ï€ÏÎ¬ÎºÏ„Î¿ÏÎµÏ‚ AI â€” ÎµÏ…Ï†Ï…Î® ÏƒÏ…ÏƒÏ„Î®Î¼Î±Ï„Î± Ï€Î¿Ï… ÏƒÎºÎ­Ï†Ï„Î¿Î½Ï„Î±Î¹, ÏƒÏ‡ÎµÎ´Î¹Î¬Î¶Î¿Ï…Î½, Ï‡ÏÎ·ÏƒÎ¹Î¼Î¿Ï€Î¿Î¹Î¿ÏÎ½ ÎµÏÎ³Î±Î»ÎµÎ¯Î± ÎºÎ±Î¹ ÎµÎºÏ„ÎµÎ»Î¿ÏÎ½ ÎµÏÎ³Î±ÏƒÎ¯ÎµÏ‚ Î¼Îµ ÎµÎ»Î¬Ï‡Î¹ÏƒÏ„Î· Î±Î½Î¸ÏÏŽÏ€Î¹Î½Î· Ï€Î±ÏÎ­Î¼Î²Î±ÏƒÎ·, Ï…Ï€Î¿ÏƒÏ„Î·ÏÎ¹Î¶ÏŒÎ¼ÎµÎ½Î± ÏŒÎ»Î¿ ÎºÎ±Î¹ Ï€ÎµÏÎ¹ÏƒÏƒÏŒÏ„ÎµÏÎ¿ Î±Ï€ÏŒ Î±Ï€Î¿Î´Î¿Ï„Î¹ÎºÎ¬ ÎœÎ¹ÎºÏÎ¬ Î“Î»Ï‰ÏƒÏƒÎ¹ÎºÎ¬ ÎœÎ¿Î½Ï„Î­Î»Î±. Î¤Î¿ Microsoft Agent Framework Î±Î½Î±Î´ÎµÎ¹ÎºÎ½ÏÎµÏ„Î±Î¹ Ï‰Ï‚ ÎºÎ¿ÏÏ…Ï†Î±Î¯Î± Î»ÏÏƒÎ· Î³Î¹Î± Ï„Î· Î´Î·Î¼Î¹Î¿Ï…ÏÎ³Î¯Î± Î±Ï…Ï„ÏŽÎ½ Ï„Ï‰Î½ ÎµÏ…Ï†Ï…ÏŽÎ½ ÏƒÏ…ÏƒÏ„Î·Î¼Î¬Ï„Ï‰Î½ Î¼Îµ Î´Ï…Î½Î±Ï„ÏŒÏ„Î·Ï„ÎµÏ‚ ÎµÎºÏ„ÏŒÏ‚ ÏƒÏÎ½Î´ÎµÏƒÎ·Ï‚ ÎºÎ±Î¹ Ï…Ï€Î¿Î»Î¿Î³Î¹ÏƒÎ¼Î¿Ï Î±Î¹Ï‡Î¼Î®Ï‚.

## Î£Ï„ÏŒÏ‡Î¿Î¹ ÎœÎ¬Î¸Î·ÏƒÎ·Ï‚

ÎœÎ­Ï‡ÏÎ¹ Ï„Î¿ Ï„Î­Î»Î¿Ï‚ Î±Ï…Ï„Î¿Ï Ï„Î¿Ï… ÏƒÎµÎ¼Î¹Î½Î±ÏÎ¯Î¿Ï…, Î¸Î± Î¼Ï€Î¿ÏÎµÎ¯Ï„Îµ Î½Î±:

- ðŸ¤– ÎšÎ±Ï„Î±Î½Î¿Î®ÏƒÎµÏ„Îµ Ï„Î¹Ï‚ Î²Î±ÏƒÎ¹ÎºÎ­Ï‚ Î­Î½Î½Î¿Î¹ÎµÏ‚ Ï„Ï‰Î½ Ï€ÏÎ±ÎºÏ„ÏŒÏÏ‰Î½ AI ÎºÎ±Î¹ Ï„Ï‰Î½ Ï€ÏÎ±ÎºÏ„Î¿ÏÎ¹ÎºÏŽÎ½ ÏƒÏ…ÏƒÏ„Î·Î¼Î¬Ï„Ï‰Î½
- ðŸ”¬ Î‘Î½Î±Î³Î½Ï‰ÏÎ¯ÏƒÎµÏ„Îµ Ï„Î± Ï€Î»ÎµÎ¿Î½ÎµÎºÏ„Î®Î¼Î±Ï„Î± Ï„Ï‰Î½ ÎœÎ¹ÎºÏÏŽÎ½ Î“Î»Ï‰ÏƒÏƒÎ¹ÎºÏŽÎ½ ÎœÎ¿Î½Ï„Î­Î»Ï‰Î½ Î­Î½Î±Î½Ï„Î¹ Ï„Ï‰Î½ ÎœÎµÎ³Î¬Î»Ï‰Î½ Î“Î»Ï‰ÏƒÏƒÎ¹ÎºÏŽÎ½ ÎœÎ¿Î½Ï„Î­Î»Ï‰Î½ ÏƒÎµ Ï€ÏÎ±ÎºÏ„Î¿ÏÎ¹ÎºÎ­Ï‚ ÎµÏ†Î±ÏÎ¼Î¿Î³Î­Ï‚
- ðŸš€ ÎœÎ¬Î¸ÎµÏ„Îµ Ï€ÏÎ¿Î·Î³Î¼Î­Î½ÎµÏ‚ ÏƒÏ„ÏÎ±Ï„Î·Î³Î¹ÎºÎ­Ï‚ Î±Î½Î¬Ï€Ï„Ï…Î¾Î·Ï‚ SLM Î³Î¹Î± Ï€ÎµÏÎ¹Î²Î¬Î»Î»Î¿Î½Ï„Î± Ï…Ï€Î¿Î»Î¿Î³Î¹ÏƒÎ¼Î¿Ï Î±Î¹Ï‡Î¼Î®Ï‚
- ðŸ“± Î¥Î»Î¿Ï€Î¿Î¹Î®ÏƒÎµÏ„Îµ Ï€ÏÎ±ÎºÏ„Î¹ÎºÎ¿ÏÏ‚ Ï€ÏÎ¬ÎºÏ„Î¿ÏÎµÏ‚ Î¼Îµ SLM Î³Î¹Î± ÎµÏ†Î±ÏÎ¼Î¿Î³Î­Ï‚ Ï€ÏÎ±Î³Î¼Î±Ï„Î¹ÎºÎ¿Ï ÎºÏŒÏƒÎ¼Î¿Ï…
- ðŸ—ï¸ Î”Î·Î¼Î¹Î¿Ï…ÏÎ³Î®ÏƒÎµÏ„Îµ Ï€ÏÎ¬ÎºÏ„Î¿ÏÎµÏ‚ Î­Ï„Î¿Î¹Î¼Î¿Ï…Ï‚ Î³Î¹Î± Ï€Î±ÏÎ±Î³Ï‰Î³Î® Ï‡ÏÎ·ÏƒÎ¹Î¼Î¿Ï€Î¿Î¹ÏŽÎ½Ï„Î±Ï‚ Ï„Î¿ Microsoft Agent Framework
- ðŸŒ Î‘Î½Î±Ï€Ï„ÏÎ¾ÎµÏ„Îµ Ï€ÏÎ¬ÎºÏ„Î¿ÏÎµÏ‚ ÎµÎºÏ„ÏŒÏ‚ ÏƒÏÎ½Î´ÎµÏƒÎ·Ï‚ Î¼Îµ Ï„Î¿Ï€Î¹ÎºÎ® ÎµÎ½ÏƒÏ‰Î¼Î¬Ï„Ï‰ÏƒÎ· LLM ÎºÎ±Î¹ SLM
- ðŸ”§ Î•Î½ÏƒÏ‰Î¼Î±Ï„ÏŽÏƒÎµÏ„Îµ Ï„Î¿ Microsoft Agent Framework Î¼Îµ Ï„Î¿ Foundry Local Î³Î¹Î± Î±Î½Î¬Ï€Ï„Ï…Î¾Î· Î±Î¹Ï‡Î¼Î®Ï‚

## ÎšÎ±Ï„Î±Î½ÏŒÎ·ÏƒÎ· Î ÏÎ±ÎºÏ„ÏŒÏÏ‰Î½ AI: Î˜ÎµÎ¼Î­Î»Î¹Î± ÎºÎ±Î¹ ÎšÎ±Ï„Î·Î³Î¿ÏÎ¹Î¿Ï€Î¿Î¹Î®ÏƒÎµÎ¹Ï‚

### ÎŸÏÎ¹ÏƒÎ¼ÏŒÏ‚ ÎºÎ±Î¹ Î’Î±ÏƒÎ¹ÎºÎ­Ï‚ ÎˆÎ½Î½Î¿Î¹ÎµÏ‚

ÎˆÎ½Î±Ï‚ Ï€ÏÎ¬ÎºÏ„Î¿ÏÎ±Ï‚ Ï„ÎµÏ‡Î½Î·Ï„Î®Ï‚ Î½Î¿Î·Î¼Î¿ÏƒÏÎ½Î·Ï‚ (AI) Î±Î½Î±Ï†Î­ÏÎµÏ„Î±Î¹ ÏƒÎµ Î­Î½Î± ÏƒÏÏƒÏ„Î·Î¼Î± Î® Ï€ÏÏŒÎ³ÏÎ±Î¼Î¼Î± Ï€Î¿Ï… ÎµÎ¯Î½Î±Î¹ Î¹ÎºÎ±Î½ÏŒ Î½Î± ÎµÎºÏ„ÎµÎ»ÎµÎ¯ Î±Ï…Ï„ÏŒÎ½Î¿Î¼Î± ÎµÏÎ³Î±ÏƒÎ¯ÎµÏ‚ Î³Î¹Î± Î»Î¿Î³Î±ÏÎ¹Î±ÏƒÎ¼ÏŒ ÎµÎ½ÏŒÏ‚ Ï‡ÏÎ®ÏƒÏ„Î· Î® Î¬Î»Î»Î¿Ï… ÏƒÏ…ÏƒÏ„Î®Î¼Î±Ï„Î¿Ï‚ ÏƒÏ‡ÎµÎ´Î¹Î¬Î¶Î¿Î½Ï„Î±Ï‚ Ï„Î· ÏÎ¿Î® ÎµÏÎ³Î±ÏƒÎ¯Î±Ï‚ Ï„Î¿Ï… ÎºÎ±Î¹ Ï‡ÏÎ·ÏƒÎ¹Î¼Î¿Ï€Î¿Î¹ÏŽÎ½Ï„Î±Ï‚ Î´Î¹Î±Î¸Î­ÏƒÎ¹Î¼Î± ÎµÏÎ³Î±Î»ÎµÎ¯Î±. Î£Îµ Î±Î½Ï„Î¯Î¸ÎµÏƒÎ· Î¼Îµ Ï„Î·Î½ Ï€Î±ÏÎ±Î´Î¿ÏƒÎ¹Î±ÎºÎ® AI Ï€Î¿Ï… Î±Ï€Î»ÏŽÏ‚ Î±Ï€Î±Î½Ï„Î¬ ÏƒÏ„Î¹Ï‚ ÎµÏÏ‰Ï„Î®ÏƒÎµÎ¹Ï‚ ÏƒÎ±Ï‚, Î­Î½Î±Ï‚ Ï€ÏÎ¬ÎºÏ„Î¿ÏÎ±Ï‚ Î¼Ï€Î¿ÏÎµÎ¯ Î½Î± ÎµÎ½ÎµÏÎ³ÎµÎ¯ Î±Î½ÎµÎ¾Î¬ÏÏ„Î·Ï„Î± Î³Î¹Î± Ï„Î·Î½ ÎµÏ€Î¯Ï„ÎµÏ…Î¾Î· ÏƒÏ„ÏŒÏ‡Ï‰Î½.

### Î Î»Î±Î¯ÏƒÎ¹Î¿ ÎšÎ±Ï„Î·Î³Î¿ÏÎ¹Î¿Ï€Î¿Î¯Î·ÏƒÎ·Ï‚ Î ÏÎ±ÎºÏ„ÏŒÏÏ‰Î½

Î— ÎºÎ±Ï„Î±Î½ÏŒÎ·ÏƒÎ· Ï„Ï‰Î½ Î¿ÏÎ¯Ï‰Î½ Ï„Ï‰Î½ Ï€ÏÎ±ÎºÏ„ÏŒÏÏ‰Î½ Î²Î¿Î·Î¸Î¬ ÏƒÏ„Î·Î½ ÎµÏ€Î¹Î»Î¿Î³Î® ÎºÎ±Ï„Î¬Î»Î»Î·Î»Ï‰Î½ Ï„ÏÏ€Ï‰Î½ Ï€ÏÎ±ÎºÏ„ÏŒÏÏ‰Î½ Î³Î¹Î± Î´Î¹Î±Ï†Î¿ÏÎµÏ„Î¹ÎºÎ¬ ÏƒÎµÎ½Î¬ÏÎ¹Î± Ï…Ï€Î¿Î»Î¿Î³Î¹ÏƒÎ¼Î¿Ï:

- **ðŸ”¬ Î‘Ï€Î»Î¿Î¯ Î ÏÎ¬ÎºÏ„Î¿ÏÎµÏ‚ Î‘Î½Ï„Î±Î½Î±ÎºÎ»Î±ÏƒÏ„Î¹ÎºÏŽÎ½**: Î£Ï…ÏƒÏ„Î®Î¼Î±Ï„Î± Î²Î±ÏƒÎ¹ÏƒÎ¼Î­Î½Î± ÏƒÎµ ÎºÎ±Î½ÏŒÎ½ÎµÏ‚ Ï€Î¿Ï… Î±Î½Ï„Î±Ï€Î¿ÎºÏÎ¯Î½Î¿Î½Ï„Î±Î¹ ÏƒÎµ Î¬Î¼ÎµÏƒÎµÏ‚ Î±Î½Ï„Î¹Î»Î®ÏˆÎµÎ¹Ï‚ (Î¸ÎµÏÎ¼Î¿ÏƒÏ„Î¬Ï„ÎµÏ‚, Î²Î±ÏƒÎ¹ÎºÏŒÏ‚ Î±Ï…Ï„Î¿Î¼Î±Ï„Î¹ÏƒÎ¼ÏŒÏ‚)
- **ðŸ“± Î ÏÎ¬ÎºÏ„Î¿ÏÎµÏ‚ Î’Î±ÏƒÎ¹ÏƒÎ¼Î­Î½Î¿Î¹ ÏƒÎµ ÎœÎ¿Î½Ï„Î­Î»Î±**: Î£Ï…ÏƒÏ„Î®Î¼Î±Ï„Î± Ï€Î¿Ï… Î´Î¹Î±Ï„Î·ÏÎ¿ÏÎ½ ÎµÏƒÏ‰Ï„ÎµÏÎ¹ÎºÎ® ÎºÎ±Ï„Î¬ÏƒÏ„Î±ÏƒÎ· ÎºÎ±Î¹ Î¼Î½Î®Î¼Î· (ÏÎ¿Î¼Ï€Î¿Ï„Î¹ÎºÎ­Ï‚ ÏƒÎºÎ¿ÏÏ€ÎµÏ‚, ÏƒÏ…ÏƒÏ„Î®Î¼Î±Ï„Î± Ï€Î»Î¿Î®Î³Î·ÏƒÎ·Ï‚)
- **âš–ï¸ Î ÏÎ¬ÎºÏ„Î¿ÏÎµÏ‚ Î’Î±ÏƒÎ¹ÏƒÎ¼Î­Î½Î¿Î¹ ÏƒÎµ Î£Ï„ÏŒÏ‡Î¿Ï…Ï‚**: Î£Ï…ÏƒÏ„Î®Î¼Î±Ï„Î± Ï€Î¿Ï… ÏƒÏ‡ÎµÎ´Î¹Î¬Î¶Î¿Ï…Î½ ÎºÎ±Î¹ ÎµÎºÏ„ÎµÎ»Î¿ÏÎ½ Î±ÎºÎ¿Î»Î¿Ï…Î¸Î¯ÎµÏ‚ Î³Î¹Î± Ï„Î·Î½ ÎµÏ€Î¯Ï„ÎµÏ…Î¾Î· ÏƒÏ„ÏŒÏ‡Ï‰Î½ (Ï€ÏÎ¿Î³ÏÎ±Î¼Î¼Î±Ï„Î¹ÏƒÏ„Î­Ï‚ Î´Î¹Î±Î´ÏÎ¿Î¼ÏŽÎ½, Ï€ÏÎ¿Î³ÏÎ±Î¼Î¼Î±Ï„Î¹ÏƒÏ„Î­Ï‚ ÎµÏÎ³Î±ÏƒÎ¹ÏŽÎ½)
- **ðŸ§  Î ÏÎ¬ÎºÏ„Î¿ÏÎµÏ‚ ÎœÎ¬Î¸Î·ÏƒÎ·Ï‚**: Î ÏÎ¿ÏƒÎ±ÏÎ¼Î¿ÏƒÏ„Î¹ÎºÎ¬ ÏƒÏ…ÏƒÏ„Î®Î¼Î±Ï„Î± Ï€Î¿Ï… Î²ÎµÎ»Ï„Î¹ÏŽÎ½Î¿Ï…Î½ Ï„Î·Î½ Î±Ï€ÏŒÎ´Î¿ÏƒÎ· Î¼Îµ Ï„Î·Î½ Ï€Î¬ÏÎ¿Î´Î¿ Ï„Î¿Ï… Ï‡ÏÏŒÎ½Î¿Ï… (ÏƒÏ…ÏƒÏ„Î®Î¼Î±Ï„Î± ÏƒÏ…ÏƒÏ„Î¬ÏƒÎµÏ‰Î½, ÎµÎ¾Î±Ï„Î¿Î¼Î¹ÎºÎµÏ…Î¼Î­Î½Î¿Î¹ Î²Î¿Î·Î¸Î¿Î¯)

### Î’Î±ÏƒÎ¹ÎºÎ¬ Î Î»ÎµÎ¿Î½ÎµÎºÏ„Î®Î¼Î±Ï„Î± Ï„Ï‰Î½ Î ÏÎ±ÎºÏ„ÏŒÏÏ‰Î½ AI

ÎŸÎ¹ Ï€ÏÎ¬ÎºÏ„Î¿ÏÎµÏ‚ AI Ï€ÏÎ¿ÏƒÏ†Î­ÏÎ¿Ï…Î½ Î±ÏÎºÎµÏ„Î¬ Î¸ÎµÎ¼ÎµÎ»Î¹ÏŽÎ´Î· Ï€Î»ÎµÎ¿Î½ÎµÎºÏ„Î®Î¼Î±Ï„Î± Ï€Î¿Ï… Ï„Î¿Ï…Ï‚ ÎºÎ±Î¸Î¹ÏƒÏ„Î¿ÏÎ½ Î¹Î´Î±Î½Î¹ÎºÎ¿ÏÏ‚ Î³Î¹Î± ÎµÏ†Î±ÏÎ¼Î¿Î³Î­Ï‚ Ï…Ï€Î¿Î»Î¿Î³Î¹ÏƒÎ¼Î¿Ï Î±Î¹Ï‡Î¼Î®Ï‚:

**Î›ÎµÎ¹Ï„Î¿Ï…ÏÎ³Î¹ÎºÎ® Î‘Ï…Ï„Î¿Î½Î¿Î¼Î¯Î±**: ÎŸÎ¹ Ï€ÏÎ¬ÎºÏ„Î¿ÏÎµÏ‚ Ï€Î±ÏÎ­Ï‡Î¿Ï…Î½ Î±Î½ÎµÎ¾Î¬ÏÏ„Î·Ï„Î· ÎµÎºÏ„Î­Î»ÎµÏƒÎ· ÎµÏÎ³Î±ÏƒÎ¹ÏŽÎ½ Ï‡Ï‰ÏÎ¯Ï‚ ÏƒÏ…Î½ÎµÏ‡Î® Î±Î½Î¸ÏÏŽÏ€Î¹Î½Î· ÎµÏ€Î¯Î²Î»ÎµÏˆÎ·, ÎºÎ±Î¸Î¹ÏƒÏ„ÏŽÎ½Ï„Î±Ï‚ Ï„Î¿Ï…Ï‚ Î¹Î´Î±Î½Î¹ÎºÎ¿ÏÏ‚ Î³Î¹Î± ÎµÏ†Î±ÏÎ¼Î¿Î³Î­Ï‚ ÏƒÎµ Ï€ÏÎ±Î³Î¼Î±Ï„Î¹ÎºÏŒ Ï‡ÏÏŒÎ½Î¿. Î‘Ï€Î±Î¹Ï„Î¿ÏÎ½ ÎµÎ»Î¬Ï‡Î¹ÏƒÏ„Î· ÎµÏ€Î¯Î²Î»ÎµÏˆÎ· ÎµÎ½ÏŽ Î´Î¹Î±Ï„Î·ÏÎ¿ÏÎ½ Ï€ÏÎ¿ÏƒÎ±ÏÎ¼Î¿ÏƒÏ„Î¹ÎºÎ® ÏƒÏ…Î¼Ï€ÎµÏÎ¹Ï†Î¿ÏÎ¬, ÎµÏ€Î¹Ï„ÏÎ­Ï€Î¿Î½Ï„Î±Ï‚ Ï„Î·Î½ Î±Î½Î¬Ï€Ï„Ï…Î¾Î· ÏƒÎµ ÏƒÏ…ÏƒÎºÎµÏ…Î­Ï‚ Î¼Îµ Ï€ÎµÏÎ¹Î¿ÏÎ¹ÏƒÎ¼Î­Î½Î¿Ï…Ï‚ Ï€ÏŒÏÎ¿Ï…Ï‚ Î¼Îµ Î¼ÎµÎ¹Ï‰Î¼Î­Î½Î¿ Î»ÎµÎ¹Ï„Î¿Ï…ÏÎ³Î¹ÎºÏŒ ÎºÏŒÏƒÏ„Î¿Ï‚.

**Î•Ï…ÎµÎ»Î¹Î¾Î¯Î± Î‘Î½Î¬Ï€Ï„Ï…Î¾Î·Ï‚**: Î‘Ï…Ï„Î¬ Ï„Î± ÏƒÏ…ÏƒÏ„Î®Î¼Î±Ï„Î± ÎµÏ€Î¹Ï„ÏÎ­Ï€Î¿Ï…Î½ Î´Ï…Î½Î±Ï„ÏŒÏ„Î·Ï„ÎµÏ‚ AI ÏƒÏ„Î· ÏƒÏ…ÏƒÎºÎµÏ…Î® Ï‡Ï‰ÏÎ¯Ï‚ Î±Ï€Î±Î¹Ï„Î®ÏƒÎµÎ¹Ï‚ ÏƒÏ…Î½Î´ÎµÏƒÎ¹Î¼ÏŒÏ„Î·Ï„Î±Ï‚ ÏƒÏ„Î¿ Î´Î¹Î±Î´Î¯ÎºÏ„Ï…Î¿, ÎµÎ½Î¹ÏƒÏ‡ÏÎ¿Ï…Î½ Ï„Î·Î½ Î¹Î´Î¹Ï‰Ï„Î¹ÎºÏŒÏ„Î·Ï„Î± ÎºÎ±Î¹ Ï„Î·Î½ Î±ÏƒÏ†Î¬Î»ÎµÎ¹Î± Î¼Î­ÏƒÏ‰ Ï„Î¿Ï€Î¹ÎºÎ®Ï‚ ÎµÏ€ÎµÎ¾ÎµÏÎ³Î±ÏƒÎ¯Î±Ï‚, Î¼Ï€Î¿ÏÎ¿ÏÎ½ Î½Î± Ï€ÏÎ¿ÏƒÎ±ÏÎ¼Î¿ÏƒÏ„Î¿ÏÎ½ Î³Î¹Î± ÎµÏ†Î±ÏÎ¼Î¿Î³Î­Ï‚ ÏƒÏ…Î³ÎºÎµÎºÏÎ¹Î¼Î­Î½Î¿Ï… Ï„Î¿Î¼Î­Î± ÎºÎ±Î¹ ÎµÎ¯Î½Î±Î¹ ÎºÎ±Ï„Î¬Î»Î»Î·Î»Î± Î³Î¹Î± Î´Î¹Î¬Ï†Î¿ÏÎ± Ï€ÎµÏÎ¹Î²Î¬Î»Î»Î¿Î½Ï„Î± Ï…Ï€Î¿Î»Î¿Î³Î¹ÏƒÎ¼Î¿Ï Î±Î¹Ï‡Î¼Î®Ï‚.

**ÎŸÎ¹ÎºÎ¿Î½Î¿Î¼Î¹ÎºÎ® Î‘Ï€Î¿Î´Î¿Ï„Î¹ÎºÏŒÏ„Î·Ï„Î±**: Î¤Î± ÏƒÏ…ÏƒÏ„Î®Î¼Î±Ï„Î± Ï€ÏÎ±ÎºÏ„ÏŒÏÏ‰Î½ Ï€ÏÎ¿ÏƒÏ†Î­ÏÎ¿Ï…Î½ Î¿Î¹ÎºÎ¿Î½Î¿Î¼Î¹ÎºÎ® Î±Î½Î¬Ï€Ï„Ï…Î¾Î· ÏƒÎµ ÏƒÏÎ³ÎºÏÎ¹ÏƒÎ· Î¼Îµ Î»ÏÏƒÎµÎ¹Ï‚ Î²Î±ÏƒÎ¹ÏƒÎ¼Î­Î½ÎµÏ‚ ÏƒÏ„Î¿ cloud, Î¼Îµ Î¼ÎµÎ¹Ï‰Î¼Î­Î½Î¿ Î»ÎµÎ¹Ï„Î¿Ï…ÏÎ³Î¹ÎºÏŒ ÎºÏŒÏƒÏ„Î¿Ï‚ ÎºÎ±Î¹ Ï‡Î±Î¼Î·Î»ÏŒÏ„ÎµÏÎµÏ‚ Î±Ï€Î±Î¹Ï„Î®ÏƒÎµÎ¹Ï‚ ÎµÏÏÎ¿Ï…Ï‚ Î¶ÏŽÎ½Î·Ï‚ Î³Î¹Î± ÎµÏ†Î±ÏÎ¼Î¿Î³Î­Ï‚ Î±Î¹Ï‡Î¼Î®Ï‚.

## Î ÏÎ¿Î·Î³Î¼Î­Î½ÎµÏ‚ Î£Ï„ÏÎ±Ï„Î·Î³Î¹ÎºÎ­Ï‚ ÎœÎ¹ÎºÏÏŽÎ½ Î“Î»Ï‰ÏƒÏƒÎ¹ÎºÏŽÎ½ ÎœÎ¿Î½Ï„Î­Î»Ï‰Î½

### Î˜ÎµÎ¼ÎµÎ»Î¹ÏŽÎ´Î· Î£Ï„Î¿Î¹Ï‡ÎµÎ¯Î± SLM (ÎœÎ¹ÎºÏÎ¬ Î“Î»Ï‰ÏƒÏƒÎ¹ÎºÎ¬ ÎœÎ¿Î½Ï„Î­Î»Î±)

ÎˆÎ½Î± ÎœÎ¹ÎºÏÏŒ Î“Î»Ï‰ÏƒÏƒÎ¹ÎºÏŒ ÎœÎ¿Î½Ï„Î­Î»Î¿ (SLM) ÎµÎ¯Î½Î±Î¹ Î­Î½Î± Î³Î»Ï‰ÏƒÏƒÎ¹ÎºÏŒ Î¼Î¿Î½Ï„Î­Î»Î¿ Ï€Î¿Ï… Î¼Ï€Î¿ÏÎµÎ¯ Î½Î± Ï‡Ï‰ÏÎ­ÏƒÎµÎ¹ ÏƒÎµ Î¼Î¹Î± ÎºÎ¿Î¹Î½Î® ÎºÎ±Ï„Î±Î½Î±Î»Ï‰Ï„Î¹ÎºÎ® Î·Î»ÎµÎºÏ„ÏÎ¿Î½Î¹ÎºÎ® ÏƒÏ…ÏƒÎºÎµÏ…Î® ÎºÎ±Î¹ Î½Î± ÎµÎºÏ„ÎµÎ»Î­ÏƒÎµÎ¹ ÏƒÏ…Î¼Ï€ÎµÏÎ¬ÏƒÎ¼Î±Ï„Î± Î¼Îµ ÎºÎ±Î¸Ï…ÏƒÏ„Î­ÏÎ·ÏƒÎ· Î±ÏÎºÎµÏ„Î¬ Ï‡Î±Î¼Î·Î»Î® ÏŽÏƒÏ„Îµ Î½Î± ÎµÎ¯Î½Î±Î¹ Ï€ÏÎ±ÎºÏ„Î¹ÎºÎ® ÏŒÏ„Î±Î½ ÎµÎ¾Ï…Ï€Î·ÏÎµÏ„ÎµÎ¯ Ï€ÏÎ±ÎºÏ„Î¿ÏÎ¹ÎºÎ¬ Î±Î¹Ï„Î®Î¼Î±Ï„Î± ÎµÎ½ÏŒÏ‚ Ï‡ÏÎ®ÏƒÏ„Î·. Î£Ï„Î·Î½ Ï€ÏÎ¬Î¾Î·, Ï„Î± SLMs ÎµÎ¯Î½Î±Î¹ ÏƒÏ…Î½Î®Î¸Ï‰Ï‚ Î¼Î¿Î½Ï„Î­Î»Î± Î¼Îµ Î»Î¹Î³ÏŒÏ„ÎµÏÎµÏ‚ Î±Ï€ÏŒ 10 Î´Î¹ÏƒÎµÎºÎ±Ï„Î¿Î¼Î¼ÏÏÎ¹Î± Ï€Î±ÏÎ±Î¼Î­Ï„ÏÎ¿Ï…Ï‚.

**Î§Î±ÏÎ±ÎºÏ„Î·ÏÎ¹ÏƒÏ„Î¹ÎºÎ¬ Î‘Î½Î±ÎºÎ¬Î»Ï…ÏˆÎ·Ï‚ ÎœÎ¿ÏÏ†Î®Ï‚**: Î¤Î± SLMs Ï€ÏÎ¿ÏƒÏ†Î­ÏÎ¿Ï…Î½ Ï€ÏÎ¿Î·Î³Î¼Î­Î½Î· Ï…Ï€Î¿ÏƒÏ„Î®ÏÎ¹Î¾Î· Î³Î¹Î± Î´Î¹Î¬Ï†Î¿ÏÎ± ÎµÏ€Î¯Ï€ÎµÎ´Î± Ï€Î¿ÏƒÎ¿Ï„Î¹ÎºÎ¿Ï€Î¿Î¯Î·ÏƒÎ·Ï‚, ÏƒÏ…Î¼Î²Î±Ï„ÏŒÏ„Î·Ï„Î± Î¼ÎµÏ„Î±Î¾Ï Ï€Î»Î±Ï„Ï†Î¿ÏÎ¼ÏŽÎ½, Î²ÎµÎ»Ï„Î¹ÏƒÏ„Î¿Ï€Î¿Î¯Î·ÏƒÎ· Î±Ï€ÏŒÎ´Î¿ÏƒÎ·Ï‚ ÏƒÎµ Ï€ÏÎ±Î³Î¼Î±Ï„Î¹ÎºÏŒ Ï‡ÏÏŒÎ½Î¿ ÎºÎ±Î¹ Î´Ï…Î½Î±Ï„ÏŒÏ„Î·Ï„ÎµÏ‚ Î±Î½Î¬Ï€Ï„Ï…Î¾Î·Ï‚ Î±Î¹Ï‡Î¼Î®Ï‚. ÎŸÎ¹ Ï‡ÏÎ®ÏƒÏ„ÎµÏ‚ Î¼Ï€Î¿ÏÎ¿ÏÎ½ Î½Î± Î­Ï‡Î¿Ï…Î½ Ï€ÏÏŒÏƒÎ²Î±ÏƒÎ· ÏƒÎµ ÎµÎ½Î¹ÏƒÏ‡Ï…Î¼Î­Î½Î· Î¹Î´Î¹Ï‰Ï„Î¹ÎºÏŒÏ„Î·Ï„Î± Î¼Î­ÏƒÏ‰ Ï„Î¿Ï€Î¹ÎºÎ®Ï‚ ÎµÏ€ÎµÎ¾ÎµÏÎ³Î±ÏƒÎ¯Î±Ï‚ ÎºÎ±Î¹ Ï…Ï€Î¿ÏƒÏ„Î®ÏÎ¹Î¾Î·Ï‚ WebGPU Î³Î¹Î± Î±Î½Î¬Ï€Ï„Ï…Î¾Î· Î¼Î­ÏƒÏ‰ Ï€ÏÎ¿Î³ÏÎ¬Î¼Î¼Î±Ï„Î¿Ï‚ Ï€ÎµÏÎ¹Î®Î³Î·ÏƒÎ·Ï‚.

**Î£Ï…Î»Î»Î¿Î³Î­Ï‚ Î•Ï€Î¹Ï€Î­Î´Ï‰Î½ Î Î¿ÏƒÎ¿Ï„Î¹ÎºÎ¿Ï€Î¿Î¯Î·ÏƒÎ·Ï‚**: Î”Î·Î¼Î¿Ï†Î¹Î»ÎµÎ¯Ï‚ Î¼Î¿ÏÏ†Î­Ï‚ SLM Ï€ÎµÏÎ¹Î»Î±Î¼Î²Î¬Î½Î¿Ï…Î½ Q4_K_M Î³Î¹Î± Î¹ÏƒÎ¿ÏÏÎ¿Ï€Î·Î¼Î­Î½Î· ÏƒÏ…Î¼Ï€Î¯ÎµÏƒÎ· ÏƒÎµ ÎºÎ¹Î½Î·Ï„Î­Ï‚ ÎµÏ†Î±ÏÎ¼Î¿Î³Î­Ï‚, Q5_K_S ÏƒÎµÎ¹ÏÎ¬ Î³Î¹Î± Î±Î½Î¬Ï€Ï„Ï…Î¾Î· Î±Î¹Ï‡Î¼Î®Ï‚ Î¼Îµ Î­Î¼Ï†Î±ÏƒÎ· ÏƒÏ„Î·Î½ Ï€Î¿Î¹ÏŒÏ„Î·Ï„Î±, Q8_0 Î³Î¹Î± ÏƒÏ‡ÎµÎ´ÏŒÎ½ Î±ÏÏ‡Î¹ÎºÎ® Î±ÎºÏÎ¯Î²ÎµÎ¹Î± ÏƒÎµ Î¹ÏƒÏ‡Ï…ÏÎ­Ï‚ ÏƒÏ…ÏƒÎºÎµÏ…Î­Ï‚ Î±Î¹Ï‡Î¼Î®Ï‚ ÎºÎ±Î¹ Ï€ÎµÎ¹ÏÎ±Î¼Î±Ï„Î¹ÎºÎ­Ï‚ Î¼Î¿ÏÏ†Î­Ï‚ ÏŒÏ€Ï‰Ï‚ Q2_K Î³Î¹Î± ÏƒÎµÎ½Î¬ÏÎ¹Î± ÎµÎ¾Î±Î¹ÏÎµÏ„Î¹ÎºÎ¬ Ï‡Î±Î¼Î·Î»ÏŽÎ½ Ï€ÏŒÏÏ‰Î½.

### GGUF (Î“ÎµÎ½Î¹ÎºÎ® ÎœÎ¿ÏÏ†Î® GGML Î³Î¹Î± Î‘Î½Î¬Ï€Ï„Ï…Î¾Î· SLM)

Î¤Î¿ GGUF Ï‡ÏÎ·ÏƒÎ¹Î¼ÎµÏÎµÎ¹ Ï‰Ï‚ Î· ÎºÏÏÎ¹Î± Î¼Î¿ÏÏ†Î® Î³Î¹Î± Ï„Î·Î½ Î±Î½Î¬Ï€Ï„Ï…Î¾Î· Ï€Î¿ÏƒÎ¿Ï„Î¹ÎºÎ¿Ï€Î¿Î¹Î·Î¼Î­Î½Ï‰Î½ SLMs ÏƒÎµ CPU ÎºÎ±Î¹ ÏƒÏ…ÏƒÎºÎµÏ…Î­Ï‚ Î±Î¹Ï‡Î¼Î®Ï‚, ÎµÎ¹Î´Î¹ÎºÎ¬ Î²ÎµÎ»Ï„Î¹ÏƒÏ„Î¿Ï€Î¿Î¹Î·Î¼Î­Î½Î· Î³Î¹Î± Ï€ÏÎ±ÎºÏ„Î¿ÏÎ¹ÎºÎ­Ï‚ ÎµÏ†Î±ÏÎ¼Î¿Î³Î­Ï‚:

**Î§Î±ÏÎ±ÎºÏ„Î·ÏÎ¹ÏƒÏ„Î¹ÎºÎ¬ Î’ÎµÎ»Ï„Î¹ÏƒÏ„Î¿Ï€Î¿Î¹Î·Î¼Î­Î½Î± Î³Î¹Î± Î ÏÎ¬ÎºÏ„Î¿ÏÎµÏ‚**: Î— Î¼Î¿ÏÏ†Î® Ï€Î±ÏÎ­Ï‡ÎµÎ¹ Î¿Î»Î¿ÎºÎ»Î·ÏÏ‰Î¼Î­Î½Î¿Ï…Ï‚ Ï€ÏŒÏÎ¿Ï…Ï‚ Î³Î¹Î± Î¼ÎµÏ„Î±Ï„ÏÎ¿Ï€Î® ÎºÎ±Î¹ Î±Î½Î¬Ï€Ï„Ï…Î¾Î· SLM Î¼Îµ ÎµÎ½Î¹ÏƒÏ‡Ï…Î¼Î­Î½Î· Ï…Ï€Î¿ÏƒÏ„Î®ÏÎ¹Î¾Î· Î³Î¹Î± ÎºÎ»Î®ÏƒÎ· ÎµÏÎ³Î±Î»ÎµÎ¯Ï‰Î½, Î´Î·Î¼Î¹Î¿Ï…ÏÎ³Î¯Î± Î´Î¿Î¼Î·Î¼Î­Î½Ï‰Î½ ÎµÎ¾ÏŒÎ´Ï‰Î½ ÎºÎ±Î¹ ÏƒÏ…Î½Î¿Î¼Î¹Î»Î¯ÎµÏ‚ Ï€Î¿Î»Î»Î±Ï€Î»ÏŽÎ½ Î³ÏÏÏ‰Î½. Î— ÏƒÏ…Î¼Î²Î±Ï„ÏŒÏ„Î·Ï„Î± Î¼ÎµÏ„Î±Î¾Ï Ï€Î»Î±Ï„Ï†Î¿ÏÎ¼ÏŽÎ½ ÎµÎ¾Î±ÏƒÏ†Î±Î»Î¯Î¶ÎµÎ¹ ÏƒÏ…Î½ÎµÏ€Î® ÏƒÏ…Î¼Ï€ÎµÏÎ¹Ï†Î¿ÏÎ¬ Ï€ÏÎ±ÎºÏ„ÏŒÏÏ‰Î½ ÏƒÎµ Î´Î¹Î±Ï†Î¿ÏÎµÏ„Î¹ÎºÎ­Ï‚ ÏƒÏ…ÏƒÎºÎµÏ…Î­Ï‚ Î±Î¹Ï‡Î¼Î®Ï‚.

**Î’ÎµÎ»Ï„Î¹ÏƒÏ„Î¿Ï€Î¿Î¯Î·ÏƒÎ· Î‘Ï€ÏŒÎ´Î¿ÏƒÎ·Ï‚**: Î¤Î¿ GGUF ÎµÏ€Î¹Ï„ÏÎ­Ï€ÎµÎ¹ Î±Ï€Î¿Ï„ÎµÎ»ÎµÏƒÎ¼Î±Ï„Î¹ÎºÎ® Ï‡ÏÎ®ÏƒÎ· Î¼Î½Î®Î¼Î·Ï‚ Î³Î¹Î± ÏÎ¿Î­Ï‚ ÎµÏÎ³Î±ÏƒÎ¯Î±Ï‚ Ï€ÏÎ±ÎºÏ„ÏŒÏÏ‰Î½, Ï…Ï€Î¿ÏƒÏ„Î·ÏÎ¯Î¶ÎµÎ¹ Î´Ï…Î½Î±Î¼Î¹ÎºÎ® Ï†ÏŒÏÏ„Ï‰ÏƒÎ· Î¼Î¿Î½Ï„Î­Î»Ï‰Î½ Î³Î¹Î± ÏƒÏ…ÏƒÏ„Î®Î¼Î±Ï„Î± Ï€Î¿Î»Î»Î±Ï€Î»ÏŽÎ½ Ï€ÏÎ±ÎºÏ„ÏŒÏÏ‰Î½ ÎºÎ±Î¹ Ï€Î±ÏÎ­Ï‡ÎµÎ¹ Î²ÎµÎ»Ï„Î¹ÏƒÏ„Î¿Ï€Î¿Î¹Î·Î¼Î­Î½Î· ÎµÎ¾Î±Î³Ï‰Î³Î® Î³Î¹Î± Î±Î»Î»Î·Î»ÎµÏ€Î¹Î´ÏÎ¬ÏƒÎµÎ¹Ï‚ Ï€ÏÎ±ÎºÏ„ÏŒÏÏ‰Î½ ÏƒÎµ Ï€ÏÎ±Î³Î¼Î±Ï„Î¹ÎºÏŒ Ï‡ÏÏŒÎ½Î¿.

### Î Î»Î±Î¯ÏƒÎ¹Î± SLM Î’ÎµÎ»Ï„Î¹ÏƒÏ„Î¿Ï€Î¿Î¹Î·Î¼Î­Î½Î± Î³Î¹Î± Î‘Î¹Ï‡Î¼Î®

#### Î’ÎµÎ»Ï„Î¹ÏƒÏ„Î¿Ï€Î¿Î¯Î·ÏƒÎ· Llama.cpp Î³Î¹Î± Î ÏÎ¬ÎºÏ„Î¿ÏÎµÏ‚

Î¤Î¿ Llama.cpp Ï€Î±ÏÎ­Ï‡ÎµÎ¹ Ï€ÏÎ¿Î·Î³Î¼Î­Î½ÎµÏ‚ Ï„ÎµÏ‡Î½Î¹ÎºÎ­Ï‚ Ï€Î¿ÏƒÎ¿Ï„Î¹ÎºÎ¿Ï€Î¿Î¯Î·ÏƒÎ·Ï‚ ÎµÎ¹Î´Î¹ÎºÎ¬ Î²ÎµÎ»Ï„Î¹ÏƒÏ„Î¿Ï€Î¿Î¹Î·Î¼Î­Î½ÎµÏ‚ Î³Î¹Î± Î±Î½Î¬Ï€Ï„Ï…Î¾Î· Ï€ÏÎ±ÎºÏ„Î¿ÏÎ¹ÎºÏŽÎ½ SLM:

**Î Î¿ÏƒÎ¿Ï„Î¹ÎºÎ¿Ï€Î¿Î¯Î·ÏƒÎ· Î•Î¹Î´Î¹ÎºÎ® Î³Î¹Î± Î ÏÎ¬ÎºÏ„Î¿ÏÎµÏ‚**: Î¤Î¿ Ï€Î»Î±Î¯ÏƒÎ¹Î¿ Ï…Ï€Î¿ÏƒÏ„Î·ÏÎ¯Î¶ÎµÎ¹ Q4_0 (Î¹Î´Î±Î½Î¹ÎºÏŒ Î³Î¹Î± Î±Î½Î¬Ï€Ï„Ï…Î¾Î· Ï€ÏÎ±ÎºÏ„ÏŒÏÏ‰Î½ ÏƒÎµ ÎºÎ¹Î½Î·Ï„Î­Ï‚ ÏƒÏ…ÏƒÎºÎµÏ…Î­Ï‚ Î¼Îµ Î¼ÎµÎ¯Ï‰ÏƒÎ· Î¼ÎµÎ³Î­Î¸Î¿Ï…Ï‚ ÎºÎ±Ï„Î¬ 75%), Q5_1 (Î¹ÏƒÎ¿ÏÏÎ¿Ï€Î·Î¼Î­Î½Î· Ï€Î¿Î¹ÏŒÏ„Î·Ï„Î±-ÏƒÏ…Î¼Ï€Î¯ÎµÏƒÎ· Î³Î¹Î± Ï€ÏÎ±ÎºÏ„ÏŒÏÎµÏ‚ Î±Î¹Ï‡Î¼Î®Ï‚) ÎºÎ±Î¹ Q8_0 (ÏƒÏ‡ÎµÎ´ÏŒÎ½ Î±ÏÏ‡Î¹ÎºÎ® Ï€Î¿Î¹ÏŒÏ„Î·Ï„Î± Î³Î¹Î± ÏƒÏ…ÏƒÏ„Î®Î¼Î±Ï„Î± Ï€ÏÎ±ÎºÏ„ÏŒÏÏ‰Î½ Ï€Î±ÏÎ±Î³Ï‰Î³Î®Ï‚). Î ÏÎ¿Î·Î³Î¼Î­Î½ÎµÏ‚ Î¼Î¿ÏÏ†Î­Ï‚ ÎµÏ€Î¹Ï„ÏÎ­Ï€Î¿Ï…Î½ Ï…Ï€ÎµÏÏƒÏ…Î¼Ï€Î¹ÎµÏƒÎ¼Î­Î½Î¿Ï…Ï‚ Ï€ÏÎ¬ÎºÏ„Î¿ÏÎµÏ‚ Î³Î¹Î± Î±ÎºÏÎ±Î¯Î± ÏƒÎµÎ½Î¬ÏÎ¹Î± Î±Î¹Ï‡Î¼Î®Ï‚.

**ÎŸÏ†Î­Î»Î· Î¥Î»Î¿Ï€Î¿Î¯Î·ÏƒÎ·Ï‚**: Î— ÎµÎ¾Î±Î³Ï‰Î³Î® Î²ÎµÎ»Ï„Î¹ÏƒÏ„Î¿Ï€Î¿Î¹Î·Î¼Î­Î½Î· Î³Î¹Î± CPU Î¼Îµ ÎµÏ€Î¹Ï„Î¬Ï‡Ï…Î½ÏƒÎ· SIMD Ï€Î±ÏÎ­Ï‡ÎµÎ¹ Î±Ï€Î¿Î´Î¿Ï„Î¹ÎºÎ® ÎµÎºÏ„Î­Î»ÎµÏƒÎ· Ï€ÏÎ±ÎºÏ„ÏŒÏÏ‰Î½. Î— ÏƒÏ…Î¼Î²Î±Ï„ÏŒÏ„Î·Ï„Î± Î¼ÎµÏ„Î±Î¾Ï Ï€Î»Î±Ï„Ï†Î¿ÏÎ¼ÏŽÎ½ ÏƒÎµ Î±ÏÏ‡Î¹Ï„ÎµÎºÏ„Î¿Î½Î¹ÎºÎ­Ï‚ x86, ARM ÎºÎ±Î¹ Apple Silicon ÎµÏ€Î¹Ï„ÏÎ­Ï€ÎµÎ¹ ÎºÎ±Î¸Î¿Î»Î¹ÎºÎ­Ï‚ Î´Ï…Î½Î±Ï„ÏŒÏ„Î·Ï„ÎµÏ‚ Î±Î½Î¬Ï€Ï„Ï…Î¾Î·Ï‚ Ï€ÏÎ±ÎºÏ„ÏŒÏÏ‰Î½.

#### Î Î»Î±Î¯ÏƒÎ¹Î¿ Apple MLX Î³Î¹Î± Î ÏÎ¬ÎºÏ„Î¿ÏÎµÏ‚ SLM

Î¤Î¿ Apple MLX Ï€Î±ÏÎ­Ï‡ÎµÎ¹ ÎµÎ³Î³ÎµÎ½Î® Î²ÎµÎ»Ï„Î¹ÏƒÏ„Î¿Ï€Î¿Î¯Î·ÏƒÎ· ÎµÎ¹Î´Î¹ÎºÎ¬ ÏƒÏ‡ÎµÎ´Î¹Î±ÏƒÎ¼Î­Î½Î· Î³Î¹Î± Ï€ÏÎ¬ÎºÏ„Î¿ÏÎµÏ‚ Î¼Îµ SLM ÏƒÎµ ÏƒÏ…ÏƒÎºÎµÏ…Î­Ï‚ Apple Silicon:

**Î’ÎµÎ»Ï„Î¹ÏƒÏ„Î¿Ï€Î¿Î¯Î·ÏƒÎ· Î ÏÎ±ÎºÏ„ÏŒÏÏ‰Î½ Apple Silicon**: Î¤Î¿ Ï€Î»Î±Î¯ÏƒÎ¹Î¿ Ï‡ÏÎ·ÏƒÎ¹Î¼Î¿Ï€Î¿Î¹ÎµÎ¯ ÎµÎ½Î¿Ï€Î¿Î¹Î·Î¼Î­Î½Î· Î±ÏÏ‡Î¹Ï„ÎµÎºÏ„Î¿Î½Î¹ÎºÎ® Î¼Î½Î®Î¼Î·Ï‚ Î¼Îµ ÎµÎ½ÏƒÏ‰Î¼Î¬Ï„Ï‰ÏƒÎ· Metal Performance Shaders, Î±Ï…Ï„ÏŒÎ¼Î±Ï„Î· Î¼Î¹ÎºÏ„Î® Î±ÎºÏÎ¯Î²ÎµÎ¹Î± Î³Î¹Î± ÎµÎ¾Î±Î³Ï‰Î³Î® Ï€ÏÎ±ÎºÏ„ÏŒÏÏ‰Î½ ÎºÎ±Î¹ Î²ÎµÎ»Ï„Î¹ÏƒÏ„Î¿Ï€Î¿Î¹Î·Î¼Î­Î½Î¿ ÎµÏÏÎ¿Ï‚ Î¶ÏŽÎ½Î·Ï‚ Î¼Î½Î®Î¼Î·Ï‚ Î³Î¹Î± ÏƒÏ…ÏƒÏ„Î®Î¼Î±Ï„Î± Ï€Î¿Î»Î»Î±Ï€Î»ÏŽÎ½ Ï€ÏÎ±ÎºÏ„ÏŒÏÏ‰Î½. ÎŸÎ¹ Ï€ÏÎ¬ÎºÏ„Î¿ÏÎµÏ‚ SLM Ï€Î±ÏÎ¿Ï…ÏƒÎ¹Î¬Î¶Î¿Ï…Î½ ÎµÎ¾Î±Î¹ÏÎµÏ„Î¹ÎºÎ® Î±Ï€ÏŒÎ´Î¿ÏƒÎ· ÏƒÎµ Ï„ÏƒÎ¹Ï€ Ï„Î·Ï‚ ÏƒÎµÎ¹ÏÎ¬Ï‚ M.

**Î§Î±ÏÎ±ÎºÏ„Î·ÏÎ¹ÏƒÏ„Î¹ÎºÎ¬ Î‘Î½Î¬Ï€Ï„Ï…Î¾Î·Ï‚**: Î¥Ï€Î¿ÏƒÏ„Î®ÏÎ¹Î¾Î· API Python ÎºÎ±Î¹ Swift Î¼Îµ Î²ÎµÎ»Ï„Î¹ÏƒÏ„Î¿Ï€Î¿Î¹Î®ÏƒÎµÎ¹Ï‚ ÎµÎ¹Î´Î¹ÎºÎ­Ï‚ Î³Î¹Î± Ï€ÏÎ¬ÎºÏ„Î¿ÏÎµÏ‚, Î±Ï…Ï„ÏŒÎ¼Î±Ï„Î· Î´Î¹Î±Ï†Î¿ÏÎ¿Ï€Î¿Î¯Î·ÏƒÎ· Î³Î¹Î± Î¼Î¬Î¸Î·ÏƒÎ· Ï€ÏÎ±ÎºÏ„ÏŒÏÏ‰Î½ ÎºÎ±Î¹ Î±Ï€ÏÏŒÏƒÎºÎ¿Ï€Ï„Î· ÎµÎ½ÏƒÏ‰Î¼Î¬Ï„Ï‰ÏƒÎ· Î¼Îµ ÎµÏÎ³Î±Î»ÎµÎ¯Î± Î±Î½Î¬Ï€Ï„Ï…Î¾Î·Ï‚ Ï„Î·Ï‚ Apple Ï€Î±ÏÎ­Ï‡Î¿Ï…Î½ Î¿Î»Î¿ÎºÎ»Î·ÏÏ‰Î¼Î­Î½Î± Ï€ÎµÏÎ¹Î²Î¬Î»Î»Î¿Î½Ï„Î± Î±Î½Î¬Ï€Ï„Ï…Î¾Î·Ï‚ Ï€ÏÎ±ÎºÏ„ÏŒÏÏ‰Î½.

#### ONNX Runtime Î³Î¹Î± Î ÏÎ¬ÎºÏ„Î¿ÏÎµÏ‚ SLM Î Î¿Î»Î»Î±Ï€Î»ÏŽÎ½ Î Î»Î±Ï„Ï†Î¿ÏÎ¼ÏŽÎ½

Î¤Î¿ ONNX Runtime Ï€Î±ÏÎ­Ï‡ÎµÎ¹ Î¼Î¹Î± ÎºÎ±Î¸Î¿Î»Î¹ÎºÎ® Î¼Î·Ï‡Î±Î½Î® ÎµÎ¾Î±Î³Ï‰Î³Î®Ï‚ Ï€Î¿Ï… ÎµÏ€Î¹Ï„ÏÎ­Ï€ÎµÎ¹ ÏƒÏ„Î¿Ï…Ï‚ Ï€ÏÎ¬ÎºÏ„Î¿ÏÎµÏ‚ SLM Î½Î± Î»ÎµÎ¹Ï„Î¿Ï…ÏÎ³Î¿ÏÎ½ Î¼Îµ ÏƒÏ…Î½Î­Ï€ÎµÎ¹Î± ÏƒÎµ Î´Î¹Î¬Ï†Î¿ÏÎµÏ‚ Ï€Î»Î±Ï„Ï†ÏŒÏÎ¼ÎµÏ‚ Ï…Î»Î¹ÎºÎ¿Ï ÎºÎ±Î¹ Î»ÎµÎ¹Ï„Î¿Ï…ÏÎ³Î¹ÎºÎ¬ ÏƒÏ…ÏƒÏ„Î®Î¼Î±Ï„Î±:

**ÎšÎ±Î¸Î¿Î»Î¹ÎºÎ® Î‘Î½Î¬Ï€Ï„Ï…Î¾Î·**: Î¤Î¿ ONNX Runtime ÎµÎ¾Î±ÏƒÏ†Î±Î»Î¯Î¶ÎµÎ¹ ÏƒÏ…Î½ÎµÏ€Î® ÏƒÏ…Î¼Ï€ÎµÏÎ¹Ï†Î¿ÏÎ¬ Ï€ÏÎ±ÎºÏ„ÏŒÏÏ‰Î½ SLM ÏƒÎµ Ï€Î»Î±Ï„Ï†ÏŒÏÎ¼ÎµÏ‚ Windows, Linux, macOS, iOS ÎºÎ±Î¹ Android. Î‘Ï…Ï„Î® Î· ÏƒÏ…Î¼Î²Î±Ï„ÏŒÏ„Î·Ï„Î± Î¼ÎµÏ„Î±Î¾Ï Ï€Î»Î±Ï„Ï†Î¿ÏÎ¼ÏŽÎ½ ÎµÏ€Î¹Ï„ÏÎ­Ï€ÎµÎ¹ ÏƒÏ„Î¿Ï…Ï‚ Ï€ÏÎ¿Î³ÏÎ±Î¼Î¼Î±Ï„Î¹ÏƒÏ„Î­Ï‚ Î½Î± Î³ÏÎ¬Ï†Î¿Ï…Î½ Î¼Î¯Î± Ï†Î¿ÏÎ¬ ÎºÎ±Î¹ Î½Î± Î±Î½Î±Ï€Ï„ÏÏƒÏƒÎ¿Ï…Î½ Ï€Î±Î½Ï„Î¿Ï, Î¼ÎµÎ¹ÏŽÎ½Î¿Î½Ï„Î±Ï‚ ÏƒÎ·Î¼Î±Î½Ï„Î¹ÎºÎ¬ Ï„Î¿ ÎºÏŒÏƒÏ„Î¿Ï‚ Î±Î½Î¬Ï€Ï„Ï…Î¾Î·Ï‚ ÎºÎ±Î¹ ÏƒÏ…Î½Ï„Î®ÏÎ·ÏƒÎ·Ï‚ Î³Î¹Î± ÎµÏ†Î±ÏÎ¼Î¿Î³Î­Ï‚ Ï€Î¿Î»Î»Î±Ï€Î»ÏŽÎ½ Ï€Î»Î±Ï„Ï†Î¿ÏÎ¼ÏŽÎ½.

**Î•Ï€Î¹Î»Î¿Î³Î­Ï‚ Î•Ï€Î¹Ï„Î¬Ï‡Ï…Î½ÏƒÎ·Ï‚ Î¥Î»Î¹ÎºÎ¿Ï**: Î¤Î¿ Ï€Î»Î±Î¯ÏƒÎ¹Î¿ Ï€Î±ÏÎ­Ï‡ÎµÎ¹ Î²ÎµÎ»Ï„Î¹ÏƒÏ„Î¿Ï€Î¿Î¹Î·Î¼Î­Î½Î¿Ï…Ï‚ Ï€Î±ÏÏŒÏ‡Î¿Ï…Ï‚ ÎµÎ¾Î±Î³Ï‰Î³Î®Ï‚ Î³Î¹Î± Î´Î¹Î¬Ï†Î¿ÏÎµÏ‚ Î´Î¹Î±Î¼Î¿ÏÏ†ÏŽÏƒÎµÎ¹Ï‚ Ï…Î»Î¹ÎºÎ¿Ï, ÏƒÏ…Î¼Ï€ÎµÏÎ¹Î»Î±Î¼Î²Î±Î½Î¿Î¼Î­Î½Ï‰Î½ CPU (Intel, AMD, ARM), GPU (NVIDIA CUDA, AMD ROCm) ÎºÎ±Î¹ ÎµÎ¾ÎµÎ¹Î´Î¹ÎºÎµÏ…Î¼Î­Î½Ï‰Î½ ÎµÏ€Î¹Ï„Î±Ï‡Ï…Î½Ï„ÏŽÎ½ (Intel VPU, Qualcomm NPU). ÎŸÎ¹ Ï€ÏÎ¬ÎºÏ„Î¿ÏÎµÏ‚ SLM Î¼Ï€Î¿ÏÎ¿ÏÎ½ Î½Î± Î±Î¾Î¹Î¿Ï€Î¿Î¹Î®ÏƒÎ¿Ï…Î½ Î±Ï…Ï„ÏŒÎ¼Î±Ï„Î± Ï„Î¿ ÎºÎ±Î»ÏÏ„ÎµÏÎ¿ Î´Î¹Î±Î¸Î­ÏƒÎ¹Î¼Î¿ Ï…Î»Î¹ÎºÏŒ Ï‡Ï‰ÏÎ¯Ï‚ Î±Î»Î»Î±Î³Î­Ï‚ ÏƒÏ„Î¿Î½ ÎºÏŽÎ´Î¹ÎºÎ±.

**Î§Î±ÏÎ±ÎºÏ„Î·ÏÎ¹ÏƒÏ„Î¹ÎºÎ¬ ÎˆÏ„Î¿Î¹Î¼Î± Î³Î¹Î± Î Î±ÏÎ±Î³Ï‰Î³Î®**: Î¤Î¿ ONNX Runtime Ï€ÏÎ¿ÏƒÏ†Î­ÏÎµÎ¹ Ï‡Î±ÏÎ±ÎºÏ„Î·ÏÎ¹ÏƒÏ„Î¹ÎºÎ¬ ÎµÏ€Î¹Ï‡ÎµÎ¹ÏÎ·Î¼Î±Ï„Î¹ÎºÎ®Ï‚ ÎºÎ»Î¬ÏƒÎ·Ï‚ Î±Ï€Î±ÏÎ±Î¯Ï„Î·Ï„Î± Î³Î¹Î± Î±Î½Î¬Ï€Ï„Ï…Î¾Î· Ï€ÏÎ±ÎºÏ„ÏŒÏÏ‰Î½ Ï€Î±ÏÎ±Î³Ï‰Î³Î®Ï‚, ÏŒÏ€Ï‰Ï‚ Î²ÎµÎ»Ï„Î¹ÏƒÏ„Î¿Ï€Î¿Î¯Î·ÏƒÎ· Î³ÏÎ±Ï†Î·Î¼Î¬Ï„Ï‰Î½ Î³Î¹Î± Ï„Î±Ï‡ÏÏ„ÎµÏÎ· ÎµÎ¾Î±Î³Ï‰Î³Î®, Î´Î¹Î±Ï‡ÎµÎ¯ÏÎ¹ÏƒÎ· Î¼Î½Î®Î¼Î·Ï‚ Î³Î¹Î± Ï€ÎµÏÎ¹Î²Î¬Î»Î»Î¿Î½Ï„Î± Î¼Îµ Ï€ÎµÏÎ¹Î¿ÏÎ¹ÏƒÎ¼Î­Î½Î¿Ï…Ï‚ Ï€ÏŒÏÎ¿Ï…Ï‚ ÎºÎ±Î¹ Î¿Î»Î¿ÎºÎ»Î·ÏÏ‰Î¼Î­Î½Î± ÎµÏÎ³Î±Î»ÎµÎ¯Î± Ï€ÏÎ¿Ï†Î¯Î» Î³Î¹Î± Î±Î½Î¬Î»Ï…ÏƒÎ· Î±Ï€ÏŒÎ´Î¿ÏƒÎ·Ï‚. Î¤Î¿ Ï€Î»Î±Î¯ÏƒÎ¹Î¿ Ï…Ï€Î¿ÏƒÏ„Î·ÏÎ¯Î¶ÎµÎ¹ API Python ÎºÎ±Î¹ C++ Î³Î¹Î± ÎµÏ…Î­Î»Î¹ÎºÏ„Î· ÎµÎ½ÏƒÏ‰Î¼Î¬Ï„Ï‰ÏƒÎ·.
- Î”Î¿ÎºÎ¹Î¼Î® ÎµÎ½ÏƒÏ‰Î¼Î¬Ï„Ï‰ÏƒÎ·Ï‚ Ï„Î¿Ï… Microsoft Agent Framework  
- Î•Ï€Î±Î»Î®Î¸ÎµÏ…ÏƒÎ· Î´Ï…Î½Î±Ï„Î¿Ï„Î®Ï„Ï‰Î½ Î»ÎµÎ¹Ï„Î¿Ï…ÏÎ³Î¯Î±Ï‚ ÎµÎºÏ„ÏŒÏ‚ ÏƒÏÎ½Î´ÎµÏƒÎ·Ï‚  
- Î”Î¿ÎºÎ¹Î¼Î® ÏƒÎµÎ½Î±ÏÎ¯Ï‰Î½ Î±Ï€Î¿Ï„Ï…Ï‡Î¯Î±Ï‚ ÎºÎ±Î¹ Î´Î¹Î±Ï‡ÎµÎ¯ÏÎ¹ÏƒÎ·Ï‚ ÏƒÏ†Î±Î»Î¼Î¬Ï„Ï‰Î½  
- Î•Ï€Î¹ÎºÏÏÏ‰ÏƒÎ· ÏÎ¿ÏŽÎ½ ÎµÏÎ³Î±ÏƒÎ¯Î±Ï‚ Ï€ÏÎ±ÎºÏ„ÏŒÏÏ‰Î½ Î±Ï€ÏŒ Î¬ÎºÏÎ¿ ÏƒÎµ Î¬ÎºÏÎ¿  

**Î£ÏÎ³ÎºÏÎ¹ÏƒÎ· Î¼Îµ Ï„Î¿ Foundry Local**:

| Î§Î±ÏÎ±ÎºÏ„Î·ÏÎ¹ÏƒÏ„Î¹ÎºÏŒ | Foundry Local | Ollama |
|----------------|---------------|--------|
| **Î ÏÎ¿Ï„ÎµÎ¹Î½ÏŒÎ¼ÎµÎ½Î· Î§ÏÎ®ÏƒÎ·** | Î Î±ÏÎ±Î³Ï‰Î³Î® Î³Î¹Î± ÎµÏ€Î¹Ï‡ÎµÎ¹ÏÎ®ÏƒÎµÎ¹Ï‚ | Î‘Î½Î¬Ï€Ï„Ï…Î¾Î· & ÎºÎ¿Î¹Î½ÏŒÏ„Î·Ï„Î± |
| **ÎŸÎ¹ÎºÎ¿ÏƒÏÏƒÏ„Î·Î¼Î± ÎœÎ¿Î½Ï„Î­Î»Ï‰Î½** | Î•Ï€Î¹Î»Î¿Î³Î® Î±Ï€ÏŒ Ï„Î· Microsoft | Î•ÎºÏ„ÎµÏ„Î±Î¼Î­Î½Î· ÎºÎ¿Î¹Î½ÏŒÏ„Î·Ï„Î± |
| **Î’ÎµÎ»Ï„Î¹ÏƒÏ„Î¿Ï€Î¿Î¯Î·ÏƒÎ· Î¥Î»Î¹ÎºÎ¿Ï** | Î‘Ï…Ï„ÏŒÎ¼Î±Ï„Î· (CUDA/NPU/CPU) | Î§ÎµÎ¹ÏÎ¿ÎºÎ¯Î½Î·Ï„Î· ÏÏÎ¸Î¼Î¹ÏƒÎ· |
| **Î§Î±ÏÎ±ÎºÏ„Î·ÏÎ¹ÏƒÏ„Î¹ÎºÎ¬ Î•Ï€Î¹Ï‡ÎµÎ¹ÏÎ®ÏƒÎµÏ‰Î½** | Î•Î½ÏƒÏ‰Î¼Î±Ï„Ï‰Î¼Î­Î½Î· Ï€Î±ÏÎ±ÎºÎ¿Î»Î¿ÏÎ¸Î·ÏƒÎ·, Î±ÏƒÏ†Î¬Î»ÎµÎ¹Î± | Î•ÏÎ³Î±Î»ÎµÎ¯Î± ÎºÎ¿Î¹Î½ÏŒÏ„Î·Ï„Î±Ï‚ |
| **Î Î¿Î»Ï…Ï€Î»Î¿ÎºÏŒÏ„Î·Ï„Î± Î‘Î½Î¬Ï€Ï„Ï…Î¾Î·Ï‚** | Î‘Ï€Î»Î® (winget install) | Î‘Ï€Î»Î® (curl install) |
| **Î£Ï…Î¼Î²Î±Ï„ÏŒÏ„Î·Ï„Î± API** | OpenAI + ÎµÏ€ÎµÎºÏ„Î¬ÏƒÎµÎ¹Ï‚ | Î ÏÏŒÏ„Ï…Ï€Î¿ OpenAI |
| **Î¥Ï€Î¿ÏƒÏ„Î®ÏÎ¹Î¾Î·** | Î•Ï€Î¯ÏƒÎ·Î¼Î· Microsoft | ÎšÎ¿Î¹Î½ÏŒÏ„Î·Ï„Î± |
| **Î™Î´Î±Î½Î¹ÎºÏŒ Î“Î¹Î±** | Î ÏÎ¬ÎºÏ„Î¿ÏÎµÏ‚ Ï€Î±ÏÎ±Î³Ï‰Î³Î®Ï‚ | Î ÏÏ‰Ï„ÏŒÏ„Ï…Ï€Î±, Î­ÏÎµÏ…Î½Î± |

**Î ÏŒÏ„Îµ Î½Î± ÎµÏ€Î¹Î»Î­Î¾ÎµÏ„Îµ Ï„Î¿ Ollama**:  
- **Î‘Î½Î¬Ï€Ï„Ï…Î¾Î· ÎºÎ±Î¹ Î ÏÏ‰Ï„ÏŒÏ„Ï…Ï€Î±**: Î“ÏÎ®Î³Î¿ÏÎ· Ï€ÎµÎ¹ÏÎ±Î¼Î±Ï„Î¹ÎºÎ® ÎµÏÎ³Î±ÏƒÎ¯Î± Î¼Îµ Î´Î¹Î±Ï†Î¿ÏÎµÏ„Î¹ÎºÎ¬ Î¼Î¿Î½Ï„Î­Î»Î±  
- **ÎœÎ¿Î½Ï„Î­Î»Î± ÎšÎ¿Î¹Î½ÏŒÏ„Î·Ï„Î±Ï‚**: Î ÏÏŒÏƒÎ²Î±ÏƒÎ· ÏƒÏ„Î± Ï€Î¹Î¿ Ï€ÏÏŒÏƒÏ†Î±Ï„Î± Î¼Î¿Î½Ï„Î­Î»Î± Ï€Î¿Ï… ÏƒÏ…Î½ÎµÎ¹ÏƒÏ†Î­ÏÎµÎ¹ Î· ÎºÎ¿Î¹Î½ÏŒÏ„Î·Ï„Î±  
- **Î•ÎºÏ€Î±Î¹Î´ÎµÏ…Ï„Î¹ÎºÎ® Î§ÏÎ®ÏƒÎ·**: ÎœÎ¬Î¸Î·ÏƒÎ· ÎºÎ±Î¹ Î´Î¹Î´Î±ÏƒÎºÎ±Î»Î¯Î± Î±Î½Î¬Ï€Ï„Ï…Î¾Î·Ï‚ Ï€ÏÎ±ÎºÏ„ÏŒÏÏ‰Î½ AI  
- **Î•ÏÎµÏ…Î½Î·Ï„Î¹ÎºÎ¬ ÎˆÏÎ³Î±**: Î‘ÎºÎ±Î´Î·Î¼Î±ÏŠÎºÎ® Î­ÏÎµÏ…Î½Î± Ï€Î¿Ï… Î±Ï€Î±Î¹Ï„ÎµÎ¯ Ï€ÏÏŒÏƒÎ²Î±ÏƒÎ· ÏƒÎµ Ï€Î¿Î¹ÎºÎ¯Î»Î± Î¼Î¿Î½Ï„Î­Î»Î±  
- **Î ÏÎ¿ÏƒÎ±ÏÎ¼Î¿ÏƒÎ¼Î­Î½Î± ÎœÎ¿Î½Ï„Î­Î»Î±**: Î”Î·Î¼Î¹Î¿Ï…ÏÎ³Î¯Î± ÎºÎ±Î¹ Î´Î¿ÎºÎ¹Î¼Î® Ï€ÏÎ¿ÏƒÎ±ÏÎ¼Î¿ÏƒÎ¼Î­Î½Ï‰Î½ Î¼Î¿Î½Ï„Î­Î»Ï‰Î½  

### VLLM: Î¥ÏˆÎ·Î»Î®Ï‚ Î‘Ï€ÏŒÎ´Î¿ÏƒÎ·Ï‚ Î•Ï€ÎµÎ¾ÎµÏÎ³Î±ÏƒÎ¯Î± Î ÏÎ±ÎºÏ„ÏŒÏÏ‰Î½ SLM  

Î¤Î¿ VLLM (Very Large Language Model inference) Ï€Î±ÏÎ­Ï‡ÎµÎ¹ Î¼Î¹Î± Î¼Î·Ï‡Î±Î½Î® ÎµÏ€ÎµÎ¾ÎµÏÎ³Î±ÏƒÎ¯Î±Ï‚ Ï…ÏˆÎ·Î»Î®Ï‚ Î±Ï€ÏŒÎ´Î¿ÏƒÎ·Ï‚ ÎºÎ±Î¹ Î±Ï€Î¿Î´Î¿Ï„Î¹ÎºÎ®Ï‚ Î¼Î½Î®Î¼Î·Ï‚, ÎµÎ¹Î´Î¹ÎºÎ¬ Î²ÎµÎ»Ï„Î¹ÏƒÏ„Î¿Ï€Î¿Î¹Î·Î¼Î­Î½Î· Î³Î¹Î± Ï€Î±ÏÎ±Î³Ï‰Î³Î¹ÎºÎ­Ï‚ Î±Î½Î±Ï€Ï„ÏÎ¾ÎµÎ¹Ï‚ SLM Î¼ÎµÎ³Î¬Î»Î·Ï‚ ÎºÎ»Î¯Î¼Î±ÎºÎ±Ï‚. Î•Î½ÏŽ Ï„Î¿ Foundry Local ÎµÏ€Î¹ÎºÎµÎ½Ï„ÏÏŽÎ½ÎµÏ„Î±Î¹ ÏƒÏ„Î·Î½ ÎµÏ…ÎºÎ¿Î»Î¯Î± Ï‡ÏÎ®ÏƒÎ·Ï‚ ÎºÎ±Î¹ Ï„Î¿ Ollama Î´Î¯Î½ÎµÎ¹ Î­Î¼Ï†Î±ÏƒÎ· ÏƒÏ„Î± Î¼Î¿Î½Ï„Î­Î»Î± ÎºÎ¿Î¹Î½ÏŒÏ„Î·Ï„Î±Ï‚, Ï„Î¿ VLLM Î´Î¹Î±Ï€ÏÎ­Ï€ÎµÎ¹ ÏƒÎµ ÏƒÎµÎ½Î¬ÏÎ¹Î± Ï…ÏˆÎ·Î»Î®Ï‚ Î±Ï€ÏŒÎ´Î¿ÏƒÎ·Ï‚ Ï€Î¿Ï… Î±Ï€Î±Î¹Ï„Î¿ÏÎ½ Î¼Î­Î³Î¹ÏƒÏ„Î· Ï„Î±Ï‡ÏÏ„Î·Ï„Î± ÎºÎ±Î¹ Î±Ï€Î¿Î´Î¿Ï„Î¹ÎºÎ® Ï‡ÏÎ®ÏƒÎ· Ï€ÏŒÏÏ‰Î½.  

**Î’Î±ÏƒÎ¹ÎºÎ® Î‘ÏÏ‡Î¹Ï„ÎµÎºÏ„Î¿Î½Î¹ÎºÎ® ÎºÎ±Î¹ Î§Î±ÏÎ±ÎºÏ„Î·ÏÎ¹ÏƒÏ„Î¹ÎºÎ¬**:  
- **PagedAttention**: Î•Ï€Î±Î½Î±ÏƒÏ„Î±Ï„Î¹ÎºÎ® Î´Î¹Î±Ï‡ÎµÎ¯ÏÎ¹ÏƒÎ· Î¼Î½Î®Î¼Î·Ï‚ Î³Î¹Î± Î±Ï€Î¿Î´Î¿Ï„Î¹ÎºÎ¿ÏÏ‚ Ï…Ï€Î¿Î»Î¿Î³Î¹ÏƒÎ¼Î¿ÏÏ‚ Ï€ÏÎ¿ÏƒÎ¿Ï‡Î®Ï‚  
- **Dynamic Batching**: ÎˆÎ¾Ï…Ï€Î½Î· Î¿Î¼Î±Î´Î¿Ï€Î¿Î¯Î·ÏƒÎ· Î±Î¹Ï„Î·Î¼Î¬Ï„Ï‰Î½ Î³Î¹Î± Î²Î­Î»Ï„Î¹ÏƒÏ„Î· Î±Ï€ÏŒÎ´Î¿ÏƒÎ·  
- **Î’ÎµÎ»Ï„Î¹ÏƒÏ„Î¿Ï€Î¿Î¯Î·ÏƒÎ· GPU**: Î ÏÎ¿Î·Î³Î¼Î­Î½Î¿Î¹ Ï€Ï…ÏÎ®Î½ÎµÏ‚ CUDA ÎºÎ±Î¹ Ï…Ï€Î¿ÏƒÏ„Î®ÏÎ¹Î¾Î· Ï€Î±ÏÎ¬Î»Î»Î·Î»Î·Ï‚ ÎµÏ€ÎµÎ¾ÎµÏÎ³Î±ÏƒÎ¯Î±Ï‚ tensor  
- **Î£Ï…Î¼Î²Î±Ï„ÏŒÏ„Î·Ï„Î± OpenAI**: Î Î»Î®ÏÎ·Ï‚ ÏƒÏ…Î¼Î²Î±Ï„ÏŒÏ„Î·Ï„Î± API Î³Î¹Î± Î±Ï€ÏÏŒÏƒÎºÎ¿Ï€Ï„Î· ÎµÎ½ÏƒÏ‰Î¼Î¬Ï„Ï‰ÏƒÎ·  
- **Speculative Decoding**: Î ÏÎ¿Î·Î³Î¼Î­Î½ÎµÏ‚ Ï„ÎµÏ‡Î½Î¹ÎºÎ­Ï‚ ÎµÏ€Î¹Ï„Î¬Ï‡Ï…Î½ÏƒÎ·Ï‚ ÎµÏ€ÎµÎ¾ÎµÏÎ³Î±ÏƒÎ¯Î±Ï‚  
- **Î¥Ï€Î¿ÏƒÏ„Î®ÏÎ¹Î¾Î· Î Î¿ÏƒÎ¿Ï„Î¹ÎºÎ¿Ï€Î¿Î¯Î·ÏƒÎ·Ï‚**: Î Î¿ÏƒÎ¿Ï„Î¹ÎºÎ¿Ï€Î¿Î¯Î·ÏƒÎ· INT4, INT8 ÎºÎ±Î¹ FP16 Î³Î¹Î± Î±Ï€Î¿Î´Î¿Ï„Î¹ÎºÏŒÏ„Î·Ï„Î± Î¼Î½Î®Î¼Î·Ï‚  

#### Î•Î³ÎºÎ±Ï„Î¬ÏƒÏ„Î±ÏƒÎ· ÎºÎ±Î¹ Î¡ÏÎ¸Î¼Î¹ÏƒÎ·  

**Î•Ï€Î¹Î»Î¿Î³Î­Ï‚ Î•Î³ÎºÎ±Ï„Î¬ÏƒÏ„Î±ÏƒÎ·Ï‚**:  
```bash
# Standard installation
pip install vllm

# With additional dependencies for agent frameworks
pip install vllm[agent] openai

# Docker deployment for production
docker pull vllm/vllm-openai:latest

# From source for latest features
git clone https://github.com/vllm-project/vllm.git
cd vllm
pip install -e .
```
  
**Î“ÏÎ®Î³Î¿ÏÎ· ÎˆÎ½Î±ÏÎ¾Î· Î³Î¹Î± Î‘Î½Î¬Ï€Ï„Ï…Î¾Î· Î ÏÎ±ÎºÏ„ÏŒÏÏ‰Î½**:  
```bash
# Start VLLM server with SLM model
python -m vllm.entrypoints.openai.api_server \
    --model microsoft/Phi-3.5-mini-instruct \
    --trust-remote-code \
    --max-model-len 4096 \
    --gpu-memory-utilization 0.8

# Alternative: Start with Qwen2.5 for lightweight agents
python -m vllm.entrypoints.openai.api_server \
    --model Qwen/Qwen2.5-0.5B-Instruct \
    --trust-remote-code \
    --max-model-len 2048 \
    --tensor-parallel-size 1

# Test API endpoint
curl http://localhost:8000/v1/models

# Test chat completion
curl http://localhost:8000/v1/chat/completions \
    -H "Content-Type: application/json" \
    -d '{
        "model": "microsoft/Phi-3.5-mini-instruct",
        "messages": [{"role": "user", "content": "Hello!"}]
    }'
```
  

#### Î•Î½ÏƒÏ‰Î¼Î¬Ï„Ï‰ÏƒÎ· Î Î»Î±Î¹ÏƒÎ¯Î¿Ï… Î ÏÎ±ÎºÏ„ÏŒÏÏ‰Î½  

**VLLM Î¼Îµ Ï„Î¿ Microsoft Agent Framework**:  
```python
from microsoft_agent_framework import Agent, Config
import openai
import subprocess
import time
import requests
from typing import Optional, Dict, Any

class VLLMManager:
    def __init__(self, model_name: str, 
                 host: str = "localhost", 
                 port: int = 8000,
                 gpu_memory_utilization: float = 0.8,
                 max_model_len: int = 4096):
        self.model_name = model_name
        self.host = host
        self.port = port
        self.base_url = f"http://{host}:{port}"
        self.gpu_memory_utilization = gpu_memory_utilization
        self.max_model_len = max_model_len
        self.process = None
        self.client = None
        
    def start_server(self) -> bool:
        """Start VLLM server with optimized settings for agents."""
        try:
            cmd = [
                "python", "-m", "vllm.entrypoints.openai.api_server",
                "--model", self.model_name,
                "--host", self.host,
                "--port", str(self.port),
                "--gpu-memory-utilization", str(self.gpu_memory_utilization),
                "--max-model-len", str(self.max_model_len),
                "--trust-remote-code",
                "--disable-log-requests",  # Reduce logging for agents
                "--served-model-name", self.get_served_model_name()
            ]
            
            self.process = subprocess.Popen(cmd, 
                stdout=subprocess.PIPE, 
                stderr=subprocess.PIPE)
            
            # Wait for server to start
            max_retries = 30
            for _ in range(max_retries):
                if self.health_check():
                    self.client = openai.OpenAI(base_url=f"{self.base_url}/v1")
                    return True
                time.sleep(2)
                
            return False
            
        except Exception as e:
            print(f"Failed to start VLLM server: {e}")
            return False
    
    def get_served_model_name(self) -> str:
        """Get a clean model name for serving."""
        return self.model_name.replace("/", "--")
    
    def health_check(self) -> bool:
        """Check if VLLM server is healthy."""
        try:
            response = requests.get(f"{self.base_url}/health", timeout=5)
            return response.status_code == 200
        except:
            return False
    
    def get_openai_client(self) -> openai.OpenAI:
        """Get OpenAI-compatible client for VLLM."""
        if not self.client:
            self.client = openai.OpenAI(base_url=f"{self.base_url}/v1")
        return self.client
    
    def get_model_info(self) -> Dict[str, Any]:
        """Get model information and statistics."""
        try:
            response = requests.get(f"{self.base_url}/v1/models")
            if response.status_code == 200:
                return response.json()
        except:
            pass
        return {}
    
    def shutdown(self):
        """Shutdown VLLM server."""
        if self.process:
            self.process.terminate()
            self.process.wait()

# Initialize VLLM for high-performance agents
vllm_manager = VLLMManager("microsoft/Phi-3.5-mini-instruct")
if vllm_manager.start_server():
    print("VLLM server started successfully")
    
    # Configure agent with VLLM backend
    agent_config = Config(
        name="vllm-performance-agent",
        model_provider="vllm",
        model_id=vllm_manager.get_served_model_name(),
        endpoint=f"{vllm_manager.base_url}/v1",
        api_key="none"  # VLLM doesn't require API key
    )
    
    agent = Agent(config=agent_config)
else:
    print("Failed to start VLLM server")
```
  
**Î¡ÏÎ¸Î¼Î¹ÏƒÎ· Î Î¿Î»Î»Î±Ï€Î»ÏŽÎ½ Î ÏÎ±ÎºÏ„ÏŒÏÏ‰Î½ Î¥ÏˆÎ·Î»Î®Ï‚ Î‘Ï€ÏŒÎ´Î¿ÏƒÎ·Ï‚**:  
```python
import asyncio
from concurrent.futures import ThreadPoolExecutor
from microsoft_agent_framework import Agent, Config
import openai

class VLLMHighThroughputManager:
    def __init__(self):
        self.model_configs = {
            "lightweight": {
                "model": "Qwen/Qwen2.5-0.5B-Instruct",
                "port": 8000,
                "max_model_len": 2048,
                "gpu_memory_utilization": 0.3
            },
            "balanced": {
                "model": "microsoft/Phi-3.5-mini-instruct",
                "port": 8001,
                "max_model_len": 4096,
                "gpu_memory_utilization": 0.5
            },
            "capable": {
                "model": "meta-llama/Llama-3.2-3B-Instruct",
                "port": 8002,
                "max_model_len": 8192,
                "gpu_memory_utilization": 0.7
            }
        }
        self.managers = {}
        self.agents = {}
        self.client_pool = {}
        
    async def initialize_all_models(self):
        """Initialize all VLLM models in parallel."""
        initialization_tasks = []
        
        for category, config in self.model_configs.items():
            task = self._initialize_model(category, config)
            initialization_tasks.append(task)
        
        results = await asyncio.gather(*initialization_tasks, return_exceptions=True)
        
        successful_inits = 0
        for i, result in enumerate(results):
            category = list(self.model_configs.keys())[i]
            if isinstance(result, Exception):
                print(f"Failed to initialize {category}: {result}")
            else:
                successful_inits += 1
                print(f"Successfully initialized {category} model")
        
        return successful_inits
    
    async def _initialize_model(self, category: str, config: Dict[str, Any]):
        """Initialize a single VLLM model instance."""
        manager = VLLMManager(
            model_name=config["model"],
            port=config["port"],
            max_model_len=config["max_model_len"],
            gpu_memory_utilization=config["gpu_memory_utilization"]
        )
        
        # Start server in thread to avoid blocking
        loop = asyncio.get_event_loop()
        with ThreadPoolExecutor() as executor:
            success = await loop.run_in_executor(executor, manager.start_server)
        
        if success:
            self.managers[category] = manager
            
            # Create agent
            agent_config = Config(
                name=f"vllm-{category}-agent",
                model_provider="vllm",
                model_id=manager.get_served_model_name(),
                endpoint=f"{manager.base_url}/v1",
                api_key="none"
            )
            
            self.agents[category] = Agent(config=agent_config)
            
            # Create client pool for high throughput
            self.client_pool[category] = [
                openai.OpenAI(base_url=f"{manager.base_url}/v1")
                for _ in range(5)  # 5 clients per model for parallelism
            ]
            
            return True
        else:
            raise Exception(f"Failed to start VLLM server for {category}")
    
    def get_optimal_agent(self, request_complexity: str, current_load: Dict[str, int]) -> str:
        """Select optimal agent based on request complexity and current load."""
        complexity_mapping = {
            "simple": "lightweight",
            "moderate": "balanced", 
            "complex": "capable"
        }
        
        preferred_category = complexity_mapping.get(request_complexity, "balanced")
        
        # Check if preferred agent is available and not overloaded
        if (preferred_category in self.agents and 
            current_load.get(preferred_category, 0) < 10):  # Max 10 concurrent per agent
            return preferred_category
        
        # Fallback to least loaded available agent
        available_agents = [(cat, load) for cat, load in current_load.items() 
                          if cat in self.agents and load < 10]
        
        if available_agents:
            return min(available_agents, key=lambda x: x[1])[0]
        
        return "balanced"  # Default fallback
    
    async def process_batch_requests(self, requests: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """Process multiple requests in parallel for maximum throughput."""
        current_load = {cat: 0 for cat in self.agents.keys()}
        tasks = []
        
        for request in requests:
            # Determine optimal agent
            complexity = request.get("complexity", "moderate")
            agent_category = self.get_optimal_agent(complexity, current_load)
            current_load[agent_category] += 1
            
            # Create processing task
            task = self._process_single_request(request, agent_category)
            tasks.append(task)
        
        # Process all requests in parallel
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # Format results
        formatted_results = []
        for i, result in enumerate(results):
            if isinstance(result, Exception):
                formatted_results.append({
                    "request_id": requests[i].get("id", i),
                    "status": "error",
                    "error": str(result)
                })
            else:
                formatted_results.append(result)
        
        return formatted_results
    
    async def _process_single_request(self, request: Dict[str, Any], agent_category: str) -> Dict[str, Any]:
        """Process a single request with the specified agent."""
        start_time = time.time()
        
        try:
            agent = self.agents[agent_category]
            response = await agent.chat_async(request["message"])
            
            processing_time = time.time() - start_time
            
            return {
                "request_id": request.get("id"),
                "status": "success",
                "response": response,
                "agent_used": agent_category,
                "processing_time": processing_time
            }
            
        except Exception as e:
            return {
                "request_id": request.get("id"),
                "status": "error",
                "error": str(e),
                "agent_used": agent_category,
                "processing_time": time.time() - start_time
            }

# High-throughput usage example
throughput_manager = VLLMHighThroughputManager()

# Initialize all models
initialized_count = await throughput_manager.initialize_all_models()
print(f"Initialized {initialized_count} models")

# Process batch requests
batch_requests = [
    {"id": 1, "message": "Simple question", "complexity": "simple"},
    {"id": 2, "message": "Complex analysis needed", "complexity": "complex"},
    {"id": 3, "message": "Moderate difficulty task", "complexity": "moderate"}
]

results = await throughput_manager.process_batch_requests(batch_requests)
for result in results:
    print(f"Request {result['request_id']}: {result['status']} in {result.get('processing_time', 0):.2f}s")
```
  

#### ÎœÎ¿Ï„Î¯Î²Î± Î‘Î½Î¬Ï€Ï„Ï…Î¾Î·Ï‚ Î Î±ÏÎ±Î³Ï‰Î³Î®Ï‚  

**Î¥Ï€Î·ÏÎµÏƒÎ¯Î± Î Î±ÏÎ±Î³Ï‰Î³Î®Ï‚ VLLM Î³Î¹Î± Î•Ï€Î¹Ï‡ÎµÎ¹ÏÎ®ÏƒÎµÎ¹Ï‚**:  
```python
import asyncio
import logging
import time
from typing import Dict, List, Optional
from dataclasses import dataclass
from microsoft_agent_framework import Agent, Config
import uvicorn
from fastapi import FastAPI, HTTPException, BackgroundTasks
from pydantic import BaseModel

@dataclass
class VLLMServerConfig:
    model_name: str
    port: int
    gpu_memory_utilization: float
    max_model_len: int
    tensor_parallel_size: int = 1
    quantization: Optional[str] = None

class AgentRequest(BaseModel):
    message: str
    agent_type: str = "general"
    priority: str = "normal"
    timeout: int = 30

class VLLMProductionService:
    def __init__(self, server_configs: Dict[str, VLLMServerConfig]):
        self.server_configs = server_configs
        self.managers = {}
        self.agents = {}
        self.metrics = {
            "requests_processed": 0,
            "requests_failed": 0,
            "total_processing_time": 0,
            "agent_usage": {name: 0 for name in server_configs.keys()},
            "throughput_per_minute": 0
        }
        self.request_queue = asyncio.Queue(maxsize=1000)
        self.processing_workers = []
        self.app = FastAPI(title="VLLM Agent Service")
        self._setup_routes()
        
    async def initialize_production_environment(self):
        """Initialize all VLLM servers for production."""
        logging.info("Initializing VLLM production environment...")
        
        initialization_tasks = []
        for name, config in self.server_configs.items():
            task = self._initialize_server(name, config)
            initialization_tasks.append(task)
        
        results = await asyncio.gather(*initialization_tasks, return_exceptions=True)
        
        successful_servers = 0
        for i, result in enumerate(results):
            server_name = list(self.server_configs.keys())[i]
            if isinstance(result, Exception):
                logging.error(f"Failed to initialize {server_name}: {result}")
            else:
                successful_servers += 1
                logging.info(f"Successfully initialized {server_name}")
        
        if successful_servers == 0:
            raise Exception("No VLLM servers could be initialized")
        
        # Start processing workers
        self.processing_workers = [
            asyncio.create_task(self._processing_worker(i))
            for i in range(min(4, successful_servers))  # 4 workers max
        ]
        
        logging.info(f"Production environment ready with {successful_servers} servers")
        return successful_servers
    
    async def _initialize_server(self, name: str, config: VLLMServerConfig):
        """Initialize a single VLLM server."""
        manager = VLLMManager(
            model_name=config.model_name,
            port=config.port,
            gpu_memory_utilization=config.gpu_memory_utilization,
            max_model_len=config.max_model_len
        )
        
        # Add quantization if specified
        if config.quantization:
            # This would be added to the manager's start command
            pass
        
        success = manager.start_server()
        if success:
            self.managers[name] = manager
            
            # Create production agent
            agent_config = Config(
                name=f"vllm-production-{name}",
                model_provider="vllm",
                model_id=manager.get_served_model_name(),
                endpoint=f"{manager.base_url}/v1",
                api_key="none",
                timeout=30.0
            )
            
            agent = Agent(config=agent_config)
            
            # Add production tools
            self._add_production_tools(agent, name)
            
            self.agents[name] = agent
            return True
        else:
            raise Exception(f"Failed to start VLLM server for {name}")
    
    def _add_production_tools(self, agent: Agent, server_type: str):
        """Add production tools based on server type."""
        if server_type == "customer_service":
            @agent.tool
            def escalate_to_human(issue: str, customer_id: str) -> str:
                """Escalate complex issues to human agents."""
                return f"Escalated issue for customer {customer_id}: {issue}"
            
            @agent.tool
            def lookup_order_status(order_id: str) -> dict:
                """Look up order status from production database."""
                # Production database lookup
                return {"order_id": order_id, "status": "shipped", "eta": "2 days"}
        
        elif server_type == "technical_support":
            @agent.tool
            def run_system_diagnostics(system_id: str) -> dict:
                """Run comprehensive system diagnostics."""
                return {"system_id": system_id, "status": "healthy", "issues": []}
            
            @agent.tool
            def create_incident_report(description: str, severity: str) -> str:
                """Create incident report in production system."""
                incident_id = f"INC-{hash(description) % 100000:05d}"
                return f"Created incident {incident_id} with severity {severity}"
    
    def _setup_routes(self):
        """Set up FastAPI routes for production service."""
        @self.app.post("/chat")
        async def chat_endpoint(request: AgentRequest, background_tasks: BackgroundTasks):
            try:
                # Add request to queue
                await self.request_queue.put({
                    "request": request,
                    "timestamp": time.time(),
                    "future": asyncio.Future()
                })
                
                # Wait for processing (with timeout)
                result = await asyncio.wait_for(
                    self._wait_for_result(request),
                    timeout=request.timeout
                )
                
                return result
                
            except asyncio.TimeoutError:
                raise HTTPException(status_code=408, detail="Request timeout")
            except Exception as e:
                raise HTTPException(status_code=500, detail=str(e))
        
        @self.app.get("/health")
        async def health_endpoint():
            return await self.get_health_status()
        
        @self.app.get("/metrics")
        async def metrics_endpoint():
            return self.get_production_metrics()
    
    async def _processing_worker(self, worker_id: int):
        """Background worker for processing agent requests."""
        logging.info(f"Starting processing worker {worker_id}")
        
        while True:
            try:
                # Get request from queue
                queue_item = await self.request_queue.get()
                request_data = queue_item["request"]
                request_future = queue_item["future"]
                
                # Select appropriate agent
                agent_name = self._select_agent(request_data.agent_type)
                
                if agent_name not in self.agents:
                    request_future.set_exception(Exception(f"Agent {agent_name} not available"))
                    continue
                
                # Process request
                start_time = time.time()
                try:
                    agent = self.agents[agent_name]
                    response = await agent.chat_async(request_data.message)
                    
                    processing_time = time.time() - start_time
                    
                    # Update metrics
                    self.metrics["requests_processed"] += 1
                    self.metrics["total_processing_time"] += processing_time
                    self.metrics["agent_usage"][agent_name] += 1
                    
                    result = {
                        "response": response,
                        "agent_used": agent_name,
                        "processing_time": processing_time,
                        "worker_id": worker_id
                    }
                    
                    request_future.set_result(result)
                    
                except Exception as e:
                    self.metrics["requests_failed"] += 1
                    request_future.set_exception(e)
                
                finally:
                    self.request_queue.task_done()
                    
            except Exception as e:
                logging.error(f"Worker {worker_id} error: {e}")
                await asyncio.sleep(1)
    
    def _select_agent(self, agent_type: str) -> str:
        """Select appropriate agent based on request type."""
        agent_mapping = {
            "customer_service": "customer_service",
            "technical": "technical_support",
            "general": "general_purpose"
        }
        
        return agent_mapping.get(agent_type, "general_purpose")
    
    async def _wait_for_result(self, request: AgentRequest):
        """Wait for request processing to complete."""
        # This is simplified - in production you'd track futures properly
        await asyncio.sleep(0.1)  # Placeholder
        return {"response": "Processed", "status": "success"}
    
    async def get_health_status(self) -> dict:
        """Get comprehensive health status of all services."""
        health_status = {
            "overall_status": "healthy",
            "servers": {},
            "queue_size": self.request_queue.qsize(),
            "active_workers": len([w for w in self.processing_workers if not w.done()]),
            "timestamp": time.time()
        }
        
        unhealthy_servers = 0
        for name, manager in self.managers.items():
            try:
                is_healthy = manager.health_check()
                health_status["servers"][name] = {
                    "status": "healthy" if is_healthy else "unhealthy",
                    "endpoint": manager.base_url,
                    "model": manager.model_name
                }
                if not is_healthy:
                    unhealthy_servers += 1
            except Exception as e:
                health_status["servers"][name] = {
                    "status": "error",
                    "error": str(e)
                }
                unhealthy_servers += 1
        
        if unhealthy_servers > 0:
            health_status["overall_status"] = "degraded" if unhealthy_servers < len(self.managers) else "unhealthy"
        
        return health_status
    
    def get_production_metrics(self) -> dict:
        """Get production performance metrics."""
        total_requests = self.metrics["requests_processed"] + self.metrics["requests_failed"]
        avg_processing_time = (
            self.metrics["total_processing_time"] / self.metrics["requests_processed"]
            if self.metrics["requests_processed"] > 0 else 0
        )
        
        success_rate = (
            self.metrics["requests_processed"] / total_requests * 100
            if total_requests > 0 else 0
        )
        
        return {
            "total_requests": total_requests,
            "successful_requests": self.metrics["requests_processed"],
            "failed_requests": self.metrics["requests_failed"],
            "success_rate_percent": success_rate,
            "average_processing_time_seconds": avg_processing_time,
            "agent_usage_distribution": self.metrics["agent_usage"],
            "queue_size": self.request_queue.qsize()
        }
    
    async def start_production_server(self, host: str = "0.0.0.0", port: int = 8080):
        """Start the production FastAPI server."""
        config = uvicorn.Config(
            self.app,
            host=host,
            port=port,
            log_level="info",
            workers=1  # Single worker for simplicity
        )
        server = uvicorn.Server(config)
        await server.serve()

# Production deployment example
production_configs = {
    "customer_service": VLLMServerConfig(
        model_name="microsoft/Phi-3.5-mini-instruct",
        port=8000,
        gpu_memory_utilization=0.4,
        max_model_len=4096
    ),
    "technical_support": VLLMServerConfig(
        model_name="meta-llama/Llama-3.2-3B-Instruct",
        port=8001,
        gpu_memory_utilization=0.6,
        max_model_len=8192
    ),
    "general_purpose": VLLMServerConfig(
        model_name="Qwen/Qwen2.5-1.5B-Instruct",
        port=8002,
        gpu_memory_utilization=0.3,
        max_model_len=2048
    )
}

production_service = VLLMProductionService(production_configs)

# Initialize and start production service
# await production_service.initialize_production_environment()
# await production_service.start_production_server()
```
  

#### Î§Î±ÏÎ±ÎºÏ„Î·ÏÎ¹ÏƒÏ„Î¹ÎºÎ¬ Î•Ï€Î¹Ï‡ÎµÎ¹ÏÎ®ÏƒÎµÏ‰Î½ ÎºÎ±Î¹ Î Î±ÏÎ±ÎºÎ¿Î»Î¿ÏÎ¸Î·ÏƒÎ·  

**Î ÏÎ¿Î·Î³Î¼Î­Î½Î· Î Î±ÏÎ±ÎºÎ¿Î»Î¿ÏÎ¸Î·ÏƒÎ· Î‘Ï€ÏŒÎ´Î¿ÏƒÎ·Ï‚ VLLM**:  
```python
import psutil
import nvidia_ml_py3 as nvml
from dataclasses import dataclass
from typing import List, Dict, Optional
import json
import asyncio

@dataclass
class PerformanceMetrics:
    timestamp: float
    requests_per_second: float
    average_latency_ms: float
    gpu_utilization_percent: float
    gpu_memory_used_gb: float
    cpu_utilization_percent: float
    memory_used_gb: float
    queue_length: int
    active_requests: int

class VLLMAdvancedMonitoring:
    def __init__(self, vllm_managers: Dict[str, VLLMManager]):
        self.managers = vllm_managers
        self.metrics_history = []
        self.alert_thresholds = {
            "gpu_utilization_max": 95,
            "gpu_memory_max_gb": 10,
            "latency_max_ms": 3000,
            "queue_length_max": 50,
            "error_rate_max_percent": 10
        }
        
        # Initialize NVIDIA ML for GPU monitoring
        try:
            nvml.nvmlInit()
            self.gpu_monitoring_available = True
            self.gpu_count = nvml.nvmlDeviceGetCount()
        except:
            self.gpu_monitoring_available = False
            self.gpu_count = 0
    
    async def collect_comprehensive_metrics(self) -> Dict[str, PerformanceMetrics]:
        """Collect detailed performance metrics for all VLLM instances."""
        all_metrics = {}
        
        for name, manager in self.managers.items():
            try:
                metrics = await self._collect_single_instance_metrics(name, manager)
                all_metrics[name] = metrics
            except Exception as e:
                logging.error(f"Failed to collect metrics for {name}: {e}")
                # Create error metrics
                all_metrics[name] = PerformanceMetrics(
                    timestamp=time.time(),
                    requests_per_second=0,
                    average_latency_ms=0,
                    gpu_utilization_percent=0,
                    gpu_memory_used_gb=0,
                    cpu_utilization_percent=0,
                    memory_used_gb=0,
                    queue_length=0,
                    active_requests=0
                )
        
        return all_metrics
    
    async def _collect_single_instance_metrics(self, name: str, manager: VLLMManager) -> PerformanceMetrics:
        """Collect metrics for a single VLLM instance."""
        timestamp = time.time()
        
        # Get VLLM-specific metrics via API
        vllm_stats = await self._get_vllm_stats(manager)
        
        # Get system metrics
        cpu_percent = psutil.cpu_percent(interval=0.1)
        memory_info = psutil.virtual_memory()
        memory_used_gb = memory_info.used / (1024**3)
        
        # Get GPU metrics if available
        gpu_utilization = 0
        gpu_memory_used = 0
        
        if self.gpu_monitoring_available and self.gpu_count > 0:
            try:
                # Assuming first GPU for simplicity
                handle = nvml.nvmlDeviceGetHandleByIndex(0)
                gpu_util = nvml.nvmlDeviceGetUtilizationRates(handle)
                gpu_utilization = gpu_util.gpu
                
                gpu_mem = nvml.nvmlDeviceGetMemoryInfo(handle)
                gpu_memory_used = gpu_mem.used / (1024**3)
                
            except Exception as e:
                logging.warning(f"GPU monitoring failed: {e}")
        
        return PerformanceMetrics(
            timestamp=timestamp,
            requests_per_second=vllm_stats.get("requests_per_second", 0),
            average_latency_ms=vllm_stats.get("average_latency_ms", 0),
            gpu_utilization_percent=gpu_utilization,
            gpu_memory_used_gb=gpu_memory_used,
            cpu_utilization_percent=cpu_percent,
            memory_used_gb=memory_used_gb,
            queue_length=vllm_stats.get("queue_length", 0),
            active_requests=vllm_stats.get("active_requests", 0)
        )
    
    async def _get_vllm_stats(self, manager: VLLMManager) -> dict:
        """Get VLLM-specific statistics via API calls."""
        try:
            # Test inference to measure latency
            start_time = time.time()
            client = manager.get_openai_client()
            
            response = await asyncio.wait_for(
                asyncio.to_thread(
                    client.chat.completions.create,
                    model=manager.get_served_model_name(),
                    messages=[{"role": "user", "content": "ping"}],
                    max_tokens=1
                ),
                timeout=5.0
            )
            
            latency_ms = (time.time() - start_time) * 1000
            
            return {
                "average_latency_ms": latency_ms,
                "requests_per_second": 1000 / latency_ms if latency_ms > 0 else 0,
                "queue_length": 0,  # Would need to be exposed by VLLM
                "active_requests": 1  # Approximation
            }
            
        except Exception as e:
            logging.warning(f"Failed to get VLLM stats: {e}")
            return {
                "average_latency_ms": 0,
                "requests_per_second": 0,
                "queue_length": 0,
                "active_requests": 0
            }
    
    def generate_performance_report(self, time_window_minutes: int = 60) -> dict:
        """Generate comprehensive performance report."""
        cutoff_time = time.time() - (time_window_minutes * 60)
        recent_metrics = [
            metrics for metrics in self.metrics_history
            if any(m.timestamp > cutoff_time for m in metrics.values())
        ]
        
        if not recent_metrics:
            return {"error": "No recent metrics available"}
        
        report = {
            "time_window_minutes": time_window_minutes,
            "total_samples": len(recent_metrics),
            "instances": {}
        }
        
        # Analyze each instance
        for instance_name in self.managers.keys():
            instance_metrics = [
                metrics[instance_name] for metrics in recent_metrics
                if instance_name in metrics
            ]
            
            if instance_metrics:
                report["instances"][instance_name] = {
                    "avg_latency_ms": sum(m.average_latency_ms for m in instance_metrics) / len(instance_metrics),
                    "max_latency_ms": max(m.average_latency_ms for m in instance_metrics),
                    "avg_gpu_utilization": sum(m.gpu_utilization_percent for m in instance_metrics) / len(instance_metrics),
                    "avg_requests_per_second": sum(m.requests_per_second for m in instance_metrics) / len(instance_metrics),
                    "max_queue_length": max(m.queue_length for m in instance_metrics),
                    "availability_percent": (len(instance_metrics) / len(recent_metrics)) * 100
                }
        
        return report
    
    async def auto_scaling_recommendations(self) -> List[dict]:
        """Generate auto-scaling recommendations based on performance metrics."""
        recommendations = []
        
        if not self.metrics_history:
            return recommendations
        
        latest_metrics = self.metrics_history[-1]
        
        for instance_name, metrics in latest_metrics.items():
            # High latency recommendation
            if metrics.average_latency_ms > self.alert_thresholds["latency_max_ms"]:
                recommendations.append({
                    "instance": instance_name,
                    "type": "scale_up",
                    "reason": f"High latency: {metrics.average_latency_ms:.0f}ms",
                    "suggestion": "Consider adding tensor parallelism or increasing GPU memory"
                })
            
            # High GPU utilization recommendation
            if metrics.gpu_utilization_percent > self.alert_thresholds["gpu_utilization_max"]:
                recommendations.append({
                    "instance": instance_name,
                    "type": "scale_out",
                    "reason": f"High GPU utilization: {metrics.gpu_utilization_percent:.1f}%",
                    "suggestion": "Consider adding additional GPU instances"
                })
            
            # Low utilization recommendation
            if (metrics.gpu_utilization_percent < 20 and 
                metrics.requests_per_second < 1):
                recommendations.append({
                    "instance": instance_name,
                    "type": "scale_down",
                    "reason": f"Low utilization: {metrics.gpu_utilization_percent:.1f}% GPU, {metrics.requests_per_second:.1f} RPS",
                    "suggestion": "Consider consolidating workloads or reducing resources"
                })
        
        return recommendations

# Advanced monitoring setup
monitoring = VLLMAdvancedMonitoring({
    "customer_service": vllm_manager,
    # Add other managers as needed
})

async def advanced_monitoring_loop():
    """Advanced monitoring with auto-scaling recommendations."""
    while True:
        try:
            # Collect metrics
            metrics = await monitoring.collect_comprehensive_metrics()
            monitoring.metrics_history.append(metrics)
            
            # Keep only last 1000 entries
            if len(monitoring.metrics_history) > 1000:
                monitoring.metrics_history = monitoring.metrics_history[-1000:]
            
            # Generate recommendations every 5 minutes
            if len(monitoring.metrics_history) % 10 == 0:  # Every 10th collection (5 minutes if collecting every 30s)
                recommendations = await monitoring.auto_scaling_recommendations()
                
                if recommendations:
                    logging.info(f"Auto-scaling recommendations: {recommendations}")
            
            # Generate performance report every hour
            if len(monitoring.metrics_history) % 120 == 0:  # Every 120th collection (1 hour)
                report = monitoring.generate_performance_report(60)
                logging.info(f"Performance report: {json.dumps(report, indent=2)}")
            
        except Exception as e:
            logging.error(f"Advanced monitoring error: {e}")
        
        await asyncio.sleep(30)  # Collect metrics every 30 seconds

# Start advanced monitoring
# asyncio.create_task(advanced_monitoring_loop())
```
  

#### Î ÏÎ¿Î·Î³Î¼Î­Î½Î· Î¡ÏÎ¸Î¼Î¹ÏƒÎ· ÎºÎ±Î¹ Î’ÎµÎ»Ï„Î¹ÏƒÏ„Î¿Ï€Î¿Î¯Î·ÏƒÎ·  

**Î ÏÏŒÏ„Ï…Ï€Î± Î¡ÏÎ¸Î¼Î¹ÏƒÎ·Ï‚ Î Î±ÏÎ±Î³Ï‰Î³Î®Ï‚ VLLM**:  
```python
from enum import Enum
from typing import Dict, Any

class DeploymentScenario(Enum):
    DEVELOPMENT = "development"
    STAGING = "staging"
    PRODUCTION_LOW = "production_low"
    PRODUCTION_HIGH = "production_high"
    ENTERPRISE = "enterprise"

class VLLMConfigTemplates:
    """Production-ready VLLM configuration templates."""
    
    @staticmethod
    def get_config_template(scenario: DeploymentScenario) -> Dict[str, Any]:
        """Get optimized configuration for deployment scenario."""
        
        templates = {
            DeploymentScenario.DEVELOPMENT: {
                "gpu_memory_utilization": 0.6,
                "max_model_len": 2048,
                "tensor_parallel_size": 1,
                "pipeline_parallel_size": 1,
                "quantization": None,
                "enable_prefix_caching": False,
                "max_num_seqs": 32,
                "max_num_batched_tokens": 2048
            },
            
            DeploymentScenario.STAGING: {
                "gpu_memory_utilization": 0.8,
                "max_model_len": 4096,
                "tensor_parallel_size": 1,
                "pipeline_parallel_size": 1,
                "quantization": "awq",
                "enable_prefix_caching": True,
                "max_num_seqs": 64,
                "max_num_batched_tokens": 4096
            },
            
            DeploymentScenario.PRODUCTION_LOW: {
                "gpu_memory_utilization": 0.85,
                "max_model_len": 4096,
                "tensor_parallel_size": 1,
                "pipeline_parallel_size": 1,
                "quantization": "awq",
                "enable_prefix_caching": True,
                "max_num_seqs": 128,
                "max_num_batched_tokens": 8192,
                "enable_chunked_prefill": True
            },
            
            DeploymentScenario.PRODUCTION_HIGH: {
                "gpu_memory_utilization": 0.9,
                "max_model_len": 8192,
                "tensor_parallel_size": 2,
                "pipeline_parallel_size": 1,
                "quantization": "awq",
                "enable_prefix_caching": True,
                "max_num_seqs": 256,
                "max_num_batched_tokens": 16384,
                "enable_chunked_prefill": True,
                "speculative_model": "small_draft_model"
            },
            
            DeploymentScenario.ENTERPRISE: {
                "gpu_memory_utilization": 0.95,
                "max_model_len": 16384,
                "tensor_parallel_size": 4,
                "pipeline_parallel_size": 2,
                "quantization": "awq",
                "enable_prefix_caching": True,
                "max_num_seqs": 512,
                "max_num_batched_tokens": 32768,
                "enable_chunked_prefill": True,
                "speculative_model": "optimized_draft_model",
                "guided_decoding_backend": "outlines"
            }
        }
        
        return templates[scenario]
    
    @staticmethod
    def generate_vllm_command(model_name: str, 
                             scenario: DeploymentScenario,
                             port: int = 8000,
                             host: str = "0.0.0.0") -> List[str]:
        """Generate optimized VLLM command for deployment scenario."""
        
        config = VLLMConfigTemplates.get_config_template(scenario)
        
        cmd = [
            "python", "-m", "vllm.entrypoints.openai.api_server",
            "--model", model_name,
            "--host", host,
            "--port", str(port),
            "--gpu-memory-utilization", str(config["gpu_memory_utilization"]),
            "--max-model-len", str(config["max_model_len"]),
            "--tensor-parallel-size", str(config["tensor_parallel_size"]),
            "--max-num-seqs", str(config["max_num_seqs"]),
            "--max-num-batched-tokens", str(config["max_num_batched_tokens"]),
            "--trust-remote-code",
            "--disable-log-requests"
        ]
        
        # Add optional parameters
        if config.get("quantization"):
            cmd.extend(["--quantization", config["quantization"]])
        
        if config.get("enable_prefix_caching"):
            cmd.append("--enable-prefix-caching")
        
        if config.get("enable_chunked_prefill"):
            cmd.append("--enable-chunked-prefill")
        
        if config.get("pipeline_parallel_size", 1) > 1:
            cmd.extend(["--pipeline-parallel-size", str(config["pipeline_parallel_size"])])
        
        if config.get("speculative_model"):
            cmd.extend(["--speculative-model", config["speculative_model"]])
        
        return cmd

# Usage examples
dev_cmd = VLLMConfigTemplates.generate_vllm_command(
    "microsoft/Phi-3.5-mini-instruct",
    DeploymentScenario.DEVELOPMENT,
    port=8000
)

prod_cmd = VLLMConfigTemplates.generate_vllm_command(
    "microsoft/Phi-3.5-mini-instruct",
    DeploymentScenario.PRODUCTION_HIGH,
    port=8001
)

print(f"Development command: {' '.join(dev_cmd)}")
print(f"Production command: {' '.join(prod_cmd)}")
```
  
**Î›Î¯ÏƒÏ„Î± Î•Î»Î­Î³Ï‡Î¿Ï… Î‘Î½Î¬Ï€Ï„Ï…Î¾Î·Ï‚ Î Î±ÏÎ±Î³Ï‰Î³Î®Ï‚ Î³Î¹Î± VLLM**:  

âœ… **Î’ÎµÎ»Ï„Î¹ÏƒÏ„Î¿Ï€Î¿Î¯Î·ÏƒÎ· Î¥Î»Î¹ÎºÎ¿Ï**:  
- Î¡ÏÎ¸Î¼Î¹ÏƒÎ· Ï€Î±ÏÎ¬Î»Î»Î·Î»Î·Ï‚ ÎµÏ€ÎµÎ¾ÎµÏÎ³Î±ÏƒÎ¯Î±Ï‚ tensor Î³Î¹Î± ÏƒÏ…ÏƒÏ„Î®Î¼Î±Ï„Î± Ï€Î¿Î»Î»Î±Ï€Î»ÏŽÎ½ GPU  
- Î•Î½ÎµÏÎ³Î¿Ï€Î¿Î¯Î·ÏƒÎ· Ï€Î¿ÏƒÎ¿Ï„Î¹ÎºÎ¿Ï€Î¿Î¯Î·ÏƒÎ·Ï‚ (AWQ/GPTQ) Î³Î¹Î± Î±Ï€Î¿Î´Î¿Ï„Î¹ÎºÏŒÏ„Î·Ï„Î± Î¼Î½Î®Î¼Î·Ï‚  
- Î¡ÏÎ¸Î¼Î¹ÏƒÎ· Î²Î­Î»Ï„Î¹ÏƒÏ„Î·Ï‚ Ï‡ÏÎ®ÏƒÎ·Ï‚ Î¼Î½Î®Î¼Î·Ï‚ GPU (85-95%)  
- Î¡ÏÎ¸Î¼Î¹ÏƒÎ· ÎºÎ±Ï„Î¬Î»Î»Î·Î»Ï‰Î½ Î¼ÎµÎ³ÎµÎ¸ÏŽÎ½ Ï€Î±ÏÏ„Î¯Î´Ï‰Î½ Î³Î¹Î± Î±Ï€ÏŒÎ´Î¿ÏƒÎ·  

âœ… **Î’ÎµÎ»Ï„Î¯Ï‰ÏƒÎ· Î‘Ï€ÏŒÎ´Î¿ÏƒÎ·Ï‚**:  
- Î•Î½ÎµÏÎ³Î¿Ï€Î¿Î¯Î·ÏƒÎ· Ï€ÏÎ¿ÏƒÏ‰ÏÎ¹Î½Î®Ï‚ Î±Ï€Î¿Î¸Î®ÎºÎµÏ…ÏƒÎ·Ï‚ Ï€ÏÎ¿Î¸ÎµÎ¼Î¬Ï„Ï‰Î½ Î³Î¹Î± ÎµÏ€Î±Î½Î±Î»Î±Î¼Î²Î±Î½ÏŒÎ¼ÎµÎ½Î± ÎµÏÏ‰Ï„Î®Î¼Î±Ï„Î±  
- Î¡ÏÎ¸Î¼Î¹ÏƒÎ· Ï„Î¼Î·Î¼Î±Ï„Î¹ÎºÎ®Ï‚ Ï€ÏÎ¿Ï†ÏŒÏÏ„Ï‰ÏƒÎ·Ï‚ Î³Î¹Î± Î¼ÎµÎ³Î¬Î»ÎµÏ‚ Î±ÎºÎ¿Î»Î¿Ï…Î¸Î¯ÎµÏ‚  
- Î¡ÏÎ¸Î¼Î¹ÏƒÎ· speculative decoding Î³Î¹Î± Ï„Î±Ï‡ÏÏ„ÎµÏÎ· ÎµÏ€ÎµÎ¾ÎµÏÎ³Î±ÏƒÎ¯Î±  
- Î’ÎµÎ»Ï„Î¹ÏƒÏ„Î¿Ï€Î¿Î¯Î·ÏƒÎ· max_num_seqs Î²Î¬ÏƒÎµÎ¹ Ï…Î»Î¹ÎºÎ¿Ï  

âœ… **Î§Î±ÏÎ±ÎºÏ„Î·ÏÎ¹ÏƒÏ„Î¹ÎºÎ¬ Î Î±ÏÎ±Î³Ï‰Î³Î®Ï‚**:  
- Î¡ÏÎ¸Î¼Î¹ÏƒÎ· Ï€Î±ÏÎ±ÎºÎ¿Î»Î¿ÏÎ¸Î·ÏƒÎ·Ï‚ Ï…Î³ÎµÎ¯Î±Ï‚ ÎºÎ±Î¹ ÏƒÏ…Î»Î»Î¿Î³Î®Ï‚ Î¼ÎµÏ„ÏÎ®ÏƒÎµÏ‰Î½  
- Î¡ÏÎ¸Î¼Î¹ÏƒÎ· Î±Ï…Ï„ÏŒÎ¼Î±Ï„Î·Ï‚ ÎµÏ€Î±Î½ÎµÎºÎºÎ¯Î½Î·ÏƒÎ·Ï‚ ÎºÎ±Î¹ ÎµÎ½Î±Î»Î»Î±ÎºÏ„Î¹ÎºÎ®Ï‚ Î»ÏÏƒÎ·Ï‚  
- Î•Ï†Î±ÏÎ¼Î¿Î³Î® Î¿Ï…ÏÎ¬Ï‚ Î±Î¹Ï„Î·Î¼Î¬Ï„Ï‰Î½ ÎºÎ±Î¹ ÎµÎ¾Î¹ÏƒÎ¿ÏÏÏŒÏ€Î·ÏƒÎ·Ï‚ Ï†Î¿ÏÏ„Î¯Î¿Ï…  
- Î¡ÏÎ¸Î¼Î¹ÏƒÎ· Î¿Î»Î¿ÎºÎ»Î·ÏÏ‰Î¼Î­Î½Î·Ï‚ ÎºÎ±Ï„Î±Î³ÏÎ±Ï†Î®Ï‚ ÎºÎ±Î¹ ÎµÎ¹Î´Î¿Ï€Î¿Î¹Î®ÏƒÎµÏ‰Î½  

âœ… **Î‘ÏƒÏ†Î¬Î»ÎµÎ¹Î± ÎºÎ±Î¹ Î‘Î¾Î¹Î¿Ï€Î¹ÏƒÏ„Î¯Î±**:  
- Î¡ÏÎ¸Î¼Î¹ÏƒÎ· ÎºÎ±Î½ÏŒÎ½Ï‰Î½ Ï„ÎµÎ¯Ï‡Î¿Ï…Ï‚ Ï€ÏÎ¿ÏƒÏ„Î±ÏƒÎ¯Î±Ï‚ ÎºÎ±Î¹ ÎµÎ»Î­Î³Ï‡Ï‰Î½ Ï€ÏÏŒÏƒÎ²Î±ÏƒÎ·Ï‚  
- Î¡ÏÎ¸Î¼Î¹ÏƒÎ· Ï€ÎµÏÎ¹Î¿ÏÎ¹ÏƒÎ¼Î¿Ï ÏÏ…Î¸Î¼Î¿Ï API ÎºÎ±Î¹ Î±Ï…Î¸ÎµÎ½Ï„Î¹ÎºÎ¿Ï€Î¿Î¯Î·ÏƒÎ·Ï‚  
- Î•Ï†Î±ÏÎ¼Î¿Î³Î® Î¿Î¼Î±Î»Î¿Ï Ï„ÎµÏÎ¼Î±Ï„Î¹ÏƒÎ¼Î¿Ï ÎºÎ±Î¹ ÎºÎ±Î¸Î±ÏÎ¹ÏƒÎ¼Î¿Ï  
- Î¡ÏÎ¸Î¼Î¹ÏƒÎ· Î±Î½Ï„Î¹Î³ÏÎ¬Ï†Ï‰Î½ Î±ÏƒÏ†Î±Î»ÎµÎ¯Î±Ï‚ ÎºÎ±Î¹ Î±Î½Î¬ÎºÏ„Î·ÏƒÎ·Ï‚ Î±Ï€ÏŒ ÎºÎ±Ï„Î±ÏƒÏ„ÏÎ¿Ï†Î®  

âœ… **Î”Î¿ÎºÎ¹Î¼Î­Ï‚ Î•Î½ÏƒÏ‰Î¼Î¬Ï„Ï‰ÏƒÎ·Ï‚**:  
- Î”Î¿ÎºÎ¹Î¼Î® ÎµÎ½ÏƒÏ‰Î¼Î¬Ï„Ï‰ÏƒÎ·Ï‚ Ï„Î¿Ï… Microsoft Agent Framework  
- Î•Ï€Î¹ÎºÏÏÏ‰ÏƒÎ· ÏƒÎµÎ½Î±ÏÎ¯Ï‰Î½ Ï…ÏˆÎ·Î»Î®Ï‚ Î±Ï€ÏŒÎ´Î¿ÏƒÎ·Ï‚  
- Î”Î¿ÎºÎ¹Î¼Î® Î´Î¹Î±Î´Î¹ÎºÎ±ÏƒÎ¹ÏŽÎ½ ÎµÎ½Î±Î»Î»Î±ÎºÏ„Î¹ÎºÎ®Ï‚ Î»ÏÏƒÎ·Ï‚ ÎºÎ±Î¹ Î±Î½Î¬ÎºÏ„Î·ÏƒÎ·Ï‚  
- ÎœÎ­Ï„ÏÎ·ÏƒÎ· Î±Ï€ÏŒÎ´Î¿ÏƒÎ·Ï‚ Ï…Ï€ÏŒ Ï†Î¿ÏÏ„Î¯Î¿  

**Î£ÏÎ³ÎºÏÎ¹ÏƒÎ· Î¼Îµ Î†Î»Î»ÎµÏ‚ Î›ÏÏƒÎµÎ¹Ï‚**:  

| Î§Î±ÏÎ±ÎºÏ„Î·ÏÎ¹ÏƒÏ„Î¹ÎºÏŒ | VLLM | Foundry Local | Ollama |
|----------------|------|---------------|--------|
| **Î ÏÎ¿Ï„ÎµÎ¹Î½ÏŒÎ¼ÎµÎ½Î· Î§ÏÎ®ÏƒÎ·** | Î Î±ÏÎ±Î³Ï‰Î³Î® Ï…ÏˆÎ·Î»Î®Ï‚ Î±Ï€ÏŒÎ´Î¿ÏƒÎ·Ï‚ | Î•Ï…ÎºÎ¿Î»Î¯Î± Ï‡ÏÎ®ÏƒÎ·Ï‚ Î³Î¹Î± ÎµÏ€Î¹Ï‡ÎµÎ¹ÏÎ®ÏƒÎµÎ¹Ï‚ | Î‘Î½Î¬Ï€Ï„Ï…Î¾Î· & ÎºÎ¿Î¹Î½ÏŒÏ„Î·Ï„Î± |
| **Î‘Ï€ÏŒÎ´Î¿ÏƒÎ·** | ÎœÎ­Î³Î¹ÏƒÏ„Î· Ï„Î±Ï‡ÏÏ„Î·Ï„Î± | Î™ÏƒÎ¿ÏÏÎ¿Ï€Î·Î¼Î­Î½Î· | ÎšÎ±Î»Î® |
| **Î‘Ï€Î¿Î´Î¿Ï„Î¹ÎºÏŒÏ„Î·Ï„Î± ÎœÎ½Î®Î¼Î·Ï‚** | Î’ÎµÎ»Ï„Î¹ÏƒÏ„Î¿Ï€Î¿Î¯Î·ÏƒÎ· PagedAttention | Î‘Ï…Ï„ÏŒÎ¼Î±Ï„Î· Î²ÎµÎ»Ï„Î¹ÏƒÏ„Î¿Ï€Î¿Î¯Î·ÏƒÎ· | Î¤Ï…Ï€Î¹ÎºÎ® |
| **Î Î¿Î»Ï…Ï€Î»Î¿ÎºÏŒÏ„Î·Ï„Î± Î¡ÏÎ¸Î¼Î¹ÏƒÎ·Ï‚** | Î¥ÏˆÎ·Î»Î® (Ï€Î¿Î»Î»Î­Ï‚ Ï€Î±ÏÎ¬Î¼ÎµÏ„ÏÎ¿Î¹) | Î§Î±Î¼Î·Î»Î® (Î±Ï…Ï„ÏŒÎ¼Î±Ï„Î·) | Î§Î±Î¼Î·Î»Î® (Î±Ï€Î»Î®) |
| **ÎšÎ»Î¹Î¼Î¬ÎºÏ‰ÏƒÎ·** | Î•Î¾Î±Î¹ÏÎµÏ„Î¹ÎºÎ® (Ï€Î±ÏÎ¬Î»Î»Î·Î»Î· ÎµÏ€ÎµÎ¾ÎµÏÎ³Î±ÏƒÎ¯Î± tensor/pipeline) | ÎšÎ±Î»Î® | Î ÎµÏÎ¹Î¿ÏÎ¹ÏƒÎ¼Î­Î½Î· |
| **Î Î¿ÏƒÎ¿Ï„Î¹ÎºÎ¿Ï€Î¿Î¯Î·ÏƒÎ·** | Î ÏÎ¿Î·Î³Î¼Î­Î½Î· (AWQ, GPTQ, FP8) | Î‘Ï…Ï„ÏŒÎ¼Î±Ï„Î· | Î¤Ï…Ï€Î¹ÎºÎ® GGUF |
| **Î§Î±ÏÎ±ÎºÏ„Î·ÏÎ¹ÏƒÏ„Î¹ÎºÎ¬ Î•Ï€Î¹Ï‡ÎµÎ¹ÏÎ®ÏƒÎµÏ‰Î½** | Î‘Ï€Î±Î¹Ï„ÎµÎ¯Ï„Î±Î¹ Ï€ÏÎ¿ÏƒÎ±ÏÎ¼Î¿ÏƒÎ¼Î­Î½Î· Ï…Î»Î¿Ï€Î¿Î¯Î·ÏƒÎ· | Î•Î½ÏƒÏ‰Î¼Î±Ï„Ï‰Î¼Î­Î½Î± | Î•ÏÎ³Î±Î»ÎµÎ¯Î± ÎºÎ¿Î¹Î½ÏŒÏ„Î·Ï„Î±Ï‚ |
| **Î™Î´Î±Î½Î¹ÎºÏŒ Î“Î¹Î±** | Î ÏÎ¬ÎºÏ„Î¿ÏÎµÏ‚ Ï€Î±ÏÎ±Î³Ï‰Î³Î®Ï‚ Î¼ÎµÎ³Î¬Î»Î·Ï‚ ÎºÎ»Î¯Î¼Î±ÎºÎ±Ï‚ | Î Î±ÏÎ±Î³Ï‰Î³Î® Î³Î¹Î± ÎµÏ€Î¹Ï‡ÎµÎ¹ÏÎ®ÏƒÎµÎ¹Ï‚ | Î‘Î½Î¬Ï€Ï„Ï…Î¾Î· |

**Î ÏŒÏ„Îµ Î½Î± ÎµÏ€Î¹Î»Î­Î¾ÎµÏ„Îµ Ï„Î¿ VLLM**:  
- **Î‘Ï€Î±Î¹Ï„Î®ÏƒÎµÎ¹Ï‚ Î¥ÏˆÎ·Î»Î®Ï‚ Î‘Ï€ÏŒÎ´Î¿ÏƒÎ·Ï‚**: Î•Ï€ÎµÎ¾ÎµÏÎ³Î±ÏƒÎ¯Î± ÎµÎºÎ±Ï„Î¿Î½Ï„Î¬Î´Ï‰Î½ Î±Î¹Ï„Î·Î¼Î¬Ï„Ï‰Î½ Î±Î½Î¬ Î´ÎµÏ…Ï„ÎµÏÏŒÎ»ÎµÏ€Ï„Î¿  
- **Î‘Î½Î±Ï€Ï„ÏÎ¾ÎµÎ¹Ï‚ ÎœÎµÎ³Î¬Î»Î·Ï‚ ÎšÎ»Î¯Î¼Î±ÎºÎ±Ï‚**: Î£Ï…ÏƒÏ„Î®Î¼Î±Ï„Î± Ï€Î¿Î»Î»Î±Ï€Î»ÏŽÎ½ GPU, Ï€Î¿Î»Î»Î±Ï€Î»ÏŽÎ½ ÎºÏŒÎ¼Î²Ï‰Î½  
- **ÎšÏÎ¯ÏƒÎ¹Î¼Î· Î‘Ï€ÏŒÎ´Î¿ÏƒÎ·**: Î§ÏÏŒÎ½Î¿Î¹ Î±Ï€ÏŒÎºÏÎ¹ÏƒÎ·Ï‚ ÎºÎ¬Ï„Ï‰ Ï„Î¿Ï… Î´ÎµÏ…Ï„ÎµÏÎ¿Î»Î­Ï€Ï„Î¿Ï… ÏƒÎµ Î¼ÎµÎ³Î¬Î»Î· ÎºÎ»Î¯Î¼Î±ÎºÎ±  
- **Î ÏÎ¿Î·Î³Î¼Î­Î½Î· Î’ÎµÎ»Ï„Î¹ÏƒÏ„Î¿Ï€Î¿Î¯Î·ÏƒÎ·**: Î‘Î½Î¬Î³ÎºÎ· Î³Î¹Î± Ï€ÏÎ¿ÏƒÎ±ÏÎ¼Î¿ÏƒÎ¼Î­Î½Î· Ï€Î¿ÏƒÎ¿Ï„Î¹ÎºÎ¿Ï€Î¿Î¯Î·ÏƒÎ· ÎºÎ±Î¹ Î¿Î¼Î±Î´Î¿Ï€Î¿Î¯Î·ÏƒÎ·  
- **Î‘Ï€Î¿Î´Î¿Ï„Î¹ÎºÏŒÏ„Î·Ï„Î± Î ÏŒÏÏ‰Î½**: ÎœÎ­Î³Î¹ÏƒÏ„Î· Î±Î¾Î¹Î¿Ï€Î¿Î¯Î·ÏƒÎ· Î±ÎºÏÎ¹Î²Î¿Ï Ï…Î»Î¹ÎºÎ¿Ï GPU  

## Î•Ï†Î±ÏÎ¼Î¿Î³Î­Ï‚ Î ÏÎ±ÎºÏ„ÏŒÏÏ‰Î½ SLM ÏƒÏ„Î¿Î½ Î ÏÎ±Î³Î¼Î±Ï„Î¹ÎºÏŒ ÎšÏŒÏƒÎ¼Î¿  

### Î ÏÎ¬ÎºÏ„Î¿ÏÎµÏ‚ Î•Î¾Ï…Ï€Î·ÏÎ­Ï„Î·ÏƒÎ·Ï‚ Î ÎµÎ»Î±Ï„ÏŽÎ½ SLM  
- **Î”Ï…Î½Î±Ï„ÏŒÏ„Î·Ï„ÎµÏ‚ SLM**: Î‘Î½Î±Î¶Î·Ï„Î®ÏƒÎµÎ¹Ï‚ Î»Î¿Î³Î±ÏÎ¹Î±ÏƒÎ¼ÏŽÎ½, ÎµÏ€Î±Î½Î±Ï†Î¿ÏÎ¬ ÎºÏ‰Î´Î¹ÎºÏŽÎ½ Ï€ÏÏŒÏƒÎ²Î±ÏƒÎ·Ï‚, Î­Î»ÎµÎ³Ï‡Î¿Ï‚ ÎºÎ±Ï„Î¬ÏƒÏ„Î±ÏƒÎ·Ï‚ Ï€Î±ÏÎ±Î³Î³ÎµÎ»Î¹ÏŽÎ½  
- **ÎŸÎ¹ÎºÎ¿Î½Î¿Î¼Î¹ÎºÎ¬ Î¿Ï†Î­Î»Î·**: ÎœÎµÎ¯Ï‰ÏƒÎ· ÎºÏŒÏƒÏ„Î¿Ï…Ï‚ ÎµÏ€ÎµÎ¾ÎµÏÎ³Î±ÏƒÎ¯Î±Ï‚ ÎºÎ±Ï„Î¬ 10 Ï†Î¿ÏÎ­Ï‚ ÏƒÎµ ÏƒÏÎ³ÎºÏÎ¹ÏƒÎ· Î¼Îµ Ï€ÏÎ¬ÎºÏ„Î¿ÏÎµÏ‚ LLM  
- **Î‘Ï€ÏŒÎ´Î¿ÏƒÎ·**: Î¤Î±Ï‡ÏÏ„ÎµÏÎ¿Î¹ Ï‡ÏÏŒÎ½Î¿Î¹ Î±Ï€ÏŒÎºÏÎ¹ÏƒÎ·Ï‚ Î¼Îµ ÏƒÏ…Î½ÎµÏ€Î® Ï€Î¿Î¹ÏŒÏ„Î·Ï„Î± Î³Î¹Î± ÏÎ¿Ï…Ï„Î¯Î½ÎµÏ‚ ÎµÏÏ‰Ï„Î®ÏƒÎµÎ¹Ï‚  

### Î ÏÎ¬ÎºÏ„Î¿ÏÎµÏ‚ Î•Ï€Î¹Ï‡ÎµÎ¹ÏÎ·ÏƒÎ¹Î±ÎºÏŽÎ½ Î”Î¹Î±Î´Î¹ÎºÎ±ÏƒÎ¹ÏŽÎ½ SLM  
- **Î ÏÎ¬ÎºÏ„Î¿ÏÎµÏ‚ ÎµÏ€ÎµÎ¾ÎµÏÎ³Î±ÏƒÎ¯Î±Ï‚ Ï„Î¹Î¼Î¿Î»Î¿Î³Î¯Ï‰Î½**: Î•Î¾Î±Î³Ï‰Î³Î® Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½, ÎµÏ€Î±Î»Î®Î¸ÎµÏ…ÏƒÎ· Ï€Î»Î·ÏÎ¿Ï†Î¿ÏÎ¹ÏŽÎ½, Î´ÏÎ¿Î¼Î¿Î»ÏŒÎ³Î·ÏƒÎ· Î³Î¹Î± Î­Î³ÎºÏÎ¹ÏƒÎ·  
- **Î ÏÎ¬ÎºÏ„Î¿ÏÎµÏ‚ Î´Î¹Î±Ï‡ÎµÎ¯ÏÎ¹ÏƒÎ·Ï‚ email**: ÎšÎ±Ï„Î·Î³Î¿ÏÎ¹Î¿Ï€Î¿Î¯Î·ÏƒÎ·, Ï€ÏÎ¿Ï„ÎµÏÎ±Î¹Î¿Ï€Î¿Î¯Î·ÏƒÎ·, Î±Ï…Ï„ÏŒÎ¼Î±Ï„Î· ÏƒÏÎ½Ï„Î±Î¾Î· Î±Ï€Î±Î½Ï„Î®ÏƒÎµÏ‰Î½  
- **Î ÏÎ¬ÎºÏ„Î¿ÏÎµÏ‚ Ï€ÏÎ¿Î³ÏÎ±Î¼Î¼Î±Ï„Î¹ÏƒÎ¼Î¿Ï**: Î£Ï…Î½Ï„Î¿Î½Î¹ÏƒÎ¼ÏŒÏ‚ ÏƒÏ…Î½Î±Î½Ï„Î®ÏƒÎµÏ‰Î½, Î´Î¹Î±Ï‡ÎµÎ¯ÏÎ¹ÏƒÎ· Î·Î¼ÎµÏÎ¿Î»Î¿Î³Î¯Ï‰Î½, Î±Ï€Î¿ÏƒÏ„Î¿Î»Î® Ï…Ï€ÎµÎ½Î¸Ï…Î¼Î¯ÏƒÎµÏ‰Î½  

### Î ÏÎ¿ÏƒÏ‰Ï€Î¹ÎºÎ¿Î¯ Î¨Î·Ï†Î¹Î±ÎºÎ¿Î¯ Î’Î¿Î·Î¸Î¿Î¯ SLM  
- **Î ÏÎ¬ÎºÏ„Î¿ÏÎµÏ‚ Î´Î¹Î±Ï‡ÎµÎ¯ÏÎ¹ÏƒÎ·Ï‚ ÎµÏÎ³Î±ÏƒÎ¹ÏŽÎ½**: Î”Î·Î¼Î¹Î¿Ï…ÏÎ³Î¯Î±, ÎµÎ½Î·Î¼Î­ÏÏ‰ÏƒÎ·, Î¿ÏÎ³Î¬Î½Ï‰ÏƒÎ· Î»Î¹ÏƒÏ„ÏŽÎ½ ÎµÏÎ³Î±ÏƒÎ¹ÏŽÎ½  
- **Î ÏÎ¬ÎºÏ„Î¿ÏÎµÏ‚ ÏƒÏ…Î»Î»Î¿Î³Î®Ï‚ Ï€Î»Î·ÏÎ¿Ï†Î¿ÏÎ¹ÏŽÎ½**: ÎˆÏÎµÏ…Î½Î± Î¸ÎµÎ¼Î¬Ï„Ï‰Î½, ÏƒÏÎ½Î¿ÏˆÎ· ÎµÏ…ÏÎ·Î¼Î¬Ï„Ï‰Î½ Ï„Î¿Ï€Î¹ÎºÎ¬  
- **Î ÏÎ¬ÎºÏ„Î¿ÏÎµÏ‚ ÎµÏ€Î¹ÎºÎ¿Î¹Î½Ï‰Î½Î¯Î±Ï‚**: Î£ÏÎ½Ï„Î±Î¾Î· email, Î¼Î·Î½Ï…Î¼Î¬Ï„Ï‰Î½, Î±Î½Î±ÏÏ„Î®ÏƒÎµÏ‰Î½ ÏƒÏ„Î± ÎºÎ¿Î¹Î½Ï‰Î½Î¹ÎºÎ¬ Î´Î¯ÎºÏ„Ï…Î± Î¹Î´Î¹Ï‰Ï„Î¹ÎºÎ¬  

### Î ÏÎ¬ÎºÏ„Î¿ÏÎµÏ‚ Î•Î¼Ï€Î¿ÏÎ¯Î¿Ï… ÎºÎ±Î¹ ÎŸÎ¹ÎºÎ¿Î½Î¿Î¼Î¹ÎºÏŽÎ½ SLM  
- **Î ÏÎ¬ÎºÏ„Î¿ÏÎµÏ‚ Ï€Î±ÏÎ±ÎºÎ¿Î»Î¿ÏÎ¸Î·ÏƒÎ·Ï‚ Î±Î³Î¿ÏÎ¬Ï‚**: Î Î±ÏÎ±ÎºÎ¿Î»Î¿ÏÎ¸Î·ÏƒÎ· Ï„Î¹Î¼ÏŽÎ½, Î±Î½Î±Î³Î½ÏŽÏÎ¹ÏƒÎ· Ï„Î¬ÏƒÎµÏ‰Î½ ÏƒÎµ Ï€ÏÎ±Î³Î¼Î±Ï„Î¹ÎºÏŒ Ï‡ÏÏŒÎ½Î¿  
- **Î ÏÎ¬ÎºÏ„Î¿ÏÎµÏ‚ Î´Î·Î¼Î¹Î¿Ï…ÏÎ³Î¯Î±Ï‚ Î±Î½Î±Ï†Î¿ÏÏŽÎ½**: Î‘Ï…Ï„ÏŒÎ¼Î±Ï„Î· Î´Î·Î¼Î¹Î¿Ï…ÏÎ³Î¯Î± Î·Î¼ÎµÏÎ®ÏƒÎ¹Ï‰Î½/ÎµÎ²Î´Î¿Î¼Î±Î´Î¹Î±Î¯Ï‰Î½ Î±Î½Î±Ï†Î¿ÏÏŽÎ½  
- **Î ÏÎ¬ÎºÏ„Î¿ÏÎµÏ‚ Î±Î¾Î¹Î¿Î»ÏŒÎ³Î·ÏƒÎ·Ï‚ ÎºÎ¹Î½Î´ÏÎ½Î¿Ï…**: Î‘Î¾Î¹Î¿Î»ÏŒÎ³Î·ÏƒÎ· Î¸Î­ÏƒÎµÏ‰Î½ Ï‡Î±ÏÏ„Î¿Ï†Ï…Î»Î±ÎºÎ¯Î¿Ï… Ï‡ÏÎ·ÏƒÎ¹Î¼Î¿Ï€Î¿Î¹ÏŽÎ½Ï„Î±Ï‚ Ï„Î¿Ï€Î¹ÎºÎ¬ Î´ÎµÎ´Î¿Î¼Î­Î½Î±  

### Î ÏÎ¬ÎºÏ„Î¿ÏÎµÏ‚ Î¥Ï€Î¿ÏƒÏ„Î®ÏÎ¹Î¾Î·Ï‚ Î¥Î³ÎµÎ¯Î±Ï‚ SLM  
- **Î ÏÎ¬ÎºÏ„Î¿ÏÎµÏ‚ Ï€ÏÎ¿Î³ÏÎ±Î¼Î¼Î±Ï„Î¹ÏƒÎ¼Î¿Ï Î±ÏƒÎ¸ÎµÎ½ÏŽÎ½**: Î£Ï…Î½Ï„Î¿Î½Î¹ÏƒÎ¼ÏŒÏ‚ ÏÎ±Î½Ï„ÎµÎ²Î¿Ï, Î±Ï€Î¿ÏƒÏ„Î¿Î»Î® Î±Ï…Ï„Î¿Î¼Î±Ï„Î¿Ï€Î¿Î¹Î·Î¼Î­Î½Ï‰Î½ Ï…Ï€ÎµÎ½Î¸Ï…Î¼Î¯ÏƒÎµÏ‰Î½  
- **Î ÏÎ¬ÎºÏ„Î¿ÏÎµÏ‚ Ï„ÎµÎºÎ¼Î·ÏÎ¯Ï‰ÏƒÎ·Ï‚**: Î”Î·Î¼Î¹Î¿Ï…ÏÎ³Î¯Î± Î¹Î±Ï„ÏÎ¹ÎºÏŽÎ½ Ï€ÎµÏÎ¹Î»Î®ÏˆÎµÏ‰Î½, Î±Î½Î±Ï†Î¿ÏÏŽÎ½ Ï„Î¿Ï€Î¹ÎºÎ¬  
- **Î ÏÎ¬ÎºÏ„Î¿ÏÎµÏ‚ Î´Î¹Î±Ï‡ÎµÎ¯ÏÎ¹ÏƒÎ·Ï‚ ÏƒÏ…Î½Ï„Î±Î³ÏŽÎ½**: Î Î±ÏÎ±ÎºÎ¿Î»Î¿ÏÎ¸Î·ÏƒÎ· Î±Î½Î±Î½ÎµÏŽÏƒÎµÏ‰Î½, Î­Î»ÎµÎ³Ï‡Î¿Ï‚ Î±Î»Î»Î·Î»ÎµÏ€Î¹Î´ÏÎ¬ÏƒÎµÏ‰Î½ Î¹Î´Î¹Ï‰Ï„Î¹ÎºÎ¬  

## Microsoft Agent Framework: Î‘Î½Î¬Ï€Ï„Ï…Î¾Î· Î ÏÎ±ÎºÏ„ÏŒÏÏ‰Î½ ÎˆÏ„Î¿Î¹Î¼Ï‰Î½ Î³Î¹Î± Î Î±ÏÎ±Î³Ï‰Î³Î®  

### Î•Ï€Î¹ÏƒÎºÏŒÏ€Î·ÏƒÎ· ÎºÎ±Î¹ Î‘ÏÏ‡Î¹Ï„ÎµÎºÏ„Î¿Î½Î¹ÎºÎ®  

Î¤Î¿ Microsoft Agent Framework Ï€Î±ÏÎ­Ï‡ÎµÎ¹ Î¼Î¹Î± Î¿Î»Î¿ÎºÎ»Î·ÏÏ‰Î¼Î­Î½Î·, ÎµÏ€Î¹Ï‡ÎµÎ¹ÏÎ·ÏƒÎ¹Î±ÎºÎ®Ï‚ ÎºÎ»Î¬ÏƒÎ·Ï‚ Ï€Î»Î±Ï„Ï†ÏŒÏÎ¼Î± Î³Î¹Î± Ï„Î·Î½ Î±Î½Î¬Ï€Ï„Ï…Î¾Î·, Ï„Î·Î½ Ï…Î»Î¿Ï€Î¿Î¯Î·ÏƒÎ· ÎºÎ±Î¹ Ï„Î· Î´Î¹Î±Ï‡ÎµÎ¯ÏÎ¹ÏƒÎ· Ï€ÏÎ±ÎºÏ„ÏŒÏÏ‰Î½ AI Ï€Î¿Ï… Î¼Ï€Î¿ÏÎ¿ÏÎ½ Î½Î± Î»ÎµÎ¹Ï„Î¿Ï…ÏÎ³Î¿ÏÎ½ Ï„ÏŒÏƒÎ¿ ÏƒÏ„Î¿ cloud ÏŒÏƒÎ¿ ÎºÎ±Î¹ ÏƒÎµ Ï€ÎµÏÎ¹Î²Î¬Î»Î»Î¿Î½Ï„Î± edge ÎµÎºÏ„ÏŒÏ‚ ÏƒÏÎ½Î´ÎµÏƒÎ·Ï‚. Î¤Î¿ Ï€Î»Î±Î¯ÏƒÎ¹Î¿ Î­Ï‡ÎµÎ¹ ÏƒÏ‡ÎµÎ´Î¹Î±ÏƒÏ„ÎµÎ¯ ÎµÎ¹Î´Î¹ÎºÎ¬ Î³Î¹Î± Î½Î± Î»ÎµÎ¹Ï„Î¿Ï…ÏÎ³ÎµÎ¯ Î±Ï€ÏÏŒÏƒÎºÎ¿Ï€Ï„Î± Î¼Îµ ÎœÎ¹ÎºÏÎ¬ Î“Î»Ï‰ÏƒÏƒÎ¹ÎºÎ¬ ÎœÎ¿Î½Ï„Î­Î»Î± ÎºÎ±Î¹ ÏƒÎµÎ½Î¬ÏÎ¹Î± Ï…Ï€Î¿Î»Î¿Î³Î¹ÏƒÎ¼Î¿Ï ÏƒÏ„Î¿ edge, ÎºÎ±Î¸Î¹ÏƒÏ„ÏŽÎ½Ï„Î±Ï‚ Ï„Î¿ Î¹Î´Î±Î½Î¹ÎºÏŒ Î³Î¹Î± Î±Î½Î±Ï€Ï„ÏÎ¾ÎµÎ¹Ï‚ Ï€Î¿Ï… Î±Ï€Î±Î¹Ï„Î¿ÏÎ½ Ï€ÏÎ¿ÏƒÏ„Î±ÏƒÎ¯Î± Ï„Î·Ï‚ Î¹Î´Î¹Ï‰Ï„Î¹ÎºÏŒÏ„Î·Ï„Î±Ï‚ ÎºÎ±Î¹ Ï€ÎµÏÎ¹Î¿ÏÎ¹ÏƒÎ¼Î­Î½Î¿Ï…Ï‚ Ï€ÏŒÏÎ¿Ï…Ï‚.  

**Î’Î±ÏƒÎ¹ÎºÎ¬ Î£Ï„Î¿Î¹Ï‡ÎµÎ¯Î± Î Î»Î±Î¹ÏƒÎ¯Î¿Ï…**:  
- **Î ÎµÏÎ¹Î²Î¬Î»Î»Î¿Î½ Î•ÎºÏ„Î­Î»ÎµÏƒÎ·Ï‚ Î ÏÎ±ÎºÏ„ÏŒÏÏ‰Î½**: Î•Î»Î±Ï†ÏÏ Ï€ÎµÏÎ¹Î²Î¬Î»Î»Î¿Î½ ÎµÎºÏ„Î­Î»ÎµÏƒÎ·Ï‚ Î²ÎµÎ»Ï„Î¹ÏƒÏ„Î¿Ï€Î¿Î¹Î·Î¼Î­Î½Î¿ Î³Î¹Î± ÏƒÏ…ÏƒÎºÎµÏ…Î­Ï‚ edge  
- **Î£ÏÏƒÏ„Î·Î¼Î± Î•Î½ÏƒÏ‰Î¼Î¬Ï„Ï‰ÏƒÎ·Ï‚ Î•ÏÎ³Î±Î»ÎµÎ¯Ï‰Î½**: Î•Ï€ÎµÎºÏ„Î¬ÏƒÎ¹Î¼Î· Î±ÏÏ‡Î¹Ï„ÎµÎºÏ„Î¿Î½Î¹ÎºÎ® Ï€ÏÎ¿ÏƒÎ¸Î·ÎºÏŽÎ½ Î³Î¹Î± ÏƒÏÎ½Î´ÎµÏƒÎ· ÎµÎ¾Ï‰Ï„ÎµÏÎ¹ÎºÏŽÎ½ Ï…Ï€Î·ÏÎµÏƒÎ¹ÏŽÎ½ ÎºÎ±Î¹ API  
- **Î”Î¹Î±Ï‡ÎµÎ¯ÏÎ¹ÏƒÎ· ÎšÎ±Ï„Î¬ÏƒÏ„Î±ÏƒÎ·Ï‚**: ÎœÏŒÎ½Î¹Î¼Î· Î¼Î½Î®Î¼Î· Ï€ÏÎ±ÎºÏ„ÏŒÏÏ‰Î½ ÎºÎ±Î¹ Ï‡ÎµÎ¹ÏÎ¹ÏƒÎ¼ÏŒÏ‚ Ï€ÎµÏÎ¹ÎµÏ‡Î¿Î¼Î­Î½Î¿Ï… Î¼ÎµÏ„Î±Î¾Ï ÏƒÏ…Î½ÎµÎ´ÏÎ¹ÏŽÎ½  
- **Î•Ï€Î¯Ï€ÎµÎ´Î¿ Î‘ÏƒÏ†Î¬Î»ÎµÎ¹Î±Ï‚**: Î•Î½ÏƒÏ‰Î¼Î±Ï„Ï‰Î¼Î­Î½Î¿Î¹ Î­Î»ÎµÎ³Ï‡Î¿Î¹ Î±ÏƒÏ†Î¬Î»ÎµÎ¹Î±Ï‚ Î³Î¹Î± ÎµÏ€Î¹Ï‡ÎµÎ¹ÏÎ·ÏƒÎ¹Î±ÎºÎ® Î±Î½Î¬Ï€Ï„Ï…Î¾Î·  
- **ÎœÎ·Ï‡Î±Î½Î® ÎŸÏÏ‡Î®ÏƒÏ„ÏÏ‰ÏƒÎ·Ï‚**: Î£Ï…Î½Ï„Î¿Î½Î¹ÏƒÎ¼ÏŒÏ‚ Ï€Î¿Î»Î»Î±Ï€Î»ÏŽÎ½ Ï€ÏÎ±ÎºÏ„ÏŒÏÏ‰Î½ ÎºÎ±Î¹ Î´Î¹Î±Ï‡ÎµÎ¯ÏÎ¹ÏƒÎ· ÏÎ¿ÏŽÎ½ ÎµÏÎ³Î±ÏƒÎ¯Î±Ï‚  

### Î’Î±ÏƒÎ¹ÎºÎ¬ Î§Î±ÏÎ±ÎºÏ„Î·ÏÎ¹ÏƒÏ„Î¹ÎºÎ¬ Î³Î¹Î± Î‘Î½Î¬Ï€Ï„Ï…Î¾Î· ÏƒÏ„Î¿ Edge  

**Î‘ÏÏ‡Î¹Ï„ÎµÎºÏ„Î¿Î½Î¹ÎºÎ® Offline-First**: Î¤Î¿ Microsoft Agent Framework ÎµÎ¯Î½Î±Î¹ ÏƒÏ‡ÎµÎ´Î¹Î±ÏƒÎ¼Î­Î½Î¿ Î¼Îµ Î±ÏÏ‡Î­Ï‚ offline-first, ÎµÏ€Î¹Ï„ÏÎ­Ï€Î¿Î½Ï„Î±Ï‚ ÏƒÏ„Î¿Ï…Ï‚ Ï€ÏÎ¬ÎºÏ„Î¿ÏÎµÏ‚ Î½Î± Î»ÎµÎ¹Ï„Î¿Ï…ÏÎ³Î¿ÏÎ½ Î±Ï€Î¿Ï„ÎµÎ»ÎµÏƒÎ¼Î±Ï„Î¹ÎºÎ¬ Ï‡Ï‰ÏÎ¯Ï‚ ÏƒÏ…Î½ÎµÏ‡Î® ÏƒÏÎ½Î´ÎµÏƒÎ· ÏƒÏ„Î¿ Î´Î¹Î±Î´Î¯ÎºÏ„Ï…Î¿. Î‘Ï…Ï„ÏŒ Ï€ÎµÏÎ¹Î»Î±Î¼Î²Î¬Î½ÎµÎ¹ Ï„Î¿Ï€Î¹ÎºÎ® ÎµÏ€ÎµÎ¾ÎµÏÎ³Î±ÏƒÎ¯Î± Î¼Î¿Î½Ï„Î­Î»Ï‰Î½, Î±Ï€Î¿Î¸Î·ÎºÎµÏ…Î¼Î­Î½ÎµÏ‚ Î²Î¬ÏƒÎµÎ¹Ï‚ Î³Î½ÏŽÏƒÎµÏ‰Î½, ÎµÎºÏ„Î­Î»ÎµÏƒÎ· ÎµÏÎ³Î±Î»ÎµÎ¯Ï‰Î½ ÎµÎºÏ„ÏŒÏ‚ ÏƒÏÎ½Î´ÎµÏƒÎ·Ï‚ ÎºÎ±Î¹ Î¿Î¼Î±Î»Î® Ï…Ï€Î¿Î²Î¬Î¸Î¼Î¹ÏƒÎ· ÏŒÏ„Î±Î½ Î¿Î¹ Ï…Ï€Î·ÏÎµÏƒÎ¯ÎµÏ‚ cloud Î´ÎµÎ½ ÎµÎ¯Î½Î±Î¹ Î´Î¹Î±Î¸Î­ÏƒÎ¹Î¼ÎµÏ‚.  

**Î’ÎµÎ»Ï„Î¹ÏƒÏ„Î¿Ï€Î¿Î¯Î·ÏƒÎ· Î ÏŒÏÏ‰Î½**: Î¤Î¿ Ï€Î»Î±Î¯ÏƒÎ¹Î¿ Ï€Î±ÏÎ­Ï‡ÎµÎ¹ Î­Î¾Ï…Ï€Î½Î· Î´Î¹Î±Ï‡ÎµÎ¯ÏÎ¹ÏƒÎ· Ï€ÏŒÏÏ‰Î½ Î¼Îµ Î±Ï…Ï„ÏŒÎ¼Î±Ï„Î· Î²ÎµÎ»Ï„Î¹ÏƒÏ„Î¿Ï€Î¿Î¯Î·ÏƒÎ· Î¼Î½Î®Î¼Î·Ï‚ Î³Î¹Î± SLMs, ÎµÎ¾Î¹ÏƒÎ¿ÏÏÏŒÏ€Î·ÏƒÎ· Ï†Î¿ÏÏ„Î¯Î¿Ï… CPU/GPU Î³Î¹Î± ÏƒÏ…ÏƒÎºÎµÏ…Î­Ï‚ edge, Ï€ÏÎ¿ÏƒÎ±ÏÎ¼Î¿ÏƒÏ„Î¹ÎºÎ® ÎµÏ€Î¹Î»Î¿Î³Î® Î¼Î¿Î½Ï„Î­Î»Ï‰Î½ Î²Î¬ÏƒÎµÎ¹ Î´Î¹Î±Î¸Î­ÏƒÎ¹Î¼Ï‰Î½ Ï€ÏŒÏÏ‰Î½ ÎºÎ±Î¹ Î¼Î¿Ï„Î¯Î²Î± ÎµÏ€ÎµÎ¾ÎµÏÎ³Î±ÏƒÎ¯Î±Ï‚ Î¼Îµ Ï‡Î±Î¼Î·Î»Î® ÎºÎ±Ï„Î±Î½Î¬Î»Ï‰ÏƒÎ· ÎµÎ½Î­ÏÎ³ÎµÎ¹Î±Ï‚ Î³Î¹Î± ÎºÎ¹Î½Î·Ï„Î­Ï‚ Î±Î½Î±Ï€Ï„ÏÎ¾ÎµÎ¹Ï‚.  

**Î‘ÏƒÏ†Î¬Î»ÎµÎ¹Î± ÎºÎ±Î¹ Î™Î´Î¹Ï‰Ï„Î¹ÎºÏŒÏ„Î·Ï„Î±**: Î§Î±ÏÎ±ÎºÏ„Î·ÏÎ¹ÏƒÏ„Î¹ÎºÎ¬ Î±ÏƒÏ†Î¬Î»ÎµÎ¹Î±Ï‚ ÎµÏ€Î¹Ï‡ÎµÎ¹ÏÎ·ÏƒÎ¹Î±ÎºÎ®Ï‚ ÎºÎ»Î¬ÏƒÎ·Ï‚ Ï€ÎµÏÎ¹Î»Î±Î¼Î²Î¬Î½Î¿Ï…Î½ Ï„Î¿Ï€Î¹ÎºÎ® ÎµÏ€ÎµÎ¾ÎµÏÎ³Î±ÏƒÎ¯Î± Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½ Î³Î¹Î± Î´Î¹Î±Ï„Î®ÏÎ·ÏƒÎ· Ï„Î·Ï‚ Î¹Î´Î¹Ï‰Ï„Î¹ÎºÏŒÏ„Î·Ï„Î±Ï‚, ÎºÏÏ…Ï€Ï„Î¿Î³ÏÎ±Ï†Î·Î¼Î­Î½Î± ÎºÎ±Î½Î¬Î»Î¹Î± ÎµÏ€Î¹ÎºÎ¿Î¹Î½Ï‰Î½Î¯Î±Ï‚ Ï€ÏÎ±ÎºÏ„ÏŒÏÏ‰Î½, ÎµÎ»Î­Î³Ï‡Î¿Ï…Ï‚ Ï€ÏÏŒÏƒÎ²Î±ÏƒÎ·Ï‚ Î²Î¬ÏƒÎµÎ¹ ÏÏŒÎ»Ï‰Î½ Î³Î¹Î± Î´Ï…Î½Î±Ï„ÏŒÏ„Î·Ï„ÎµÏ‚ Ï€ÏÎ±ÎºÏ„ÏŒÏÏ‰Î½ ÎºÎ±Î¹ ÎºÎ±Ï„Î±Î³ÏÎ±Ï†Î® ÎµÎ½ÎµÏÎ³ÎµÎ¹ÏŽÎ½ Î³Î¹Î± Î±Ï€Î±Î¹Ï„Î®ÏƒÎµÎ¹Ï‚ ÏƒÏ…Î¼Î¼ÏŒÏÏ†Ï‰ÏƒÎ·Ï‚.  

### Î•Î½ÏƒÏ‰Î¼Î¬Ï„Ï‰ÏƒÎ· Î¼Îµ Ï„Î¿ Foundry Local  

Î¤Î¿ Microsoft Agent Framework ÎµÎ½ÏƒÏ‰Î¼Î±Ï„ÏŽÎ½ÎµÏ„Î±Î¹ Î±Ï€ÏÏŒÏƒÎºÎ¿Ï€Ï„Î± Î¼Îµ Ï„Î¿ Foundry Local Î³Î¹Î± Î½Î± Ï€Î±ÏÎ­Ï‡ÎµÎ¹ Î¼Î¹Î± Î¿Î»Î¿ÎºÎ»Î·ÏÏ‰Î¼Î­Î½Î· Î»ÏÏƒÎ· edge AI:  

**Î‘Ï…Ï„ÏŒÎ¼Î±Ï„Î· Î‘Î½Î±ÎºÎ¬Î»Ï…ÏˆÎ· ÎœÎ¿Î½Ï„Î­Î»Ï‰Î½**: Î¤Î¿ Ï€Î»Î±Î¯ÏƒÎ¹Î¿ Î±Î½Î¹Ï‡Î½ÎµÏÎµÎ¹ Î±Ï…Ï„ÏŒÎ¼Î±Ï„Î± ÎºÎ±Î¹ ÏƒÏ…Î½Î´Î­ÎµÏ„Î±Î¹ Î¼Îµ Ï€Î±ÏÎ¿Ï…ÏƒÎ¯ÎµÏ‚ Ï„Î¿Ï… Foundry Local, Î±Î½Î±ÎºÎ±Î»ÏÏ€Ï„ÎµÎ¹ Î´Î¹Î±Î¸Î­ÏƒÎ¹Î¼Î± Î¼Î¿Î½Ï„Î­Î»Î± SLM ÎºÎ±Î¹ ÎµÏ€Î¹Î»Î­Î³ÎµÎ¹ Î²Î­Î»Ï„Î¹ÏƒÏ„Î± Î¼Î¿Î½Ï„Î­Î»Î± Î²Î¬ÏƒÎµÎ¹ Î±Ï€Î±Î¹Ï„Î®ÏƒÎµÏ‰Î½ Ï€ÏÎ±ÎºÏ„ÏŒÏÏ‰Î½ ÎºÎ±Î¹ Î´Ï…Î½Î±Ï„Î¿Ï„Î®Ï„Ï‰Î½ Ï…Î»Î¹ÎºÎ¿Ï.  

**Î”Ï…Î½Î±Î¼Î¹ÎºÎ® Î¦ÏŒÏÏ„Ï‰ÏƒÎ· ÎœÎ¿Î½Ï„Î­Î»Ï‰Î½**: ÎŸÎ¹ Ï€ÏÎ¬ÎºÏ„Î¿ÏÎµÏ‚ Î¼Ï€Î¿ÏÎ¿ÏÎ½ Î½Î± Ï†Î¿ÏÏ„ÏŽÎ½Î¿Ï…Î½ Î´Ï…Î½Î±Î¼Î¹ÎºÎ¬ Î´Î¹Î±Ï†Î¿ÏÎµÏ„Î¹ÎºÎ¬ SLMs Î³Î¹Î± ÏƒÏ…Î³ÎºÎµÎºÏÎ¹Î¼Î­Î½ÎµÏ‚ ÎµÏÎ³Î±ÏƒÎ¯ÎµÏ‚, ÎµÏ€Î¹Ï„ÏÎ­Ï€Î¿Î½Ï„Î±Ï‚ ÏƒÏ…ÏƒÏ„Î®Î¼Î±Ï„Î± Ï€ÏÎ±ÎºÏ„ÏŒÏÏ‰Î½ Ï€Î¿Î»Î»Î±Ï€Î»ÏŽÎ½ Î¼Î¿Î½Ï„Î­Î»Ï‰Î½ ÏŒÏ€Î¿Ï… Î´Î¹Î±Ï†Î¿ÏÎµÏ„Î¹ÎºÎ¬ Î¼Î¿Î½Ï„Î­Î»Î± Ï‡ÎµÎ¹ÏÎ¯Î¶Î¿Î½Ï„Î±Î¹ Î´Î¹Î±Ï†Î¿ÏÎµÏ„Î¹ÎºÎ¿ÏÏ‚ Ï„ÏÏ€Î¿Ï…Ï‚ Î±Î¹Ï„Î·Î¼Î¬Ï„Ï‰Î½ ÎºÎ±Î¹ Î±Ï…Ï„ÏŒÎ¼Î±Ï„Î· ÎµÎ½Î±Î»Î»Î±ÎºÏ„Î¹ÎºÎ® Î»ÏÏƒÎ· Î¼ÎµÏ„Î±Î¾Ï Î¼Î¿Î½Ï„Î­Î»Ï‰Î½ Î²Î¬ÏƒÎµÎ¹ Î´Î¹Î±Î¸ÎµÏƒÎ¹Î¼ÏŒÏ„Î·Ï„Î±Ï‚ ÎºÎ±Î¹ Î±Ï€ÏŒÎ´Î¿ÏƒÎ·Ï‚.  

**Î’ÎµÎ»Ï„Î¹ÏƒÏ„Î¿Ï€Î¿Î¯Î·ÏƒÎ· Î‘Ï€ÏŒÎ´Î¿ÏƒÎ·Ï‚**: Î•Î½ÏƒÏ‰Î¼Î±Ï„Ï‰Î¼Î­Î½Î¿Î¹ Î¼Î·Ï‡Î±Î½Î¹ÏƒÎ¼Î¿Î¯ Ï€ÏÎ¿ÏƒÏ‰ÏÎ¹Î½Î®Ï‚ Î±Ï€Î¿Î¸Î®ÎºÎµÏ…ÏƒÎ·Ï‚ Î¼ÎµÎ¹ÏŽÎ½Î¿Ï…Î½ Ï„Î¿Ï…Ï‚ Ï‡ÏÏŒÎ½Î¿Ï…Ï‚ Ï†ÏŒÏÏ„Ï‰ÏƒÎ·Ï‚ Î¼Î¿Î½Ï„Î­Î»Ï‰Î½, Î· ÏƒÏ…Î³ÎºÎ­Î½Ï„ÏÏ‰ÏƒÎ· ÏƒÏ…Î½Î´Î­ÏƒÎµÏ‰Î½ Î²ÎµÎ»Ï„Î¹ÏƒÏ„Î¿Ï€Î¿Î¹ÎµÎ¯ Ï„Î¹Ï‚ ÎºÎ»Î®ÏƒÎµÎ¹Ï‚ API ÏƒÏ„Î¿ Foundry Local ÎºÎ±Î¹ Î· Î­Î¾Ï…Ï€Î½Î· Î¿Î¼Î±Î´Î¿Ï€Î¿Î¯Î·ÏƒÎ· Î²ÎµÎ»Ï„Î¹ÏŽÎ½ÎµÎ¹ Ï„Î·Î½ Î±Ï€ÏŒÎ´Î¿ÏƒÎ· Î³Î¹Î± Ï€Î¿Î»Î»Î±Ï€Î»Î¬ Î±Î¹Ï„Î®Î¼Î±Ï„Î± Ï€ÏÎ±ÎºÏ„ÏŒÏÏ‰Î½.  

### Î”Î·Î¼Î¹Î¿Ï…ÏÎ³Î¯Î± Î ÏÎ±ÎºÏ„ÏŒÏÏ‰Î½ Î¼Îµ Ï„Î¿ Microsoft Agent Framework  

#### ÎŸÏÎ¹ÏƒÎ¼ÏŒÏ‚ ÎºÎ±Î¹ Î¡ÏÎ¸Î¼Î¹ÏƒÎ· Î ÏÎ±ÎºÏ„ÏŒÏÏ‰Î½  

```python
from microsoft_agent_framework import Agent, Tool, Config
from foundry_local import FoundryLocalManager

# Configure agent with Foundry Local integration
config = Config(
    name="customer-service-agent",
    model_provider="foundry-local",
    model_alias="phi-4-mini",
    max_tokens=512,
    temperature=0.1,
    offline_mode=True
)

# Initialize Foundry Local connection
foundry = FoundryLocalManager("phi-4-mini")

# Create agent instance
agent = Agent(
    config=config,
    model_endpoint=foundry.endpoint,
    api_key=foundry.api_key
)
```
  
#### Î•Î½ÏƒÏ‰Î¼Î¬Ï„Ï‰ÏƒÎ· Î•ÏÎ³Î±Î»ÎµÎ¯Ï‰Î½ Î³Î¹Î± Î£ÎµÎ½Î¬ÏÎ¹Î± Edge  

```python
# Define tools for offline operation
@agent.tool
def lookup_customer_info(customer_id: str) -> dict:
    """Look up customer information from local database."""
    # Local database query - works offline
    return local_db.get_customer(customer_id)

@agent.tool
def create_support_ticket(issue: str, priority: str) -> str:
    """Create a support ticket in local system."""
    # Local ticket creation with sync when online
    ticket_id = local_system.create_ticket(issue, priority)
    return f"Ticket {ticket_id} created successfully"

@agent.tool
def schedule_callback(customer_id: str, preferred_time: str) -> str:
    """Schedule a callback for the customer."""
    # Local scheduling with calendar integration
    return local_calendar.schedule(customer_id, preferred_time)
```
  
#### ÎŸÏÏ‡Î®ÏƒÏ„ÏÏ‰ÏƒÎ· Î Î¿Î»Î»Î±Ï€Î»ÏŽÎ½ Î ÏÎ±ÎºÏ„ÏŒÏÏ‰Î½  

```python
from microsoft_agent_framework import AgentOrchestrator

# Create specialized agents for different domains
scheduling_agent = Agent(
    config=Config(
        name="scheduling-agent",
        model_alias="qwen2.5-0.5b",  # Lightweight for simple tasks
        specialized_for="scheduling"
    )
)

technical_support_agent = Agent(
    config=Config(
        name="technical-agent",
        model_alias="phi-4-mini",  # More capable for complex issues
        specialized_for="technical_support"
    )
)

# Orchestrate multiple agents
orchestrator = AgentOrchestrator([
    scheduling_agent,
    technical_support_agent
])

# Route requests based on intent
result = orchestrator.process_request(
    "I need to schedule a callback for a technical issue",
    routing_strategy="intent-based"
)
```
  

### Î ÏÎ¿Î·Î³Î¼Î­Î½Î± ÎœÎ¿Ï„Î¯Î²Î± Î‘Î½Î¬Ï€Ï„Ï…Î¾Î·Ï‚ ÏƒÏ„Î¿ Edge  

#### Î™ÎµÏÎ±ÏÏ‡Î¹ÎºÎ® Î‘ÏÏ‡Î¹Ï„ÎµÎºÏ„Î¿Î½Î¹ÎºÎ® Î ÏÎ±ÎºÏ„ÏŒÏÏ‰Î½  

**Î¤Î¿Ï€Î¹ÎºÎ¬ Î£Ï…Î¼Ï€Î»Î­Î³Î¼Î±Ï„Î± Î ÏÎ±ÎºÏ„ÏŒÏÏ‰Î½**: Î‘Î½Î¬Ï€Ï„Ï…Î¾Î· Ï€Î¿Î»Î»Î±Ï€Î»ÏŽÎ½ ÎµÎ¾ÎµÎ¹Î´Î¹ÎºÎµÏ…Î¼Î­Î½Ï‰Î½ Ï€ÏÎ±ÎºÏ„ÏŒÏÏ‰Î½ SLM ÏƒÎµ ÏƒÏ…ÏƒÎºÎµÏ…Î­Ï‚ edge, ÎºÎ±Î¸Î­Î½Î±Ï‚ Î²ÎµÎ»Ï„Î¹ÏƒÏ„Î¿Ï€Î¿Î¹Î·
**Î•Ï€Î¹Î»Î¿Î³Î® Î Î»Î±Î¹ÏƒÎ¯Î¿Ï… Î³Î¹Î± Î‘Î½Î¬Ï€Ï„Ï…Î¾Î· Î ÏÎ±ÎºÏ„ÏŒÏÏ‰Î½**: Î•Ï€Î¹Î»Î­Î¾Ï„Îµ Ï€Î»Î±Î¯ÏƒÎ¹Î± Î²ÎµÎ»Ï„Î¹ÏƒÏ„Î¿Ï€Î¿Î¯Î·ÏƒÎ·Ï‚ Î¼Îµ Î²Î¬ÏƒÎ· Ï„Î¿ Ï…Î»Î¹ÎºÏŒ ÏƒÏ„ÏŒÏ‡Î¿ ÎºÎ±Î¹ Ï„Î¹Ï‚ Î±Ï€Î±Î¹Ï„Î®ÏƒÎµÎ¹Ï‚ Ï„Ï‰Î½ Ï€ÏÎ±ÎºÏ„ÏŒÏÏ‰Î½. Î§ÏÎ·ÏƒÎ¹Î¼Î¿Ï€Î¿Î¹Î®ÏƒÏ„Îµ Ï„Î¿ Llama.cpp Î³Î¹Î± Î±Î½Î¬Ï€Ï„Ï…Î¾Î· Ï€ÏÎ±ÎºÏ„ÏŒÏÏ‰Î½ Î²ÎµÎ»Ï„Î¹ÏƒÏ„Î¿Ï€Î¿Î¹Î·Î¼Î­Î½Ï‰Î½ Î³Î¹Î± CPU, Ï„Î¿ Apple MLX Î³Î¹Î± ÎµÏ†Î±ÏÎ¼Î¿Î³Î­Ï‚ Ï€ÏÎ±ÎºÏ„ÏŒÏÏ‰Î½ ÏƒÎµ Apple Silicon ÎºÎ±Î¹ Ï„Î¿ ONNX Î³Î¹Î± ÏƒÏ…Î¼Î²Î±Ï„ÏŒÏ„Î·Ï„Î± Ï€ÏÎ±ÎºÏ„ÏŒÏÏ‰Î½ ÏƒÎµ Ï€Î¿Î»Î»Î±Ï€Î»Î­Ï‚ Ï€Î»Î±Ï„Ï†ÏŒÏÎ¼ÎµÏ‚.

## Î ÏÎ±ÎºÏ„Î¹ÎºÎ® ÎœÎµÏ„Î±Ï„ÏÎ¿Ï€Î® SLM Î ÏÎ±ÎºÏ„ÏŒÏÏ‰Î½ ÎºÎ±Î¹ Î ÎµÏÎ¹Ï€Ï„ÏŽÏƒÎµÎ¹Ï‚ Î§ÏÎ®ÏƒÎ·Ï‚

### Î£ÎµÎ½Î¬ÏÎ¹Î± Î‘Î½Î¬Ï€Ï„Ï…Î¾Î·Ï‚ Î ÏÎ±ÎºÏ„ÏŒÏÏ‰Î½ ÏƒÏ„Î¿Î½ Î ÏÎ±Î³Î¼Î±Ï„Î¹ÎºÏŒ ÎšÏŒÏƒÎ¼Î¿

**Î•Ï†Î±ÏÎ¼Î¿Î³Î­Ï‚ Î ÏÎ±ÎºÏ„ÏŒÏÏ‰Î½ ÏƒÎµ ÎšÎ¹Î½Î·Ï„Î­Ï‚ Î£Ï…ÏƒÎºÎµÏ…Î­Ï‚**: ÎŸÎ¹ Î¼Î¿ÏÏ†Î­Ï‚ Q4_K ÎµÎ¯Î½Î±Î¹ Î¹Î´Î±Î½Î¹ÎºÎ­Ï‚ Î³Î¹Î± ÎµÏ†Î±ÏÎ¼Î¿Î³Î­Ï‚ Ï€ÏÎ±ÎºÏ„ÏŒÏÏ‰Î½ ÏƒÎµ smartphones Î¼Îµ ÎµÎ»Î¬Ï‡Î¹ÏƒÏ„Î· ÎºÎ±Ï„Î±Î½Î¬Î»Ï‰ÏƒÎ· Î¼Î½Î®Î¼Î·Ï‚, ÎµÎ½ÏŽ Î¿Î¹ Q8_0 Ï€ÏÎ¿ÏƒÏ†Î­ÏÎ¿Ï…Î½ Î¹ÏƒÎ¿ÏÏÎ¿Ï€Î·Î¼Î­Î½Î· Î±Ï€ÏŒÎ´Î¿ÏƒÎ· Î³Î¹Î± ÏƒÏ…ÏƒÏ„Î®Î¼Î±Ï„Î± Ï€ÏÎ±ÎºÏ„ÏŒÏÏ‰Î½ ÏƒÎµ tablets. ÎŸÎ¹ Î¼Î¿ÏÏ†Î­Ï‚ Q5_K Ï€Î±ÏÎ­Ï‡Î¿Ï…Î½ Î±Î½ÏŽÏ„ÎµÏÎ· Ï€Î¿Î¹ÏŒÏ„Î·Ï„Î± Î³Î¹Î± Ï€ÏÎ±ÎºÏ„ÏŒÏÎµÏ‚ Ï€Î±ÏÎ±Î³Ï‰Î³Î¹ÎºÏŒÏ„Î·Ï„Î±Ï‚ ÏƒÎµ ÎºÎ¹Î½Î·Ï„Î­Ï‚ ÏƒÏ…ÏƒÎºÎµÏ…Î­Ï‚.

**Î¥Ï€Î¿Î»Î¿Î³Î¹ÏƒÏ„Î¹ÎºÎ® Î™ÏƒÏ‡ÏÏ‚ Î ÏÎ±ÎºÏ„ÏŒÏÏ‰Î½ ÏƒÎµ Î•Ï€Î¹Ï„ÏÎ±Ï€Î­Î¶Î¹Î¿Ï…Ï‚ Î¥Ï€Î¿Î»Î¿Î³Î¹ÏƒÏ„Î­Ï‚ ÎºÎ±Î¹ Edge Î£Ï…ÏƒÎºÎµÏ…Î­Ï‚**: ÎŸÎ¹ Q5_K Ï€ÏÎ¿ÏƒÏ†Î­ÏÎ¿Ï…Î½ Î²Î­Î»Ï„Î¹ÏƒÏ„Î· Î±Ï€ÏŒÎ´Î¿ÏƒÎ· Î³Î¹Î± ÎµÏ†Î±ÏÎ¼Î¿Î³Î­Ï‚ Ï€ÏÎ±ÎºÏ„ÏŒÏÏ‰Î½ ÏƒÎµ ÎµÏ€Î¹Ï„ÏÎ±Ï€Î­Î¶Î¹Î¿Ï…Ï‚ Ï…Ï€Î¿Î»Î¿Î³Î¹ÏƒÏ„Î­Ï‚, Î¿Î¹ Q8_0 Ï€Î±ÏÎ­Ï‡Î¿Ï…Î½ Ï…ÏˆÎ·Î»Î®Ï‚ Ï€Î¿Î¹ÏŒÏ„Î·Ï„Î±Ï‚ ÏƒÏ…Î¼Ï€ÎµÏÎ¬ÏƒÎ¼Î±Ï„Î± Î³Î¹Î± Ï€ÎµÏÎ¹Î²Î¬Î»Î»Î¿Î½Ï„Î± Ï€ÏÎ±ÎºÏ„ÏŒÏÏ‰Î½ ÏƒÎµ ÏƒÏ„Î±Î¸Î¼Î¿ÏÏ‚ ÎµÏÎ³Î±ÏƒÎ¯Î±Ï‚, ÎºÎ±Î¹ Î¿Î¹ Q4_K ÎµÏ€Î¹Ï„ÏÎ­Ï€Î¿Ï…Î½ Î±Ï€Î¿Î´Î¿Ï„Î¹ÎºÎ® ÎµÏ€ÎµÎ¾ÎµÏÎ³Î±ÏƒÎ¯Î± ÏƒÎµ edge ÏƒÏ…ÏƒÎºÎµÏ…Î­Ï‚.

**ÎˆÏÎµÏ…Î½Î± ÎºÎ±Î¹ Î ÎµÎ¹ÏÎ±Î¼Î±Ï„Î¹ÎºÎ¿Î¯ Î ÏÎ¬ÎºÏ„Î¿ÏÎµÏ‚**: Î ÏÎ¿Î·Î³Î¼Î­Î½ÎµÏ‚ Î¼Î¿ÏÏ†Î­Ï‚ Ï€Î¿ÏƒÎ¿Ï„Î¹ÎºÎ¿Ï€Î¿Î¯Î·ÏƒÎ·Ï‚ ÎµÏ€Î¹Ï„ÏÎ­Ï€Î¿Ï…Î½ Ï„Î·Î½ ÎµÎ¾ÎµÏÎµÏÎ½Î·ÏƒÎ· Ï€ÏÎ±ÎºÏ„ÏŒÏÏ‰Î½ Î¼Îµ ÎµÎ¾Î±Î¹ÏÎµÏ„Î¹ÎºÎ¬ Ï‡Î±Î¼Î·Î»Î® Î±ÎºÏÎ¯Î²ÎµÎ¹Î± Î³Î¹Î± Î±ÎºÎ±Î´Î·Î¼Î±ÏŠÎºÎ® Î­ÏÎµÏ…Î½Î± ÎºÎ±Î¹ ÎµÏ†Î±ÏÎ¼Î¿Î³Î­Ï‚ Ï€ÏÎ±ÎºÏ„ÏŒÏÏ‰Î½ proof-of-concept Ï€Î¿Ï… Î±Ï€Î±Î¹Ï„Î¿ÏÎ½ Î±ÎºÏÎ±Î¯Î¿Ï…Ï‚ Ï€ÎµÏÎ¹Î¿ÏÎ¹ÏƒÎ¼Î¿ÏÏ‚ Ï€ÏŒÏÏ‰Î½.

### Î”ÎµÎ¯ÎºÏ„ÎµÏ‚ Î‘Ï€ÏŒÎ´Î¿ÏƒÎ·Ï‚ Î ÏÎ±ÎºÏ„ÏŒÏÏ‰Î½ SLM

**Î¤Î±Ï‡ÏÏ„Î·Ï„Î± Î£Ï…Î¼Ï€ÎµÏÎ±ÏƒÎ¼Î¬Ï„Ï‰Î½ Î ÏÎ±ÎºÏ„ÏŒÏÏ‰Î½**: ÎŸÎ¹ Q4_K ÎµÏ€Î¹Ï„Ï…Î³Ï‡Î¬Î½Î¿Ï…Î½ Ï„Î¿Ï…Ï‚ Ï„Î±Ï‡ÏÏ„ÎµÏÎ¿Ï…Ï‚ Ï‡ÏÏŒÎ½Î¿Ï…Ï‚ Î±Ï€ÏŒÎºÏÎ¹ÏƒÎ·Ï‚ Ï€ÏÎ±ÎºÏ„ÏŒÏÏ‰Î½ ÏƒÎµ ÎºÎ¹Î½Î·Ï„Î­Ï‚ CPU, Î¿Î¹ Q5_K Ï€Î±ÏÎ­Ï‡Î¿Ï…Î½ Î¹ÏƒÎ¿ÏÏÎ¿Ï€Î·Î¼Î­Î½Î· Î±Î½Î±Î»Î¿Î³Î¯Î± Ï„Î±Ï‡ÏÏ„Î·Ï„Î±Ï‚-Ï€Î¿Î¹ÏŒÏ„Î·Ï„Î±Ï‚ Î³Î¹Î± Î³ÎµÎ½Î¹ÎºÎ­Ï‚ ÎµÏ†Î±ÏÎ¼Î¿Î³Î­Ï‚ Ï€ÏÎ±ÎºÏ„ÏŒÏÏ‰Î½, Î¿Î¹ Q8_0 Ï€ÏÎ¿ÏƒÏ†Î­ÏÎ¿Ï…Î½ Î±Î½ÏŽÏ„ÎµÏÎ· Ï€Î¿Î¹ÏŒÏ„Î·Ï„Î± Î³Î¹Î± ÏƒÏÎ½Î¸ÎµÏ„ÎµÏ‚ ÎµÏÎ³Î±ÏƒÎ¯ÎµÏ‚ Ï€ÏÎ±ÎºÏ„ÏŒÏÏ‰Î½, ÎºÎ±Î¹ Î¿Î¹ Ï€ÎµÎ¹ÏÎ±Î¼Î±Ï„Î¹ÎºÎ­Ï‚ Î¼Î¿ÏÏ†Î­Ï‚ ÎµÏ€Î¹Ï„Ï…Î³Ï‡Î¬Î½Î¿Ï…Î½ Î¼Î­Î³Î¹ÏƒÏ„Î· Î±Ï€ÏŒÎ´Î¿ÏƒÎ· Î³Î¹Î± ÎµÎ¾ÎµÎ¹Î´Î¹ÎºÎµÏ…Î¼Î­Î½Î¿ Ï…Î»Î¹ÎºÏŒ Ï€ÏÎ±ÎºÏ„ÏŒÏÏ‰Î½.

**Î‘Ï€Î±Î¹Ï„Î®ÏƒÎµÎ¹Ï‚ ÎœÎ½Î®Î¼Î·Ï‚ Î ÏÎ±ÎºÏ„ÏŒÏÏ‰Î½**: Î¤Î± ÎµÏ€Î¯Ï€ÎµÎ´Î± Ï€Î¿ÏƒÎ¿Ï„Î¹ÎºÎ¿Ï€Î¿Î¯Î·ÏƒÎ·Ï‚ Î³Î¹Î± Ï€ÏÎ±ÎºÏ„ÏŒÏÎµÏ‚ ÎºÏ…Î¼Î±Î¯Î½Î¿Î½Ï„Î±Î¹ Î±Ï€ÏŒ Q2_K (ÎºÎ¬Ï„Ï‰ Î±Ï€ÏŒ 500MB Î³Î¹Î± Î¼Î¹ÎºÏÎ¬ Î¼Î¿Î½Ï„Î­Î»Î± Ï€ÏÎ±ÎºÏ„ÏŒÏÏ‰Î½) Î­Ï‰Ï‚ Q8_0 (Ï€ÎµÏÎ¯Ï€Î¿Ï… 50% Ï„Î¿Ï… Î±ÏÏ‡Î¹ÎºÎ¿Ï Î¼ÎµÎ³Î­Î¸Î¿Ï…Ï‚), Î¼Îµ Ï€ÎµÎ¹ÏÎ±Î¼Î±Ï„Î¹ÎºÎ­Ï‚ Î´Î¹Î±Î¼Î¿ÏÏ†ÏŽÏƒÎµÎ¹Ï‚ Î½Î± ÎµÏ€Î¹Ï„Ï…Î³Ï‡Î¬Î½Î¿Ï…Î½ Î¼Î­Î³Î¹ÏƒÏ„Î· ÏƒÏ…Î¼Ï€Î¯ÎµÏƒÎ· Î³Î¹Î± Ï€ÎµÏÎ¹Î²Î¬Î»Î»Î¿Î½Ï„Î± Ï€ÏÎ±ÎºÏ„ÏŒÏÏ‰Î½ Î¼Îµ Ï€ÎµÏÎ¹Î¿ÏÎ¹ÏƒÎ¼Î­Î½Î¿Ï…Ï‚ Ï€ÏŒÏÎ¿Ï…Ï‚.

## Î ÏÎ¿ÎºÎ»Î®ÏƒÎµÎ¹Ï‚ ÎºÎ±Î¹ Î£ÎºÎ­ÏˆÎµÎ¹Ï‚ Î³Î¹Î± Î ÏÎ¬ÎºÏ„Î¿ÏÎµÏ‚ SLM

### Î£Ï…Î¼Î²Î¹Î²Î±ÏƒÎ¼Î¿Î¯ Î‘Ï€ÏŒÎ´Î¿ÏƒÎ·Ï‚ ÏƒÎµ Î£Ï…ÏƒÏ„Î®Î¼Î±Ï„Î± Î ÏÎ±ÎºÏ„ÏŒÏÏ‰Î½

Î— Î±Î½Î¬Ï€Ï„Ï…Î¾Î· Ï€ÏÎ±ÎºÏ„ÏŒÏÏ‰Î½ SLM Î±Ï€Î±Î¹Ï„ÎµÎ¯ Ï€ÏÎ¿ÏƒÎµÎºÏ„Î¹ÎºÎ® ÎµÎ¾Î­Ï„Î±ÏƒÎ· Ï„Ï‰Î½ ÏƒÏ…Î¼Î²Î¹Î²Î±ÏƒÎ¼ÏŽÎ½ Î¼ÎµÏ„Î±Î¾Ï Î¼ÎµÎ³Î­Î¸Î¿Ï…Ï‚ Î¼Î¿Î½Ï„Î­Î»Î¿Ï…, Ï„Î±Ï‡ÏÏ„Î·Ï„Î±Ï‚ Î±Ï€ÏŒÎºÏÎ¹ÏƒÎ·Ï‚ Ï€ÏÎ±ÎºÏ„ÏŒÏÏ‰Î½ ÎºÎ±Î¹ Ï€Î¿Î¹ÏŒÏ„Î·Ï„Î±Ï‚ ÎµÎ¾ÏŒÎ´Î¿Ï…. Î•Î½ÏŽ Î¿Î¹ Q4_K Ï€ÏÎ¿ÏƒÏ†Î­ÏÎ¿Ï…Î½ ÎµÎ¾Î±Î¹ÏÎµÏ„Î¹ÎºÎ® Ï„Î±Ï‡ÏÏ„Î·Ï„Î± ÎºÎ±Î¹ Î±Ï€Î¿Î´Î¿Ï„Î¹ÎºÏŒÏ„Î·Ï„Î± Î³Î¹Î± ÎºÎ¹Î½Î·Ï„Î¿ÏÏ‚ Ï€ÏÎ¬ÎºÏ„Î¿ÏÎµÏ‚, Î¿Î¹ Q8_0 Ï€Î±ÏÎ­Ï‡Î¿Ï…Î½ Î±Î½ÏŽÏ„ÎµÏÎ· Ï€Î¿Î¹ÏŒÏ„Î·Ï„Î± Î³Î¹Î± ÏƒÏÎ½Î¸ÎµÏ„ÎµÏ‚ ÎµÏÎ³Î±ÏƒÎ¯ÎµÏ‚ Ï€ÏÎ±ÎºÏ„ÏŒÏÏ‰Î½. ÎŸÎ¹ Q5_K Î²ÏÎ¯ÏƒÎºÎ¿Î½Ï„Î±Î¹ ÏƒÏ„Î· Î¼Î­ÏƒÎ· ÎºÎ±Î¹ ÎµÎ¯Î½Î±Î¹ ÎºÎ±Ï„Î¬Î»Î»Î·Î»Î¿Î¹ Î³Î¹Î± Ï„Î¹Ï‚ Ï€ÎµÏÎ¹ÏƒÏƒÏŒÏ„ÎµÏÎµÏ‚ Î³ÎµÎ½Î¹ÎºÎ­Ï‚ ÎµÏ†Î±ÏÎ¼Î¿Î³Î­Ï‚ Ï€ÏÎ±ÎºÏ„ÏŒÏÏ‰Î½.

### Î£Ï…Î¼Î²Î±Ï„ÏŒÏ„Î·Ï„Î± Î¥Î»Î¹ÎºÎ¿Ï Î³Î¹Î± Î ÏÎ¬ÎºÏ„Î¿ÏÎµÏ‚ SLM

Î”Î¹Î±Ï†Î¿ÏÎµÏ„Î¹ÎºÎ­Ï‚ edge ÏƒÏ…ÏƒÎºÎµÏ…Î­Ï‚ Î­Ï‡Î¿Ï…Î½ Ï€Î¿Î¹ÎºÎ¯Î»ÎµÏ‚ Î´Ï…Î½Î±Ï„ÏŒÏ„Î·Ï„ÎµÏ‚ Î³Î¹Î± Î±Î½Î¬Ï€Ï„Ï…Î¾Î· Ï€ÏÎ±ÎºÏ„ÏŒÏÏ‰Î½ SLM. ÎŸÎ¹ Q4_K Î»ÎµÎ¹Ï„Î¿Ï…ÏÎ³Î¿ÏÎ½ Î±Ï€Î¿Î´Î¿Ï„Î¹ÎºÎ¬ ÏƒÎµ Î²Î±ÏƒÎ¹ÎºÎ¿ÏÏ‚ ÎµÏ€ÎµÎ¾ÎµÏÎ³Î±ÏƒÏ„Î­Ï‚ Î³Î¹Î± Î±Ï€Î»Î¿ÏÏ‚ Ï€ÏÎ¬ÎºÏ„Î¿ÏÎµÏ‚, Î¿Î¹ Q5_K Î±Ï€Î±Î¹Ï„Î¿ÏÎ½ Î¼Î­Ï„ÏÎ¹Î¿Ï…Ï‚ Ï…Ï€Î¿Î»Î¿Î³Î¹ÏƒÏ„Î¹ÎºÎ¿ÏÏ‚ Ï€ÏŒÏÎ¿Ï…Ï‚ Î³Î¹Î± Î¹ÏƒÎ¿ÏÏÎ¿Ï€Î·Î¼Î­Î½Î· Î±Ï€ÏŒÎ´Î¿ÏƒÎ· Ï€ÏÎ±ÎºÏ„ÏŒÏÏ‰Î½, ÎºÎ±Î¹ Î¿Î¹ Q8_0 ÎµÏ€Ï‰Ï†ÎµÎ»Î¿ÏÎ½Ï„Î±Î¹ Î±Ï€ÏŒ Ï…Î»Î¹ÎºÏŒ Ï…ÏˆÎ·Î»Î®Ï‚ Î±Ï€ÏŒÎ´Î¿ÏƒÎ·Ï‚ Î³Î¹Î± Ï€ÏÎ¿Î·Î³Î¼Î­Î½ÎµÏ‚ Î´Ï…Î½Î±Ï„ÏŒÏ„Î·Ï„ÎµÏ‚ Ï€ÏÎ±ÎºÏ„ÏŒÏÏ‰Î½.

### Î‘ÏƒÏ†Î¬Î»ÎµÎ¹Î± ÎºÎ±Î¹ Î™Î´Î¹Ï‰Ï„Î¹ÎºÏŒÏ„Î·Ï„Î± ÏƒÎµ Î£Ï…ÏƒÏ„Î®Î¼Î±Ï„Î± Î ÏÎ±ÎºÏ„ÏŒÏÏ‰Î½ SLM

Î•Î½ÏŽ Î¿Î¹ Ï€ÏÎ¬ÎºÏ„Î¿ÏÎµÏ‚ SLM ÎµÏ€Î¹Ï„ÏÎ­Ï€Î¿Ï…Î½ Ï„Î¿Ï€Î¹ÎºÎ® ÎµÏ€ÎµÎ¾ÎµÏÎ³Î±ÏƒÎ¯Î± Î³Î¹Î± ÎµÎ½Î¹ÏƒÏ‡Ï…Î¼Î­Î½Î· Î¹Î´Î¹Ï‰Ï„Î¹ÎºÏŒÏ„Î·Ï„Î±, Ï€ÏÎ­Ï€ÎµÎ¹ Î½Î± ÎµÏ†Î±ÏÎ¼Î¿ÏƒÏ„Î¿ÏÎ½ ÎºÎ±Ï„Î¬Î»Î»Î·Î»Î± Î¼Î­Ï„ÏÎ± Î±ÏƒÏ†Î±Î»ÎµÎ¯Î±Ï‚ Î³Î¹Î± Ï„Î·Î½ Ï€ÏÎ¿ÏƒÏ„Î±ÏƒÎ¯Î± Ï„Ï‰Î½ Î¼Î¿Î½Ï„Î­Î»Ï‰Î½ Ï€ÏÎ±ÎºÏ„ÏŒÏÏ‰Î½ ÎºÎ±Î¹ Ï„Ï‰Î½ Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½ ÏƒÎµ edge Ï€ÎµÏÎ¹Î²Î¬Î»Î»Î¿Î½Ï„Î±. Î‘Ï…Ï„ÏŒ ÎµÎ¯Î½Î±Î¹ Î¹Î´Î¹Î±Î¯Ï„ÎµÏÎ± ÏƒÎ·Î¼Î±Î½Ï„Î¹ÎºÏŒ ÎºÎ±Ï„Î¬ Ï„Î·Î½ Î±Î½Î¬Ï€Ï„Ï…Î¾Î· Ï€ÏÎ±ÎºÏ„ÏŒÏÏ‰Î½ Ï…ÏˆÎ·Î»Î®Ï‚ Î±ÎºÏÎ¯Î²ÎµÎ¹Î±Ï‚ ÏƒÎµ ÎµÏ„Î±Î¹ÏÎ¹ÎºÎ¬ Ï€ÎµÏÎ¹Î²Î¬Î»Î»Î¿Î½Ï„Î± Î® ÏƒÏ…Î¼Ï€Î¹ÎµÏƒÎ¼Î­Î½Ï‰Î½ Ï€ÏÎ±ÎºÏ„ÏŒÏÏ‰Î½ ÏƒÎµ ÎµÏ†Î±ÏÎ¼Î¿Î³Î­Ï‚ Ï€Î¿Ï… Ï‡ÎµÎ¹ÏÎ¯Î¶Î¿Î½Ï„Î±Î¹ ÎµÏ…Î±Î¯ÏƒÎ¸Î·Ï„Î± Î´ÎµÎ´Î¿Î¼Î­Î½Î±.

## ÎœÎµÎ»Î»Î¿Î½Ï„Î¹ÎºÎ­Ï‚ Î¤Î¬ÏƒÎµÎ¹Ï‚ ÏƒÏ„Î·Î½ Î‘Î½Î¬Ï€Ï„Ï…Î¾Î· Î ÏÎ±ÎºÏ„ÏŒÏÏ‰Î½ SLM

Î¤Î¿ Ï„Î¿Ï€Î¯Î¿ Ï„Ï‰Î½ Ï€ÏÎ±ÎºÏ„ÏŒÏÏ‰Î½ SLM ÏƒÏ…Î½ÎµÏ‡Î¯Î¶ÎµÎ¹ Î½Î± ÎµÎ¾ÎµÎ»Î¯ÏƒÏƒÎµÏ„Î±Î¹ Î¼Îµ Ï€ÏÎ¿ÏŒÎ´Î¿Ï…Ï‚ ÏƒÏ„Î¹Ï‚ Ï„ÎµÏ‡Î½Î¹ÎºÎ­Ï‚ ÏƒÏ…Î¼Ï€Î¯ÎµÏƒÎ·Ï‚, Ï„Î¹Ï‚ Î¼ÎµÎ¸ÏŒÎ´Î¿Ï…Ï‚ Î²ÎµÎ»Ï„Î¹ÏƒÏ„Î¿Ï€Î¿Î¯Î·ÏƒÎ·Ï‚ ÎºÎ±Î¹ Ï„Î¹Ï‚ ÏƒÏ„ÏÎ±Ï„Î·Î³Î¹ÎºÎ­Ï‚ Î±Î½Î¬Ï€Ï„Ï…Î¾Î·Ï‚ ÏƒÎµ edge ÏƒÏ…ÏƒÎºÎµÏ…Î­Ï‚. ÎŸÎ¹ Î¼ÎµÎ»Î»Î¿Î½Ï„Î¹ÎºÎ­Ï‚ ÎµÎ¾ÎµÎ»Î¯Î¾ÎµÎ¹Ï‚ Ï€ÎµÏÎ¹Î»Î±Î¼Î²Î¬Î½Î¿Ï…Î½ Ï€Î¹Î¿ Î±Ï€Î¿Î´Î¿Ï„Î¹ÎºÎ¿ÏÏ‚ Î±Î»Î³ÏŒÏÎ¹Î¸Î¼Î¿Ï…Ï‚ Ï€Î¿ÏƒÎ¿Ï„Î¹ÎºÎ¿Ï€Î¿Î¯Î·ÏƒÎ·Ï‚ Î³Î¹Î± Î¼Î¿Î½Ï„Î­Î»Î± Ï€ÏÎ±ÎºÏ„ÏŒÏÏ‰Î½, Î²ÎµÎ»Ï„Î¹Ï‰Î¼Î­Î½ÎµÏ‚ Î¼ÎµÎ¸ÏŒÎ´Î¿Ï…Ï‚ ÏƒÏ…Î¼Ï€Î¯ÎµÏƒÎ·Ï‚ Î³Î¹Î± ÏÎ¿Î­Ï‚ ÎµÏÎ³Î±ÏƒÎ¯Î±Ï‚ Ï€ÏÎ±ÎºÏ„ÏŒÏÏ‰Î½ ÎºÎ±Î¹ ÎºÎ±Î»ÏÏ„ÎµÏÎ· ÎµÎ½ÏƒÏ‰Î¼Î¬Ï„Ï‰ÏƒÎ· Î¼Îµ ÎµÏ€Î¹Ï„Î±Ï‡Ï…Î½Ï„Î­Ï‚ Ï…Î»Î¹ÎºÎ¿Ï edge Î³Î¹Î± ÎµÏ€ÎµÎ¾ÎµÏÎ³Î±ÏƒÎ¯Î± Ï€ÏÎ±ÎºÏ„ÏŒÏÏ‰Î½.

**Î ÏÎ¿Î²Î»Î­ÏˆÎµÎ¹Ï‚ Î‘Î³Î¿ÏÎ¬Ï‚ Î³Î¹Î± Î ÏÎ¬ÎºÏ„Î¿ÏÎµÏ‚ SLM**: Î£ÏÎ¼Ï†Ï‰Î½Î± Î¼Îµ Ï€ÏÏŒÏƒÏ†Î±Ï„Î· Î­ÏÎµÏ…Î½Î±, Î· Î±Ï…Ï„Î¿Î¼Î±Ï„Î¿Ï€Î¿Î¯Î·ÏƒÎ· Î¼Îµ Ï„Î· Î²Î¿Î®Î¸ÎµÎ¹Î± Ï€ÏÎ±ÎºÏ„ÏŒÏÏ‰Î½ Î¸Î± Î¼Ï€Î¿ÏÎ¿ÏÏƒÎµ Î½Î± ÎµÎ¾Î±Î»ÎµÎ¯ÏˆÎµÎ¹ Ï„Î¿ 40â€“60% Ï„Ï‰Î½ ÎµÏ€Î±Î½Î±Î»Î±Î¼Î²Î±Î½ÏŒÎ¼ÎµÎ½Ï‰Î½ Î³Î½Ï‰ÏƒÏ„Î¹ÎºÏŽÎ½ ÎµÏÎ³Î±ÏƒÎ¹ÏŽÎ½ ÏƒÎµ ÎµÏ„Î±Î¹ÏÎ¹ÎºÎ­Ï‚ ÏÎ¿Î­Ï‚ ÎµÏÎ³Î±ÏƒÎ¯Î±Ï‚ Î­Ï‰Ï‚ Ï„Î¿ 2027, Î¼Îµ Ï„Î¿Ï…Ï‚ SLM Î½Î± Î·Î³Î¿ÏÎ½Ï„Î±Î¹ Î±Ï…Ï„Î®Ï‚ Ï„Î·Ï‚ Î¼ÎµÏ„Î±Î¼ÏŒÏÏ†Ï‰ÏƒÎ·Ï‚ Î»ÏŒÎ³Ï‰ Ï„Î·Ï‚ Î¿Î¹ÎºÎ¿Î½Î¿Î¼Î¹ÎºÎ®Ï‚ Î±Ï€Î¿Î´Î¿Ï„Î¹ÎºÏŒÏ„Î·Ï„Î±Ï‚ ÎºÎ±Î¹ Ï„Î·Ï‚ ÎµÏ…ÎµÎ»Î¹Î¾Î¯Î±Ï‚ Î±Î½Î¬Ï€Ï„Ï…Î¾Î·Ï‚.

**Î¤ÎµÏ‡Î½Î¿Î»Î¿Î³Î¹ÎºÎ­Ï‚ Î¤Î¬ÏƒÎµÎ¹Ï‚ ÏƒÏ„Î¿Ï…Ï‚ Î ÏÎ¬ÎºÏ„Î¿ÏÎµÏ‚ SLM**:
- **Î•Î¾ÎµÎ¹Î´Î¹ÎºÎµÏ…Î¼Î­Î½Î¿Î¹ Î ÏÎ¬ÎºÏ„Î¿ÏÎµÏ‚ SLM**: ÎœÎ¿Î½Ï„Î­Î»Î± ÎµÎ¹Î´Î¹ÎºÎ¬ ÎµÎºÏ€Î±Î¹Î´ÎµÏ…Î¼Î­Î½Î± Î³Î¹Î± ÏƒÏ…Î³ÎºÎµÎºÏÎ¹Î¼Î­Î½ÎµÏ‚ ÎµÏÎ³Î±ÏƒÎ¯ÎµÏ‚ Ï€ÏÎ±ÎºÏ„ÏŒÏÏ‰Î½ ÎºÎ±Î¹ Î²Î¹Î¿Î¼Î·Ï‡Î±Î½Î¯ÎµÏ‚
- **Î¥Ï€Î¿Î»Î¿Î³Î¹ÏƒÏ„Î¹ÎºÎ® Î™ÏƒÏ‡ÏÏ‚ Î ÏÎ±ÎºÏ„ÏŒÏÏ‰Î½ ÏƒÎµ Edge Î£Ï…ÏƒÎºÎµÏ…Î­Ï‚**: Î•Î½Î¹ÏƒÏ‡Ï…Î¼Î­Î½ÎµÏ‚ Î´Ï…Î½Î±Ï„ÏŒÏ„Î·Ï„ÎµÏ‚ Ï€ÏÎ±ÎºÏ„ÏŒÏÏ‰Î½ ÏƒÎµ ÏƒÏ…ÏƒÎºÎµÏ…Î­Ï‚ Î¼Îµ Î²ÎµÎ»Ï„Î¹Ï‰Î¼Î­Î½Î· Î¹Î´Î¹Ï‰Ï„Î¹ÎºÏŒÏ„Î·Ï„Î± ÎºÎ±Î¹ Î¼ÎµÎ¹Ï‰Î¼Î­Î½Î· ÎºÎ±Î¸Ï…ÏƒÏ„Î­ÏÎ·ÏƒÎ·
- **ÎŸÏÏ‡Î®ÏƒÏ„ÏÎ± Î ÏÎ±ÎºÏ„ÏŒÏÏ‰Î½**: ÎšÎ±Î»ÏÏ„ÎµÏÎ¿Ï‚ ÏƒÏ…Î½Ï„Î¿Î½Î¹ÏƒÎ¼ÏŒÏ‚ Î¼ÎµÏ„Î±Î¾Ï Ï€Î¿Î»Î»Î±Ï€Î»ÏŽÎ½ Ï€ÏÎ±ÎºÏ„ÏŒÏÏ‰Î½ SLM Î¼Îµ Î´Ï…Î½Î±Î¼Î¹ÎºÎ® Î´ÏÎ¿Î¼Î¿Î»ÏŒÎ³Î·ÏƒÎ· ÎºÎ±Î¹ ÎµÎ¾Î¹ÏƒÎ¿ÏÏÏŒÏ€Î·ÏƒÎ· Ï†Î¿ÏÏ„Î¯Î¿Ï…
- **Î”Î·Î¼Î¿ÎºÏÎ±Ï„Î¹ÎºÎ¿Ï€Î¿Î¯Î·ÏƒÎ·**: Î— ÎµÏ…ÎµÎ»Î¹Î¾Î¯Î± Ï„Ï‰Î½ SLM ÎµÏ€Î¹Ï„ÏÎ­Ï€ÎµÎ¹ ÎµÏ…ÏÏÏ„ÎµÏÎ· ÏƒÏ…Î¼Î¼ÎµÏ„Î¿Ï‡Î® ÏƒÏ„Î·Î½ Î±Î½Î¬Ï€Ï„Ï…Î¾Î· Ï€ÏÎ±ÎºÏ„ÏŒÏÏ‰Î½ Î±Ï€ÏŒ Î¿ÏÎ³Î±Î½Î¹ÏƒÎ¼Î¿ÏÏ‚

## ÎžÎµÎºÎ¹Î½ÏŽÎ½Ï„Î±Ï‚ Î¼Îµ Î ÏÎ¬ÎºÏ„Î¿ÏÎµÏ‚ SLM

### Î’Î®Î¼Î± 1: Î¡ÏÎ¸Î¼Î¹ÏƒÎ· Î ÎµÏÎ¹Î²Î¬Î»Î»Î¿Î½Ï„Î¿Ï‚ Microsoft Agent Framework

**Î•Î³ÎºÎ±Ï„Î¬ÏƒÏ„Î±ÏƒÎ· Î•Î¾Î±ÏÏ„Î®ÏƒÎµÏ‰Î½**:
```bash
# Install Microsoft Agent Framework
pip install microsoft-agent-framework

# Install Foundry Local SDK for edge deployment
pip install foundry-local-sdk

# Install additional dependencies for edge agents
pip install openai asyncio
```

**Î‘ÏÏ‡Î¹ÎºÎ¿Ï€Î¿Î¯Î·ÏƒÎ· Foundry Local**:
```bash
# Start Foundry Local service
foundry service start

# Load default model for agent development
foundry model run phi-4-mini
```

### Î’Î®Î¼Î± 2: Î•Ï€Î¹Î»Î­Î¾Ï„Îµ Ï„Î¿ SLM Î³Î¹Î± Î•Ï†Î±ÏÎ¼Î¿Î³Î­Ï‚ Î ÏÎ±ÎºÏ„ÏŒÏÏ‰Î½
Î”Î·Î¼Î¿Ï†Î¹Î»ÎµÎ¯Ï‚ ÎµÏ€Î¹Î»Î¿Î³Î­Ï‚ Î³Î¹Î± Ï„Î¿ Microsoft Agent Framework:
- **Microsoft Phi-4 Mini (3.8B)**: Î•Î¾Î±Î¹ÏÎµÏ„Î¹ÎºÏŒ Î³Î¹Î± Î³ÎµÎ½Î¹ÎºÎ­Ï‚ ÎµÏÎ³Î±ÏƒÎ¯ÎµÏ‚ Ï€ÏÎ±ÎºÏ„ÏŒÏÏ‰Î½ Î¼Îµ Î¹ÏƒÎ¿ÏÏÎ¿Ï€Î·Î¼Î­Î½Î· Î±Ï€ÏŒÎ´Î¿ÏƒÎ·
- **Qwen2.5-0.5B (0.5B)**: Î¥Ï€ÎµÏ-Î±Ï€Î¿Î´Î¿Ï„Î¹ÎºÏŒ Î³Î¹Î± Î±Ï€Î»Î¿ÏÏ‚ Ï€ÏÎ¬ÎºÏ„Î¿ÏÎµÏ‚ Î´ÏÎ¿Î¼Î¿Î»ÏŒÎ³Î·ÏƒÎ·Ï‚ ÎºÎ±Î¹ Ï„Î±Î¾Î¹Î½ÏŒÎ¼Î·ÏƒÎ·Ï‚
- **Qwen2.5-Coder-0.5B (0.5B)**: Î•Î¾ÎµÎ¹Î´Î¹ÎºÎµÏ…Î¼Î­Î½Î¿ Î³Î¹Î± ÎµÏÎ³Î±ÏƒÎ¯ÎµÏ‚ Ï€ÏÎ±ÎºÏ„ÏŒÏÏ‰Î½ Ï€Î¿Ï… ÏƒÏ‡ÎµÏ„Î¯Î¶Î¿Î½Ï„Î±Î¹ Î¼Îµ ÎºÏŽÎ´Î¹ÎºÎ±
- **Phi-4 (7B)**: Î ÏÎ¿Î·Î³Î¼Î­Î½Î· Î»Î¿Î³Î¹ÎºÎ® Î³Î¹Î± ÏƒÏÎ½Î¸ÎµÏ„Î± edge ÏƒÎµÎ½Î¬ÏÎ¹Î± ÏŒÏ„Î±Î½ Ï…Ï€Î¬ÏÏ‡Î¿Ï…Î½ Î´Î¹Î±Î¸Î­ÏƒÎ¹Î¼Î¿Î¹ Ï€ÏŒÏÎ¿Î¹

### Î’Î®Î¼Î± 3: Î”Î·Î¼Î¹Î¿Ï…ÏÎ³Î®ÏƒÏ„Îµ Ï„Î¿Î½ Î ÏÏŽÏ„Î¿ ÏƒÎ±Ï‚ Î ÏÎ¬ÎºÏ„Î¿ÏÎ± Î¼Îµ Ï„Î¿ Microsoft Agent Framework

**Î’Î±ÏƒÎ¹ÎºÎ® Î¡ÏÎ¸Î¼Î¹ÏƒÎ· Î ÏÎ¬ÎºÏ„Î¿ÏÎ±**:
```python
from microsoft_agent_framework import Agent, Config
from foundry_local import FoundryLocalManager

# Initialize Foundry Local connection
foundry = FoundryLocalManager("phi-4-mini")

# Create agent configuration
config = Config(
    name="my-first-agent",
    model_provider="foundry-local",
    model_alias="phi-4-mini",
    offline_mode=True
)

# Create and configure agent
agent = Agent(
    config=config,
    model_endpoint=foundry.endpoint,
    api_key=foundry.api_key
)

# Define a simple tool
@agent.tool
def get_current_time() -> str:
    """Get the current time."""
    from datetime import datetime
    return datetime.now().strftime("%Y-%m-%d %H:%M:%S")

# Test the agent
response = agent.chat("What time is it?")
print(response)
```

### Î’Î®Î¼Î± 4: ÎŸÏÎ¯ÏƒÏ„Îµ Î ÎµÎ´Î¯Î¿ ÎºÎ±Î¹ Î‘Ï€Î±Î¹Ï„Î®ÏƒÎµÎ¹Ï‚ Î ÏÎ¬ÎºÏ„Î¿ÏÎ±
ÎžÎµÎºÎ¹Î½Î®ÏƒÏ„Îµ Î¼Îµ ÎµÏƒÏ„Î¹Î±ÏƒÎ¼Î­Î½ÎµÏ‚, ÎºÎ±Î»Î¬ ÎºÎ±Î¸Î¿ÏÎ¹ÏƒÎ¼Î­Î½ÎµÏ‚ ÎµÏ†Î±ÏÎ¼Î¿Î³Î­Ï‚ Ï€ÏÎ±ÎºÏ„ÏŒÏÏ‰Î½ Ï‡ÏÎ·ÏƒÎ¹Î¼Î¿Ï€Î¿Î¹ÏŽÎ½Ï„Î±Ï‚ Ï„Î¿ Microsoft Agent Framework:
- **Î ÏÎ¬ÎºÏ„Î¿ÏÎµÏ‚ ÎµÎ½ÏŒÏ‚ Ï„Î¿Î¼Î­Î±**: Î•Î¾Ï…Ï€Î·ÏÎ­Ï„Î·ÏƒÎ· Ï€ÎµÎ»Î±Ï„ÏŽÎ½ Î‰ Ï€ÏÎ¿Î³ÏÎ±Î¼Î¼Î±Ï„Î¹ÏƒÎ¼ÏŒÏ‚ Î‰ Î­ÏÎµÏ…Î½Î±
- **Î£Î±Ï†ÎµÎ¯Ï‚ ÏƒÏ„ÏŒÏ‡Î¿Î¹ Ï€ÏÎ±ÎºÏ„ÏŒÏÏ‰Î½**: Î£Ï…Î³ÎºÎµÎºÏÎ¹Î¼Î­Î½Î¿Î¹, Î¼ÎµÏ„ÏÎ®ÏƒÎ¹Î¼Î¿Î¹ ÏƒÏ„ÏŒÏ‡Î¿Î¹ Î³Î¹Î± Ï„Î·Î½ Î±Ï€ÏŒÎ´Î¿ÏƒÎ· Ï€ÏÎ±ÎºÏ„ÏŒÏÏ‰Î½
- **Î ÎµÏÎ¹Î¿ÏÎ¹ÏƒÎ¼Î­Î½Î· ÎµÎ½ÏƒÏ‰Î¼Î¬Ï„Ï‰ÏƒÎ· ÎµÏÎ³Î±Î»ÎµÎ¯Ï‰Î½**: ÎœÎ­Î³Î¹ÏƒÏ„Î¿ 3-5 ÎµÏÎ³Î±Î»ÎµÎ¯Î± Î³Î¹Î± Î±ÏÏ‡Î¹ÎºÎ® Î±Î½Î¬Ï€Ï„Ï…Î¾Î· Ï€ÏÎ±ÎºÏ„ÏŒÏÏ‰Î½
- **ÎšÎ±Î¸Î¿ÏÎ¹ÏƒÎ¼Î­Î½Î± ÏŒÏÎ¹Î± Ï€ÏÎ±ÎºÏ„ÏŒÏÏ‰Î½**: Î£Î±Ï†ÎµÎ¯Ï‚ Î´Î¹Î±Î´ÏÎ¿Î¼Î­Ï‚ ÎºÎ»Î¹Î¼Î¬ÎºÏ‰ÏƒÎ·Ï‚ Î³Î¹Î± ÏƒÏÎ½Î¸ÎµÏ„Î± ÏƒÎµÎ½Î¬ÏÎ¹Î±
- **Î£Ï‡ÎµÎ´Î¹Î±ÏƒÎ¼ÏŒÏ‚ Î¼Îµ Ï€ÏÎ¿Ï„ÎµÏÎ±Î¹ÏŒÏ„Î·Ï„Î± ÏƒÏ„Î¿ edge**: Î”ÏŽÏƒÏ„Îµ Î­Î¼Ï†Î±ÏƒÎ· ÏƒÏ„Î· Î»ÎµÎ¹Ï„Î¿Ï…ÏÎ³Î¹ÎºÏŒÏ„Î·Ï„Î± ÎµÎºÏ„ÏŒÏ‚ ÏƒÏÎ½Î´ÎµÏƒÎ·Ï‚ ÎºÎ±Î¹ Ï„Î·Î½ Ï„Î¿Ï€Î¹ÎºÎ® ÎµÏ€ÎµÎ¾ÎµÏÎ³Î±ÏƒÎ¯Î±

### Î’Î®Î¼Î± 5: Î•Ï†Î±ÏÎ¼ÏŒÏƒÏ„Îµ Î‘Î½Î¬Ï€Ï„Ï…Î¾Î· ÏƒÏ„Î¿ Edge Î¼Îµ Ï„Î¿ Microsoft Agent Framework

**Î”Î¹Î±Î¼ÏŒÏÏ†Ï‰ÏƒÎ· Î ÏŒÏÏ‰Î½**:
```python
from microsoft_agent_framework import ResourceConfig

# Configure for edge deployment
resource_config = ResourceConfig(
    max_memory_usage="2GB",
    max_concurrent_agents=2,
    model_cache_size="1GB",
    auto_unload_idle_models=True,
    power_management=True
)

agent = Agent(
    config=config,
    resource_limits=resource_config
)
```

**Î‘Î½Î¬Ï€Ï„Ï…Î¾Î· ÎœÎ­Ï„ÏÏ‰Î½ Î‘ÏƒÏ†Î±Î»ÎµÎ¯Î±Ï‚ Î³Î¹Î± Edge Î ÏÎ¬ÎºÏ„Î¿ÏÎµÏ‚**:
- **Î¤Î¿Ï€Î¹ÎºÎ® ÎµÏ€Î¹ÎºÏÏÏ‰ÏƒÎ· ÎµÎ¹ÏƒÏŒÎ´Î¿Ï…**: Î•Î»Î­Î³Î¾Ï„Îµ Î±Î¹Ï„Î®Î¼Î±Ï„Î± Ï‡Ï‰ÏÎ¯Ï‚ ÎµÎ¾Î¬ÏÏ„Î·ÏƒÎ· Î±Ï€ÏŒ Ï„Î¿ cloud
- **Î¦Î¹Î»Ï„ÏÎ¬ÏÎ¹ÏƒÎ¼Î± ÎµÎ¾ÏŒÎ´Î¿Ï… ÎµÎºÏ„ÏŒÏ‚ ÏƒÏÎ½Î´ÎµÏƒÎ·Ï‚**: Î’ÎµÎ²Î±Î¹Ï‰Î¸ÎµÎ¯Ï„Îµ ÏŒÏ„Î¹ Î¿Î¹ Î±Ï€Î±Î½Ï„Î®ÏƒÎµÎ¹Ï‚ Ï€Î»Î·ÏÎ¿ÏÎ½ Ï„Î± Ï€ÏÏŒÏ„Ï…Ï€Î± Ï€Î¿Î¹ÏŒÏ„Î·Ï„Î±Ï‚ Ï„Î¿Ï€Î¹ÎºÎ¬
- **ÎˆÎ»ÎµÎ³Ï‡Î¿Î¹ Î±ÏƒÏ†Î±Î»ÎµÎ¯Î±Ï‚ ÏƒÏ„Î¿ edge**: Î•Ï†Î±ÏÎ¼ÏŒÏƒÏ„Îµ Î¼Î­Ï„ÏÎ± Î±ÏƒÏ†Î±Î»ÎµÎ¯Î±Ï‚ Ï‡Ï‰ÏÎ¯Ï‚ Î½Î± Î±Ï€Î±Î¹Ï„ÎµÎ¯Ï„Î±Î¹ ÏƒÏÎ½Î´ÎµÏƒÎ· ÏƒÏ„Î¿ Î´Î¹Î±Î´Î¯ÎºÏ„Ï…Î¿
- **Î¤Î¿Ï€Î¹ÎºÎ® Ï€Î±ÏÎ±ÎºÎ¿Î»Î¿ÏÎ¸Î·ÏƒÎ·**: Î Î±ÏÎ±ÎºÎ¿Î»Î¿Ï…Î¸Î®ÏƒÏ„Îµ Ï„Î·Î½ Î±Ï€ÏŒÎ´Î¿ÏƒÎ· ÎºÎ±Î¹ ÎµÎ½Ï„Î¿Ï€Î¯ÏƒÏ„Îµ Ï€ÏÎ¿Î²Î»Î®Î¼Î±Ï„Î± Ï‡ÏÎ·ÏƒÎ¹Î¼Î¿Ï€Î¿Î¹ÏŽÎ½Ï„Î±Ï‚ Ï„Î·Î»ÎµÎ¼ÎµÏ„ÏÎ¯Î± edge

### Î’Î®Î¼Î± 6: ÎœÎµÏ„ÏÎ®ÏƒÏ„Îµ ÎºÎ±Î¹ Î’ÎµÎ»Ï„Î¹ÏƒÏ„Î¿Ï€Î¿Î¹Î®ÏƒÏ„Îµ Ï„Î·Î½ Î‘Ï€ÏŒÎ´Î¿ÏƒÎ· Î ÏÎ±ÎºÏ„ÏŒÏÏ‰Î½ ÏƒÏ„Î¿ Edge
- **Î Î¿ÏƒÎ¿ÏƒÏ„Î¬ Î¿Î»Î¿ÎºÎ»Î®ÏÏ‰ÏƒÎ·Ï‚ ÎµÏÎ³Î±ÏƒÎ¹ÏŽÎ½ Ï€ÏÎ±ÎºÏ„ÏŒÏÏ‰Î½**: Î Î±ÏÎ±ÎºÎ¿Î»Î¿Ï…Î¸Î®ÏƒÏ„Îµ Ï€Î¿ÏƒÎ¿ÏƒÏ„Î¬ ÎµÏ€Î¹Ï„Ï…Ï‡Î¯Î±Ï‚ ÏƒÎµ ÏƒÎµÎ½Î¬ÏÎ¹Î± ÎµÎºÏ„ÏŒÏ‚ ÏƒÏÎ½Î´ÎµÏƒÎ·Ï‚
- **Î§ÏÏŒÎ½Î¿Î¹ Î±Ï€ÏŒÎºÏÎ¹ÏƒÎ·Ï‚ Ï€ÏÎ±ÎºÏ„ÏŒÏÏ‰Î½**: Î•Î¾Î±ÏƒÏ†Î±Î»Î¯ÏƒÏ„Îµ Ï‡ÏÏŒÎ½Î¿Ï…Ï‚ Î±Ï€ÏŒÎºÏÎ¹ÏƒÎ·Ï‚ ÎºÎ¬Ï„Ï‰ Ï„Î¿Ï… Î´ÎµÏ…Ï„ÎµÏÎ¿Î»Î­Ï€Ï„Î¿Ï… Î³Î¹Î± Î±Î½Î¬Ï€Ï„Ï…Î¾Î· ÏƒÏ„Î¿ edge
- **Î§ÏÎ®ÏƒÎ· Ï€ÏŒÏÏ‰Î½**: Î Î±ÏÎ±ÎºÎ¿Î»Î¿Ï…Î¸Î®ÏƒÏ„Îµ Ï„Î· Î¼Î½Î®Î¼Î·, Ï„Î·Î½ CPU ÎºÎ±Î¹ Ï„Î·Î½ ÎºÎ±Ï„Î±Î½Î¬Î»Ï‰ÏƒÎ· Î¼Ï€Î±Ï„Î±ÏÎ¯Î±Ï‚ ÏƒÎµ edge ÏƒÏ…ÏƒÎºÎµÏ…Î­Ï‚
- **ÎŸÎ¹ÎºÎ¿Î½Î¿Î¼Î¹ÎºÎ® Î±Ï€Î¿Î´Î¿Ï„Î¹ÎºÏŒÏ„Î·Ï„Î±**: Î£Ï…Î³ÎºÏÎ¯Î½ÎµÏ„Îµ Ï„Î¿ ÎºÏŒÏƒÏ„Î¿Ï‚ Î±Î½Î¬Ï€Ï„Ï…Î¾Î·Ï‚ ÏƒÏ„Î¿ edge Î¼Îµ ÎµÎ½Î±Î»Î»Î±ÎºÏ„Î¹ÎºÎ­Ï‚ Î»ÏÏƒÎµÎ¹Ï‚ ÏƒÏ„Î¿ cloud
- **Î‘Î¾Î¹Î¿Ï€Î¹ÏƒÏ„Î¯Î± ÎµÎºÏ„ÏŒÏ‚ ÏƒÏÎ½Î´ÎµÏƒÎ·Ï‚**: ÎœÎµÏ„ÏÎ®ÏƒÏ„Îµ Ï„Î·Î½ Î±Ï€ÏŒÎ´Î¿ÏƒÎ· Ï€ÏÎ±ÎºÏ„ÏŒÏÏ‰Î½ ÎºÎ±Ï„Î¬ Ï„Î· Î´Î¹Î¬ÏÎºÎµÎ¹Î± Î´Î¹Î±ÎºÎ¿Ï€ÏŽÎ½ Î´Î¹ÎºÏ„ÏÎ¿Ï…

## Î’Î±ÏƒÎ¹ÎºÎ¬ Î£Ï…Î¼Ï€ÎµÏÎ¬ÏƒÎ¼Î±Ï„Î± Î³Î¹Î± Ï„Î·Î½ Î•Ï†Î±ÏÎ¼Î¿Î³Î® Î ÏÎ±ÎºÏ„ÏŒÏÏ‰Î½ SLM

1. **ÎŸÎ¹ SLM ÎµÎ¯Î½Î±Î¹ ÎµÏ€Î±ÏÎºÎµÎ¯Ï‚ Î³Î¹Î± Ï€ÏÎ¬ÎºÏ„Î¿ÏÎµÏ‚**: Î“Î¹Î± Ï„Î¹Ï‚ Ï€ÎµÏÎ¹ÏƒÏƒÏŒÏ„ÎµÏÎµÏ‚ ÎµÏÎ³Î±ÏƒÎ¯ÎµÏ‚ Ï€ÏÎ±ÎºÏ„ÏŒÏÏ‰Î½, Ï„Î± Î¼Î¹ÎºÏÎ¬ Î¼Î¿Î½Ï„Î­Î»Î± Î±Ï€Î¿Î´Î¯Î´Î¿Ï…Î½ ÎµÎ¾Î¯ÏƒÎ¿Ï… ÎºÎ±Î»Î¬ Î¼Îµ Ï„Î± Î¼ÎµÎ³Î¬Î»Î±, Ï€ÏÎ¿ÏƒÏ†Î­ÏÎ¿Î½Ï„Î±Ï‚ ÏƒÎ·Î¼Î±Î½Ï„Î¹ÎºÎ¬ Ï€Î»ÎµÎ¿Î½ÎµÎºÏ„Î®Î¼Î±Ï„Î±
2. **ÎŸÎ¹ÎºÎ¿Î½Î¿Î¼Î¹ÎºÎ® Î±Ï€Î¿Î´Î¿Ï„Î¹ÎºÏŒÏ„Î·Ï„Î± ÏƒÏ„Î¿Ï…Ï‚ Ï€ÏÎ¬ÎºÏ„Î¿ÏÎµÏ‚**: 10-30 Ï†Î¿ÏÎ­Ï‚ Ï†Î¸Î·Î½ÏŒÏ„ÎµÏÎ¿ Î½Î± Î»ÎµÎ¹Ï„Î¿Ï…ÏÎ³Î¿ÏÎ½ Ï€ÏÎ¬ÎºÏ„Î¿ÏÎµÏ‚ SLM, ÎºÎ±Î¸Î¹ÏƒÏ„ÏŽÎ½Ï„Î±Ï‚ Ï„Î¿Ï…Ï‚ Î¿Î¹ÎºÎ¿Î½Î¿Î¼Î¹ÎºÎ¬ Î²Î¹ÏŽÏƒÎ¹Î¼Î¿Ï…Ï‚ Î³Î¹Î± ÎµÏ…ÏÎµÎ¯Î± Î±Î½Î¬Ï€Ï„Ï…Î¾Î·
3. **Î— ÎµÎ¾ÎµÎ¹Î´Î¯ÎºÎµÏ…ÏƒÎ· Î»ÎµÎ¹Ï„Î¿Ï…ÏÎ³ÎµÎ¯ Î³Î¹Î± Ï€ÏÎ¬ÎºÏ„Î¿ÏÎµÏ‚**: ÎŸÎ¹ SLM Ï€Î¿Ï… Î­Ï‡Î¿Ï…Î½ Ï€ÏÎ¿ÏƒÎ±ÏÎ¼Î¿ÏƒÏ„ÎµÎ¯ ÏƒÏ…Ï‡Î½Î¬ Ï…Ï€ÎµÏÎ­Ï‡Î¿Ï…Î½ Ï„Ï‰Î½ Î³ÎµÎ½Î¹ÎºÏŽÎ½ LLM ÏƒÎµ ÏƒÏ…Î³ÎºÎµÎºÏÎ¹Î¼Î­Î½ÎµÏ‚ ÎµÏ†Î±ÏÎ¼Î¿Î³Î­Ï‚ Ï€ÏÎ±ÎºÏ„ÏŒÏÏ‰Î½
4. **Î¥Î²ÏÎ¹Î´Î¹ÎºÎ® Î±ÏÏ‡Î¹Ï„ÎµÎºÏ„Î¿Î½Î¹ÎºÎ® Ï€ÏÎ±ÎºÏ„ÏŒÏÏ‰Î½**: Î§ÏÎ·ÏƒÎ¹Î¼Î¿Ï€Î¿Î¹Î®ÏƒÏ„Îµ SLM Î³Î¹Î± ÏÎ¿Ï…Ï„Î¯Î½ÎµÏ‚ ÎµÏÎ³Î±ÏƒÎ¯ÎµÏ‚ Ï€ÏÎ±ÎºÏ„ÏŒÏÏ‰Î½, LLM Î³Î¹Î± ÏƒÏÎ½Î¸ÎµÏ„Î· Î»Î¿Î³Î¹ÎºÎ® ÏŒÏ„Î±Î½ ÎµÎ¯Î½Î±Î¹ Î±Ï€Î±ÏÎ±Î¯Ï„Î·Ï„Î¿
5. **Î¤Î¿ Microsoft Agent Framework ÎµÏ€Î¹Ï„ÏÎ­Ï€ÎµÎ¹ Ï„Î·Î½ Î±Î½Î¬Ï€Ï„Ï…Î¾Î· Ï€Î±ÏÎ±Î³Ï‰Î³Î®Ï‚**: Î Î±ÏÎ­Ï‡ÎµÎ¹ ÎµÏÎ³Î±Î»ÎµÎ¯Î± ÎµÏ€Î¹Ï€Î­Î´Î¿Ï… ÎµÏ€Î¹Ï‡ÎµÎ¯ÏÎ·ÏƒÎ·Ï‚ Î³Î¹Î± Ï„Î· Î´Î·Î¼Î¹Î¿Ï…ÏÎ³Î¯Î±, Î±Î½Î¬Ï€Ï„Ï…Î¾Î· ÎºÎ±Î¹ Î´Î¹Î±Ï‡ÎµÎ¯ÏÎ¹ÏƒÎ· edge Ï€ÏÎ±ÎºÏ„ÏŒÏÏ‰Î½
6. **Î‘ÏÏ‡Î­Ï‚ ÏƒÏ‡ÎµÎ´Î¹Î±ÏƒÎ¼Î¿Ï Î¼Îµ Ï€ÏÎ¿Ï„ÎµÏÎ±Î¹ÏŒÏ„Î·Ï„Î± ÏƒÏ„Î¿ edge**: Î ÏÎ¬ÎºÏ„Î¿ÏÎµÏ‚ Î¼Îµ Î´Ï…Î½Î±Ï„ÏŒÏ„Î·Ï„Î± ÎµÎºÏ„ÏŒÏ‚ ÏƒÏÎ½Î´ÎµÏƒÎ·Ï‚ ÎºÎ±Î¹ Ï„Î¿Ï€Î¹ÎºÎ® ÎµÏ€ÎµÎ¾ÎµÏÎ³Î±ÏƒÎ¯Î± ÎµÎ¾Î±ÏƒÏ†Î±Î»Î¯Î¶Î¿Ï…Î½ Î¹Î´Î¹Ï‰Ï„Î¹ÎºÏŒÏ„Î·Ï„Î± ÎºÎ±Î¹ Î±Î¾Î¹Î¿Ï€Î¹ÏƒÏ„Î¯Î±
7. **Î•Î½ÏƒÏ‰Î¼Î¬Ï„Ï‰ÏƒÎ· Foundry Local**: Î‘Ï€ÏÏŒÏƒÎºÎ¿Ï€Ï„Î· ÏƒÏÎ½Î´ÎµÏƒÎ· Î¼ÎµÏ„Î±Î¾Ï Ï„Î¿Ï… Microsoft Agent Framework ÎºÎ±Î¹ Ï„Î·Ï‚ Ï„Î¿Ï€Î¹ÎºÎ®Ï‚ ÎµÏ€ÎµÎ¾ÎµÏÎ³Î±ÏƒÎ¯Î±Ï‚ Î¼Î¿Î½Ï„Î­Î»Ï‰Î½
8. **Î¤Î¿ Î¼Î­Î»Î»Î¿Î½ ÎµÎ¯Î½Î±Î¹ Î¿Î¹ Ï€ÏÎ¬ÎºÏ„Î¿ÏÎµÏ‚ SLM**: ÎœÎ¹ÎºÏÎ¬ Î³Î»Ï‰ÏƒÏƒÎ¹ÎºÎ¬ Î¼Î¿Î½Ï„Î­Î»Î± Î¼Îµ Ï€Î»Î±Î¯ÏƒÎ¹Î± Ï€Î±ÏÎ±Î³Ï‰Î³Î®Ï‚ ÎµÎ¯Î½Î±Î¹ Ï„Î¿ Î¼Î­Î»Î»Î¿Î½ Ï„Î·Ï‚ AI Ï€ÏÎ±ÎºÏ„ÏŒÏÏ‰Î½, ÎµÏ€Î¹Ï„ÏÎ­Ï€Î¿Î½Ï„Î±Ï‚ Î´Î·Î¼Î¿ÎºÏÎ±Ï„Î¹ÎºÎ® ÎºÎ±Î¹ Î±Ï€Î¿Î´Î¿Ï„Î¹ÎºÎ® Î±Î½Î¬Ï€Ï„Ï…Î¾Î· Ï€ÏÎ±ÎºÏ„ÏŒÏÏ‰Î½

## Î‘Î½Î±Ï†Î¿ÏÎ­Ï‚ ÎºÎ±Î¹ Î ÎµÏÎ±Î¹Ï„Î­ÏÏ‰ Î‘Î½Î¬Î³Î½Ï‰ÏƒÎ·

### Î’Î±ÏƒÎ¹ÎºÎ¬ Î•ÏÎµÏ…Î½Î·Ï„Î¹ÎºÎ¬ ÎˆÎ³Î³ÏÎ±Ï†Î± ÎºÎ±Î¹ Î”Î·Î¼Î¿ÏƒÎ¹ÎµÏÏƒÎµÎ¹Ï‚

#### AI Î ÏÎ¬ÎºÏ„Î¿ÏÎµÏ‚ ÎºÎ±Î¹ Î£Ï…ÏƒÏ„Î®Î¼Î±Ï„Î± Î ÏÎ±ÎºÏ„ÏŒÏÏ‰Î½
- **"Language Agents as Optimizable Graphs"** (2024) - Î˜ÎµÎ¼ÎµÎ»Î¹ÏŽÎ´Î·Ï‚ Î­ÏÎµÏ…Î½Î± Î³Î¹Î± Ï„Î·Î½ Î±ÏÏ‡Î¹Ï„ÎµÎºÏ„Î¿Î½Î¹ÎºÎ® ÎºÎ±Î¹ Ï„Î¹Ï‚ ÏƒÏ„ÏÎ±Ï„Î·Î³Î¹ÎºÎ­Ï‚ Î²ÎµÎ»Ï„Î¹ÏƒÏ„Î¿Ï€Î¿Î¯Î·ÏƒÎ·Ï‚ Ï€ÏÎ±ÎºÏ„ÏŒÏÏ‰Î½
  - Î£Ï…Î³Î³ÏÎ±Ï†ÎµÎ¯Ï‚: Wenyue Hua, Lishan Yang, et al.
  - Î£ÏÎ½Î´ÎµÏƒÎ¼Î¿Ï‚: https://arxiv.org/abs/2402.16823
  - Î’Î±ÏƒÎ¹ÎºÎ­Ï‚ Î Î»Î·ÏÎ¿Ï†Î¿ÏÎ¯ÎµÏ‚: Î£Ï‡ÎµÎ´Î¹Î±ÏƒÎ¼ÏŒÏ‚ Ï€ÏÎ±ÎºÏ„ÏŒÏÏ‰Î½ Î¼Îµ Î²Î¬ÏƒÎ· Î³ÏÎ±Ï†Î®Î¼Î±Ï„Î± ÎºÎ±Î¹ ÏƒÏ„ÏÎ±Ï„Î·Î³Î¹ÎºÎ­Ï‚ Î²ÎµÎ»Ï„Î¹ÏƒÏ„Î¿Ï€Î¿Î¯Î·ÏƒÎ·Ï‚

- **"The Rise and Potential of Large Language Model Based Agents"** (2023)
  - Î£Ï…Î³Î³ÏÎ±Ï†ÎµÎ¯Ï‚: Zhiheng Xi, Wenxiang Chen, et al.
  - Î£ÏÎ½Î´ÎµÏƒÎ¼Î¿Ï‚: https://arxiv.org/abs/2309.07864
  - Î’Î±ÏƒÎ¹ÎºÎ­Ï‚ Î Î»Î·ÏÎ¿Ï†Î¿ÏÎ¯ÎµÏ‚: Î•ÎºÏ„ÎµÎ½Î®Ï‚ ÎµÏ€Î¹ÏƒÎºÏŒÏ€Î·ÏƒÎ· Ï„Ï‰Î½ Î´Ï…Î½Î±Ï„Î¿Ï„Î®Ï„Ï‰Î½ ÎºÎ±Î¹ ÎµÏ†Î±ÏÎ¼Î¿Î³ÏŽÎ½ Ï€ÏÎ±ÎºÏ„ÏŒÏÏ‰Î½ Î²Î±ÏƒÎ¹ÏƒÎ¼Î­Î½Ï‰Î½ ÏƒÎµ LLM

- **"Cognitive Architectures for Language Agents"** (2024)
  - Î£Ï…Î³Î³ÏÎ±Ï†ÎµÎ¯Ï‚: Theodore Sumers, Shunyu Yao, et al.
  - Î£ÏÎ½Î´ÎµÏƒÎ¼Î¿Ï‚: https://arxiv.org/abs/2309.02427
  - Î’Î±ÏƒÎ¹ÎºÎ­Ï‚ Î Î»Î·ÏÎ¿Ï†Î¿ÏÎ¯ÎµÏ‚: Î“Î½Ï‰ÏƒÏ„Î¹ÎºÎ¬ Ï€Î»Î±Î¯ÏƒÎ¹Î± Î³Î¹Î± Ï„Î¿ ÏƒÏ‡ÎµÎ´Î¹Î±ÏƒÎ¼ÏŒ ÎµÏ…Ï†Ï…ÏŽÎ½ Ï€ÏÎ±ÎºÏ„ÏŒÏÏ‰Î½

#### ÎœÎ¹ÎºÏÎ¬ Î“Î»Ï‰ÏƒÏƒÎ¹ÎºÎ¬ ÎœÎ¿Î½Ï„Î­Î»Î± ÎºÎ±Î¹ Î’ÎµÎ»Ï„Î¹ÏƒÏ„Î¿Ï€Î¿Î¯Î·ÏƒÎ·
- **"Phi-3 Technical Report: A Highly Capable Language Model Locally on Your Phone"** (2024)
  - Î£Ï…Î³Î³ÏÎ±Ï†ÎµÎ¯Ï‚: Microsoft Research Team
  - Î£ÏÎ½Î´ÎµÏƒÎ¼Î¿Ï‚: https://arxiv.org/abs/2404.14219
  - Î’Î±ÏƒÎ¹ÎºÎ­Ï‚ Î Î»Î·ÏÎ¿Ï†Î¿ÏÎ¯ÎµÏ‚: Î‘ÏÏ‡Î­Ï‚ ÏƒÏ‡ÎµÎ´Î¹Î±ÏƒÎ¼Î¿Ï SLM ÎºÎ±Î¹ ÏƒÏ„ÏÎ±Ï„Î·Î³Î¹ÎºÎ­Ï‚ Î±Î½Î¬Ï€Ï„Ï…Î¾Î·Ï‚ ÏƒÎµ ÎºÎ¹Î½Î·Ï„Î­Ï‚ ÏƒÏ…ÏƒÎºÎµÏ…Î­Ï‚

- **"Qwen2.5 Technical Report"** (2024)
  - Î£Ï…Î³Î³ÏÎ±Ï†ÎµÎ¯Ï‚: Alibaba Cloud Team
  - Î£ÏÎ½Î´ÎµÏƒÎ¼Î¿Ï‚: https://arxiv.org/abs/2407.10671
  - Î’Î±ÏƒÎ¹ÎºÎ­Ï‚ Î Î»Î·ÏÎ¿Ï†Î¿ÏÎ¯ÎµÏ‚: Î ÏÎ¿Î·Î³Î¼Î­Î½ÎµÏ‚ Ï„ÎµÏ‡Î½Î¹ÎºÎ­Ï‚ ÎµÎºÏ€Î±Î¯Î´ÎµÏ…ÏƒÎ·Ï‚ SLM ÎºÎ±Î¹ Î²ÎµÎ»Ï„Î¹ÏƒÏ„Î¿Ï€Î¿Î¯Î·ÏƒÎ· Î±Ï€ÏŒÎ´Î¿ÏƒÎ·Ï‚

- **"TinyLlama: An Open-Source Small Language Model"** (2024)
  - Î£Ï…Î³Î³ÏÎ±Ï†ÎµÎ¯Ï‚: Peiyuan Zhang, Guangtao Zeng, et al.
  - Î£ÏÎ½Î´ÎµÏƒÎ¼Î¿Ï‚: https://arxiv.org/abs/2401.02385
  - Î’Î±ÏƒÎ¹ÎºÎ­Ï‚ Î Î»Î·ÏÎ¿Ï†Î¿ÏÎ¯ÎµÏ‚: Î£Ï‡ÎµÎ´Î¹Î±ÏƒÎ¼ÏŒÏ‚ Ï…Ï€ÎµÏ-ÏƒÏ…Î¼Ï€Î±Î³ÏŽÎ½ Î¼Î¿Î½Ï„Î­Î»Ï‰Î½ ÎºÎ±Î¹ Î±Ï€Î¿Î´Î¿Ï„Î¹ÎºÏŒÏ„Î·Ï„Î± ÎµÎºÏ€Î±Î¯Î´ÎµÏ…ÏƒÎ·Ï‚

### Î•Ï€Î¯ÏƒÎ·Î¼Î· Î¤ÎµÎºÎ¼Î·ÏÎ¯Ï‰ÏƒÎ· ÎºÎ±Î¹ Î Î»Î±Î¯ÏƒÎ¹Î±

#### Microsoft Agent Framework
- **Î•Ï€Î¯ÏƒÎ·Î¼Î· Î¤ÎµÎºÎ¼Î·ÏÎ¯Ï‰ÏƒÎ·**: https://docs.microsoft.com/en-us/azure/ai-services/agents/
- **Î‘Ï€Î¿Î¸ÎµÏ„Î®ÏÎ¹Î¿ GitHub**: https://github.com/microsoft/agent-framework

#### Foundry Local
- **ÎšÏÏÎ¹Î¿ Î‘Ï€Î¿Î¸ÎµÏ„Î®ÏÎ¹Î¿**: https://github.com/microsoft/foundry-local
- **Î¤ÎµÎºÎ¼Î·ÏÎ¯Ï‰ÏƒÎ·**: https://github.com/microsoft/foundry-local/blob/main/docs/README.md


#### VLLM
- **ÎšÏÏÎ¹Î¿ Î‘Ï€Î¿Î¸ÎµÏ„Î®ÏÎ¹Î¿**: https://github.com/vllm-project/vllm
- **Î¤ÎµÎºÎ¼Î·ÏÎ¯Ï‰ÏƒÎ·**: https://docs.vllm.ai/


#### Ollama
- **Î•Ï€Î¯ÏƒÎ·Î¼Î¿Ï‚ Î™ÏƒÏ„ÏŒÏ„Î¿Ï€Î¿Ï‚**: https://ollama.ai/
- **Î‘Ï€Î¿Î¸ÎµÏ„Î®ÏÎ¹Î¿ GitHub**: https://github.com/ollama/ollama

### Î Î»Î±Î¯ÏƒÎ¹Î± Î’ÎµÎ»Ï„Î¹ÏƒÏ„Î¿Ï€Î¿Î¯Î·ÏƒÎ·Ï‚ ÎœÎ¿Î½Ï„Î­Î»Ï‰Î½

#### Llama.cpp
- **Î‘Ï€Î¿Î¸ÎµÏ„Î®ÏÎ¹Î¿**: https://github.com/ggml-org/llama.cpp


#### Microsoft Olive
- **Î¤ÎµÎºÎ¼Î·ÏÎ¯Ï‰ÏƒÎ·**: https://microsoft.github.io/Olive/
- **Î‘Ï€Î¿Î¸ÎµÏ„Î®ÏÎ¹Î¿ GitHub**: https://github.com/microsoft/Olive

#### OpenVINO
- **Î•Ï€Î¯ÏƒÎ·Î¼Î¿Ï‚ Î™ÏƒÏ„ÏŒÏ„Î¿Ï€Î¿Ï‚**: https://

---

**Î‘Ï€Î¿Ï€Î¿Î¯Î·ÏƒÎ· ÎµÏ…Î¸ÏÎ½Î·Ï‚**:  
Î‘Ï…Ï„ÏŒ Ï„Î¿ Î­Î³Î³ÏÎ±Ï†Î¿ Î­Ï‡ÎµÎ¹ Î¼ÎµÏ„Î±Ï†ÏÎ±ÏƒÏ„ÎµÎ¯ Ï‡ÏÎ·ÏƒÎ¹Î¼Î¿Ï€Î¿Î¹ÏŽÎ½Ï„Î±Ï‚ Ï„Î·Î½ Ï…Ï€Î·ÏÎµÏƒÎ¯Î± Î¼ÎµÏ„Î¬Ï†ÏÎ±ÏƒÎ·Ï‚ AI [Co-op Translator](https://github.com/Azure/co-op-translator). Î Î±ÏÏŒÎ»Î¿ Ï€Î¿Ï… ÎºÎ±Ï„Î±Î²Î¬Î»Î»Î¿Ï…Î¼Îµ Ï€ÏÎ¿ÏƒÏ€Î¬Î¸ÎµÎ¹ÎµÏ‚ Î³Î¹Î± Î±ÎºÏÎ¯Î²ÎµÎ¹Î±, Ï€Î±ÏÎ±ÎºÎ±Î»Î¿ÏÎ¼Îµ Î½Î± Î³Î½Ï‰ÏÎ¯Î¶ÎµÏ„Îµ ÏŒÏ„Î¹ Î¿Î¹ Î±Ï…Ï„Î¿Î¼Î±Ï„Î¿Ï€Î¿Î¹Î·Î¼Î­Î½ÎµÏ‚ Î¼ÎµÏ„Î±Ï†ÏÎ¬ÏƒÎµÎ¹Ï‚ ÎµÎ½Î´Î­Ï‡ÎµÏ„Î±Î¹ Î½Î± Ï€ÎµÏÎ¹Î­Ï‡Î¿Ï…Î½ Î»Î¬Î¸Î· Î® Î±Î½Î±ÎºÏÎ¯Î²ÎµÎ¹ÎµÏ‚. Î¤Î¿ Ï€ÏÏ‰Ï„ÏŒÏ„Ï…Ï€Î¿ Î­Î³Î³ÏÎ±Ï†Î¿ ÏƒÏ„Î· Î¼Î·Ï„ÏÎ¹ÎºÎ® Ï„Î¿Ï… Î³Î»ÏŽÏƒÏƒÎ± Î¸Î± Ï€ÏÎ­Ï€ÎµÎ¹ Î½Î± Î¸ÎµÏ‰ÏÎµÎ¯Ï„Î±Î¹ Î· Î±Ï…Î¸ÎµÎ½Ï„Î¹ÎºÎ® Ï€Î·Î³Î®. Î“Î¹Î± ÎºÏÎ¯ÏƒÎ¹Î¼ÎµÏ‚ Ï€Î»Î·ÏÎ¿Ï†Î¿ÏÎ¯ÎµÏ‚, ÏƒÏ…Î½Î¹ÏƒÏ„Î¬Ï„Î±Î¹ ÎµÏ€Î±Î³Î³ÎµÎ»Î¼Î±Ï„Î¹ÎºÎ® Î±Î½Î¸ÏÏŽÏ€Î¹Î½Î· Î¼ÎµÏ„Î¬Ï†ÏÎ±ÏƒÎ·. Î”ÎµÎ½ Ï†Î­ÏÎ¿Ï…Î¼Îµ ÎµÏ…Î¸ÏÎ½Î· Î³Î¹Î± Ï„Ï…Ï‡ÏŒÎ½ Ï€Î±ÏÎµÎ¾Î·Î³Î®ÏƒÎµÎ¹Ï‚ Î® ÎµÏƒÏ†Î±Î»Î¼Î­Î½ÎµÏ‚ ÎµÏÎ¼Î·Î½ÎµÎ¯ÎµÏ‚ Ï€Î¿Ï… Ï€ÏÎ¿ÎºÏÏ€Ï„Î¿Ï…Î½ Î±Ï€ÏŒ Ï„Î· Ï‡ÏÎ®ÏƒÎ· Î±Ï…Ï„Î®Ï‚ Ï„Î·Ï‚ Î¼ÎµÏ„Î¬Ï†ÏÎ±ÏƒÎ·Ï‚.