<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "45923ada94573fee7c82cc4f0c3bb344",
  "translation_date": "2025-10-28T23:11:14+00:00",
  "source_file": "Workshop/Readme.md",
  "language_code": "ro"
}
-->
# EdgeAI pentru ÃncepÄƒtori - Atelier

> **Curs practic pentru dezvoltarea aplicaÈ›iilor Edge AI pregÄƒtite pentru producÈ›ie**
>
> StÄƒpÃ¢neÈ™te implementarea AI localÄƒ cu Microsoft Foundry Local, de la prima completare de chat pÃ¢nÄƒ la orchestrarea multi-agent Ã®n 6 sesiuni progresive.

---

## ğŸ¯ Introducere

Bine aÈ›i venit la **Atelierul EdgeAI pentru ÃncepÄƒtori** - ghidul dvs. practic pentru construirea aplicaÈ›iilor inteligente care ruleazÄƒ complet pe hardware local. Acest atelier transformÄƒ conceptele teoretice ale Edge AI Ã®n abilitÄƒÈ›i practice prin exerciÈ›ii progresive utilizÃ¢nd Microsoft Foundry Local È™i Small Language Models (SLMs).

### De ce acest atelier?

**RevoluÈ›ia Edge AI este aici**

OrganizaÈ›iile din Ã®ntreaga lume trec de la AI dependent de cloud la calculul edge din trei motive critice:

1. **ConfidenÈ›ialitate & Conformitate** - Procesarea datelor sensibile local, fÄƒrÄƒ transmiterea lor Ã®n cloud (HIPAA, GDPR, reglementÄƒri financiare)
2. **PerformanÈ›Äƒ** - Eliminarea latenÈ›ei reÈ›elei (50-500ms local vs 500-2000ms tur-retur Ã®n cloud)
3. **Controlul Costurilor** - Eliminarea costurilor per token API È™i scalarea fÄƒrÄƒ cheltuieli de cloud

**Dar Edge AI este diferit**

Rularea AI pe dispozitive locale necesitÄƒ abilitÄƒÈ›i noi:
- Selectarea È™i optimizarea modelelor pentru constrÃ¢ngerile de resurse
- Managementul serviciilor locale È™i accelerarea hardware
- Ingineria prompturilor pentru modele mai mici
- Modele de implementare pentru dispozitive edge

**Acest atelier oferÄƒ aceste abilitÄƒÈ›i**

Ãn 6 sesiuni concentrate (~3 ore Ã®n total), veÈ›i progresa de la "Hello World" la implementarea sistemelor multi-agent pregÄƒtite pentru producÈ›ie - toate rulÃ¢nd local pe maÈ™ina dvs.

---

## ğŸ“š Obiective de ÃnvÄƒÈ›are

Prin completarea acestui atelier, veÈ›i putea:

### CompetenÈ›e de bazÄƒ
1. **ImplementaÈ›i È™i gestionaÈ›i servicii AI locale**
   - InstalaÈ›i È™i configuraÈ›i Microsoft Foundry Local
   - SelectaÈ›i modele adecvate pentru implementarea edge
   - GestionaÈ›i ciclul de viaÈ›Äƒ al modelelor (descÄƒrcare, Ã®ncÄƒrcare, cache)
   - MonitorizaÈ›i utilizarea resurselor È™i optimizaÈ›i performanÈ›a

2. **ConstruiÈ›i aplicaÈ›ii alimentate de AI**
   - ImplementaÈ›i completÄƒri de chat compatibile cu OpenAI local
   - ProiectaÈ›i prompturi eficiente pentru Small Language Models
   - GestionaÈ›i rÄƒspunsurile Ã®n flux pentru o experienÈ›Äƒ mai bunÄƒ
   - IntegraÈ›i modele locale Ã®n aplicaÈ›ii existente

3. **CreaÈ›i sisteme RAG (Retrieval Augmented Generation)**
   - ConstruiÈ›i cÄƒutÄƒri semantice cu embeddings
   - FundamentaÈ›i rÄƒspunsurile LLM Ã®n cunoÈ™tinÈ›e specifice domeniului
   - EvaluaÈ›i calitatea RAG cu metrici standard din industrie
   - ScalaÈ›i de la prototip la producÈ›ie

4. **OptimizaÈ›i performanÈ›a modelelor**
   - EvaluaÈ›i mai multe modele pentru cazul dvs. de utilizare
   - MÄƒsuraÈ›i latenÈ›a, debitul È™i timpul primului token
   - SelectaÈ›i modele optime bazate pe compromisuri Ã®ntre vitezÄƒ È™i calitate
   - ComparaÈ›i compromisurile SLM vs LLM Ã®n scenarii reale

5. **OrchestraÈ›i sisteme multi-agent**
   - ProiectaÈ›i agenÈ›i specializaÈ›i pentru diferite sarcini
   - ImplementaÈ›i memorie È™i gestionarea contextului pentru agenÈ›i
   - CoordonaÈ›i agenÈ›ii Ã®n fluxuri de lucru complexe
   - DirecÈ›ionaÈ›i cererile inteligent Ã®ntre mai multe modele

6. **ImplementaÈ›i soluÈ›ii pregÄƒtite pentru producÈ›ie**
   - ImplementaÈ›i gestionarea erorilor È™i logica de retry
   - MonitorizaÈ›i utilizarea tokenurilor È™i resursele sistemului
   - ConstruiÈ›i arhitecturi scalabile cu modele ca instrumente
   - PlanificaÈ›i cÄƒi de migrare de la edge la hibrid (edge + cloud)

---

## ğŸ“ Rezultate de ÃnvÄƒÈ›are

### Ce veÈ›i construi

PÃ¢nÄƒ la finalul acestui atelier, veÈ›i fi creat:

| Sesiune | Rezultat | AbilitÄƒÈ›i Demonstrate |
|---------|----------|-----------------------|
| **1** | AplicaÈ›ie de chat cu streaming | Configurare serviciu, completÄƒri de bazÄƒ, UX streaming |
| **2** | Sistem RAG cu evaluare | Embeddings, cÄƒutare semanticÄƒ, metrici de calitate |
| **3** | SuitÄƒ de benchmark multi-model | MÄƒsurarea performanÈ›ei, compararea modelelor |
| **4** | Comparator SLM vs LLM | Analiza compromisurilor, strategii de optimizare |
| **5** | Orchestrator multi-agent | Proiectare agenÈ›i, gestionarea memoriei, coordonare |
| **6** | Sistem de rutare inteligent | Detectarea intenÈ›iei, selecÈ›ia modelului, scalabilitate |

### Matrice de CompetenÈ›e

| Nivel de AbilitÄƒÈ›i | Sesiunea 1-2 | Sesiunea 3-4 | Sesiunea 5-6 |
|--------------------|--------------|--------------|--------------|
| **ÃncepÄƒtor** | âœ… Configurare & bazÄƒ | âš ï¸ Provocator | âŒ Prea avansat |
| **Intermediar** | âœ… Revizuire rapidÄƒ | âœ… ÃnvÄƒÈ›are de bazÄƒ | âš ï¸ Obiective extinse |
| **Avansat** | âœ… UÈ™or de parcurs | âœ… PerfecÈ›ionare | âœ… Modele de producÈ›ie |

### AbilitÄƒÈ›i PregÄƒtite pentru CarierÄƒ

**DupÄƒ acest atelier, veÈ›i fi pregÄƒtit sÄƒ:**

âœ… **ConstruiÈ›i AplicaÈ›ii Centrate pe ConfidenÈ›ialitate**
- AplicaÈ›ii de sÄƒnÄƒtate care gestioneazÄƒ PHI/PII local
- Servicii financiare cu cerinÈ›e de conformitate
- Sisteme guvernamentale cu nevoi de suveranitate a datelor

âœ… **OptimizaÈ›i pentru Medii Edge**
- Dispozitive IoT cu resurse limitate
- AplicaÈ›ii mobile offline-first
- Sisteme Ã®n timp real cu latenÈ›Äƒ redusÄƒ

âœ… **ProiectaÈ›i Arhitecturi Inteligente**
- Sisteme multi-agent pentru fluxuri de lucru complexe
- ImplementÄƒri hibride edge-cloud
- InfrastructurÄƒ AI optimizatÄƒ pentru costuri

âœ… **ConduceÈ›i IniÈ›iative Edge AI**
- EvaluaÈ›i fezabilitatea Edge AI pentru proiecte
- SelectaÈ›i modele È™i cadre adecvate
- ArhitecturaÈ›i soluÈ›ii AI locale scalabile

---

## ğŸ—ºï¸ Structura Atelierului

### Prezentare GeneralÄƒ a Sesiunilor (6 Sesiuni Ã— 30 Minute = 3 Ore)

| Sesiune | Subiect | Focus | DuratÄƒ |
|---------|---------|-------|--------|
| **1** | ÃncepeÈ›i cu Foundry Local | Instalare, validare, primele completÄƒri | 30 min |
| **2** | Construirea SoluÈ›iilor AI cu RAG | Ingineria prompturilor, embeddings, evaluare | 30 min |
| **3** | Modele Open Source | Descoperirea modelelor, benchmarking, selecÈ›ie | 30 min |
| **4** | Modele de UltimÄƒ GeneraÈ›ie | SLM vs LLM, optimizare, cadre | 30 min |
| **5** | AgenÈ›i AlimentaÈ›i de AI | Proiectare agenÈ›i, orchestrare, memorie | 30 min |
| **6** | Modele ca Instrumente | Rutare, chaining, strategii de scalare | 30 min |

---

## ğŸš€ Start Rapid

### CerinÈ›e Prealabile

**CerinÈ›e de Sistem:**
- **OS**: Windows 10/11, macOS 11+, sau Linux (Ubuntu 20.04+)
- **RAM**: minim 8GB, recomandat 16GB+
- **SpaÈ›iu de Stocare**: 10GB+ liber pentru modele
- **CPU**: Procesor modern cu suport AVX2
- **GPU** (opÈ›ional): Compatibil CUDA sau Qualcomm NPU pentru accelerare

**CerinÈ›e Software:**
- **Python 3.8+** ([DescÄƒrcare](https://www.python.org/downloads/))
- **Microsoft Foundry Local** ([Ghid de Instalare](../../../Workshop))
- **Git** ([DescÄƒrcare](https://git-scm.com/downloads))
- **Visual Studio Code** (recomandat) ([DescÄƒrcare](https://code.visualstudio.com/))

### Configurare Ã®n 3 PaÈ™i

#### 1. InstalaÈ›i Foundry Local

**Windows:**
```powershell
winget install Microsoft.FoundryLocal
```

**macOS:**
```bash
brew tap microsoft/foundrylocal
brew install foundrylocal
```

**VerificaÈ›i Instalarea:**
```bash
foundry --version
foundry service status
```

**AsiguraÈ›i-vÄƒ cÄƒ Azure AI Foundry Local ruleazÄƒ pe un port fix**

```bash
# Set FoundryLocal to use port 58123 (default)
foundry service set --port 58123 --show

# Or use a different port
foundry service set --port 58000 --show
```

**VerificaÈ›i funcÈ›ionarea:**
```bash
# Check service status
foundry service status

# Test the endpoint
curl http://127.0.0.1:58123/v1/models
```
**GÄƒsirea Modelelor Disponibile**
Pentru a vedea ce modele sunt disponibile Ã®n instanÈ›a dvs. Foundry Local, puteÈ›i interoga endpoint-ul modelelor:

```bash
# cmd/bash/powershell
foundry model list
```

UtilizÃ¢nd Endpoint Web 

```bash
# Windows PowerShell
powershell -Command "Invoke-RestMethod -Uri 'http://127.0.0.1:58123/v1/models' -Method Get"

# Or using curl (if available)
curl http://127.0.0.1:58123/v1/models
```

#### 2. ClonaÈ›i Repozitoriul & InstalaÈ›i DependenÈ›ele

```bash
# Clone repository
git clone https://github.com/microsoft/edgeai-for-beginners.git
cd edgeai-for-beginners/Workshop

# Create virtual environment
python -m venv .venv

# Activate virtual environment
# Windows:
.\.venv\Scripts\activate
# macOS/Linux:
source .venv/bin/activate

# Install dependencies
pip install -r requirements.txt
```

#### 3. RulaÈ›i Primul Exemplu

```bash
# Start Foundry Local and load a model
foundry model run phi-4-mini

# Run the chat bootstrap sample
cd samples
python -m session01.chat_bootstrap "What is edge AI?"
```

**âœ… Succes!** Ar trebui sÄƒ vedeÈ›i un rÄƒspuns Ã®n flux despre Edge AI.

---

## ğŸ“¦ Resurse pentru Atelier

### Exemple Python

Exemple practice progresive care demonstreazÄƒ fiecare concept:

| Sesiune | Exemplu | Descriere | Timp de Rulare |
|---------|---------|-----------|----------------|
| 1 | [`chat_bootstrap.py`](../../../Workshop/samples/session01/chat_bootstrap.py) | Chat de bazÄƒ & streaming | ~30s |
| 2 | [`rag_pipeline.py`](../../../Workshop/samples/session02/rag_pipeline.py) | RAG cu embeddings | ~45s |
| 2 | [`rag_eval_ragas.py`](../../../Workshop/samples/session02/rag_eval_ragas.py) | Evaluarea calitÄƒÈ›ii RAG | ~60s |
| 3 | [`benchmark_oss_models.py`](../../../Workshop/samples/session03/benchmark_oss_models.py) | Benchmarking multi-model | ~2-3m |
| 4 | [`model_compare.py`](../../../Workshop/samples/session04/model_compare.py) | ComparaÈ›ie SLM vs LLM | ~45s |
| 5 | [`agents_orchestrator.py`](../../../Workshop/samples/session05/agents_orchestrator.py) | Sistem multi-agent | ~60s |
| 6 | [`models_router.py`](../../../Workshop/samples/session06/models_router.py) | Rutare bazatÄƒ pe intenÈ›ie | ~45s |
| 6 | [`models_pipeline.py`](../../../Workshop/samples/session06/models_pipeline.py) | Pipeline multi-pas | ~60s |

### Jupyter Notebooks

Explorare interactivÄƒ cu explicaÈ›ii È™i vizualizÄƒri:

| Sesiune | Notebook | Descriere | Dificultate |
|---------|----------|-----------|-------------|
| 1 | [`session01_chat_bootstrap.ipynb`](./notebooks/session01_chat_bootstrap.ipynb) | Bazele chat-ului & streaming | â­ ÃncepÄƒtor |
| 2 | [`session02_rag_pipeline.ipynb`](./notebooks/session02_rag_pipeline.ipynb) | Construirea sistemului RAG | â­â­ Intermediar |
| 2 | [`session02_rag_eval_ragas.ipynb`](./notebooks/session02_rag_eval_ragas.ipynb) | Evaluarea calitÄƒÈ›ii RAG | â­â­ Intermediar |
| 3 | [`session03_benchmark_oss_models.ipynb`](./notebooks/session03_benchmark_oss_models.ipynb) | Benchmarking modele | â­â­ Intermediar |
| 4 | [`session04_model_compare.ipynb`](./notebooks/session04_model_compare.ipynb) | ComparaÈ›ie modele | â­â­ Intermediar |
| 5 | [`session05_agents_orchestrator.ipynb`](./notebooks/session05_agents_orchestrator.ipynb) | Orchestrarea agenÈ›ilor | â­â­â­ Avansat |
| 6 | [`session06_models_router.ipynb`](./notebooks/session06_models_router.ipynb) | Rutare pe bazÄƒ de intenÈ›ie | â­â­â­ Avansat |
| 6 | [`session06_models_pipeline.ipynb`](./notebooks/session06_models_pipeline.ipynb) | Orchestrarea pipeline-ului | â­â­â­ Avansat |

### DocumentaÈ›ie

Ghiduri È™i referinÈ›e complete:

| Document | Descriere | CÃ¢nd sÄƒ folosiÈ›i |
|----------|-----------|------------------|
| [QUICK_START.md](./QUICK_START.md) | Ghid rapid de configurare | ÃncepeÈ›i de la zero |
| [QUICK_REFERENCE.md](./QUICK_REFERENCE.md) | Foaie de parcurs pentru comenzi & API | AveÈ›i nevoie de rÄƒspunsuri rapide |
| [FOUNDRY_SDK_QUICKREF.md](./FOUNDRY_SDK_QUICKREF.md) | Modele SDK & exemple | Scrierea codului |
| [ENV_CONFIGURATION.md](./ENV_CONFIGURATION.md) | Ghid pentru variabilele de mediu | Configurarea exemplelor |
| [SAMPLES_UPDATE_SUMMARY.md](./SAMPLES_UPDATE_SUMMARY.md) | ÃmbunÄƒtÄƒÈ›iri recente ale exemplelor | ÃnÈ›elegerea schimbÄƒrilor |
| [SDK_MIGRATION_NOTES.md](./SDK_MIGRATION_NOTES.md) | Ghid de migrare | Actualizarea codului |
| [notebooks/TROUBLESHOOTING.md](./notebooks/TROUBLESHOOTING.md) | Probleme comune & soluÈ›ii | Depanarea problemelor |

---

## ğŸ“ RecomandÄƒri pentru Parcursul de ÃnvÄƒÈ›are

### Pentru ÃncepÄƒtori (3-4 ore)
1. âœ… Sesiunea 1: ÃncepeÈ›i (focus pe configurare È™i chat de bazÄƒ)
2. âœ… Sesiunea 2: Bazele RAG (sÄƒriÈ›i peste evaluare iniÈ›ial)
3. âœ… Sesiunea 3: Benchmarking simplu (doar 2 modele)
4. â­ï¸ SÄƒriÈ›i peste Sesiunile 4-6 pentru moment
5. ğŸ”„ ReveniÈ›i la Sesiunile 4-6 dupÄƒ construirea primei aplicaÈ›ii

### Pentru Dezvoltatori Intermediari (3 ore)
1. âš¡ Sesiunea 1: Validare rapidÄƒ a configurÄƒrii
2. âœ… Sesiunea 2: Pipeline complet RAG cu evaluare
3. âœ… Sesiunea 3: SuitÄƒ completÄƒ de benchmarking
4. âœ… Sesiunea 4: Optimizarea modelelor
5. âœ… Sesiunile 5-6: Focus pe modele de arhitecturÄƒ

### Pentru Practicieni AvansaÈ›i (2-3 ore)
1. âš¡ Sesiunile 1-3: Revizuire rapidÄƒ È™i validare
2. âœ… Sesiunea 4: Detalii despre optimizare
3. âœ… Sesiunea 5: ArhitecturÄƒ multi-agent
4. âœ… Sesiunea 6: Modele de producÈ›ie È™i scalare
5. ğŸš€ ExtindeÈ›i: ConstruiÈ›i logicÄƒ de rutare personalizatÄƒ È™i implementÄƒri hibride

---

## Pachetul de Sesiuni ale Atelierului (Laboratoare Concentrate de 30 de Minute)

DacÄƒ urmaÈ›i formatul condensat al atelierului de 6 sesiuni, utilizaÈ›i aceste ghiduri dedicate (fiecare se potriveÈ™te È™i completeazÄƒ documentaÈ›ia mai amplÄƒ de mai sus):

| Sesiunea Atelierului | Ghid | Focus Principal |
|----------------------|------|-----------------|
| 1 | [Session01-GettingStartedFoundryLocal](./Session01-GettingStartedFoundryLocal.md) | Instalare, validare, rulare phi & GPT-OSS-20B, accelerare |
| 2 | [Session02-BuildAISolutionsRAG](./Session02-BuildAISolutionsRAG.md) | Ingineria prompturilor, modele RAG, fundamentare CSV & documente, migrare |
| 3 | [Session03-OpenSourceModels](./Session03-OpenSourceModels.md) | Integrare Hugging Face, benchmarking, selecÈ›ie modele |
| 4 | [Session04-CuttingEdgeModels](./Session04-CuttingEdgeModels.md) | SLM vs LLM, WebGPU, Chainlit RAG, accelerare ONNX |
| 5 | [Session05-AIPoweredAgents](./Session05-AIPoweredAgents.md) | Roluri ale agenÈ›ilor, memorie, unelte, orchestrare |
| 6 | [Session06-ModelsAsTools](./Session06-ModelsAsTools.md) | Rutare, concatenare, scalare cÄƒtre Azure |

Fiecare fiÈ™ier de sesiune include: rezumat, obiective de Ã®nvÄƒÈ›are, demonstraÈ›ie de 30 de minute, proiect de Ã®nceput, listÄƒ de verificare pentru validare, depanare È™i referinÈ›e la SDK-ul oficial Foundry Local Python.

### Scripturi Exemple

Instalare dependenÈ›e workshop (Windows):

```powershell
cd Workshop
py -m venv .venv
.\.venv\Scripts\activate
pip install -r requirements.txt
```

macOS / Linux:

```bash
cd Workshop
python3 -m venv .venv
source .venv/bin/activate
pip install -r requirements.txt
```

DacÄƒ serviciul Foundry Local ruleazÄƒ pe o altÄƒ maÈ™inÄƒ (Windows) sau VM de pe macOS, exportaÈ›i endpoint-ul:

```bash
export FOUNDRY_LOCAL_ENDPOINT=http://<windows-host>:5273/v1
```

| Sesiune | Script(uri) | Descriere |
|---------|-------------|-----------|
| 1 | `samples/session01/chat_bootstrap.py` | Bootstrap serviciu & chat streaming |
| 2 | `samples/session02/rag_pipeline.py` | RAG minimal (embedding-uri Ã®n memorie) |
|   | `samples/session02/rag_eval_ragas.py` | Evaluare RAG cu metrici ragas |
| 3 | `samples/session03/benchmark_oss_models.py` | Benchmarking pentru latenÈ›Äƒ & throughput multi-model |
| 4 | `samples/session04/model_compare.py` | ComparaÈ›ie SLM vs LLM (latenÈ›Äƒ & rezultate exemplu) |
| 5 | `samples/session05/agents_orchestrator.py` | Pipeline de cercetare cu doi agenÈ›i â†’ editorial |
| 6 | `samples/session06/models_router.py` | DemonstraÈ›ie de rutare bazatÄƒ pe intenÈ›ie |
|   | `samples/session06/models_pipeline.py` | LanÈ› multi-pas planificare/executare/perfecÈ›ionare |

### Variabile de Mediu (Comune pentru Exemple)

| VariabilÄƒ | Scop | Exemplu |
|-----------|------|---------|
| `FOUNDRY_LOCAL_ALIAS` | Alias-ul modelului unic implicit pentru exemplele de bazÄƒ | `phi-4-mini` |
| `SLM_ALIAS` / `LLM_ALIAS` | SLM explicit vs model mai mare pentru comparaÈ›ie | `phi-4-mini` / `gpt-oss-20b` |
| `BENCH_MODELS` | ListÄƒ de alias-uri pentru benchmark | `qwen2.5-0.5b,mistral-7b` |
| `BENCH_ROUNDS` | RepetiÈ›ii de benchmark per model | `3` |
| `BENCH_PROMPT` | Prompt utilizat Ã®n benchmark | `Explain retrieval augmented generation briefly.` |
| `EMBED_MODEL` | Model de embedding sentence-transformers | `sentence-transformers/all-MiniLM-L6-v2` |
| `RAG_QUESTION` | Suprascriere Ã®ntrebare de test pentru pipeline-ul RAG | `Why use RAG with local inference?` |
| `AGENT_QUESTION` | Suprascriere Ã®ntrebare pentru pipeline-ul agenÈ›ilor | `Explain why edge AI matters for compliance.` |
| `AGENT_MODEL_PRIMARY` | Alias-ul modelului pentru agentul de cercetare | `phi-4-mini` |
| `AGENT_MODEL_EDITOR` | Alias-ul modelului pentru agentul editor (poate fi diferit) | `gpt-oss-20b` |
| `SHOW_USAGE` | CÃ¢nd este `1`, afiÈ™eazÄƒ utilizarea token-urilor per completare | `1` |
| `RETRY_ON_FAIL` | CÃ¢nd este `1`, Ã®ncearcÄƒ din nou o datÄƒ Ã®n caz de erori temporare de chat | `1` |
| `RETRY_BACKOFF` | Secunde de aÈ™teptare Ã®nainte de a Ã®ncerca din nou | `1.0` |

DacÄƒ o variabilÄƒ nu este setatÄƒ, scripturile revin la setÄƒrile implicite. Pentru demonstraÈ›iile cu un singur model, de obicei aveÈ›i nevoie doar de `FOUNDRY_LOCAL_ALIAS`.

### Modul Utilitar

Toate exemplele Ã®mpÄƒrtÄƒÈ™esc acum un helper `samples/workshop_utils.py` care oferÄƒ:

* Crearea cache-ului `FoundryLocalManager` + client OpenAI
* Helper `chat_once()` cu opÈ›iuni de retry + afiÈ™are utilizare
* Raportare simplÄƒ a utilizÄƒrii token-urilor (activatÄƒ prin `SHOW_USAGE=1`)

Acest lucru reduce duplicarea È™i evidenÈ›iazÄƒ cele mai bune practici pentru orchestrarea eficientÄƒ a modelelor locale.

## ÃmbunÄƒtÄƒÈ›iri OpÈ›ionale (Ãntre Sesiuni)

| TemÄƒ | ÃmbunÄƒtÄƒÈ›ire | Sesiuni | Env / Toggle |
|------|--------------|---------|--------------|
| Determinism | TemperaturÄƒ fixÄƒ + seturi stabile de prompt-uri | 1â€“6 | Setare `temperature=0`, `top_p=1` |
| Vizibilitate Utilizare Token | Predare consistentÄƒ cost/eficienÈ›Äƒ | 1â€“6 | `SHOW_USAGE=1` |
| Streaming Primul Token | MetricÄƒ de latenÈ›Äƒ perceputÄƒ | 1,3,4,6 | `BENCH_STREAM=1` (benchmark) |
| RezilienÈ›Äƒ la Retry | Gestionarea pornirii reci temporare | Toate | `RETRY_ON_FAIL=1` + `RETRY_BACKOFF` |
| AgenÈ›i Multi-Model | Specializare pe roluri eterogene | 5 | `AGENT_MODEL_PRIMARY`, `AGENT_MODEL_EDITOR` |
| Rutare AdaptivÄƒ | IntenÈ›ie + euristici de cost | 6 | ExtindeÈ›i router-ul cu logicÄƒ de escaladare |
| Memorie VectorialÄƒ | Recapitulare semanticÄƒ pe termen lung | 2,5,6 | IntegraÈ›i indexul de embedding FAISS/Chroma |
| Export Traseu | Auditare & evaluare | 2,5,6 | AdÄƒugaÈ›i linii JSON per pas |
| Rubrici de Calitate | UrmÄƒrire calitativÄƒ | 3â€“6 | Prompt-uri secundare de evaluare |
| Teste de Fum | Validare rapidÄƒ Ã®nainte de workshop | Toate | `python Workshop/tests/smoke.py` |

### Start Rapid Determinist

```powershell
set FOUNDRY_LOCAL_ALIAS=phi-4-mini
set SHOW_USAGE=1
python Workshop\tests\smoke.py
```

AÈ™teptaÈ›i numÄƒr stabil de token-uri pentru intrÄƒri identice repetate.

### Evaluare RAG (Sesiunea 2)

UtilizaÈ›i `rag_eval_ragas.py` pentru a calcula relevanÈ›a rÄƒspunsului, fidelitatea È™i precizia contextului pe un set de date sintetic mic:

```powershell
cd Workshop/samples
python -m session02.rag_eval_ragas
```

ExtindeÈ›i prin furnizarea unui JSONL mai mare de Ã®ntrebÄƒri, contexte È™i adevÄƒruri de bazÄƒ, apoi convertiÈ›i-l Ã®ntr-un `Dataset` Hugging Face.

## AnexÄƒ Comenzi CLI Precise

Workshop-ul utilizeazÄƒ deliberat doar comenzi CLI Foundry Local documentate / stabile.

### Comenzi Stabile Referite

| Categorie | ComandÄƒ | Scop |
|-----------|---------|------|
| Core | `foundry --version` | AfiÈ™eazÄƒ versiunea instalatÄƒ |
| Core | `foundry init` | IniÈ›ializeazÄƒ configuraÈ›ia |
| Serviciu | `foundry service start` | PorneÈ™te serviciul local (dacÄƒ nu este auto) |
| Serviciu | `foundry status` | AfiÈ™eazÄƒ starea serviciului |
| Modele | `foundry model list` | ListeazÄƒ catalogul / modelele disponibile |
| Modele | `foundry model download <alias>` | DescarcÄƒ greutÄƒÈ›ile modelului Ã®n cache |
| Modele | `foundry model run <alias>` | LanseazÄƒ (Ã®ncarcÄƒ) un model local; combinÄƒ cu `--prompt` pentru o singurÄƒ execuÈ›ie |
| Modele | `foundry model unload <alias>` / `foundry model stop <alias>` | DezÃ®ncarcÄƒ un model din memorie (dacÄƒ este suportat) |
| Cache | `foundry cache list` | ListeazÄƒ modelele cache-ate (descÄƒrcate) |
| Sistem | `foundry system info` | Snapshot capacitÄƒÈ›i hardware & accelerare |
| Sistem | `foundry system gpu-info` | InformaÈ›ii de diagnosticare GPU |
| Config | `foundry config list` | AfiÈ™eazÄƒ valorile curente ale configuraÈ›iei |
| Config | `foundry config set <key> <value>` | ActualizeazÄƒ configuraÈ›ia |

### Model Prompt Pattern Oneâ€‘Shot

Ãn loc de subcomanda `model chat` depreciatÄƒ, utilizaÈ›i:

```powershell
foundry model run <alias> --prompt "Your question here"
```

Aceasta executÄƒ un ciclu prompt/rÄƒspuns unic È™i apoi se Ã®nchide.

### Modele / Pattern-uri Evitate

| Depreciat / Nondocumentat | Ãnlocuire / Ghidare |
|---------------------------|---------------------|
| `foundry model chat <model> "..."` | `foundry model run <model> --prompt "..."` |
| `foundry model list --running` | UtilizaÈ›i simplu `foundry model list` + activitate recentÄƒ / loguri |
| `foundry model list --cached` | `foundry cache list` |
| `foundry model stats <model>` | UtilizaÈ›i scriptul de benchmark Python + unelte OS (Task Manager / `nvidia-smi`) |
| `foundry model benchmark ...` | `samples/session03/benchmark_oss_models.py` |

### Benchmarking & Telemetrie

- LatenÈ›Äƒ, p95, token-uri/sec: `samples/session03/benchmark_oss_models.py`
- LatenÈ›Äƒ primului token (streaming): setaÈ›i `BENCH_STREAM=1`
- Utilizare resurse: monitoare OS (Task Manager, Activity Monitor, `nvidia-smi`) + `foundry system info`.

Pe mÄƒsurÄƒ ce noi comenzi CLI de telemetrie se stabilizeazÄƒ, acestea pot fi integrate cu modificÄƒri minime Ã®n markdown-urile sesiunii.

### GardÄƒ AutomatÄƒ de Lint

Un linter automat previne reintroducerea pattern-urilor CLI depreciate Ã®n interiorul blocurilor de cod ale fiÈ™ierelor markdown:

Script: `Workshop/scripts/lint_markdown_cli.py`

Pattern-urile depreciate sunt blocate Ã®n interiorul blocurilor de cod.

Ãnlocuiri recomandate:
| Depreciat | Ãnlocuire |
|-----------|-----------|
| `foundry model chat <a> "..."` | `foundry model run <a> --prompt "..."` |
| `model list --running` | `model list` |
| `model list --cached` | `cache list` |
| `model stats` | Script de benchmark + unelte de sistem |
| `model benchmark` | `samples/session03/benchmark_oss_models.py` |
| `model list --available` | `model list` |

RulaÈ›i local:
```powershell
python Workshop\scripts\lint_markdown_cli.py --verbose
```

GitHub Action: `.github/workflows/markdown-cli-lint.yml` ruleazÄƒ la fiecare push & PR.

Hook opÈ›ional pre-commit:
```bash
echo "python Workshop/scripts/lint_markdown_cli.py" > .git/hooks/pre-commit
chmod +x .git/hooks/pre-commit
```

## Tabel Rapid Migrare CLI â†’ SDK

| SarcinÄƒ | Linie UnicÄƒ CLI | Echivalent SDK (Python) | Note |
|---------|-----------------|--------------------------|------|
| RuleazÄƒ un model o datÄƒ (prompt) | `foundry model run phi-4-mini --prompt "Hello"` | `manager=FoundryLocalManager("phi-4-mini"); client=OpenAI(base_url=manager.endpoint, api_key=manager.api_key or "not-needed"); client.chat.completions.create(model=manager.get_model_info("phi-4-mini").id, messages=[{"role":"user","content":"Hello"}])` | SDK iniÈ›ializeazÄƒ serviciul & cache-ul automat |
| DescarcÄƒ (cache) model | `foundry model download qwen2.5-0.5b` | `FoundryLocalManager("qwen2.5-0.5b")  # triggers download/load` | Managerul alege cea mai bunÄƒ variantÄƒ dacÄƒ alias-ul se potriveÈ™te cu mai multe versiuni |
| ListeazÄƒ catalogul | `foundry model list` | `# use manager for each alias or maintain known list` | CLI agregÄƒ; SDK Ã®n prezent instanÈ›iere per-alias |
| ListeazÄƒ modelele cache-ate | `foundry cache list` | `manager.list_cached_models()` | DupÄƒ iniÈ›ializarea managerului (orice alias) |
| ActiveazÄƒ accelerarea GPU | `foundry config set compute.onnx.enable_gpu true` | `# CLI action; SDK assumes config already applied` | ConfiguraÈ›ia este efect extern |
| ObÈ›ine URL-ul endpoint-ului | (implicit) | `manager.endpoint` | Utilizat pentru a crea client compatibil OpenAI |
| ÃncÄƒlzeÈ™te un model | `foundry model run <alias>` apoi primul prompt | `chat_once(alias, messages=[...])` (utilitar) | Utilitarele gestioneazÄƒ Ã®ncÄƒlzirea iniÈ›ialÄƒ a latenÈ›ei reci |
| MÄƒsoarÄƒ latenÈ›a | `python -m session03.benchmark_oss_models` | `import benchmark_oss_models` (sau script nou de export) | Prefer scriptul pentru metrici consistente |
| OpreÈ™te / dezÃ®ncarcÄƒ modelul | `foundry model unload <alias>` | (Nu este expus â€“ reporniÈ›i serviciul / procesul) | De obicei, nu este necesar pentru fluxul workshop-ului |
| RecupereazÄƒ utilizarea token-urilor | (vizualizaÈ›i output-ul) | `resp.usage.total_tokens` | Furnizat dacÄƒ backend-ul returneazÄƒ obiectul de utilizare |

## Export Markdown Benchmark

UtilizaÈ›i scriptul `Workshop/scripts/export_benchmark_markdown.py` pentru a rula un benchmark proaspÄƒt (aceeaÈ™i logicÄƒ ca `samples/session03/benchmark_oss_models.py`) È™i a emite un tabel Markdown prietenos cu GitHub plus JSON brut.

### Exemplu

```powershell
python Workshop\scripts\export_benchmark_markdown.py --models "qwen2.5-0.5b,mistral-7b" --prompt "Explain retrieval augmented generation briefly." --rounds 3 --output benchmark_report.md
```

FiÈ™iere generate:
| FiÈ™ier | ConÈ›inut |
|--------|----------|
| `benchmark_report.md` | Tabel Markdown + indicaÈ›ii de interpretare |
| `benchmark_report.json` | Array de metrici brute (pentru comparare / urmÄƒrirea tendinÈ›elor) |

SetaÈ›i `BENCH_STREAM=1` Ã®n mediu pentru a include latenÈ›a primului token, dacÄƒ este suportatÄƒ.

---

**Declinare de responsabilitate**:  
Acest document a fost tradus folosind serviciul de traducere AI [Co-op Translator](https://github.com/Azure/co-op-translator). DeÈ™i ne strÄƒduim sÄƒ asigurÄƒm acurateÈ›ea, vÄƒ rugÄƒm sÄƒ fiÈ›i conÈ™tienÈ›i cÄƒ traducerile automate pot conÈ›ine erori sau inexactitÄƒÈ›i. Documentul original Ã®n limba sa natalÄƒ ar trebui considerat sursa autoritarÄƒ. Pentru informaÈ›ii critice, se recomandÄƒ traducerea profesionalÄƒ realizatÄƒ de oameni. Nu ne asumÄƒm responsabilitatea pentru neÃ®nÈ›elegerile sau interpretÄƒrile greÈ™ite care pot apÄƒrea din utilizarea acestei traduceri.