# Sesiunea 1: Ãnceputuri cu Foundry Local

## Rezumat

ÃnvaÈ›Äƒ sÄƒ instalezi, configurezi È™i sÄƒ rulezi primele modele AI folosind Microsoft Foundry Local. AceastÄƒ sesiune practicÄƒ oferÄƒ o introducere pas cu pas Ã®n inferenÈ›a localÄƒ, de la instalare pÃ¢nÄƒ la construirea primei aplicaÈ›ii de chat utilizÃ¢nd modele precum Phi-4, Qwen È™i DeepSeek.

## Obiective de Ã®nvÄƒÈ›are

PÃ¢nÄƒ la finalul acestei sesiuni, vei putea:

- **Instala È™i Configura**: Configura Foundry Local cu verificarea corectÄƒ a instalÄƒrii
- **StÄƒpÃ¢ni operaÈ›iunile CLI**: Utiliza CLI-ul Foundry Local pentru gestionarea È™i implementarea modelelor
- **Rula primul model**: Implementa È™i interacÈ›iona cu un model AI local
- **Construi o aplicaÈ›ie de chat**: Crea o aplicaÈ›ie de chat de bazÄƒ folosind Foundry Local Python SDK
- **ÃnÈ›elege AI local**: ÃnÈ›elege fundamentele inferenÈ›ei locale È™i gestionÄƒrii modelelor

## CerinÈ›e preliminare

### CerinÈ›e de sistem

- **Windows**: Windows 11 (22H2 sau mai recent) SAU **macOS**: macOS 11+ (suport limitat)
- **RAM**: Minimum 8GB, recomandat 16GB+
- **SpaÈ›iu de stocare**: Minimum 10GB liber pentru modele
- **Python**: InstalatÄƒ versiunea 3.10 sau mai recentÄƒ
- **Acces Administrator**: Privilegii de administrator pentru instalare

### Mediu de dezvoltare

- Visual Studio Code cu extensia Python (recomandat)
- Acces la linia de comandÄƒ (PowerShell pe Windows, Terminal pe macOS)
- Git pentru clonarea depozitelor (opÈ›ional)

## Fluxul atelierului (30 de minute)

### Pasul 1: Instalarea Foundry Local (5 minute)

#### Instalare pe Windows

InstaleazÄƒ Foundry Local folosind managerul de pachete Windows:

```powershell
# Install via winget (recommended)
winget install Microsoft.FoundryLocal
```

Alternativ: DescarcÄƒ direct de la [Microsoft Learn](https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/install)

#### Instalare pe macOS (Suport limitat)

> [!NOTE] 
> Suportul pentru macOS este Ã®n prezent Ã®n versiune de previzualizare. VerificÄƒ documentaÈ›ia oficialÄƒ pentru cele mai recente informaÈ›ii.

DacÄƒ este disponibil, instaleazÄƒ folosind Homebrew:

```bash
# If Homebrew formula is available
brew update
brew install foundry-local

# Or manual download (check official docs for latest)
curl -L -o foundry-local.tar.gz "https://download.microsoft.com/foundry-local/latest/macos/foundry-local.tar.gz"
tar -xzf foundry-local.tar.gz
sudo ./install.sh
```

**Alternativ pentru utilizatorii macOS:**
- FoloseÈ™te o maÈ™inÄƒ virtualÄƒ Windows 11 (Parallels/UTM) È™i urmeazÄƒ paÈ™ii pentru Windows
- RuleazÄƒ prin container, dacÄƒ este disponibil, È™i configureazÄƒ `FOUNDRY_LOCAL_ENDPOINT`

### Pasul 2: Verificarea instalÄƒrii (3 minute)

DupÄƒ instalare, reporneÈ™te terminalul È™i verificÄƒ funcÈ›ionarea Foundry Local:

```powershell
# Check if Foundry Local is installed correctly
foundry --version

# View available commands
foundry --help
```

Rezultatul aÈ™teptat ar trebui sÄƒ afiÈ™eze informaÈ›ii despre versiune È™i comenzi disponibile.

### Pasul 3: Configurarea mediului Python (5 minute)

CreeazÄƒ un mediu Python dedicat pentru acest atelier:

**Windows:**
```powershell
# Create virtual environment
py -m venv .venv

# Activate environment
.\.venv\Scripts\Activate.ps1

# Upgrade pip and install dependencies
python -m pip install --upgrade pip
pip install foundry-local-sdk openai
```

**macOS/Linux:**
```bash
# Create virtual environment
python3 -m venv .venv

# Activate environment
source .venv/bin/activate

# Upgrade pip and install dependencies
python -m pip install --upgrade pip
pip install foundry-local-sdk openai
```

### Pasul 4: RuleazÄƒ primul model (7 minute)

Acum sÄƒ rulÄƒm primul model AI local!

#### Ãncepe cu Phi-4 Mini (Modelul recomandat pentru Ã®nceput)

```powershell
# Download and start phi-4-mini (lightweight, fast)
foundry model run phi-4-mini

# Test the model with a simple prompt
foundry model run phi-4-mini --prompt "Hello, introduce yourself in one sentence"
```

> [!TIP]
> AceastÄƒ comandÄƒ descarcÄƒ modelul (prima datÄƒ) È™i porneÈ™te automat serviciul Foundry Local.

#### VerificÄƒ ce ruleazÄƒ

```powershell
# List available models (shows downloaded models)
foundry model list

# Check service status
foundry service status

# See what models are cached locally
foundry cache list
```

#### ÃncearcÄƒ modele diferite

DupÄƒ ce phi-4-mini funcÈ›ioneazÄƒ, experimenteazÄƒ cu alte modele:

```powershell
# Larger model with better capabilities
foundry model run gpt-oss-20b --prompt "Explain edge AI in simple terms"

# Fast, efficient model
foundry model run qwen2.5-0.5b --prompt "What are the benefits of local AI inference?"
```

### Pasul 5: ConstruieÈ™te prima aplicaÈ›ie de chat (10 minute)

Acum sÄƒ creÄƒm o aplicaÈ›ie Python care foloseÈ™te modelele pe care tocmai le-am pornit.

#### CreeazÄƒ scriptul de chat

CreeazÄƒ un fiÈ™ier nou numit `my_first_chat.py` (sau foloseÈ™te exemplul furnizat):

```python
#!/usr/bin/env python3
"""
My First Foundry Local Chat Application
Using FoundryLocalManager for automatic service management
"""

import os
from foundry_local import FoundryLocalManager
from openai import OpenAI

def main():
    # Get model alias from environment or use default
    alias = os.getenv("FOUNDRY_LOCAL_ALIAS", "phi-4-mini")
    
    try:
        # Initialize Foundry Local Manager (auto-starts service, downloads model)
        manager = FoundryLocalManager(alias)
        
        # Create OpenAI client pointing to local endpoint
        client = OpenAI(
            base_url=manager.endpoint,
            api_key=manager.api_key or "not-needed"
        )
        
        # Get the actual model ID for this alias
        model_id = manager.get_model_info(alias).id
        
        print("ğŸ¤– Welcome to your first local AI chat!")
        print(f"ï¿½ Using model: {alias} -> {model_id}")
        print(f"ğŸŒ Endpoint: {manager.endpoint}")
        print("ï¿½ğŸ’¡ Type 'quit' to exit\n")
        
    except Exception as e:
        print(f"âŒ Failed to initialize Foundry Local: {e}")
        print("ğŸ’¡ Make sure Foundry Local is installed: foundry --version")
        return
    
    while True:
        # Get user input
        user_message = input("You: ").strip()
        
        if user_message.lower() in ['quit', 'exit', 'bye']:
            print("ğŸ‘‹ Goodbye!")
            break
            
        if not user_message:
            continue
            
        try:
            # Send message to local AI model
            response = client.chat.completions.create(
                model=model_id,
                messages=[
                    {"role": "system", "content": "You are a helpful AI assistant running locally."},
                    {"role": "user", "content": user_message}
                ],
                max_tokens=200,
                temperature=0.7
            )
            
            # Display the response
            ai_response = response.choices[0].message.content
            print(f"ğŸ¤– AI: {ai_response}\n")
            
        except Exception as e:
            print(f"âŒ Error: {e}")
            print("ğŸ’¡ Check service status: foundry service status\n")

if __name__ == "__main__":
    main()
```

> [!TIP]
> **Exemple relevante**: Pentru utilizare avansatÄƒ, vezi:
>
> - **Exemplu Python**: `Workshop/samples/session01/chat_bootstrap.py` - Include rÄƒspunsuri Ã®n flux È™i gestionarea erorilor
> - **Jupyter Notebook**: `Workshop/notebooks/session01_chat_bootstrap.ipynb` - Versiune interactivÄƒ cu explicaÈ›ii detaliate

#### TesteazÄƒ aplicaÈ›ia de chat

```powershell
# No need to manually start models - FoundryLocalManager handles this!
# Just run your chat application
python my_first_chat.py
```

Alternativ: FoloseÈ™te direct exemplele furnizate

```powershell
# Try the complete sample with streaming support
cd Workshop/samples
python -m session01.chat_bootstrap "Your question here"
```

Sau exploreazÄƒ notebook-ul interactiv  
Deschide Workshop/notebooks/session01_chat_bootstrap.ipynb Ã®n VS Code

ÃncearcÄƒ aceste conversaÈ›ii exemplu:

- "Ce este Microsoft Foundry Local?"
- "ListeazÄƒ 3 beneficii ale rulÄƒrii modelelor AI local"
- "AjutÄƒ-mÄƒ sÄƒ Ã®nÈ›eleg AI-ul edge"

## Ce ai realizat

FelicitÄƒri! Ai reuÈ™it sÄƒ:

1. âœ… **Instalezi Foundry Local** È™i sÄƒ verifici funcÈ›ionarea acestuia
2. âœ… **PorneÈ™ti primul model AI** (phi-4-mini) local
3. âœ… **Testezi modele diferite** prin linia de comandÄƒ
4. âœ… **ConstruieÈ™ti o aplicaÈ›ie de chat** care se conecteazÄƒ la AI-ul local
5. âœ… **Experimentezi inferenÈ›a AI localÄƒ** fÄƒrÄƒ dependenÈ›e de cloud

## ÃnÈ›elegerea procesului

### InferenÈ›a AI localÄƒ

- Modelele AI ruleazÄƒ complet pe computerul tÄƒu
- Nicio datÄƒ nu este trimisÄƒ Ã®n cloud
- RÄƒspunsurile sunt generate local folosind CPU/GPU-ul tÄƒu
- ConfidenÈ›ialitatea È™i securitatea sunt menÈ›inute

### Gestionarea modelelor

- `foundry model run` descarcÄƒ È™i porneÈ™te modelele
- **FoundryLocalManager SDK** gestioneazÄƒ automat pornirea serviciului È™i Ã®ncÄƒrcarea modelelor
- Modelele sunt stocate local pentru utilizÄƒri viitoare
- Pot fi descÄƒrcate mai multe modele, dar de obicei ruleazÄƒ unul singur la un moment dat
- Serviciul gestioneazÄƒ automat ciclul de viaÈ›Äƒ al modelului

### AbordÄƒri SDK vs CLI

- **Abordarea CLI**: Gestionarea manualÄƒ a modelelor cu `foundry model run <model>`
- **Abordarea SDK**: Gestionarea automatÄƒ a serviciului È™i a modelelor cu `FoundryLocalManager(alias)`
- **Recomandare**: FoloseÈ™te SDK pentru aplicaÈ›ii, CLI pentru testare È™i explorare

## ReferinÈ›Äƒ comenzi comune

### Comenzi esenÈ›iale CLI

```powershell
# Installation & Setup
foundry --version              # Check installation
foundry --help                 # View all commands

# Model Management
foundry model list             # List available models
foundry model run <model>      # Download and start a model
foundry model run <model> --prompt "text"  # One-shot prompt
foundry cache list             # Show downloaded models

# Service Management
foundry service status         # Check if service is running
foundry service start          # Start the service manually
foundry service stop           # Stop the service
```

### RecomandÄƒri pentru modele

- **phi-4-mini**: Cel mai bun model pentru Ã®nceput - rapid, uÈ™or, calitate bunÄƒ
- **qwen2.5-0.5b**: InferenÈ›Äƒ rapidÄƒ, consum minim de memorie
- **gpt-oss-20b**: RÄƒspunsuri de calitate superioarÄƒ, necesitÄƒ mai multe resurse
- **deepseek-coder-1.3b**: Optimizat pentru sarcini de programare È™i codare

## Depanare

### "Comanda Foundry nu a fost gÄƒsitÄƒ"

**SoluÈ›ie:**

```powershell
# Restart your terminal after installation
# Or manually add to PATH (Windows)
$env:PATH += ";C:\Program Files\Microsoft\FoundryLocal"
```

### "Modelul nu a putut fi Ã®ncÄƒrcat"

**SoluÈ›ie:**

```powershell
# Check available system memory
foundry service status

# Try a smaller model first
foundry model run phi-4-mini

# Check disk space for model downloads
# Models are stored in: %USERPROFILE%\.foundry\models (Windows)
```

### "Conexiune refuzatÄƒ pe localhost"

**SoluÈ›ie:**

```powershell
# Check if service is running
foundry service status

# Start service if needed
foundry service start

# Verify the port (default is 5273)
# Check for port conflicts with: netstat -an | findstr 5273
```

## PaÈ™i urmÄƒtori

### AcÈ›iuni imediate

1. **ExperimenteazÄƒ** cu modele È™i solicitÄƒri diferite
2. **ModificÄƒ** aplicaÈ›ia de chat pentru a Ã®ncerca modele diferite
3. **CreeazÄƒ** propriile tale solicitÄƒri È™i testeazÄƒ rÄƒspunsurile
4. **ExploreazÄƒ** Sesiunea 2: Construirea aplicaÈ›iilor RAG

### Cale de Ã®nvÄƒÈ›are avansatÄƒ

1. **Sesiunea 2**: ConstruieÈ™te soluÈ›ii AI cu RAG (Generare AugmentatÄƒ prin Recuperare)
2. **Sesiunea 3**: ComparÄƒ diferite modele open-source
3. **Sesiunea 4**: LucreazÄƒ cu modele de ultimÄƒ generaÈ›ie
4. **Sesiunea 5**: ConstruieÈ™te sisteme AI multi-agent

## Variabile de mediu (OpÈ›ional)

Pentru utilizare avansatÄƒ, poÈ›i seta aceste variabile de mediu:

| VariabilÄƒ | Scop | Exemplu |
|----------|---------|---------|
| `FOUNDRY_LOCAL_ALIAS` | Modelul implicit de utilizat | `phi-4-mini` |
| `FOUNDRY_LOCAL_ENDPOINT` | Suprascrie URL-ul endpoint-ului | `http://localhost:5273/v1` |

CreeazÄƒ un fiÈ™ier `.env` Ã®n directorul proiectului:
```
FOUNDRY_LOCAL_ALIAS=phi-4-mini
FOUNDRY_LOCAL_ENDPOINT=auto
```

## Resurse suplimentare

### DocumentaÈ›ie

- [ReferinÈ›Äƒ Foundry Local Python SDK](https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/reference/reference-sdk?pivots=programming-language-python)
- [Ghid de instalare Foundry Local](https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/install)
- [Catalogul de modele](https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/models)

### Cod exemplu

- **Exemplu Python Sesiunea01**: `Workshop/samples/session01/chat_bootstrap.py` - AplicaÈ›ie completÄƒ de chat cu streaming
- **Notebook Sesiunea01**: `Workshop/notebooks/session01_chat_bootstrap.ipynb` - Tutorial interactiv  
- [Exemplu Modul08 01](../Module08/samples/01/README.md) - Introducere rapidÄƒ Ã®n REST Chat
- [Exemplu Modul08 02](../Module08/samples/02/README.md) - Integrare OpenAI SDK
- [Exemplu Modul08 03](../Module08/samples/03/README.md) - Descoperirea È™i evaluarea modelelor

### Comunitate

- [DiscuÈ›ii GitHub Foundry Local](https://github.com/microsoft/Foundry-Local/discussions)
- [Comunitatea Azure AI](https://techcommunity.microsoft.com/category/artificialintelligence)

---

**Durata sesiunii**: 30 de minute practicÄƒ + 15 minute Ã®ntrebÄƒri È™i rÄƒspunsuri  
**Nivel de dificultate**: ÃncepÄƒtor  
**CerinÈ›e preliminare**: Windows 11/macOS 11+, Python 3.10+, Acces administrator

## Scenariu exemplu pentru atelier

### Context real

**Scenariu**: O echipÄƒ IT dintr-o companie trebuie sÄƒ evalueze inferenÈ›a AI pe dispozitiv pentru procesarea feedback-ului sensibil al angajaÈ›ilor fÄƒrÄƒ a trimite date cÄƒtre servicii externe.

**Obiectivul tÄƒu**: DemonstreazÄƒ cÄƒ modelele AI locale pot oferi rÄƒspunsuri de calitate cu o latenÈ›Äƒ sub o secundÄƒ, menÈ›inÃ¢nd Ã®n acelaÈ™i timp confidenÈ›ialitatea completÄƒ a datelor.

### SolicitÄƒri de testare

FoloseÈ™te aceste solicitÄƒri pentru a valida configurarea:

```json
[
    "List two benefits of local inference.",
    "Summarize why keeping data on device improves privacy.",
    "Give one trade-off when choosing a small model over a large model."
]
```

### Criterii de succes

- âœ… Toate solicitÄƒrile primesc rÄƒspunsuri Ã®n mai puÈ›in de 2 secunde
- âœ… Nicio datÄƒ nu pÄƒrÄƒseÈ™te computerul local
- âœ… RÄƒspunsurile sunt relevante È™i utile
- âœ… AplicaÈ›ia ta de chat funcÈ›ioneazÄƒ fÄƒrÄƒ probleme

AceastÄƒ validare asigurÄƒ cÄƒ configurarea ta Foundry Local este pregÄƒtitÄƒ pentru atelierele avansate din Sesiunile 2-6.

---

<!-- CO-OP TRANSLATOR DISCLAIMER START -->
**Declinare de responsabilitate**:  
Acest document a fost tradus folosind serviciul de traducere AI [Co-op Translator](https://github.com/Azure/co-op-translator). DeÈ™i ne strÄƒduim sÄƒ asigurÄƒm acurateÈ›ea, vÄƒ rugÄƒm sÄƒ fiÈ›i conÈ™tienÈ›i cÄƒ traducerile automate pot conÈ›ine erori sau inexactitÄƒÈ›i. Documentul original Ã®n limba sa maternÄƒ ar trebui considerat sursa autoritarÄƒ. Pentru informaÈ›ii critice, se recomandÄƒ traducerea profesionalÄƒ realizatÄƒ de oameni. Nu ne asumÄƒm responsabilitatea pentru neÃ®nÈ›elegerile sau interpretÄƒrile greÈ™ite care pot apÄƒrea din utilizarea acestei traduceri.
<!-- CO-OP TRANSLATOR DISCLAIMER END -->